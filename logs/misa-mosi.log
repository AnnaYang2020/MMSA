2021-01-27 00:32:25:INFO:Start running misa...
2021-01-27 00:32:25:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1111}>
2021-01-27 00:32:25:INFO:Let's use 1 GPUs!
2021-01-27 00:32:26:INFO:train samples: (1284,)
2021-01-27 00:32:26:INFO:valid samples: (229,)
2021-01-27 00:32:27:INFO:test samples: (686,)
2021-01-27 00:32:27:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:32:27:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:32:27:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:32:27:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:32:27:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:32:27:INFO:loading file None
2021-01-27 00:32:27:INFO:loading file None
2021-01-27 00:32:27:INFO:loading file None
2021-01-27 00:32:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:32:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:32:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:32:34:INFO:The model has 110620273 trainable parameters
2021-01-27 00:32:44:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.3140  Has0_acc_2: 0.6308  Has0_F1_score: 0.6489  Non0_acc_2: 0.6239  Non0_F1_score: 0.6424  Mult_acc_5: 0.2134  Mult_acc_7: 0.2126  MAE: 1.2070  Corr: 0.3669 
2021-01-27 00:32:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8146  Non0_acc_2: 0.8333  Non0_F1_score: 0.8367  Mult_acc_5: 0.3930  Mult_acc_7: 0.3188  MAE: 1.0453  Corr: 0.6607  Loss: 1.8356 
2021-01-27 00:32:54:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5892  Has0_acc_2: 0.8232  Has0_F1_score: 0.8224  Non0_acc_2: 0.8432  Non0_F1_score: 0.8429  Mult_acc_5: 0.3847  Mult_acc_7: 0.3676  MAE: 0.7930  Corr: 0.7499 
2021-01-27 00:32:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7761  Non0_acc_2: 0.7731  Non0_F1_score: 0.7815  Mult_acc_5: 0.4236  Mult_acc_7: 0.3493  MAE: 0.9118  Corr: 0.7495  Loss: 1.3924 
2021-01-27 00:32:58:INFO:Start running misa...
2021-01-27 00:32:58:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1111}>
2021-01-27 00:32:58:INFO:Let's use 1 GPUs!
2021-01-27 00:32:59:INFO:train samples: (1284,)
2021-01-27 00:32:59:INFO:valid samples: (229,)
2021-01-27 00:33:00:INFO:test samples: (686,)
2021-01-27 00:33:00:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:33:00:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:33:00:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:33:00:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:33:00:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:33:00:INFO:loading file None
2021-01-27 00:33:00:INFO:loading file None
2021-01-27 00:33:00:INFO:loading file None
2021-01-27 00:33:00:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:33:00:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:33:00:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:33:06:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.6610  Has0_acc_2: 0.8606  Has0_F1_score: 0.8601  Non0_acc_2: 0.8814  Non0_F1_score: 0.8814  Mult_acc_5: 0.5195  Mult_acc_7: 0.4805  MAE: 0.6168  Corr: 0.8530 
2021-01-27 00:33:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8186  Non0_acc_2: 0.8333  Non0_F1_score: 0.8362  Mult_acc_5: 0.4498  Mult_acc_7: 0.3624  MAE: 0.8179  Corr: 0.7762  Loss: 1.1494 
2021-01-27 00:33:07:INFO:The model has 110621043 trainable parameters
2021-01-27 00:33:17:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.0961  Has0_acc_2: 0.5537  Has0_F1_score: 0.5655  Non0_acc_2: 0.1706  Non0_F1_score: 0.1456  Acc_3: 0.5343  F1_score_3: 0.5558 
2021-01-27 00:33:17:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.1175  Has0_acc_2: 0.8902  Has0_F1_score: 0.8900  Non0_acc_2: 0.9058  Non0_F1_score: 0.9059  Mult_acc_5: 0.5779  Mult_acc_7: 0.5249  MAE: 0.5249  Corr: 0.8985 
2021-01-27 00:33:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6550  Has0_F1_score: 0.6916  Non0_acc_2: 0.1574  Non0_F1_score: 0.1003  Acc_3: 0.6507  F1_score_3: 0.6974  Loss: 0.7992 
2021-01-27 00:33:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7842  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4672  Mult_acc_7: 0.3712  MAE: 0.8392  Corr: 0.7544  Loss: 1.3621 
2021-01-27 00:33:28:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.8909  Has0_acc_2: 0.8855  Has0_F1_score: 0.8851  Non0_acc_2: 0.9058  Non0_F1_score: 0.9056  Mult_acc_5: 0.6036  Mult_acc_7: 0.5623  MAE: 0.4864  Corr: 0.9141 
2021-01-27 00:33:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7939  Non0_acc_2: 0.7870  Non0_F1_score: 0.7953  Mult_acc_5: 0.4017  Mult_acc_7: 0.2969  MAE: 0.9427  Corr: 0.7741  Loss: 1.4849 
2021-01-27 00:33:28:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.0588  Has0_acc_2: 0.7399  Has0_F1_score: 0.7453  Non0_acc_2: 0.2794  Non0_F1_score: 0.2466  Acc_3: 0.7251  F1_score_3: 0.7447 
2021-01-27 00:33:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7637  Non0_acc_2: 0.2269  Non0_F1_score: 0.1678  Acc_3: 0.7336  F1_score_3: 0.7676  Loss: 0.6671 
2021-01-27 00:33:38:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.7376  Has0_acc_2: 0.9089  Has0_F1_score: 0.9087  Non0_acc_2: 0.9261  Non0_F1_score: 0.9261  Mult_acc_5: 0.6176  Mult_acc_7: 0.5584  MAE: 0.4622  Corr: 0.9244 
2021-01-27 00:33:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8025  Non0_acc_2: 0.8241  Non0_F1_score: 0.8241  Mult_acc_5: 0.4934  Mult_acc_7: 0.4017  MAE: 0.7835  Corr: 0.7677  Loss: 1.1625 
2021-01-27 00:33:40:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.2448  Has0_acc_2: 0.9260  Has0_F1_score: 0.9262  Non0_acc_2: 0.4135  Non0_F1_score: 0.4089  Acc_3: 0.9011  F1_score_3: 0.9201 
2021-01-27 00:33:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.3704  Non0_F1_score: 0.3948  Acc_3: 0.7817  F1_score_3: 0.8023  Loss: 0.6161 
2021-01-27 00:33:49:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.5432  Has0_acc_2: 0.9307  Has0_F1_score: 0.9306  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.6846  Mult_acc_7: 0.6184  MAE: 0.3809  Corr: 0.9476 
2021-01-27 00:33:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8130  Non0_acc_2: 0.8056  Non0_F1_score: 0.8108  Mult_acc_5: 0.4585  Mult_acc_7: 0.3450  MAE: 0.8500  Corr: 0.7682  Loss: 1.3739 
2021-01-27 00:33:52:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.7902  Has0_acc_2: 0.9486  Has0_F1_score: 0.9486  Non0_acc_2: 0.4330  Non0_F1_score: 0.4357  Acc_3: 0.9237  F1_score_3: 0.9430 
2021-01-27 00:33:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7757  Non0_acc_2: 0.2639  Non0_F1_score: 0.2243  Acc_3: 0.7424  F1_score_3: 0.7702  Loss: 0.9607 
2021-01-27 00:33:59:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.4988  Has0_acc_2: 0.9237  Has0_F1_score: 0.9235  Non0_acc_2: 0.9407  Non0_F1_score: 0.9407  Mult_acc_5: 0.6947  Mult_acc_7: 0.6363  MAE: 0.3787  Corr: 0.9490 
2021-01-27 00:34:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8340  Non0_acc_2: 0.8287  Non0_F1_score: 0.8331  Mult_acc_5: 0.4585  Mult_acc_7: 0.3319  MAE: 0.8958  Corr: 0.7652  Loss: 1.3974 
2021-01-27 00:34:02:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.6320  Has0_acc_2: 0.9525  Has0_F1_score: 0.9526  Non0_acc_2: 0.4330  Non0_F1_score: 0.4314  Acc_3: 0.9322  F1_score_3: 0.9519 
2021-01-27 00:34:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8165  Non0_acc_2: 0.3519  Non0_F1_score: 0.3630  Acc_3: 0.7773  F1_score_3: 0.7987  Loss: 0.9003 
2021-01-27 00:34:09:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4742  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9513  Non0_F1_score: 0.9513  Mult_acc_5: 0.6799  Mult_acc_7: 0.6246  MAE: 0.3885  Corr: 0.9474 
2021-01-27 00:34:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8241  Non0_F1_score: 0.8235  Mult_acc_5: 0.4891  Mult_acc_7: 0.4017  MAE: 0.7603  Corr: 0.7857  Loss: 1.1222 
2021-01-27 00:34:12:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.5255  Has0_acc_2: 0.9673  Has0_F1_score: 0.9673  Non0_acc_2: 0.4411  Non0_F1_score: 0.4419  Acc_3: 0.9431  F1_score_3: 0.9630 
2021-01-27 00:34:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8207  Non0_acc_2: 0.3750  Non0_F1_score: 0.4050  Acc_3: 0.7773  F1_score_3: 0.7977  Loss: 1.0354 
2021-01-27 00:34:21:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.3757  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9578  Non0_F1_score: 0.9577  Mult_acc_5: 0.7609  Mult_acc_7: 0.7103  MAE: 0.3166  Corr: 0.9643 
2021-01-27 00:34:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8182  Non0_acc_2: 0.8287  Non0_F1_score: 0.8309  Mult_acc_5: 0.4760  Mult_acc_7: 0.3755  MAE: 0.7822  Corr: 0.7859  Loss: 1.0873 
2021-01-27 00:34:23:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.5078  Has0_acc_2: 0.9533  Has0_F1_score: 0.9533  Non0_acc_2: 0.4330  Non0_F1_score: 0.4334  Acc_3: 0.9283  F1_score_3: 0.9478 
2021-01-27 00:34:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.4978  Has0_F1_score: 0.6261  Non0_acc_2: 0.4259  Non0_F1_score: 0.5897  Acc_3: 0.4410  F1_score_3: 0.5719  Loss: 2.2725 
2021-01-27 00:34:33:INFO:TRAIN-(misa) (1/11/1)>> loss: 0.3539  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9553  Non0_F1_score: 0.9554  Mult_acc_5: 0.7422  Mult_acc_7: 0.6830  MAE: 0.3163  Corr: 0.9647 
2021-01-27 00:34:33:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.6011  Has0_acc_2: 0.9112  Has0_F1_score: 0.9112  Non0_acc_2: 0.4143  Non0_F1_score: 0.4195  Acc_3: 0.8832  F1_score_3: 0.9004 
2021-01-27 00:34:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8128  Non0_acc_2: 0.8287  Non0_F1_score: 0.8301  Mult_acc_5: 0.4672  Mult_acc_7: 0.3755  MAE: 0.8077  Corr: 0.7719  Loss: 1.1995 
2021-01-27 00:34:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7502  Non0_acc_2: 0.3889  Non0_F1_score: 0.4583  Acc_3: 0.6987  F1_score_3: 0.7182  Loss: 1.0425 
2021-01-27 00:34:43:INFO:TRAIN-(misa) (2/12/1)>> loss: 0.3253  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7671  Mult_acc_7: 0.7087  MAE: 0.3051  Corr: 0.9670 
2021-01-27 00:34:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7795  Non0_acc_2: 0.8102  Non0_F1_score: 0.8091  Mult_acc_5: 0.4585  Mult_acc_7: 0.3624  MAE: 0.8125  Corr: 0.7786  Loss: 1.3235 
2021-01-27 00:34:44:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4047  Has0_acc_2: 0.9595  Has0_F1_score: 0.9595  Non0_acc_2: 0.4395  Non0_F1_score: 0.4426  Acc_3: 0.9361  F1_score_3: 0.9547 
2021-01-27 00:34:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8209  Non0_acc_2: 0.3565  Non0_F1_score: 0.3677  Acc_3: 0.7860  F1_score_3: 0.8064  Loss: 0.8805 
2021-01-27 00:34:54:INFO:TRAIN-(misa) (3/13/1)>> loss: 0.3450  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7414  Mult_acc_7: 0.6752  MAE: 0.3345  Corr: 0.9610 
2021-01-27 00:34:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7982  Non0_acc_2: 0.8194  Non0_F1_score: 0.8196  Mult_acc_5: 0.5022  Mult_acc_7: 0.4148  MAE: 0.7635  Corr: 0.7791  Loss: 1.0439 
2021-01-27 00:34:55:INFO:TRAIN-(misa) (7/10/1)>> loss: 0.2726  Has0_acc_2: 0.9836  Has0_F1_score: 0.9837  Non0_acc_2: 0.4468  Non0_F1_score: 0.4472  Acc_3: 0.9766  F1_score_3: 0.9795 
2021-01-27 00:34:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8167  Non0_acc_2: 0.3519  Non0_F1_score: 0.3593  Acc_3: 0.7817  F1_score_3: 0.7948  Loss: 0.8932 
2021-01-27 00:35:06:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2894  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9586  Non0_F1_score: 0.9585  Mult_acc_5: 0.7656  Mult_acc_7: 0.7126  MAE: 0.2819  Corr: 0.9720 
2021-01-27 00:35:06:INFO:TRAIN-(misa) (8/11/1)>> loss: 0.2260  Has0_acc_2: 0.9774  Has0_F1_score: 0.9774  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9883  F1_score_3: 0.9888 
2021-01-27 00:35:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8227  Non0_acc_2: 0.8287  Non0_F1_score: 0.8309  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.8139  Corr: 0.7791  Loss: 1.1774 
2021-01-27 00:35:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8034  Non0_acc_2: 0.3519  Non0_F1_score: 0.3647  Acc_3: 0.7511  F1_score_3: 0.7379  Loss: 1.1231 
2021-01-27 00:35:08:INFO:TEST-(misa) >>  Has0_acc_2: 0.8397  Has0_F1_score: 0.8410  Non0_acc_2: 0.5259  Non0_F1_score: 0.5479  Acc_3: 0.8090  F1_score_3: 0.8286  Loss: 0.5768 
2021-01-27 00:35:08:INFO:Start running misa...
2021-01-27 00:35:08:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1112}>
2021-01-27 00:35:08:INFO:Let's use 1 GPUs!
2021-01-27 00:35:09:INFO:train samples: (1284,)
2021-01-27 00:35:09:INFO:valid samples: (229,)
2021-01-27 00:35:09:INFO:test samples: (686,)
2021-01-27 00:35:09:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:35:09:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:35:09:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:35:09:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:35:09:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:35:09:INFO:loading file None
2021-01-27 00:35:09:INFO:loading file None
2021-01-27 00:35:09:INFO:loading file None
2021-01-27 00:35:09:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:35:09:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:35:09:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:35:13:INFO:The model has 110621043 trainable parameters
2021-01-27 00:35:17:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2880  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9569  Non0_F1_score: 0.9569  Mult_acc_5: 0.7609  Mult_acc_7: 0.7072  MAE: 0.2990  Corr: 0.9685 
2021-01-27 00:35:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7897  Non0_acc_2: 0.8102  Non0_F1_score: 0.8106  Mult_acc_5: 0.4541  Mult_acc_7: 0.3712  MAE: 0.7760  Corr: 0.7764  Loss: 1.0722 
2021-01-27 00:35:23:INFO:TRAIN-(misa) (1/1/2)>> loss: 3.0552  Has0_acc_2: 0.5436  Has0_F1_score: 0.5587  Non0_acc_2: 0.1625  Non0_F1_score: 0.1357  Acc_3: 0.5210  F1_score_3: 0.5400 
2021-01-27 00:35:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.6856  Has0_F1_score: 0.6897  Non0_acc_2: 0.2593  Non0_F1_score: 0.2459  Acc_3: 0.6681  F1_score_3: 0.6900  Loss: 0.8602 
2021-01-27 00:35:27:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2585  Has0_acc_2: 0.9455  Has0_F1_score: 0.9453  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7773  Mult_acc_7: 0.7204  MAE: 0.2734  Corr: 0.9735 
2021-01-27 00:35:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7883  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4454  Mult_acc_7: 0.3537  MAE: 0.8087  Corr: 0.7755  Loss: 1.1731 
2021-01-27 00:35:35:INFO:TRAIN-(misa) (1/2/2)>> loss: 2.2037  Has0_acc_2: 0.5436  Has0_F1_score: 0.5635  Non0_acc_2: 0.1462  Non0_F1_score: 0.1154  Acc_3: 0.5288  F1_score_3: 0.5582 
2021-01-27 00:35:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.4847  Has0_F1_score: 0.6015  Non0_acc_2: 0.4074  Non0_F1_score: 0.5598  Acc_3: 0.4279  F1_score_3: 0.5471  Loss: 0.8690 
2021-01-27 00:35:38:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.2768  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7445  Mult_acc_7: 0.6916  MAE: 0.3065  Corr: 0.9675 
2021-01-27 00:35:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8112  Non0_acc_2: 0.8333  Non0_F1_score: 0.8333  Mult_acc_5: 0.5022  Mult_acc_7: 0.3843  MAE: 0.7649  Corr: 0.7790  Loss: 1.0515 
2021-01-27 00:35:45:INFO:TRAIN-(misa) (2/3/2)>> loss: 1.6458  Has0_acc_2: 0.5319  Has0_F1_score: 0.5410  Non0_acc_2: 0.1722  Non0_F1_score: 0.1530  Acc_3: 0.5156  F1_score_3: 0.5343 
2021-01-27 00:35:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.5939  Has0_F1_score: 0.6342  Non0_acc_2: 0.1250  Non0_F1_score: 0.0809  Acc_3: 0.5852  F1_score_3: 0.6356  Loss: 0.8700 
2021-01-27 00:35:48:INFO:TRAIN-(misa) (5/18/1)>> loss: 0.2446  Has0_acc_2: 0.9361  Has0_F1_score: 0.9359  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7687  Mult_acc_7: 0.7134  MAE: 0.2743  Corr: 0.9740 
2021-01-27 00:35:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8318  Non0_acc_2: 0.8380  Non0_F1_score: 0.8405  Mult_acc_5: 0.5066  Mult_acc_7: 0.3886  MAE: 0.8309  Corr: 0.7918  Loss: 1.2260 
2021-01-27 00:35:56:INFO:TRAIN-(misa) (3/4/2)>> loss: 1.3147  Has0_acc_2: 0.5405  Has0_F1_score: 0.5684  Non0_acc_2: 0.1332  Non0_F1_score: 0.0986  Acc_3: 0.5319  F1_score_3: 0.5677 
2021-01-27 00:35:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8450 
2021-01-27 00:35:59:INFO:TRAIN-(misa) (6/19/1)>> loss: 0.2378  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7921  Mult_acc_7: 0.7360  MAE: 0.2765  Corr: 0.9732 
2021-01-27 00:36:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.7399  Corr: 0.7919  Loss: 1.0194 
2021-01-27 00:36:08:INFO:TRAIN-(misa) (1/5/2)>> loss: 1.1851  Has0_acc_2: 0.5639  Has0_F1_score: 0.5900  Non0_acc_2: 0.1454  Non0_F1_score: 0.1078  Acc_3: 0.5545  F1_score_3: 0.5892 
2021-01-27 00:36:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6243  Non0_acc_2: 0.1806  Non0_F1_score: 0.1495  Acc_3: 0.5983  F1_score_3: 0.6283  Loss: 0.8645 
2021-01-27 00:36:11:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.2380  Has0_acc_2: 0.9455  Has0_F1_score: 0.9453  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7687  Mult_acc_7: 0.7142  MAE: 0.2788  Corr: 0.9728 
2021-01-27 00:36:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8064  Non0_acc_2: 0.8287  Non0_F1_score: 0.8282  Mult_acc_5: 0.4760  Mult_acc_7: 0.3930  MAE: 0.7696  Corr: 0.7877  Loss: 1.1318 
2021-01-27 00:36:19:INFO:TRAIN-(misa) (2/6/2)>> loss: 1.1021  Has0_acc_2: 0.5421  Has0_F1_score: 0.5727  Non0_acc_2: 0.1267  Non0_F1_score: 0.0908  Acc_3: 0.5319  F1_score_3: 0.5708 
2021-01-27 00:36:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8571 
2021-01-27 00:36:22:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.2441  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7734  Mult_acc_7: 0.7204  MAE: 0.2812  Corr: 0.9721 
2021-01-27 00:36:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8064  Non0_acc_2: 0.8333  Non0_F1_score: 0.8329  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7576  Corr: 0.7826  Loss: 1.1434 
2021-01-27 00:36:29:INFO:TRAIN-(misa) (3/7/2)>> loss: 1.0713  Has0_acc_2: 0.5631  Has0_F1_score: 0.5832  Non0_acc_2: 0.1568  Non0_F1_score: 0.1231  Acc_3: 0.5514  F1_score_3: 0.5809 
2021-01-27 00:36:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5459  Has0_F1_score: 0.7016  Non0_acc_2: 0.0046  Non0_F1_score: 0.0001  Acc_3: 0.5459  F1_score_3: 0.7016  Loss: 0.8484 
2021-01-27 00:36:33:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.2013  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9708  Non0_F1_score: 0.9707  Mult_acc_5: 0.8193  Mult_acc_7: 0.7757  MAE: 0.2378  Corr: 0.9800 
2021-01-27 00:36:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8030  Non0_acc_2: 0.8241  Non0_F1_score: 0.8246  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7405  Corr: 0.7909  Loss: 1.0310 
2021-01-27 00:36:40:INFO:TRAIN-(misa) (4/8/2)>> loss: 1.0512  Has0_acc_2: 0.5615  Has0_F1_score: 0.5837  Non0_acc_2: 0.1535  Non0_F1_score: 0.1187  Acc_3: 0.5522  F1_score_3: 0.5831 
2021-01-27 00:36:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5197  Has0_F1_score: 0.5274  Non0_acc_2: 0.2963  Non0_F1_score: 0.3566  Acc_3: 0.4934  F1_score_3: 0.5148  Loss: 0.8655 
2021-01-27 00:36:44:INFO:TRAIN-(misa) (4/23/1)>> loss: 0.1951  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7952  Mult_acc_7: 0.7516  MAE: 0.2356  Corr: 0.9808 
2021-01-27 00:36:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8414  Non0_acc_2: 0.8426  Non0_F1_score: 0.8458  Mult_acc_5: 0.4760  Mult_acc_7: 0.3624  MAE: 0.8360  Corr: 0.7871  Loss: 1.2921 
2021-01-27 00:36:51:INFO:TRAIN-(misa) (5/9/2)>> loss: 1.0117  Has0_acc_2: 0.5631  Has0_F1_score: 0.6030  Non0_acc_2: 0.1210  Non0_F1_score: 0.0781  Acc_3: 0.5561  F1_score_3: 0.6033 
2021-01-27 00:36:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8641 
2021-01-27 00:36:55:INFO:TRAIN-(misa) (5/24/1)>> loss: 0.2631  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9634  Non0_F1_score: 0.9634  Mult_acc_5: 0.7617  Mult_acc_7: 0.7072  MAE: 0.2887  Corr: 0.9709 
2021-01-27 00:36:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8203  Non0_acc_2: 0.8148  Non0_F1_score: 0.8186  Mult_acc_5: 0.5153  Mult_acc_7: 0.4148  MAE: 0.7713  Corr: 0.7887  Loss: 1.1655 
2021-01-27 00:37:01:INFO:TRAIN-(misa) (6/10/2)>> loss: 1.0110  Has0_acc_2: 0.5319  Has0_F1_score: 0.5574  Non0_acc_2: 0.1365  Non0_F1_score: 0.1042  Acc_3: 0.5249  F1_score_3: 0.5579 
2021-01-27 00:37:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8623 
2021-01-27 00:37:06:INFO:TRAIN-(misa) (6/25/1)>> loss: 0.2762  Has0_acc_2: 0.9416  Has0_F1_score: 0.9415  Non0_acc_2: 0.9545  Non0_F1_score: 0.9546  Mult_acc_5: 0.7399  Mult_acc_7: 0.6822  MAE: 0.3151  Corr: 0.9653 
2021-01-27 00:37:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8194  Non0_F1_score: 0.8188  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.7656  Corr: 0.7916  Loss: 1.0994 
2021-01-27 00:37:12:INFO:TRAIN-(misa) (7/11/2)>> loss: 0.9785  Has0_acc_2: 0.5701  Has0_F1_score: 0.6051  Non0_acc_2: 0.1340  Non0_F1_score: 0.0911  Acc_3: 0.5646  F1_score_3: 0.6068 
2021-01-27 00:37:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5852  Has0_F1_score: 0.6415  Non0_acc_2: 0.1065  Non0_F1_score: 0.0599  Acc_3: 0.5852  F1_score_3: 0.6467  Loss: 0.8610 
2021-01-27 00:37:17:INFO:TRAIN-(misa) (7/26/1)>> loss: 0.2076  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9643  Non0_F1_score: 0.9642  Mult_acc_5: 0.7928  Mult_acc_7: 0.7422  MAE: 0.2546  Corr: 0.9772 
2021-01-27 00:37:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4803  Mult_acc_7: 0.3974  MAE: 0.7543  Corr: 0.7951  Loss: 1.0108 
2021-01-27 00:37:23:INFO:TRAIN-(misa) (8/12/2)>> loss: 0.9858  Has0_acc_2: 0.5802  Has0_F1_score: 0.5908  Non0_acc_2: 0.1925  Non0_F1_score: 0.1671  Acc_3: 0.5685  F1_score_3: 0.5893 
2021-01-27 00:37:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8601 
2021-01-27 00:37:26:INFO:TEST-(misa) >>  Has0_acc_2: 0.4169  Has0_F1_score: 0.5621  Non0_acc_2: 0.0213  Non0_F1_score: 0.0020  Acc_3: 0.4169  F1_score_3: 0.5623  Loss: 0.8817 
2021-01-27 00:37:26:INFO:Start running misa...
2021-01-27 00:37:26:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1113}>
2021-01-27 00:37:26:INFO:Let's use 1 GPUs!
2021-01-27 00:37:26:INFO:train samples: (1284,)
2021-01-27 00:37:26:INFO:valid samples: (229,)
2021-01-27 00:37:26:INFO:test samples: (686,)
2021-01-27 00:37:26:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:37:26:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:37:26:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:37:26:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:37:26:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:37:26:INFO:loading file None
2021-01-27 00:37:26:INFO:loading file None
2021-01-27 00:37:26:INFO:loading file None
2021-01-27 00:37:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:37:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:37:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:37:29:INFO:TRAIN-(misa) (1/27/1)>> loss: 0.2025  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7921  Mult_acc_7: 0.7391  MAE: 0.2494  Corr: 0.9774 
2021-01-27 00:37:29:INFO:The model has 110621043 trainable parameters
2021-01-27 00:37:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8283  Non0_acc_2: 0.8241  Non0_F1_score: 0.8271  Mult_acc_5: 0.4541  Mult_acc_7: 0.3493  MAE: 0.8055  Corr: 0.7927  Loss: 1.1559 
2021-01-27 00:37:39:INFO:TRAIN-(misa) (1/1/3)>> loss: 3.1934  Has0_acc_2: 0.5678  Has0_F1_score: 0.5867  Non0_acc_2: 0.1543  Non0_F1_score: 0.1206  Acc_3: 0.5452  F1_score_3: 0.5731 
2021-01-27 00:37:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.5808  Has0_F1_score: 0.6822  Non0_acc_2: 0.0556  Non0_F1_score: 0.0156  Acc_3: 0.5808  F1_score_3: 0.6838  Loss: 0.8211 
2021-01-27 00:37:40:INFO:TRAIN-(misa) (2/28/1)>> loss: 0.2077  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9618  Non0_F1_score: 0.9619  Mult_acc_5: 0.7695  Mult_acc_7: 0.7181  MAE: 0.2759  Corr: 0.9739 
2021-01-27 00:37:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8082  Non0_acc_2: 0.8241  Non0_F1_score: 0.8253  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7620  Corr: 0.7900  Loss: 1.0311 
2021-01-27 00:37:51:INFO:TRAIN-(misa) (3/29/1)>> loss: 0.1787  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8123  Mult_acc_7: 0.7640  MAE: 0.2390  Corr: 0.9801 
2021-01-27 00:37:51:INFO:TRAIN-(misa) (1/2/3)>> loss: 2.1703  Has0_acc_2: 0.7313  Has0_F1_score: 0.7362  Non0_acc_2: 0.2811  Non0_F1_score: 0.2525  Acc_3: 0.7173  F1_score_3: 0.7361 
2021-01-27 00:37:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.4891  Mult_acc_7: 0.4017  MAE: 0.7300  Corr: 0.7961  Loss: 1.0156 
2021-01-27 00:37:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8035  Non0_acc_2: 0.3750  Non0_F1_score: 0.4134  Acc_3: 0.7555  F1_score_3: 0.7745  Loss: 0.6617 
2021-01-27 00:38:01:INFO:TRAIN-(misa) (4/30/1)>> loss: 0.1592  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8326  Mult_acc_7: 0.7827  MAE: 0.2215  Corr: 0.9827 
2021-01-27 00:38:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7949  Non0_acc_2: 0.8102  Non0_F1_score: 0.8113  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7525  Corr: 0.7904  Loss: 1.0743 
2021-01-27 00:38:03:INFO:TRAIN-(misa) (1/3/3)>> loss: 1.3517  Has0_acc_2: 0.8988  Has0_F1_score: 0.8989  Non0_acc_2: 0.4013  Non0_F1_score: 0.3984  Acc_3: 0.8746  F1_score_3: 0.8931 
2021-01-27 00:38:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7820  Non0_acc_2: 0.2639  Non0_F1_score: 0.2185  Acc_3: 0.7555  F1_score_3: 0.7841  Loss: 0.7165 
2021-01-27 00:38:12:INFO:TRAIN-(misa) (5/31/1)>> loss: 0.1446  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8372  Mult_acc_7: 0.7921  MAE: 0.2033  Corr: 0.9856 
2021-01-27 00:38:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7976  Non0_acc_2: 0.8241  Non0_F1_score: 0.8236  Mult_acc_5: 0.4716  Mult_acc_7: 0.3974  MAE: 0.7645  Corr: 0.7842  Loss: 1.0623 
2021-01-27 00:38:14:INFO:TRAIN-(misa) (2/4/3)>> loss: 0.8796  Has0_acc_2: 0.9424  Has0_F1_score: 0.9425  Non0_acc_2: 0.4281  Non0_F1_score: 0.4277  Acc_3: 0.9206  F1_score_3: 0.9399 
2021-01-27 00:38:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7828  Non0_acc_2: 0.2870  Non0_F1_score: 0.2559  Acc_3: 0.7598  F1_score_3: 0.7855  Loss: 0.8365 
2021-01-27 00:38:23:INFO:TRAIN-(misa) (6/32/1)>> loss: 0.1391  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9829  Non0_F1_score: 0.9830  Mult_acc_5: 0.8520  Mult_acc_7: 0.8084  MAE: 0.1957  Corr: 0.9863 
2021-01-27 00:38:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7883  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4498  Mult_acc_7: 0.3668  MAE: 0.7805  Corr: 0.7853  Loss: 1.0875 
2021-01-27 00:38:25:INFO:TRAIN-(misa) (3/5/3)>> loss: 0.6668  Has0_acc_2: 0.9634  Has0_F1_score: 0.9635  Non0_acc_2: 0.4354  Non0_F1_score: 0.4330  Acc_3: 0.9385  F1_score_3: 0.9582 
2021-01-27 00:38:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7471  Non0_acc_2: 0.2130  Non0_F1_score: 0.1519  Acc_3: 0.7205  F1_score_3: 0.7562  Loss: 1.4176 
2021-01-27 00:38:33:INFO:TRAIN-(misa) (7/33/1)>> loss: 0.1410  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8279  Mult_acc_7: 0.7850  MAE: 0.2110  Corr: 0.9846 
2021-01-27 00:38:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8273  Non0_acc_2: 0.8333  Non0_F1_score: 0.8357  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7696  Corr: 0.7889  Loss: 1.1729 
2021-01-27 00:38:36:INFO:TRAIN-(misa) (4/6/3)>> loss: 0.6577  Has0_acc_2: 0.9494  Has0_F1_score: 0.9495  Non0_acc_2: 0.4314  Non0_F1_score: 0.4298  Acc_3: 0.9291  F1_score_3: 0.9487 
2021-01-27 00:38:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8176  Non0_acc_2: 0.3241  Non0_F1_score: 0.3132  Acc_3: 0.7773  F1_score_3: 0.8005  Loss: 1.0289 
2021-01-27 00:38:44:INFO:TRAIN-(misa) (8/34/1)>> loss: 0.1423  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8240  Mult_acc_7: 0.7788  MAE: 0.2172  Corr: 0.9837 
2021-01-27 00:38:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.5153  Mult_acc_7: 0.4236  MAE: 0.7416  Corr: 0.7925  Loss: 1.0532 
2021-01-27 00:38:46:INFO:TRAIN-(misa) (5/7/3)>> loss: 0.5784  Has0_acc_2: 0.9525  Has0_F1_score: 0.9525  Non0_acc_2: 0.4370  Non0_F1_score: 0.4402  Acc_3: 0.9315  F1_score_3: 0.9472 
2021-01-27 00:38:46:INFO:TEST-(misa) >>  Has0_acc_2: 0.8061  Has0_F1_score: 0.8077  Non0_acc_2: 0.8262  Non0_F1_score: 0.8270  Mult_acc_5: 0.4767  Mult_acc_7: 0.4169  MAE: 0.7766  Corr: 0.7589  Loss: 1.0840 
2021-01-27 00:38:46:INFO:Start running misa...
2021-01-27 00:38:46:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1112}>
2021-01-27 00:38:46:INFO:Let's use 1 GPUs!
2021-01-27 00:38:46:INFO:train samples: (1284,)
2021-01-27 00:38:47:INFO:valid samples: (229,)
2021-01-27 00:38:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7900  Non0_acc_2: 0.3611  Non0_F1_score: 0.3883  Acc_3: 0.7555  F1_score_3: 0.7759  Loss: 0.9060 
2021-01-27 00:38:47:INFO:test samples: (686,)
2021-01-27 00:38:47:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:38:47:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:38:47:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:38:47:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:38:47:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:38:47:INFO:loading file None
2021-01-27 00:38:47:INFO:loading file None
2021-01-27 00:38:47:INFO:loading file None
2021-01-27 00:38:47:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:38:47:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:38:47:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:38:50:INFO:The model has 110620273 trainable parameters
2021-01-27 00:38:57:INFO:TRAIN-(misa) (6/8/3)>> loss: 0.4282  Has0_acc_2: 0.9727  Has0_F1_score: 0.9728  Non0_acc_2: 0.4435  Non0_F1_score: 0.4431  Acc_3: 0.9502  F1_score_3: 0.9687 
2021-01-27 00:38:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8048  Non0_acc_2: 0.3241  Non0_F1_score: 0.3150  Acc_3: 0.7729  F1_score_3: 0.7961  Loss: 0.9543 
2021-01-27 00:39:00:INFO:TRAIN-(misa) (1/1/2)>> loss: 4.2901  Has0_acc_2: 0.6347  Has0_F1_score: 0.6505  Non0_acc_2: 0.6320  Non0_F1_score: 0.6487  Mult_acc_5: 0.2204  Mult_acc_7: 0.2204  MAE: 1.2066  Corr: 0.3538 
2021-01-27 00:39:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7758  Non0_acc_2: 0.8148  Non0_F1_score: 0.8141  Mult_acc_5: 0.2533  Mult_acc_7: 0.2533  MAE: 1.0278  Corr: 0.7151  Loss: 1.5027 
2021-01-27 00:39:07:INFO:TRAIN-(misa) (7/9/3)>> loss: 0.3615  Has0_acc_2: 0.9782  Has0_F1_score: 0.9782  Non0_acc_2: 0.4452  Non0_F1_score: 0.4444  Acc_3: 0.9650  F1_score_3: 0.9735 
2021-01-27 00:39:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7736  Non0_acc_2: 0.2685  Non0_F1_score: 0.2358  Acc_3: 0.7424  F1_score_3: 0.7584  Loss: 1.3952 
2021-01-27 00:39:12:INFO:TRAIN-(misa) (1/2/2)>> loss: 2.5855  Has0_acc_2: 0.8107  Has0_F1_score: 0.8099  Non0_acc_2: 0.8318  Non0_F1_score: 0.8315  Mult_acc_5: 0.4276  Mult_acc_7: 0.4011  MAE: 0.7737  Corr: 0.7558 
2021-01-27 00:39:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7711  Non0_acc_2: 0.8102  Non0_F1_score: 0.8092  Mult_acc_5: 0.3668  Mult_acc_7: 0.3100  MAE: 0.9196  Corr: 0.7404  Loss: 1.3534 
2021-01-27 00:39:18:INFO:TRAIN-(misa) (8/10/3)>> loss: 0.3216  Has0_acc_2: 0.9704  Has0_F1_score: 0.9705  Non0_acc_2: 0.4452  Non0_F1_score: 0.4452  Acc_3: 0.9712  F1_score_3: 0.9749 
2021-01-27 00:39:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7796  Non0_acc_2: 0.2639  Non0_F1_score: 0.2243  Acc_3: 0.7380  F1_score_3: 0.7510  Loss: 1.4348 
2021-01-27 00:39:20:INFO:TEST-(misa) >>  Has0_acc_2: 0.8426  Has0_F1_score: 0.8438  Non0_acc_2: 0.5259  Non0_F1_score: 0.5466  Acc_3: 0.8120  F1_score_3: 0.8315  Loss: 0.6059 
2021-01-27 00:39:20:INFO:Start running misa...
2021-01-27 00:39:20:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1114}>
2021-01-27 00:39:20:INFO:Let's use 1 GPUs!
2021-01-27 00:39:21:INFO:train samples: (1284,)
2021-01-27 00:39:21:INFO:valid samples: (229,)
2021-01-27 00:39:21:INFO:test samples: (686,)
2021-01-27 00:39:21:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:39:21:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:39:21:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:39:21:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:39:21:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:39:21:INFO:loading file None
2021-01-27 00:39:21:INFO:loading file None
2021-01-27 00:39:21:INFO:loading file None
2021-01-27 00:39:21:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:39:21:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:39:21:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:39:24:INFO:TRAIN-(misa) (1/3/2)>> loss: 1.6787  Has0_acc_2: 0.8606  Has0_F1_score: 0.8601  Non0_acc_2: 0.8822  Non0_F1_score: 0.8821  Mult_acc_5: 0.4852  Mult_acc_7: 0.4408  MAE: 0.6374  Corr: 0.8485 
2021-01-27 00:39:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8090  Non0_acc_2: 0.8241  Non0_F1_score: 0.8262  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.8412  Corr: 0.7441  Loss: 1.4916 
2021-01-27 00:39:25:INFO:The model has 110621043 trainable parameters
2021-01-27 00:39:35:INFO:TRAIN-(misa) (2/4/2)>> loss: 1.1907  Has0_acc_2: 0.9011  Has0_F1_score: 0.9007  Non0_acc_2: 0.9139  Non0_F1_score: 0.9137  Mult_acc_5: 0.5436  Mult_acc_7: 0.4938  MAE: 0.5455  Corr: 0.8899 
2021-01-27 00:39:35:INFO:TRAIN-(misa) (1/1/4)>> loss: 3.4040  Has0_acc_2: 0.5202  Has0_F1_score: 0.5303  Non0_acc_2: 0.1657  Non0_F1_score: 0.1464  Acc_3: 0.5047  F1_score_3: 0.5228 
2021-01-27 00:39:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8389  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5109  Mult_acc_7: 0.4279  MAE: 0.7739  Corr: 0.7632  Loss: 1.1479 
2021-01-27 00:39:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8333 
2021-01-27 00:39:47:INFO:TRAIN-(misa) (1/5/2)>> loss: 0.8457  Has0_acc_2: 0.9143  Has0_F1_score: 0.9142  Non0_acc_2: 0.9301  Non0_F1_score: 0.9302  Mult_acc_5: 0.6207  Mult_acc_7: 0.5717  MAE: 0.4585  Corr: 0.9224 
2021-01-27 00:39:48:INFO:TRAIN-(misa) (1/2/4)>> loss: 2.3696  Has0_acc_2: 0.6363  Has0_F1_score: 0.6653  Non0_acc_2: 0.1657  Non0_F1_score: 0.1121  Acc_3: 0.6269  F1_score_3: 0.6657 
2021-01-27 00:39:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8027  Non0_acc_2: 0.8287  Non0_F1_score: 0.8291  Mult_acc_5: 0.5240  Mult_acc_7: 0.4410  MAE: 0.7705  Corr: 0.7543  Loss: 1.2349 
2021-01-27 00:39:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.7511  Has0_F1_score: 0.7580  Non0_acc_2: 0.2731  Non0_F1_score: 0.2417  Acc_3: 0.7380  F1_score_3: 0.7637  Loss: 0.7575 
2021-01-27 00:39:58:INFO:TRAIN-(misa) (2/6/2)>> loss: 0.6892  Has0_acc_2: 0.9206  Has0_F1_score: 0.9203  Non0_acc_2: 0.9391  Non0_F1_score: 0.9390  Mult_acc_5: 0.6519  Mult_acc_7: 0.5942  MAE: 0.4236  Corr: 0.9343 
2021-01-27 00:39:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7885  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4716  Mult_acc_7: 0.3799  MAE: 0.8318  Corr: 0.7746  Loss: 1.3611 
2021-01-27 00:40:00:INFO:TRAIN-(misa) (1/3/4)>> loss: 1.6227  Has0_acc_2: 0.8100  Has0_F1_score: 0.8126  Non0_acc_2: 0.3266  Non0_F1_score: 0.2986  Acc_3: 0.7928  F1_score_3: 0.8116 
2021-01-27 00:40:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7536  Non0_acc_2: 0.4120  Non0_F1_score: 0.5001  Acc_3: 0.6987  F1_score_3: 0.7210  Loss: 0.7261 
2021-01-27 00:40:09:INFO:TRAIN-(misa) (3/7/2)>> loss: 0.5849  Has0_acc_2: 0.9299  Has0_F1_score: 0.9296  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.6854  Mult_acc_7: 0.6223  MAE: 0.3823  Corr: 0.9465 
2021-01-27 00:40:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4978  Mult_acc_7: 0.3886  MAE: 0.7506  Corr: 0.7729  Loss: 1.1693 
2021-01-27 00:40:11:INFO:TRAIN-(misa) (1/4/4)>> loss: 1.1089  Has0_acc_2: 0.8762  Has0_F1_score: 0.8763  Non0_acc_2: 0.3964  Non0_F1_score: 0.3982  Acc_3: 0.8551  F1_score_3: 0.8731 
2021-01-27 00:40:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.3472  Non0_F1_score: 0.3510  Acc_3: 0.7860  F1_score_3: 0.8086  Loss: 0.6460 
2021-01-27 00:40:19:INFO:TRAIN-(misa) (4/8/2)>> loss: 0.4700  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9504  Non0_F1_score: 0.9504  Mult_acc_5: 0.7321  Mult_acc_7: 0.6745  MAE: 0.3303  Corr: 0.9607 
2021-01-27 00:40:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7452  Corr: 0.7700  Loss: 1.1427 
2021-01-27 00:40:23:INFO:TRAIN-(misa) (1/5/4)>> loss: 0.7214  Has0_acc_2: 0.9509  Has0_F1_score: 0.9510  Non0_acc_2: 0.4330  Non0_F1_score: 0.4318  Acc_3: 0.9315  F1_score_3: 0.9511 
2021-01-27 00:40:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7867  Non0_acc_2: 0.2639  Non0_F1_score: 0.2165  Acc_3: 0.7598  F1_score_3: 0.7888  Loss: 0.9281 
2021-01-27 00:40:31:INFO:TRAIN-(misa) (1/9/2)>> loss: 0.4462  Has0_acc_2: 0.9260  Has0_F1_score: 0.9259  Non0_acc_2: 0.9423  Non0_F1_score: 0.9423  Mult_acc_5: 0.7414  Mult_acc_7: 0.6846  MAE: 0.3418  Corr: 0.9577 
2021-01-27 00:40:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8065  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7610  Corr: 0.7678  Loss: 1.1851 
2021-01-27 00:40:34:INFO:TRAIN-(misa) (2/6/4)>> loss: 0.6883  Has0_acc_2: 0.9408  Has0_F1_score: 0.9409  Non0_acc_2: 0.4240  Non0_F1_score: 0.4206  Acc_3: 0.9190  F1_score_3: 0.9384 
2021-01-27 00:40:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7642  Has0_F1_score: 0.7650  Non0_acc_2: 0.3750  Non0_F1_score: 0.4261  Acc_3: 0.7205  F1_score_3: 0.7394  Loss: 1.0530 
2021-01-27 00:40:42:INFO:TRAIN-(misa) (2/10/2)>> loss: 0.3860  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7609  Mult_acc_7: 0.7017  MAE: 0.3093  Corr: 0.9661 
2021-01-27 00:40:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5240  Mult_acc_7: 0.4323  MAE: 0.7732  Corr: 0.7723  Loss: 1.1865 
2021-01-27 00:40:44:INFO:TRAIN-(misa) (3/7/4)>> loss: 0.6050  Has0_acc_2: 0.9408  Has0_F1_score: 0.9409  Non0_acc_2: 0.4322  Non0_F1_score: 0.4349  Acc_3: 0.9229  F1_score_3: 0.9412 
2021-01-27 00:40:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7795  Non0_acc_2: 0.3102  Non0_F1_score: 0.2979  Acc_3: 0.7555  F1_score_3: 0.7786  Loss: 0.9465 
2021-01-27 00:40:53:INFO:TRAIN-(misa) (3/11/2)>> loss: 0.3720  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.7220  Mult_acc_7: 0.6659  MAE: 0.3190  Corr: 0.9650 
2021-01-27 00:40:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8219  Non0_acc_2: 0.8380  Non0_F1_score: 0.8397  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7807  Corr: 0.7754  Loss: 1.2106 
2021-01-27 00:40:55:INFO:TRAIN-(misa) (4/8/4)>> loss: 0.5070  Has0_acc_2: 0.9525  Has0_F1_score: 0.9526  Non0_acc_2: 0.4322  Non0_F1_score: 0.4294  Acc_3: 0.9330  F1_score_3: 0.9527 
2021-01-27 00:40:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7931  Non0_acc_2: 0.3102  Non0_F1_score: 0.2924  Acc_3: 0.7686  F1_score_3: 0.7926  Loss: 0.9112 
2021-01-27 00:41:03:INFO:TRAIN-(misa) (4/12/2)>> loss: 0.3735  Has0_acc_2: 0.9307  Has0_F1_score: 0.9305  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7414  Mult_acc_7: 0.6846  MAE: 0.3229  Corr: 0.9636 
2021-01-27 00:41:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8419  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7731  Corr: 0.7910  Loss: 1.1736 
2021-01-27 00:41:06:INFO:TRAIN-(misa) (5/9/4)>> loss: 0.4036  Has0_acc_2: 0.9727  Has0_F1_score: 0.9728  Non0_acc_2: 0.4444  Non0_F1_score: 0.4444  Acc_3: 0.9556  F1_score_3: 0.9684 
2021-01-27 00:41:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7692  Non0_acc_2: 0.3750  Non0_F1_score: 0.4245  Acc_3: 0.7205  F1_score_3: 0.7368  Loss: 1.2664 
2021-01-27 00:41:14:INFO:TRAIN-(misa) (5/13/2)>> loss: 0.3642  Has0_acc_2: 0.9400  Has0_F1_score: 0.9398  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7282  Mult_acc_7: 0.6682  MAE: 0.3329  Corr: 0.9616 
2021-01-27 00:41:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5546  Mult_acc_7: 0.4803  MAE: 0.7228  Corr: 0.7817  Loss: 1.0852 
2021-01-27 00:41:16:INFO:TRAIN-(misa) (6/10/4)>> loss: 0.3340  Has0_acc_2: 0.9774  Has0_F1_score: 0.9774  Non0_acc_2: 0.4484  Non0_F1_score: 0.4496  Acc_3: 0.9759  F1_score_3: 0.9788 
2021-01-27 00:41:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7886  Non0_acc_2: 0.3102  Non0_F1_score: 0.2942  Acc_3: 0.7598  F1_score_3: 0.7820  Loss: 1.1495 
2021-01-27 00:41:26:INFO:TRAIN-(misa) (1/14/2)>> loss: 0.2936  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7773  Mult_acc_7: 0.7407  MAE: 0.2759  Corr: 0.9742 
2021-01-27 00:41:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7788  Corr: 0.7768  Loss: 1.2226 
2021-01-27 00:41:27:INFO:TRAIN-(misa) (7/11/4)>> loss: 0.2689  Has0_acc_2: 0.9751  Has0_F1_score: 0.9751  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9860  F1_score_3: 0.9865 
2021-01-27 00:41:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8082  Non0_acc_2: 0.3519  Non0_F1_score: 0.3593  Acc_3: 0.7860  F1_score_3: 0.8006  Loss: 1.0725 
2021-01-27 00:41:37:INFO:TRAIN-(misa) (2/15/2)>> loss: 0.2761  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.8076  Mult_acc_7: 0.7625  MAE: 0.2645  Corr: 0.9753 
2021-01-27 00:41:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5371  Mult_acc_7: 0.4367  MAE: 0.7477  Corr: 0.7861  Loss: 1.1208 
2021-01-27 00:41:37:INFO:TRAIN-(misa) (8/12/4)>> loss: 0.2615  Has0_acc_2: 0.9712  Has0_F1_score: 0.9712  Non0_acc_2: 0.4452  Non0_F1_score: 0.4452  Acc_3: 0.9883  F1_score_3: 0.9885 
2021-01-27 00:41:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.7598  Has0_F1_score: 0.7612  Non0_acc_2: 0.3843  Non0_F1_score: 0.4427  Acc_3: 0.7162  F1_score_3: 0.7214  Loss: 1.6144 
2021-01-27 00:41:40:INFO:TEST-(misa) >>  Has0_acc_2: 0.8353  Has0_F1_score: 0.8356  Non0_acc_2: 0.5122  Non0_F1_score: 0.5234  Acc_3: 0.8061  F1_score_3: 0.8249  Loss: 0.5753 
2021-01-27 00:41:40:INFO:Start running misa...
2021-01-27 00:41:40:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1115}>
2021-01-27 00:41:40:INFO:Let's use 1 GPUs!
2021-01-27 00:41:40:INFO:train samples: (1284,)
2021-01-27 00:41:41:INFO:valid samples: (229,)
2021-01-27 00:41:41:INFO:test samples: (686,)
2021-01-27 00:41:41:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:41:41:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:41:41:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:41:41:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:41:41:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:41:41:INFO:loading file None
2021-01-27 00:41:41:INFO:loading file None
2021-01-27 00:41:41:INFO:loading file None
2021-01-27 00:41:41:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:41:41:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:41:41:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:41:44:INFO:The model has 110621043 trainable parameters
2021-01-27 00:41:48:INFO:TRAIN-(misa) (3/16/2)>> loss: 0.3076  Has0_acc_2: 0.9315  Has0_F1_score: 0.9312  Non0_acc_2: 0.9488  Non0_F1_score: 0.9488  Mult_acc_5: 0.7664  Mult_acc_7: 0.7150  MAE: 0.3079  Corr: 0.9668 
2021-01-27 00:41:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8347  Non0_acc_2: 0.8519  Non0_F1_score: 0.8532  Mult_acc_5: 0.5546  Mult_acc_7: 0.4716  MAE: 0.7242  Corr: 0.7849  Loss: 1.0311 
2021-01-27 00:41:54:INFO:TRAIN-(misa) (1/1/5)>> loss: 3.1598  Has0_acc_2: 0.5467  Has0_F1_score: 0.5735  Non0_acc_2: 0.1340  Non0_F1_score: 0.0990  Acc_3: 0.5296  F1_score_3: 0.5600 
2021-01-27 00:41:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7354  Non0_acc_2: 0.2407  Non0_F1_score: 0.2011  Acc_3: 0.7074  F1_score_3: 0.7360  Loss: 0.8034 
2021-01-27 00:42:00:INFO:TRAIN-(misa) (1/17/2)>> loss: 0.2708  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7695  Mult_acc_7: 0.7173  MAE: 0.2671  Corr: 0.9744 
2021-01-27 00:42:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8333  Non0_F1_score: 0.8324  Mult_acc_5: 0.4323  Mult_acc_7: 0.3581  MAE: 0.7814  Corr: 0.7888  Loss: 1.1286 
2021-01-27 00:42:06:INFO:TRAIN-(misa) (1/2/5)>> loss: 2.1138  Has0_acc_2: 0.7866  Has0_F1_score: 0.7890  Non0_acc_2: 0.3184  Non0_F1_score: 0.2952  Acc_3: 0.7679  F1_score_3: 0.7860 
2021-01-27 00:42:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7793  Non0_acc_2: 0.3935  Non0_F1_score: 0.4564  Acc_3: 0.7293  F1_score_3: 0.7485  Loss: 0.6683 
2021-01-27 00:42:10:INFO:TRAIN-(misa) (2/18/2)>> loss: 0.2695  Has0_acc_2: 0.9369  Has0_F1_score: 0.9367  Non0_acc_2: 0.9561  Non0_F1_score: 0.9561  Mult_acc_5: 0.7749  Mult_acc_7: 0.7181  MAE: 0.2825  Corr: 0.9725 
2021-01-27 00:42:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8335  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5415  Mult_acc_7: 0.4541  MAE: 0.7010  Corr: 0.7935  Loss: 1.0085 
2021-01-27 00:42:19:INFO:TRAIN-(misa) (1/3/5)>> loss: 1.3744  Has0_acc_2: 0.9159  Has0_F1_score: 0.9159  Non0_acc_2: 0.4216  Non0_F1_score: 0.4291  Acc_3: 0.8917  F1_score_3: 0.9103 
2021-01-27 00:42:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.3472  Non0_F1_score: 0.3510  Acc_3: 0.7860  F1_score_3: 0.8079  Loss: 0.5874 
2021-01-27 00:42:23:INFO:TRAIN-(misa) (1/19/2)>> loss: 0.2369  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.7967  Mult_acc_7: 0.7492  MAE: 0.2452  Corr: 0.9787 
2021-01-27 00:42:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.5022  Mult_acc_7: 0.4148  MAE: 0.7517  Corr: 0.7968  Loss: 1.0295 
2021-01-27 00:42:31:INFO:TRAIN-(misa) (1/4/5)>> loss: 0.9227  Has0_acc_2: 0.9509  Has0_F1_score: 0.9510  Non0_acc_2: 0.4330  Non0_F1_score: 0.4334  Acc_3: 0.9283  F1_score_3: 0.9479 
2021-01-27 00:42:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8167  Non0_acc_2: 0.3843  Non0_F1_score: 0.4253  Acc_3: 0.7686  F1_score_3: 0.7881  Loss: 0.7201 
2021-01-27 00:42:33:INFO:TRAIN-(misa) (2/20/2)>> loss: 0.2280  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7975  Mult_acc_7: 0.7453  MAE: 0.2503  Corr: 0.9783 
2021-01-27 00:42:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7973  Non0_acc_2: 0.8333  Non0_F1_score: 0.8328  Mult_acc_5: 0.4978  Mult_acc_7: 0.4148  MAE: 0.7378  Corr: 0.7941  Loss: 1.0003 
2021-01-27 00:42:42:INFO:TRAIN-(misa) (2/5/5)>> loss: 0.7368  Has0_acc_2: 0.9688  Has0_F1_score: 0.9689  Non0_acc_2: 0.4411  Non0_F1_score: 0.4419  Acc_3: 0.9431  F1_score_3: 0.9629 
2021-01-27 00:42:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.7380  Has0_F1_score: 0.7518  Non0_acc_2: 0.2269  Non0_F1_score: 0.1754  Acc_3: 0.7162  F1_score_3: 0.7489  Loss: 1.0998 
2021-01-27 00:42:46:INFO:TRAIN-(misa) (1/21/2)>> loss: 0.2191  Has0_acc_2: 0.9463  Has0_F1_score: 0.9462  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.8115  Mult_acc_7: 0.7640  MAE: 0.2434  Corr: 0.9786 
2021-01-27 00:42:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8302  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5459  Mult_acc_7: 0.4410  MAE: 0.7123  Corr: 0.8033  Loss: 1.0369 
2021-01-27 00:42:53:INFO:TRAIN-(misa) (3/6/5)>> loss: 0.5961  Has0_acc_2: 0.9766  Has0_F1_score: 0.9767  Non0_acc_2: 0.4403  Non0_F1_score: 0.4375  Acc_3: 0.9486  F1_score_3: 0.9685 
2021-01-27 00:42:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7917  Non0_acc_2: 0.3935  Non0_F1_score: 0.4518  Acc_3: 0.7424  F1_score_3: 0.7616  Loss: 1.0597 
2021-01-27 00:42:56:INFO:TRAIN-(misa) (2/22/2)>> loss: 0.2157  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8146  Mult_acc_7: 0.7780  MAE: 0.2435  Corr: 0.9786 
2021-01-27 00:42:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5502  Mult_acc_7: 0.4585  MAE: 0.7095  Corr: 0.7975  Loss: 0.9586 
2021-01-27 00:43:03:INFO:TRAIN-(misa) (4/7/5)>> loss: 0.5110  Has0_acc_2: 0.9751  Has0_F1_score: 0.9751  Non0_acc_2: 0.4435  Non0_F1_score: 0.4439  Acc_3: 0.9494  F1_score_3: 0.9682 
2021-01-27 00:43:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7900  Non0_acc_2: 0.3472  Non0_F1_score: 0.3668  Acc_3: 0.7467  F1_score_3: 0.7649  Loss: 1.2120 
2021-01-27 00:43:08:INFO:TRAIN-(misa) (1/23/2)>> loss: 0.2066  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8030  Mult_acc_7: 0.7562  MAE: 0.2425  Corr: 0.9791 
2021-01-27 00:43:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7886  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4236  Mult_acc_7: 0.3450  MAE: 0.8223  Corr: 0.7866  Loss: 1.2561 
2021-01-27 00:43:14:INFO:TRAIN-(misa) (5/8/5)>> loss: 0.5103  Has0_acc_2: 0.9696  Has0_F1_score: 0.9697  Non0_acc_2: 0.4411  Non0_F1_score: 0.4419  Acc_3: 0.9470  F1_score_3: 0.9607 
2021-01-27 00:43:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7733  Non0_acc_2: 0.3194  Non0_F1_score: 0.3212  Acc_3: 0.7293  F1_score_3: 0.7422  Loss: 1.0866 
2021-01-27 00:43:19:INFO:TRAIN-(misa) (2/24/2)>> loss: 0.2242  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9634  Non0_F1_score: 0.9634  Mult_acc_5: 0.7812  Mult_acc_7: 0.7336  MAE: 0.2700  Corr: 0.9747 
2021-01-27 00:43:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8400  Non0_acc_2: 0.8519  Non0_F1_score: 0.8540  Mult_acc_5: 0.5240  Mult_acc_7: 0.4323  MAE: 0.7162  Corr: 0.8028  Loss: 0.9941 
2021-01-27 00:43:25:INFO:TRAIN-(misa) (6/9/5)>> loss: 0.3867  Has0_acc_2: 0.9805  Has0_F1_score: 0.9806  Non0_acc_2: 0.4452  Non0_F1_score: 0.4440  Acc_3: 0.9712  F1_score_3: 0.9763 
2021-01-27 00:43:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7782  Non0_acc_2: 0.3796  Non0_F1_score: 0.4313  Acc_3: 0.7205  F1_score_3: 0.7352  Loss: 1.3429 
2021-01-27 00:43:30:INFO:TRAIN-(misa) (3/25/2)>> loss: 0.1969  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8092  Mult_acc_7: 0.7710  MAE: 0.2393  Corr: 0.9800 
2021-01-27 00:43:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8657  Non0_F1_score: 0.8661  Mult_acc_5: 0.5415  Mult_acc_7: 0.4585  MAE: 0.7199  Corr: 0.7956  Loss: 1.0313 
2021-01-27 00:43:36:INFO:TRAIN-(misa) (7/10/5)>> loss: 0.3552  Has0_acc_2: 0.9735  Has0_F1_score: 0.9736  Non0_acc_2: 0.4444  Non0_F1_score: 0.4448  Acc_3: 0.9743  F1_score_3: 0.9764 
2021-01-27 00:43:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7692  Non0_acc_2: 0.3750  Non0_F1_score: 0.4245  Acc_3: 0.7205  F1_score_3: 0.7368  Loss: 1.5542 
2021-01-27 00:43:40:INFO:TRAIN-(misa) (4/26/2)>> loss: 0.1816  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8146  Mult_acc_7: 0.7702  MAE: 0.2236  Corr: 0.9823 
2021-01-27 00:43:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7513  Corr: 0.7914  Loss: 1.0206 
2021-01-27 00:43:47:INFO:TRAIN-(misa) (8/11/5)>> loss: 0.3603  Has0_acc_2: 0.9618  Has0_F1_score: 0.9619  Non0_acc_2: 0.4387  Non0_F1_score: 0.4383  Acc_3: 0.9720  F1_score_3: 0.9726 
2021-01-27 00:43:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7739  Non0_acc_2: 0.3148  Non0_F1_score: 0.3114  Acc_3: 0.7467  F1_score_3: 0.7597  Loss: 1.4459 
2021-01-27 00:43:50:INFO:TEST-(misa) >>  Has0_acc_2: 0.8163  Has0_F1_score: 0.8157  Non0_acc_2: 0.4878  Non0_F1_score: 0.4859  Acc_3: 0.7886  F1_score_3: 0.8062  Loss: 0.5643 
2021-01-27 00:43:50:INFO:Results are saved to results/results/mosi-misa-classification.csv...
2021-01-27 00:43:51:INFO:TRAIN-(misa) (5/27/2)>> loss: 0.1695  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8388  Mult_acc_7: 0.7952  MAE: 0.2108  Corr: 0.9843 
2021-01-27 00:43:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8425  Non0_acc_2: 0.8657  Non0_F1_score: 0.8663  Mult_acc_5: 0.5721  Mult_acc_7: 0.4934  MAE: 0.6980  Corr: 0.8026  Loss: 1.0226 
2021-01-27 00:44:02:INFO:TRAIN-(misa) (6/28/2)>> loss: 0.1788  Has0_acc_2: 0.9587  Has0_F1_score: 0.9587  Non0_acc_2: 0.9764  Non0_F1_score: 0.9765  Mult_acc_5: 0.8154  Mult_acc_7: 0.7710  MAE: 0.2194  Corr: 0.9830 
2021-01-27 00:44:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8333  Non0_acc_2: 0.8611  Non0_F1_score: 0.8613  Mult_acc_5: 0.5459  Mult_acc_7: 0.4541  MAE: 0.7121  Corr: 0.7984  Loss: 0.9891 
2021-01-27 00:44:12:INFO:TRAIN-(misa) (7/29/2)>> loss: 0.1666  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8372  Mult_acc_7: 0.7858  MAE: 0.2108  Corr: 0.9839 
2021-01-27 00:44:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8283  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7318  Corr: 0.7939  Loss: 0.9872 
2021-01-27 00:44:23:INFO:TRAIN-(misa) (8/30/2)>> loss: 0.1588  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8466  Mult_acc_7: 0.8076  MAE: 0.2004  Corr: 0.9857 
2021-01-27 00:44:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7107  Corr: 0.8021  Loss: 0.9906 
2021-01-27 00:44:25:INFO:TEST-(misa) >>  Has0_acc_2: 0.8120  Has0_F1_score: 0.8116  Non0_acc_2: 0.8262  Non0_F1_score: 0.8253  Mult_acc_5: 0.4723  Mult_acc_7: 0.4184  MAE: 0.7934  Corr: 0.7818  Loss: 1.1198 
2021-01-27 00:44:25:INFO:Start running misa...
2021-01-27 00:44:25:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1113}>
2021-01-27 00:44:25:INFO:Let's use 1 GPUs!
2021-01-27 00:44:26:INFO:train samples: (1284,)
2021-01-27 00:44:26:INFO:valid samples: (229,)
2021-01-27 00:44:27:INFO:test samples: (686,)
2021-01-27 00:44:27:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:44:27:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:44:27:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:44:27:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:44:27:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:44:27:INFO:loading file None
2021-01-27 00:44:27:INFO:loading file None
2021-01-27 00:44:27:INFO:loading file None
2021-01-27 00:44:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:44:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:44:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:44:30:INFO:The model has 110620273 trainable parameters
2021-01-27 00:44:39:INFO:TRAIN-(misa) (1/1/3)>> loss: 4.4529  Has0_acc_2: 0.6643  Has0_F1_score: 0.6746  Non0_acc_2: 0.6637  Non0_F1_score: 0.6747  Mult_acc_5: 0.2188  Mult_acc_7: 0.2181  MAE: 1.1959  Corr: 0.3847 
2021-01-27 00:44:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.6900  Has0_F1_score: 0.6958  Non0_acc_2: 0.7222  Non0_F1_score: 0.7276  Mult_acc_5: 0.2576  Mult_acc_7: 0.2533  MAE: 1.1829  Corr: 0.6161  Loss: 1.9636 
2021-01-27 00:44:51:INFO:TRAIN-(misa) (1/2/3)>> loss: 2.7509  Has0_acc_2: 0.8037  Has0_F1_score: 0.8029  Non0_acc_2: 0.8213  Non0_F1_score: 0.8210  Mult_acc_5: 0.3699  Mult_acc_7: 0.3512  MAE: 0.8224  Corr: 0.7293 
2021-01-27 00:44:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7839  Non0_acc_2: 0.8148  Non0_F1_score: 0.8138  Mult_acc_5: 0.4541  Mult_acc_7: 0.3755  MAE: 0.8745  Corr: 0.7215  Loss: 1.3699 
2021-01-27 00:45:02:INFO:TRAIN-(misa) (1/3/3)>> loss: 1.7993  Has0_acc_2: 0.8598  Has0_F1_score: 0.8592  Non0_acc_2: 0.8765  Non0_F1_score: 0.8763  Mult_acc_5: 0.4798  Mult_acc_7: 0.4424  MAE: 0.6483  Corr: 0.8419 
2021-01-27 00:45:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8105  Non0_acc_2: 0.8426  Non0_F1_score: 0.8419  Mult_acc_5: 0.4410  Mult_acc_7: 0.3406  MAE: 0.8173  Corr: 0.7720  Loss: 1.1182 
2021-01-27 00:45:14:INFO:TRAIN-(misa) (1/4/3)>> loss: 1.2024  Has0_acc_2: 0.8917  Has0_F1_score: 0.8913  Non0_acc_2: 0.9106  Non0_F1_score: 0.9105  Mult_acc_5: 0.5740  Mult_acc_7: 0.5288  MAE: 0.5097  Corr: 0.9018 
2021-01-27 00:45:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.4716  Mult_acc_7: 0.3624  MAE: 0.7879  Corr: 0.7804  Loss: 1.1243 
2021-01-27 00:45:25:INFO:TRAIN-(misa) (2/5/3)>> loss: 0.8780  Has0_acc_2: 0.9221  Has0_F1_score: 0.9220  Non0_acc_2: 0.9423  Non0_F1_score: 0.9424  Mult_acc_5: 0.6207  Mult_acc_7: 0.5600  MAE: 0.4423  Corr: 0.9304 
2021-01-27 00:45:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.8061  Non0_acc_2: 0.7963  Non0_F1_score: 0.8034  Mult_acc_5: 0.4803  Mult_acc_7: 0.3668  MAE: 0.8877  Corr: 0.7677  Loss: 1.3893 
2021-01-27 00:45:35:INFO:TRAIN-(misa) (3/6/3)>> loss: 0.7063  Has0_acc_2: 0.9151  Has0_F1_score: 0.9149  Non0_acc_2: 0.9285  Non0_F1_score: 0.9285  Mult_acc_5: 0.6768  Mult_acc_7: 0.6192  MAE: 0.4015  Corr: 0.9416 
2021-01-27 00:45:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.8333  Non0_F1_score: 0.8345  Mult_acc_5: 0.5022  Mult_acc_7: 0.3930  MAE: 0.7828  Corr: 0.7784  Loss: 1.1280 
2021-01-27 00:45:45:INFO:TRAIN-(misa) (4/7/3)>> loss: 0.5767  Has0_acc_2: 0.9330  Has0_F1_score: 0.9329  Non0_acc_2: 0.9496  Non0_F1_score: 0.9497  Mult_acc_5: 0.6994  Mult_acc_7: 0.6417  MAE: 0.3595  Corr: 0.9545 
2021-01-27 00:45:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7732  Corr: 0.7854  Loss: 1.0708 
2021-01-27 00:45:57:INFO:TRAIN-(misa) (1/8/3)>> loss: 0.5162  Has0_acc_2: 0.9346  Has0_F1_score: 0.9344  Non0_acc_2: 0.9513  Non0_F1_score: 0.9512  Mult_acc_5: 0.7227  Mult_acc_7: 0.6612  MAE: 0.3389  Corr: 0.9587 
2021-01-27 00:45:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.5066  Mult_acc_7: 0.3799  MAE: 0.7823  Corr: 0.7884  Loss: 1.1610 
2021-01-27 00:46:07:INFO:TRAIN-(misa) (2/9/3)>> loss: 0.4889  Has0_acc_2: 0.9260  Has0_F1_score: 0.9258  Non0_acc_2: 0.9464  Non0_F1_score: 0.9464  Mult_acc_5: 0.7220  Mult_acc_7: 0.6519  MAE: 0.3537  Corr: 0.9558 
2021-01-27 00:46:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.7598  Has0_F1_score: 0.7591  Non0_acc_2: 0.7963  Non0_F1_score: 0.7960  Mult_acc_5: 0.4323  Mult_acc_7: 0.3231  MAE: 0.8693  Corr: 0.7757  Loss: 1.3533 
2021-01-27 00:46:18:INFO:TRAIN-(misa) (3/10/3)>> loss: 0.4783  Has0_acc_2: 0.9393  Has0_F1_score: 0.9391  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7212  Mult_acc_7: 0.6620  MAE: 0.3510  Corr: 0.9563 
2021-01-27 00:46:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8237  Non0_acc_2: 0.8241  Non0_F1_score: 0.8271  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.8065  Corr: 0.7899  Loss: 1.2029 
2021-01-27 00:46:28:INFO:TRAIN-(misa) (4/11/3)>> loss: 0.4574  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9553  Non0_F1_score: 0.9553  Mult_acc_5: 0.6893  Mult_acc_7: 0.6340  MAE: 0.3553  Corr: 0.9543 
2021-01-27 00:46:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8148  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.5240  Mult_acc_7: 0.4192  MAE: 0.7598  Corr: 0.7901  Loss: 1.0695 
2021-01-27 00:46:40:INFO:TRAIN-(misa) (1/12/3)>> loss: 0.3848  Has0_acc_2: 0.9385  Has0_F1_score: 0.9383  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7484  Mult_acc_7: 0.6947  MAE: 0.3118  Corr: 0.9644 
2021-01-27 00:46:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8223  Non0_acc_2: 0.8380  Non0_F1_score: 0.8401  Mult_acc_5: 0.5371  Mult_acc_7: 0.4323  MAE: 0.7518  Corr: 0.7946  Loss: 1.0748 
2021-01-27 00:46:50:INFO:TRAIN-(misa) (2/13/3)>> loss: 0.3504  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7422  Mult_acc_7: 0.6893  MAE: 0.2970  Corr: 0.9676 
2021-01-27 00:46:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5284  Mult_acc_7: 0.4148  MAE: 0.7518  Corr: 0.7931  Loss: 1.1819 
2021-01-27 00:47:00:INFO:TRAIN-(misa) (3/14/3)>> loss: 0.3579  Has0_acc_2: 0.9416  Has0_F1_score: 0.9415  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7484  Mult_acc_7: 0.7033  MAE: 0.3118  Corr: 0.9652 
2021-01-27 00:47:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8060  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4629  Mult_acc_7: 0.3581  MAE: 0.7871  Corr: 0.7918  Loss: 1.1428 
2021-01-27 00:47:11:INFO:TRAIN-(misa) (4/15/3)>> loss: 0.3352  Has0_acc_2: 0.9385  Has0_F1_score: 0.9383  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7383  Mult_acc_7: 0.6893  MAE: 0.3062  Corr: 0.9665 
2021-01-27 00:47:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.7031  Has0_F1_score: 0.7073  Non0_acc_2: 0.7407  Non0_F1_score: 0.7443  Mult_acc_5: 0.3581  Mult_acc_7: 0.2838  MAE: 1.0728  Corr: 0.7679  Loss: 1.9670 
2021-01-27 00:47:21:INFO:TRAIN-(misa) (5/16/3)>> loss: 0.3834  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9399  Non0_F1_score: 0.9398  Mult_acc_5: 0.7048  Mult_acc_7: 0.6456  MAE: 0.3614  Corr: 0.9545 
2021-01-27 00:47:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8211  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5109  Mult_acc_7: 0.3886  MAE: 0.7664  Corr: 0.7950  Loss: 1.1253 
2021-01-27 00:47:31:INFO:TRAIN-(misa) (6/17/3)>> loss: 0.3196  Has0_acc_2: 0.9229  Has0_F1_score: 0.9226  Non0_acc_2: 0.9431  Non0_F1_score: 0.9431  Mult_acc_5: 0.7360  Mult_acc_7: 0.6931  MAE: 0.3146  Corr: 0.9655 
2021-01-27 00:47:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7868  Corr: 0.7733  Loss: 1.1283 
2021-01-27 00:47:42:INFO:TRAIN-(misa) (7/18/3)>> loss: 0.2709  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.7843  Mult_acc_7: 0.7391  MAE: 0.2658  Corr: 0.9752 
2021-01-27 00:47:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7508  Corr: 0.7848  Loss: 1.1154 
2021-01-27 00:47:52:INFO:TRAIN-(misa) (8/19/3)>> loss: 0.2661  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.7827  Mult_acc_7: 0.7352  MAE: 0.2650  Corr: 0.9755 
2021-01-27 00:47:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7884  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.8232  Corr: 0.7852  Loss: 1.1630 
2021-01-27 00:47:54:INFO:TEST-(misa) >>  Has0_acc_2: 0.8222  Has0_F1_score: 0.8247  Non0_acc_2: 0.8460  Non0_F1_score: 0.8476  Mult_acc_5: 0.4971  Mult_acc_7: 0.4359  MAE: 0.7529  Corr: 0.7750  Loss: 1.0276 
2021-01-27 00:47:54:INFO:Start running misa...
2021-01-27 00:47:54:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1114}>
2021-01-27 00:47:54:INFO:Let's use 1 GPUs!
2021-01-27 00:47:55:INFO:train samples: (1284,)
2021-01-27 00:47:55:INFO:valid samples: (229,)
2021-01-27 00:47:56:INFO:test samples: (686,)
2021-01-27 00:47:56:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:47:56:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:47:56:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:47:56:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:47:56:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:47:56:INFO:loading file None
2021-01-27 00:47:56:INFO:loading file None
2021-01-27 00:47:56:INFO:loading file None
2021-01-27 00:47:56:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:47:56:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:47:56:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:47:59:INFO:The model has 110620273 trainable parameters
2021-01-27 00:48:08:INFO:TRAIN-(misa) (1/1/4)>> loss: 4.6547  Has0_acc_2: 0.6254  Has0_F1_score: 0.6454  Non0_acc_2: 0.6271  Non0_F1_score: 0.6490  Mult_acc_5: 0.2188  Mult_acc_7: 0.2188  MAE: 1.2350  Corr: 0.3228 
2021-01-27 00:48:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7664  Non0_acc_2: 0.8009  Non0_F1_score: 0.7998  Mult_acc_5: 0.2882  Mult_acc_7: 0.2882  MAE: 1.0614  Corr: 0.6911  Loss: 1.5593 
2021-01-27 00:48:20:INFO:TRAIN-(misa) (1/2/4)>> loss: 2.9005  Has0_acc_2: 0.8154  Has0_F1_score: 0.8151  Non0_acc_2: 0.8310  Non0_F1_score: 0.8312  Mult_acc_5: 0.3559  Mult_acc_7: 0.3388  MAE: 0.8218  Corr: 0.7341 
2021-01-27 00:48:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7265  Non0_acc_2: 0.7593  Non0_F1_score: 0.7609  Mult_acc_5: 0.3450  Mult_acc_7: 0.2926  MAE: 1.0437  Corr: 0.7689  Loss: 1.6734 
2021-01-27 00:48:30:INFO:TRAIN-(misa) (2/3/4)>> loss: 1.9138  Has0_acc_2: 0.8629  Has0_F1_score: 0.8625  Non0_acc_2: 0.8773  Non0_F1_score: 0.8772  Mult_acc_5: 0.4431  Mult_acc_7: 0.4097  MAE: 0.6814  Corr: 0.8250 
2021-01-27 00:48:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.4629  Mult_acc_7: 0.3668  MAE: 0.8457  Corr: 0.7266  Loss: 1.3204 
2021-01-27 00:48:42:INFO:TRAIN-(misa) (1/4/4)>> loss: 1.2020  Has0_acc_2: 0.9003  Has0_F1_score: 0.9001  Non0_acc_2: 0.9180  Non0_F1_score: 0.9180  Mult_acc_5: 0.6012  Mult_acc_7: 0.5498  MAE: 0.4931  Corr: 0.9075 
2021-01-27 00:48:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7982  Non0_acc_2: 0.8194  Non0_F1_score: 0.8196  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.7937  Corr: 0.7638  Loss: 1.1292 
2021-01-27 00:48:54:INFO:TRAIN-(misa) (1/5/4)>> loss: 0.8312  Has0_acc_2: 0.9151  Has0_F1_score: 0.9150  Non0_acc_2: 0.9318  Non0_F1_score: 0.9319  Mult_acc_5: 0.6495  Mult_acc_7: 0.5896  MAE: 0.4288  Corr: 0.9319 
2021-01-27 00:48:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7710  Non0_acc_2: 0.8056  Non0_F1_score: 0.8046  Mult_acc_5: 0.4803  Mult_acc_7: 0.3843  MAE: 0.8222  Corr: 0.7712  Loss: 1.2173 
2021-01-27 00:49:05:INFO:TRAIN-(misa) (2/6/4)>> loss: 0.6654  Has0_acc_2: 0.9276  Has0_F1_score: 0.9273  Non0_acc_2: 0.9464  Non0_F1_score: 0.9463  Mult_acc_5: 0.6776  Mult_acc_7: 0.6238  MAE: 0.3855  Corr: 0.9464 
2021-01-27 00:49:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8016  Non0_acc_2: 0.8380  Non0_F1_score: 0.8372  Mult_acc_5: 0.4803  Mult_acc_7: 0.3843  MAE: 0.7681  Corr: 0.7835  Loss: 1.1237 
2021-01-27 00:49:16:INFO:TRAIN-(misa) (1/7/4)>> loss: 0.5885  Has0_acc_2: 0.9276  Has0_F1_score: 0.9273  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.6752  Mult_acc_7: 0.6199  MAE: 0.3824  Corr: 0.9465 
2021-01-27 00:49:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7642  Has0_F1_score: 0.7630  Non0_acc_2: 0.8009  Non0_F1_score: 0.8003  Mult_acc_5: 0.4367  Mult_acc_7: 0.2926  MAE: 0.9912  Corr: 0.7756  Loss: 1.6547 
2021-01-27 00:49:27:INFO:TRAIN-(misa) (2/8/4)>> loss: 0.6312  Has0_acc_2: 0.9252  Has0_F1_score: 0.9250  Non0_acc_2: 0.9374  Non0_F1_score: 0.9374  Mult_acc_5: 0.6410  Mult_acc_7: 0.5841  MAE: 0.4256  Corr: 0.9346 
2021-01-27 00:49:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.5066  Mult_acc_7: 0.4192  MAE: 0.7645  Corr: 0.7742  Loss: 1.1430 
2021-01-27 00:49:37:INFO:TRAIN-(misa) (3/9/4)>> loss: 0.4832  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7040  Mult_acc_7: 0.6456  MAE: 0.3603  Corr: 0.9541 
2021-01-27 00:49:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8197  Non0_acc_2: 0.8194  Non0_F1_score: 0.8228  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7847  Corr: 0.7897  Loss: 1.1495 
2021-01-27 00:49:48:INFO:TRAIN-(misa) (4/10/4)>> loss: 0.4886  Has0_acc_2: 0.9206  Has0_F1_score: 0.9205  Non0_acc_2: 0.9374  Non0_F1_score: 0.9375  Mult_acc_5: 0.6916  Mult_acc_7: 0.6215  MAE: 0.3855  Corr: 0.9485 
2021-01-27 00:49:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8018  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7489  Corr: 0.7810  Loss: 1.0999 
2021-01-27 00:49:59:INFO:TRAIN-(misa) (1/11/4)>> loss: 0.4348  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7508  Mult_acc_7: 0.6939  MAE: 0.3335  Corr: 0.9596 
2021-01-27 00:50:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.8194  Non0_F1_score: 0.8202  Mult_acc_5: 0.5328  Mult_acc_7: 0.4367  MAE: 0.7344  Corr: 0.7917  Loss: 1.1265 
2021-01-27 00:50:10:INFO:TRAIN-(misa) (2/12/4)>> loss: 0.4372  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6908  Mult_acc_7: 0.6308  MAE: 0.3767  Corr: 0.9509 
2021-01-27 00:50:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7604  Corr: 0.7658  Loss: 1.2281 
2021-01-27 00:50:20:INFO:TRAIN-(misa) (3/13/4)>> loss: 0.3607  Has0_acc_2: 0.9424  Has0_F1_score: 0.9423  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7609  Mult_acc_7: 0.7103  MAE: 0.3037  Corr: 0.9678 
2021-01-27 00:50:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5153  Mult_acc_7: 0.4279  MAE: 0.7401  Corr: 0.7790  Loss: 1.0819 
2021-01-27 00:50:33:INFO:TRAIN-(misa) (1/14/4)>> loss: 0.3693  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7484  Mult_acc_7: 0.6916  MAE: 0.3187  Corr: 0.9647 
2021-01-27 00:50:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8016  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.5415  Mult_acc_7: 0.4323  MAE: 0.7687  Corr: 0.7780  Loss: 1.1957 
2021-01-27 00:50:43:INFO:TRAIN-(misa) (2/15/4)>> loss: 0.3113  Has0_acc_2: 0.9377  Has0_F1_score: 0.9375  Non0_acc_2: 0.9561  Non0_F1_score: 0.9561  Mult_acc_5: 0.7609  Mult_acc_7: 0.7087  MAE: 0.2915  Corr: 0.9701 
2021-01-27 00:50:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8241  Non0_F1_score: 0.8235  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7398  Corr: 0.7777  Loss: 1.1382 
2021-01-27 00:50:54:INFO:TRAIN-(misa) (3/16/4)>> loss: 0.3024  Has0_acc_2: 0.9502  Has0_F1_score: 0.9501  Non0_acc_2: 0.9626  Non0_F1_score: 0.9626  Mult_acc_5: 0.7656  Mult_acc_7: 0.7188  MAE: 0.2842  Corr: 0.9706 
2021-01-27 00:50:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7803  Non0_acc_2: 0.8194  Non0_F1_score: 0.8188  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.8444  Corr: 0.7668  Loss: 1.4065 
2021-01-27 00:51:05:INFO:TRAIN-(misa) (4/17/4)>> loss: 0.3133  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7601  Mult_acc_7: 0.7072  MAE: 0.3024  Corr: 0.9672 
2021-01-27 00:51:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8027  Non0_acc_2: 0.8194  Non0_F1_score: 0.8196  Mult_acc_5: 0.5459  Mult_acc_7: 0.4454  MAE: 0.7400  Corr: 0.7773  Loss: 1.1339 
2021-01-27 00:51:15:INFO:TRAIN-(misa) (5/18/4)>> loss: 0.2863  Has0_acc_2: 0.9502  Has0_F1_score: 0.9501  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.7773  Mult_acc_7: 0.7360  MAE: 0.2823  Corr: 0.9718 
2021-01-27 00:51:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8176  Non0_acc_2: 0.8148  Non0_F1_score: 0.8205  Mult_acc_5: 0.4934  Mult_acc_7: 0.3624  MAE: 0.8313  Corr: 0.7816  Loss: 1.2647 
2021-01-27 00:51:26:INFO:TRAIN-(misa) (6/19/4)>> loss: 0.3017  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.7399  Mult_acc_7: 0.6924  MAE: 0.3125  Corr: 0.9660 
2021-01-27 00:51:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8025  Non0_acc_2: 0.8241  Non0_F1_score: 0.8241  Mult_acc_5: 0.5502  Mult_acc_7: 0.4236  MAE: 0.7653  Corr: 0.7751  Loss: 1.2364 
2021-01-27 00:51:37:INFO:TRAIN-(misa) (7/20/4)>> loss: 0.2795  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9626  Non0_F1_score: 0.9626  Mult_acc_5: 0.7570  Mult_acc_7: 0.7103  MAE: 0.2868  Corr: 0.9713 
2021-01-27 00:51:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8287  Non0_F1_score: 0.8279  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7389  Corr: 0.7805  Loss: 1.0638 
2021-01-27 00:51:48:INFO:TRAIN-(misa) (1/21/4)>> loss: 0.2438  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7967  Mult_acc_7: 0.7547  MAE: 0.2519  Corr: 0.9781 
2021-01-27 00:51:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5633  Mult_acc_7: 0.4498  MAE: 0.7318  Corr: 0.7817  Loss: 1.1314 
2021-01-27 00:51:59:INFO:TRAIN-(misa) (2/22/4)>> loss: 0.2570  Has0_acc_2: 0.9494  Has0_F1_score: 0.9492  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7702  Mult_acc_7: 0.7165  MAE: 0.2872  Corr: 0.9712 
2021-01-27 00:52:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8148  Non0_acc_2: 0.8472  Non0_F1_score: 0.8464  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7540  Corr: 0.7798  Loss: 1.1792 
2021-01-27 00:52:10:INFO:TRAIN-(misa) (3/23/4)>> loss: 0.2343  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7913  Mult_acc_7: 0.7508  MAE: 0.2610  Corr: 0.9758 
2021-01-27 00:52:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8106  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5459  Mult_acc_7: 0.4498  MAE: 0.7212  Corr: 0.7767  Loss: 1.0653 
2021-01-27 00:52:20:INFO:TRAIN-(misa) (4/24/4)>> loss: 0.2019  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8014  Mult_acc_7: 0.7617  MAE: 0.2309  Corr: 0.9813 
2021-01-27 00:52:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7455  Corr: 0.7728  Loss: 1.1259 
2021-01-27 00:52:31:INFO:TRAIN-(misa) (5/25/4)>> loss: 0.2134  Has0_acc_2: 0.9486  Has0_F1_score: 0.9484  Non0_acc_2: 0.9708  Non0_F1_score: 0.9707  Mult_acc_5: 0.8061  Mult_acc_7: 0.7648  MAE: 0.2501  Corr: 0.9779 
2021-01-27 00:52:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7999  Non0_acc_2: 0.8148  Non0_F1_score: 0.8165  Mult_acc_5: 0.5328  Mult_acc_7: 0.4279  MAE: 0.7501  Corr: 0.7754  Loss: 1.1017 
2021-01-27 00:52:41:INFO:TRAIN-(misa) (6/26/4)>> loss: 0.2074  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.8131  Mult_acc_7: 0.7671  MAE: 0.2485  Corr: 0.9783 
2021-01-27 00:52:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8239  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5153  Mult_acc_7: 0.4236  MAE: 0.7412  Corr: 0.7803  Loss: 1.0598 
2021-01-27 00:52:53:INFO:TRAIN-(misa) (1/27/4)>> loss: 0.2027  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.7913  Mult_acc_7: 0.7414  MAE: 0.2416  Corr: 0.9800 
2021-01-27 00:52:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8090  Non0_acc_2: 0.8194  Non0_F1_score: 0.8214  Mult_acc_5: 0.5502  Mult_acc_7: 0.4541  MAE: 0.7273  Corr: 0.7826  Loss: 1.1099 
2021-01-27 00:53:04:INFO:TRAIN-(misa) (2/28/4)>> loss: 0.1919  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8100  Mult_acc_7: 0.7625  MAE: 0.2329  Corr: 0.9810 
2021-01-27 00:53:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.5328  Mult_acc_7: 0.4454  MAE: 0.7238  Corr: 0.7790  Loss: 1.1030 
2021-01-27 00:53:16:INFO:TRAIN-(misa) (3/29/4)>> loss: 0.1749  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8310  Mult_acc_7: 0.7960  MAE: 0.2147  Corr: 0.9835 
2021-01-27 00:53:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.5153  Mult_acc_7: 0.4323  MAE: 0.7464  Corr: 0.7673  Loss: 1.1478 
2021-01-27 00:53:27:INFO:TRAIN-(misa) (4/30/4)>> loss: 0.1603  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8466  Mult_acc_7: 0.8022  MAE: 0.2060  Corr: 0.9849 
2021-01-27 00:53:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8070  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5284  Mult_acc_7: 0.4498  MAE: 0.7503  Corr: 0.7629  Loss: 1.2467 
2021-01-27 00:53:38:INFO:TRAIN-(misa) (5/31/4)>> loss: 0.1575  Has0_acc_2: 0.9727  Has0_F1_score: 0.9727  Non0_acc_2: 0.9894  Non0_F1_score: 0.9894  Mult_acc_5: 0.8411  Mult_acc_7: 0.7936  MAE: 0.2031  Corr: 0.9855 
2021-01-27 00:53:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8241  Non0_F1_score: 0.8235  Mult_acc_5: 0.4934  Mult_acc_7: 0.4061  MAE: 0.7686  Corr: 0.7643  Loss: 1.1202 
2021-01-27 00:53:49:INFO:TRAIN-(misa) (6/32/4)>> loss: 0.1685  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.8053  Mult_acc_7: 0.7601  MAE: 0.2314  Corr: 0.9816 
2021-01-27 00:53:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7807  Non0_acc_2: 0.8056  Non0_F1_score: 0.8058  Mult_acc_5: 0.4891  Mult_acc_7: 0.4061  MAE: 0.7684  Corr: 0.7614  Loss: 1.1223 
2021-01-27 00:53:59:INFO:TRAIN-(misa) (7/33/4)>> loss: 0.1497  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8474  Mult_acc_7: 0.8123  MAE: 0.2035  Corr: 0.9858 
2021-01-27 00:54:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7931  Non0_acc_2: 0.8194  Non0_F1_score: 0.8189  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7605  Corr: 0.7696  Loss: 1.1259 
2021-01-27 00:54:10:INFO:TRAIN-(misa) (8/34/4)>> loss: 0.1438  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8660  Mult_acc_7: 0.8294  MAE: 0.1845  Corr: 0.9877 
2021-01-27 00:54:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7892  Non0_acc_2: 0.8148  Non0_F1_score: 0.8148  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7491  Corr: 0.7711  Loss: 1.1010 
2021-01-27 00:54:13:INFO:TEST-(misa) >>  Has0_acc_2: 0.8047  Has0_F1_score: 0.8053  Non0_acc_2: 0.8216  Non0_F1_score: 0.8216  Mult_acc_5: 0.4636  Mult_acc_7: 0.4067  MAE: 0.7884  Corr: 0.7560  Loss: 1.1413 
2021-01-27 00:54:13:INFO:Start running misa...
2021-01-27 00:54:13:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1115}>
2021-01-27 00:54:13:INFO:Let's use 1 GPUs!
2021-01-27 00:54:13:INFO:train samples: (1284,)
2021-01-27 00:54:14:INFO:valid samples: (229,)
2021-01-27 00:54:14:INFO:test samples: (686,)
2021-01-27 00:54:14:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:54:14:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:54:14:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:54:14:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:54:14:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:54:14:INFO:loading file None
2021-01-27 00:54:14:INFO:loading file None
2021-01-27 00:54:14:INFO:loading file None
2021-01-27 00:54:14:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:54:14:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:54:14:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:54:18:INFO:The model has 110620273 trainable parameters
2021-01-27 00:54:28:INFO:TRAIN-(misa) (1/1/5)>> loss: 4.3330  Has0_acc_2: 0.6340  Has0_F1_score: 0.6412  Non0_acc_2: 0.6385  Non0_F1_score: 0.6471  Mult_acc_5: 0.2118  Mult_acc_7: 0.2111  MAE: 1.1868  Corr: 0.3854 
2021-01-27 00:54:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7999  Non0_acc_2: 0.8009  Non0_F1_score: 0.8067  Mult_acc_5: 0.3319  Mult_acc_7: 0.2707  MAE: 1.0654  Corr: 0.6519  Loss: 1.8546 
2021-01-27 00:54:41:INFO:TRAIN-(misa) (1/2/5)>> loss: 2.7335  Has0_acc_2: 0.8185  Has0_F1_score: 0.8178  Non0_acc_2: 0.8351  Non0_F1_score: 0.8348  Mult_acc_5: 0.3995  Mult_acc_7: 0.3785  MAE: 0.8086  Corr: 0.7277 
2021-01-27 00:54:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8017  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4105  Mult_acc_7: 0.3362  MAE: 0.9001  Corr: 0.7123  Loss: 1.4486 
2021-01-27 00:54:53:INFO:TRAIN-(misa) (1/3/5)>> loss: 1.7401  Has0_acc_2: 0.8785  Has0_F1_score: 0.8781  Non0_acc_2: 0.8952  Non0_F1_score: 0.8951  Mult_acc_5: 0.5241  Mult_acc_7: 0.4751  MAE: 0.5958  Corr: 0.8614 
2021-01-27 00:54:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7709  Non0_acc_2: 0.8056  Non0_F1_score: 0.8045  Mult_acc_5: 0.3930  Mult_acc_7: 0.3319  MAE: 0.8541  Corr: 0.7446  Loss: 1.3117 
2021-01-27 00:55:04:INFO:TRAIN-(misa) (1/4/5)>> loss: 1.2413  Has0_acc_2: 0.9034  Has0_F1_score: 0.9033  Non0_acc_2: 0.9196  Non0_F1_score: 0.9196  Mult_acc_5: 0.5724  Mult_acc_7: 0.5234  MAE: 0.5008  Corr: 0.9071 
2021-01-27 00:55:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8018  Non0_acc_2: 0.8333  Non0_F1_score: 0.8328  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.8082  Corr: 0.7528  Loss: 1.3411 
2021-01-27 00:55:15:INFO:TRAIN-(misa) (2/5/5)>> loss: 0.9410  Has0_acc_2: 0.9097  Has0_F1_score: 0.9094  Non0_acc_2: 0.9277  Non0_F1_score: 0.9276  Mult_acc_5: 0.6067  Mult_acc_7: 0.5483  MAE: 0.4645  Corr: 0.9240 
2021-01-27 00:55:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8084  Non0_acc_2: 0.8009  Non0_F1_score: 0.8060  Mult_acc_5: 0.4585  Mult_acc_7: 0.3581  MAE: 0.9117  Corr: 0.7628  Loss: 1.4895 
2021-01-27 00:55:25:INFO:TRAIN-(misa) (3/6/5)>> loss: 0.9031  Has0_acc_2: 0.9182  Has0_F1_score: 0.9183  Non0_acc_2: 0.9253  Non0_F1_score: 0.9254  Mult_acc_5: 0.5981  Mult_acc_7: 0.5397  MAE: 0.4916  Corr: 0.9156 
2021-01-27 00:55:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.7973  Corr: 0.7634  Loss: 1.1687 
2021-01-27 00:55:37:INFO:TRAIN-(misa) (1/7/5)>> loss: 0.6400  Has0_acc_2: 0.9276  Has0_F1_score: 0.9274  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.7087  Mult_acc_7: 0.6534  MAE: 0.3650  Corr: 0.9519 
2021-01-27 00:55:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7534  Corr: 0.7774  Loss: 1.1588 
2021-01-27 00:55:49:INFO:TRAIN-(misa) (1/8/5)>> loss: 0.5430  Has0_acc_2: 0.9369  Has0_F1_score: 0.9367  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7305  Mult_acc_7: 0.6682  MAE: 0.3394  Corr: 0.9597 
2021-01-27 00:55:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7541  Corr: 0.7769  Loss: 1.0653 
2021-01-27 00:56:00:INFO:TRAIN-(misa) (1/9/5)>> loss: 0.5105  Has0_acc_2: 0.9307  Has0_F1_score: 0.9305  Non0_acc_2: 0.9488  Non0_F1_score: 0.9488  Mult_acc_5: 0.7266  Mult_acc_7: 0.6690  MAE: 0.3339  Corr: 0.9598 
2021-01-27 00:56:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5328  Mult_acc_7: 0.4454  MAE: 0.7427  Corr: 0.7777  Loss: 1.1103 
2021-01-27 00:56:11:INFO:TRAIN-(misa) (2/10/5)>> loss: 0.4724  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9504  Non0_F1_score: 0.9505  Mult_acc_5: 0.7259  Mult_acc_7: 0.6612  MAE: 0.3403  Corr: 0.9597 
2021-01-27 00:56:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7760  Corr: 0.7659  Loss: 1.1978 
2021-01-27 00:56:22:INFO:TRAIN-(misa) (3/11/5)>> loss: 0.4259  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9578  Non0_F1_score: 0.9577  Mult_acc_5: 0.7679  Mult_acc_7: 0.7079  MAE: 0.3169  Corr: 0.9637 
2021-01-27 00:56:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7681  Corr: 0.7733  Loss: 1.1605 
2021-01-27 00:56:32:INFO:TRAIN-(misa) (4/12/5)>> loss: 0.3841  Has0_acc_2: 0.9361  Has0_F1_score: 0.9360  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7484  Mult_acc_7: 0.6947  MAE: 0.3166  Corr: 0.9654 
2021-01-27 00:56:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8404  Non0_acc_2: 0.8472  Non0_F1_score: 0.8496  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.8095  Corr: 0.7808  Loss: 1.2491 
2021-01-27 00:56:43:INFO:TRAIN-(misa) (5/13/5)>> loss: 0.3809  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9488  Non0_F1_score: 0.9488  Mult_acc_5: 0.7336  Mult_acc_7: 0.6830  MAE: 0.3247  Corr: 0.9630 
2021-01-27 00:56:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.8463  Corr: 0.7558  Loss: 1.2921 
2021-01-27 00:56:54:INFO:TRAIN-(misa) (6/14/5)>> loss: 0.3372  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7484  Mult_acc_7: 0.7002  MAE: 0.2845  Corr: 0.9712 
2021-01-27 00:56:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7253  Corr: 0.7859  Loss: 1.0423 
2021-01-27 00:57:07:INFO:TRAIN-(misa) (1/15/5)>> loss: 0.2951  Has0_acc_2: 0.9540  Has0_F1_score: 0.9540  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.7975  Mult_acc_7: 0.7461  MAE: 0.2533  Corr: 0.9774 
2021-01-27 00:57:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8314  Non0_acc_2: 0.8426  Non0_F1_score: 0.8449  Mult_acc_5: 0.5109  Mult_acc_7: 0.4105  MAE: 0.7945  Corr: 0.7769  Loss: 1.2659 
2021-01-27 00:57:18:INFO:TRAIN-(misa) (2/16/5)>> loss: 0.3313  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9553  Non0_F1_score: 0.9554  Mult_acc_5: 0.7702  Mult_acc_7: 0.7118  MAE: 0.2990  Corr: 0.9684 
2021-01-27 00:57:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5546  Mult_acc_7: 0.4585  MAE: 0.7352  Corr: 0.7851  Loss: 1.0885 
2021-01-27 00:57:29:INFO:TRAIN-(misa) (3/17/5)>> loss: 0.2738  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.7905  Mult_acc_7: 0.7407  MAE: 0.2521  Corr: 0.9777 
2021-01-27 00:57:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8450  Non0_acc_2: 0.8472  Non0_F1_score: 0.8496  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7656  Corr: 0.7908  Loss: 1.1699 
2021-01-27 00:57:40:INFO:TRAIN-(misa) (4/18/5)>> loss: 0.2859  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7578  Mult_acc_7: 0.7087  MAE: 0.2764  Corr: 0.9734 
2021-01-27 00:57:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5459  Mult_acc_7: 0.4629  MAE: 0.7128  Corr: 0.7957  Loss: 1.0730 
2021-01-27 00:57:51:INFO:TRAIN-(misa) (5/19/5)>> loss: 0.2557  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.8107  Mult_acc_7: 0.7539  MAE: 0.2487  Corr: 0.9778 
2021-01-27 00:57:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8314  Non0_acc_2: 0.8241  Non0_F1_score: 0.8302  Mult_acc_5: 0.4629  Mult_acc_7: 0.3668  MAE: 0.8290  Corr: 0.7925  Loss: 1.1932 
2021-01-27 00:58:02:INFO:TRAIN-(misa) (6/20/5)>> loss: 0.2866  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7562  Mult_acc_7: 0.6986  MAE: 0.2948  Corr: 0.9696 
2021-01-27 00:58:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8132  Non0_acc_2: 0.8241  Non0_F1_score: 0.8257  Mult_acc_5: 0.5197  Mult_acc_7: 0.4279  MAE: 0.7557  Corr: 0.7869  Loss: 1.0680 
2021-01-27 00:58:12:INFO:TRAIN-(misa) (7/21/5)>> loss: 0.2327  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8123  Mult_acc_7: 0.7702  MAE: 0.2340  Corr: 0.9803 
2021-01-27 00:58:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5328  Mult_acc_7: 0.4410  MAE: 0.7346  Corr: 0.7873  Loss: 1.0536 
2021-01-27 00:58:24:INFO:TRAIN-(misa) (8/22/5)>> loss: 0.2248  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8139  Mult_acc_7: 0.7702  MAE: 0.2462  Corr: 0.9789 
2021-01-27 00:58:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5459  Mult_acc_7: 0.4585  MAE: 0.7205  Corr: 0.7914  Loss: 1.0098 
2021-01-27 00:58:36:INFO:TRAIN-(misa) (1/23/5)>> loss: 0.2094  Has0_acc_2: 0.9626  Has0_F1_score: 0.9626  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8209  Mult_acc_7: 0.7773  MAE: 0.2182  Corr: 0.9832 
2021-01-27 00:58:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7233  Corr: 0.7918  Loss: 1.0343 
2021-01-27 00:58:47:INFO:TRAIN-(misa) (2/24/5)>> loss: 0.2126  Has0_acc_2: 0.9572  Has0_F1_score: 0.9570  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8232  Mult_acc_7: 0.7710  MAE: 0.2306  Corr: 0.9819 
2021-01-27 00:58:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8166  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7367  Corr: 0.7892  Loss: 1.1073 
2021-01-27 00:58:58:INFO:TRAIN-(misa) (3/25/5)>> loss: 0.2221  Has0_acc_2: 0.9533  Has0_F1_score: 0.9532  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8139  Mult_acc_7: 0.7531  MAE: 0.2521  Corr: 0.9778 
2021-01-27 00:58:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5415  Mult_acc_7: 0.4541  MAE: 0.7355  Corr: 0.7872  Loss: 1.1145 
2021-01-27 00:59:08:INFO:TRAIN-(misa) (4/26/5)>> loss: 0.1905  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8349  Mult_acc_7: 0.7843  MAE: 0.2158  Corr: 0.9831 
2021-01-27 00:59:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7659  Corr: 0.7902  Loss: 1.0749 
2021-01-27 00:59:18:INFO:TRAIN-(misa) (5/27/5)>> loss: 0.2088  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.8069  Mult_acc_7: 0.7640  MAE: 0.2489  Corr: 0.9785 
2021-01-27 00:59:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8070  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5546  Mult_acc_7: 0.4672  MAE: 0.7180  Corr: 0.7931  Loss: 0.9881 
2021-01-27 00:59:30:INFO:TRAIN-(misa) (1/28/5)>> loss: 0.1807  Has0_acc_2: 0.9572  Has0_F1_score: 0.9570  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8349  Mult_acc_7: 0.7905  MAE: 0.2106  Corr: 0.9840 
2021-01-27 00:59:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7384  Corr: 0.7881  Loss: 1.0818 
2021-01-27 00:59:41:INFO:TRAIN-(misa) (2/29/5)>> loss: 0.1784  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8248  Mult_acc_7: 0.7788  MAE: 0.2125  Corr: 0.9838 
2021-01-27 00:59:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5109  Mult_acc_7: 0.4279  MAE: 0.7416  Corr: 0.7956  Loss: 1.0191 
2021-01-27 00:59:51:INFO:TRAIN-(misa) (3/30/5)>> loss: 0.1775  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8069  Mult_acc_7: 0.7593  MAE: 0.2190  Corr: 0.9830 
2021-01-27 00:59:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7142  Corr: 0.7959  Loss: 1.0135 
2021-01-27 01:00:01:INFO:TRAIN-(misa) (4/31/5)>> loss: 0.1638  Has0_acc_2: 0.9657  Has0_F1_score: 0.9657  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8474  Mult_acc_7: 0.8045  MAE: 0.2006  Corr: 0.9852 
2021-01-27 01:00:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8565  Non0_F1_score: 0.8577  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7177  Corr: 0.7968  Loss: 1.0033 
2021-01-27 01:00:12:INFO:TRAIN-(misa) (5/32/5)>> loss: 0.1563  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8442  Mult_acc_7: 0.8084  MAE: 0.1973  Corr: 0.9862 
2021-01-27 01:00:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7278  Corr: 0.7905  Loss: 1.0519 
2021-01-27 01:00:23:INFO:TRAIN-(misa) (6/33/5)>> loss: 0.1515  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8520  Mult_acc_7: 0.8123  MAE: 0.1904  Corr: 0.9868 
2021-01-27 01:00:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8121  Non0_acc_2: 0.8333  Non0_F1_score: 0.8342  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7579  Corr: 0.7864  Loss: 1.1456 
2021-01-27 01:00:33:INFO:TRAIN-(misa) (7/34/5)>> loss: 0.1683  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8318  Mult_acc_7: 0.7812  MAE: 0.2212  Corr: 0.9831 
2021-01-27 01:00:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8302  Non0_acc_2: 0.8519  Non0_F1_score: 0.8532  Mult_acc_5: 0.5502  Mult_acc_7: 0.4541  MAE: 0.7165  Corr: 0.7929  Loss: 1.0602 
2021-01-27 01:00:44:INFO:TRAIN-(misa) (8/35/5)>> loss: 0.1459  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8427  Mult_acc_7: 0.7967  MAE: 0.1947  Corr: 0.9868 
2021-01-27 01:00:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8426  Non0_F1_score: 0.8437  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7326  Corr: 0.7882  Loss: 1.0438 
2021-01-27 01:00:46:INFO:TEST-(misa) >>  Has0_acc_2: 0.8163  Has0_F1_score: 0.8169  Non0_acc_2: 0.8338  Non0_F1_score: 0.8338  Mult_acc_5: 0.4854  Mult_acc_7: 0.4242  MAE: 0.7500  Corr: 0.7860  Loss: 1.0296 
2021-01-27 01:00:46:INFO:Results are saved to results/results/mosi-misa-regression.csv...
