2021-01-27 00:32:25:INFO:Start running misa...
2021-01-27 00:32:25:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1111}>
2021-01-27 00:32:25:INFO:Let's use 1 GPUs!
2021-01-27 00:32:26:INFO:train samples: (1284,)
2021-01-27 00:32:26:INFO:valid samples: (229,)
2021-01-27 00:32:27:INFO:test samples: (686,)
2021-01-27 00:32:27:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:32:27:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:32:27:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:32:27:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:32:27:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:32:27:INFO:loading file None
2021-01-27 00:32:27:INFO:loading file None
2021-01-27 00:32:27:INFO:loading file None
2021-01-27 00:32:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:32:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:32:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:32:34:INFO:The model has 110620273 trainable parameters
2021-01-27 00:32:44:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.3140  Has0_acc_2: 0.6308  Has0_F1_score: 0.6489  Non0_acc_2: 0.6239  Non0_F1_score: 0.6424  Mult_acc_5: 0.2134  Mult_acc_7: 0.2126  MAE: 1.2070  Corr: 0.3669 
2021-01-27 00:32:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8146  Non0_acc_2: 0.8333  Non0_F1_score: 0.8367  Mult_acc_5: 0.3930  Mult_acc_7: 0.3188  MAE: 1.0453  Corr: 0.6607  Loss: 1.8356 
2021-01-27 00:32:54:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5892  Has0_acc_2: 0.8232  Has0_F1_score: 0.8224  Non0_acc_2: 0.8432  Non0_F1_score: 0.8429  Mult_acc_5: 0.3847  Mult_acc_7: 0.3676  MAE: 0.7930  Corr: 0.7499 
2021-01-27 00:32:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7761  Non0_acc_2: 0.7731  Non0_F1_score: 0.7815  Mult_acc_5: 0.4236  Mult_acc_7: 0.3493  MAE: 0.9118  Corr: 0.7495  Loss: 1.3924 
2021-01-27 00:32:58:INFO:Start running misa...
2021-01-27 00:32:58:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1111}>
2021-01-27 00:32:58:INFO:Let's use 1 GPUs!
2021-01-27 00:32:59:INFO:train samples: (1284,)
2021-01-27 00:32:59:INFO:valid samples: (229,)
2021-01-27 00:33:00:INFO:test samples: (686,)
2021-01-27 00:33:00:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:33:00:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:33:00:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:33:00:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:33:00:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:33:00:INFO:loading file None
2021-01-27 00:33:00:INFO:loading file None
2021-01-27 00:33:00:INFO:loading file None
2021-01-27 00:33:00:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:33:00:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:33:00:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:33:06:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.6610  Has0_acc_2: 0.8606  Has0_F1_score: 0.8601  Non0_acc_2: 0.8814  Non0_F1_score: 0.8814  Mult_acc_5: 0.5195  Mult_acc_7: 0.4805  MAE: 0.6168  Corr: 0.8530 
2021-01-27 00:33:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8186  Non0_acc_2: 0.8333  Non0_F1_score: 0.8362  Mult_acc_5: 0.4498  Mult_acc_7: 0.3624  MAE: 0.8179  Corr: 0.7762  Loss: 1.1494 
2021-01-27 00:33:07:INFO:The model has 110621043 trainable parameters
2021-01-27 00:33:17:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.0961  Has0_acc_2: 0.5537  Has0_F1_score: 0.5655  Non0_acc_2: 0.1706  Non0_F1_score: 0.1456  Acc_3: 0.5343  F1_score_3: 0.5558 
2021-01-27 00:33:17:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.1175  Has0_acc_2: 0.8902  Has0_F1_score: 0.8900  Non0_acc_2: 0.9058  Non0_F1_score: 0.9059  Mult_acc_5: 0.5779  Mult_acc_7: 0.5249  MAE: 0.5249  Corr: 0.8985 
2021-01-27 00:33:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6550  Has0_F1_score: 0.6916  Non0_acc_2: 0.1574  Non0_F1_score: 0.1003  Acc_3: 0.6507  F1_score_3: 0.6974  Loss: 0.7992 
2021-01-27 00:33:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7842  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4672  Mult_acc_7: 0.3712  MAE: 0.8392  Corr: 0.7544  Loss: 1.3621 
2021-01-27 00:33:28:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.8909  Has0_acc_2: 0.8855  Has0_F1_score: 0.8851  Non0_acc_2: 0.9058  Non0_F1_score: 0.9056  Mult_acc_5: 0.6036  Mult_acc_7: 0.5623  MAE: 0.4864  Corr: 0.9141 
2021-01-27 00:33:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7939  Non0_acc_2: 0.7870  Non0_F1_score: 0.7953  Mult_acc_5: 0.4017  Mult_acc_7: 0.2969  MAE: 0.9427  Corr: 0.7741  Loss: 1.4849 
2021-01-27 00:33:28:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.0588  Has0_acc_2: 0.7399  Has0_F1_score: 0.7453  Non0_acc_2: 0.2794  Non0_F1_score: 0.2466  Acc_3: 0.7251  F1_score_3: 0.7447 
2021-01-27 00:33:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7637  Non0_acc_2: 0.2269  Non0_F1_score: 0.1678  Acc_3: 0.7336  F1_score_3: 0.7676  Loss: 0.6671 
2021-01-27 00:33:38:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.7376  Has0_acc_2: 0.9089  Has0_F1_score: 0.9087  Non0_acc_2: 0.9261  Non0_F1_score: 0.9261  Mult_acc_5: 0.6176  Mult_acc_7: 0.5584  MAE: 0.4622  Corr: 0.9244 
2021-01-27 00:33:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8025  Non0_acc_2: 0.8241  Non0_F1_score: 0.8241  Mult_acc_5: 0.4934  Mult_acc_7: 0.4017  MAE: 0.7835  Corr: 0.7677  Loss: 1.1625 
2021-01-27 00:33:40:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.2448  Has0_acc_2: 0.9260  Has0_F1_score: 0.9262  Non0_acc_2: 0.4135  Non0_F1_score: 0.4089  Acc_3: 0.9011  F1_score_3: 0.9201 
2021-01-27 00:33:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.3704  Non0_F1_score: 0.3948  Acc_3: 0.7817  F1_score_3: 0.8023  Loss: 0.6161 
2021-01-27 00:33:49:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.5432  Has0_acc_2: 0.9307  Has0_F1_score: 0.9306  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.6846  Mult_acc_7: 0.6184  MAE: 0.3809  Corr: 0.9476 
2021-01-27 00:33:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8130  Non0_acc_2: 0.8056  Non0_F1_score: 0.8108  Mult_acc_5: 0.4585  Mult_acc_7: 0.3450  MAE: 0.8500  Corr: 0.7682  Loss: 1.3739 
2021-01-27 00:33:52:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.7902  Has0_acc_2: 0.9486  Has0_F1_score: 0.9486  Non0_acc_2: 0.4330  Non0_F1_score: 0.4357  Acc_3: 0.9237  F1_score_3: 0.9430 
2021-01-27 00:33:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7757  Non0_acc_2: 0.2639  Non0_F1_score: 0.2243  Acc_3: 0.7424  F1_score_3: 0.7702  Loss: 0.9607 
2021-01-27 00:33:59:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.4988  Has0_acc_2: 0.9237  Has0_F1_score: 0.9235  Non0_acc_2: 0.9407  Non0_F1_score: 0.9407  Mult_acc_5: 0.6947  Mult_acc_7: 0.6363  MAE: 0.3787  Corr: 0.9490 
2021-01-27 00:34:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8340  Non0_acc_2: 0.8287  Non0_F1_score: 0.8331  Mult_acc_5: 0.4585  Mult_acc_7: 0.3319  MAE: 0.8958  Corr: 0.7652  Loss: 1.3974 
2021-01-27 00:34:02:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.6320  Has0_acc_2: 0.9525  Has0_F1_score: 0.9526  Non0_acc_2: 0.4330  Non0_F1_score: 0.4314  Acc_3: 0.9322  F1_score_3: 0.9519 
2021-01-27 00:34:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8165  Non0_acc_2: 0.3519  Non0_F1_score: 0.3630  Acc_3: 0.7773  F1_score_3: 0.7987  Loss: 0.9003 
2021-01-27 00:34:09:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4742  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9513  Non0_F1_score: 0.9513  Mult_acc_5: 0.6799  Mult_acc_7: 0.6246  MAE: 0.3885  Corr: 0.9474 
2021-01-27 00:34:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8241  Non0_F1_score: 0.8235  Mult_acc_5: 0.4891  Mult_acc_7: 0.4017  MAE: 0.7603  Corr: 0.7857  Loss: 1.1222 
2021-01-27 00:34:12:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.5255  Has0_acc_2: 0.9673  Has0_F1_score: 0.9673  Non0_acc_2: 0.4411  Non0_F1_score: 0.4419  Acc_3: 0.9431  F1_score_3: 0.9630 
2021-01-27 00:34:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8207  Non0_acc_2: 0.3750  Non0_F1_score: 0.4050  Acc_3: 0.7773  F1_score_3: 0.7977  Loss: 1.0354 
2021-01-27 00:34:21:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.3757  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9578  Non0_F1_score: 0.9577  Mult_acc_5: 0.7609  Mult_acc_7: 0.7103  MAE: 0.3166  Corr: 0.9643 
2021-01-27 00:34:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8182  Non0_acc_2: 0.8287  Non0_F1_score: 0.8309  Mult_acc_5: 0.4760  Mult_acc_7: 0.3755  MAE: 0.7822  Corr: 0.7859  Loss: 1.0873 
2021-01-27 00:34:23:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.5078  Has0_acc_2: 0.9533  Has0_F1_score: 0.9533  Non0_acc_2: 0.4330  Non0_F1_score: 0.4334  Acc_3: 0.9283  F1_score_3: 0.9478 
2021-01-27 00:34:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.4978  Has0_F1_score: 0.6261  Non0_acc_2: 0.4259  Non0_F1_score: 0.5897  Acc_3: 0.4410  F1_score_3: 0.5719  Loss: 2.2725 
2021-01-27 00:34:33:INFO:TRAIN-(misa) (1/11/1)>> loss: 0.3539  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9553  Non0_F1_score: 0.9554  Mult_acc_5: 0.7422  Mult_acc_7: 0.6830  MAE: 0.3163  Corr: 0.9647 
2021-01-27 00:34:33:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.6011  Has0_acc_2: 0.9112  Has0_F1_score: 0.9112  Non0_acc_2: 0.4143  Non0_F1_score: 0.4195  Acc_3: 0.8832  F1_score_3: 0.9004 
2021-01-27 00:34:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8128  Non0_acc_2: 0.8287  Non0_F1_score: 0.8301  Mult_acc_5: 0.4672  Mult_acc_7: 0.3755  MAE: 0.8077  Corr: 0.7719  Loss: 1.1995 
2021-01-27 00:34:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7502  Non0_acc_2: 0.3889  Non0_F1_score: 0.4583  Acc_3: 0.6987  F1_score_3: 0.7182  Loss: 1.0425 
2021-01-27 00:34:43:INFO:TRAIN-(misa) (2/12/1)>> loss: 0.3253  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7671  Mult_acc_7: 0.7087  MAE: 0.3051  Corr: 0.9670 
2021-01-27 00:34:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7795  Non0_acc_2: 0.8102  Non0_F1_score: 0.8091  Mult_acc_5: 0.4585  Mult_acc_7: 0.3624  MAE: 0.8125  Corr: 0.7786  Loss: 1.3235 
2021-01-27 00:34:44:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4047  Has0_acc_2: 0.9595  Has0_F1_score: 0.9595  Non0_acc_2: 0.4395  Non0_F1_score: 0.4426  Acc_3: 0.9361  F1_score_3: 0.9547 
2021-01-27 00:34:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8209  Non0_acc_2: 0.3565  Non0_F1_score: 0.3677  Acc_3: 0.7860  F1_score_3: 0.8064  Loss: 0.8805 
2021-01-27 00:34:54:INFO:TRAIN-(misa) (3/13/1)>> loss: 0.3450  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7414  Mult_acc_7: 0.6752  MAE: 0.3345  Corr: 0.9610 
2021-01-27 00:34:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7982  Non0_acc_2: 0.8194  Non0_F1_score: 0.8196  Mult_acc_5: 0.5022  Mult_acc_7: 0.4148  MAE: 0.7635  Corr: 0.7791  Loss: 1.0439 
2021-01-27 00:34:55:INFO:TRAIN-(misa) (7/10/1)>> loss: 0.2726  Has0_acc_2: 0.9836  Has0_F1_score: 0.9837  Non0_acc_2: 0.4468  Non0_F1_score: 0.4472  Acc_3: 0.9766  F1_score_3: 0.9795 
2021-01-27 00:34:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8167  Non0_acc_2: 0.3519  Non0_F1_score: 0.3593  Acc_3: 0.7817  F1_score_3: 0.7948  Loss: 0.8932 
2021-01-27 00:35:06:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2894  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9586  Non0_F1_score: 0.9585  Mult_acc_5: 0.7656  Mult_acc_7: 0.7126  MAE: 0.2819  Corr: 0.9720 
2021-01-27 00:35:06:INFO:TRAIN-(misa) (8/11/1)>> loss: 0.2260  Has0_acc_2: 0.9774  Has0_F1_score: 0.9774  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9883  F1_score_3: 0.9888 
2021-01-27 00:35:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8227  Non0_acc_2: 0.8287  Non0_F1_score: 0.8309  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.8139  Corr: 0.7791  Loss: 1.1774 
2021-01-27 00:35:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8034  Non0_acc_2: 0.3519  Non0_F1_score: 0.3647  Acc_3: 0.7511  F1_score_3: 0.7379  Loss: 1.1231 
2021-01-27 00:35:08:INFO:TEST-(misa) >>  Has0_acc_2: 0.8397  Has0_F1_score: 0.8410  Non0_acc_2: 0.5259  Non0_F1_score: 0.5479  Acc_3: 0.8090  F1_score_3: 0.8286  Loss: 0.5768 
2021-01-27 00:35:08:INFO:Start running misa...
2021-01-27 00:35:08:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1112}>
2021-01-27 00:35:08:INFO:Let's use 1 GPUs!
2021-01-27 00:35:09:INFO:train samples: (1284,)
2021-01-27 00:35:09:INFO:valid samples: (229,)
2021-01-27 00:35:09:INFO:test samples: (686,)
2021-01-27 00:35:09:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:35:09:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:35:09:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:35:09:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:35:09:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:35:09:INFO:loading file None
2021-01-27 00:35:09:INFO:loading file None
2021-01-27 00:35:09:INFO:loading file None
2021-01-27 00:35:09:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:35:09:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:35:09:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:35:13:INFO:The model has 110621043 trainable parameters
2021-01-27 00:35:17:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2880  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9569  Non0_F1_score: 0.9569  Mult_acc_5: 0.7609  Mult_acc_7: 0.7072  MAE: 0.2990  Corr: 0.9685 
2021-01-27 00:35:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7897  Non0_acc_2: 0.8102  Non0_F1_score: 0.8106  Mult_acc_5: 0.4541  Mult_acc_7: 0.3712  MAE: 0.7760  Corr: 0.7764  Loss: 1.0722 
2021-01-27 00:35:23:INFO:TRAIN-(misa) (1/1/2)>> loss: 3.0552  Has0_acc_2: 0.5436  Has0_F1_score: 0.5587  Non0_acc_2: 0.1625  Non0_F1_score: 0.1357  Acc_3: 0.5210  F1_score_3: 0.5400 
2021-01-27 00:35:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.6856  Has0_F1_score: 0.6897  Non0_acc_2: 0.2593  Non0_F1_score: 0.2459  Acc_3: 0.6681  F1_score_3: 0.6900  Loss: 0.8602 
2021-01-27 00:35:27:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2585  Has0_acc_2: 0.9455  Has0_F1_score: 0.9453  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7773  Mult_acc_7: 0.7204  MAE: 0.2734  Corr: 0.9735 
2021-01-27 00:35:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7883  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4454  Mult_acc_7: 0.3537  MAE: 0.8087  Corr: 0.7755  Loss: 1.1731 
2021-01-27 00:35:35:INFO:TRAIN-(misa) (1/2/2)>> loss: 2.2037  Has0_acc_2: 0.5436  Has0_F1_score: 0.5635  Non0_acc_2: 0.1462  Non0_F1_score: 0.1154  Acc_3: 0.5288  F1_score_3: 0.5582 
2021-01-27 00:35:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.4847  Has0_F1_score: 0.6015  Non0_acc_2: 0.4074  Non0_F1_score: 0.5598  Acc_3: 0.4279  F1_score_3: 0.5471  Loss: 0.8690 
2021-01-27 00:35:38:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.2768  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7445  Mult_acc_7: 0.6916  MAE: 0.3065  Corr: 0.9675 
2021-01-27 00:35:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8112  Non0_acc_2: 0.8333  Non0_F1_score: 0.8333  Mult_acc_5: 0.5022  Mult_acc_7: 0.3843  MAE: 0.7649  Corr: 0.7790  Loss: 1.0515 
2021-01-27 00:35:45:INFO:TRAIN-(misa) (2/3/2)>> loss: 1.6458  Has0_acc_2: 0.5319  Has0_F1_score: 0.5410  Non0_acc_2: 0.1722  Non0_F1_score: 0.1530  Acc_3: 0.5156  F1_score_3: 0.5343 
2021-01-27 00:35:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.5939  Has0_F1_score: 0.6342  Non0_acc_2: 0.1250  Non0_F1_score: 0.0809  Acc_3: 0.5852  F1_score_3: 0.6356  Loss: 0.8700 
2021-01-27 00:35:48:INFO:TRAIN-(misa) (5/18/1)>> loss: 0.2446  Has0_acc_2: 0.9361  Has0_F1_score: 0.9359  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7687  Mult_acc_7: 0.7134  MAE: 0.2743  Corr: 0.9740 
2021-01-27 00:35:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8318  Non0_acc_2: 0.8380  Non0_F1_score: 0.8405  Mult_acc_5: 0.5066  Mult_acc_7: 0.3886  MAE: 0.8309  Corr: 0.7918  Loss: 1.2260 
2021-01-27 00:35:56:INFO:TRAIN-(misa) (3/4/2)>> loss: 1.3147  Has0_acc_2: 0.5405  Has0_F1_score: 0.5684  Non0_acc_2: 0.1332  Non0_F1_score: 0.0986  Acc_3: 0.5319  F1_score_3: 0.5677 
2021-01-27 00:35:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8450 
2021-01-27 00:35:59:INFO:TRAIN-(misa) (6/19/1)>> loss: 0.2378  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7921  Mult_acc_7: 0.7360  MAE: 0.2765  Corr: 0.9732 
2021-01-27 00:36:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.7399  Corr: 0.7919  Loss: 1.0194 
2021-01-27 00:36:08:INFO:TRAIN-(misa) (1/5/2)>> loss: 1.1851  Has0_acc_2: 0.5639  Has0_F1_score: 0.5900  Non0_acc_2: 0.1454  Non0_F1_score: 0.1078  Acc_3: 0.5545  F1_score_3: 0.5892 
2021-01-27 00:36:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6243  Non0_acc_2: 0.1806  Non0_F1_score: 0.1495  Acc_3: 0.5983  F1_score_3: 0.6283  Loss: 0.8645 
2021-01-27 00:36:11:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.2380  Has0_acc_2: 0.9455  Has0_F1_score: 0.9453  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7687  Mult_acc_7: 0.7142  MAE: 0.2788  Corr: 0.9728 
2021-01-27 00:36:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8064  Non0_acc_2: 0.8287  Non0_F1_score: 0.8282  Mult_acc_5: 0.4760  Mult_acc_7: 0.3930  MAE: 0.7696  Corr: 0.7877  Loss: 1.1318 
2021-01-27 00:36:19:INFO:TRAIN-(misa) (2/6/2)>> loss: 1.1021  Has0_acc_2: 0.5421  Has0_F1_score: 0.5727  Non0_acc_2: 0.1267  Non0_F1_score: 0.0908  Acc_3: 0.5319  F1_score_3: 0.5708 
2021-01-27 00:36:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8571 
2021-01-27 00:36:22:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.2441  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7734  Mult_acc_7: 0.7204  MAE: 0.2812  Corr: 0.9721 
2021-01-27 00:36:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8064  Non0_acc_2: 0.8333  Non0_F1_score: 0.8329  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7576  Corr: 0.7826  Loss: 1.1434 
2021-01-27 00:36:29:INFO:TRAIN-(misa) (3/7/2)>> loss: 1.0713  Has0_acc_2: 0.5631  Has0_F1_score: 0.5832  Non0_acc_2: 0.1568  Non0_F1_score: 0.1231  Acc_3: 0.5514  F1_score_3: 0.5809 
2021-01-27 00:36:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5459  Has0_F1_score: 0.7016  Non0_acc_2: 0.0046  Non0_F1_score: 0.0001  Acc_3: 0.5459  F1_score_3: 0.7016  Loss: 0.8484 
2021-01-27 00:36:33:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.2013  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9708  Non0_F1_score: 0.9707  Mult_acc_5: 0.8193  Mult_acc_7: 0.7757  MAE: 0.2378  Corr: 0.9800 
2021-01-27 00:36:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8030  Non0_acc_2: 0.8241  Non0_F1_score: 0.8246  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7405  Corr: 0.7909  Loss: 1.0310 
2021-01-27 00:36:40:INFO:TRAIN-(misa) (4/8/2)>> loss: 1.0512  Has0_acc_2: 0.5615  Has0_F1_score: 0.5837  Non0_acc_2: 0.1535  Non0_F1_score: 0.1187  Acc_3: 0.5522  F1_score_3: 0.5831 
2021-01-27 00:36:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5197  Has0_F1_score: 0.5274  Non0_acc_2: 0.2963  Non0_F1_score: 0.3566  Acc_3: 0.4934  F1_score_3: 0.5148  Loss: 0.8655 
2021-01-27 00:36:44:INFO:TRAIN-(misa) (4/23/1)>> loss: 0.1951  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7952  Mult_acc_7: 0.7516  MAE: 0.2356  Corr: 0.9808 
2021-01-27 00:36:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8414  Non0_acc_2: 0.8426  Non0_F1_score: 0.8458  Mult_acc_5: 0.4760  Mult_acc_7: 0.3624  MAE: 0.8360  Corr: 0.7871  Loss: 1.2921 
2021-01-27 00:36:51:INFO:TRAIN-(misa) (5/9/2)>> loss: 1.0117  Has0_acc_2: 0.5631  Has0_F1_score: 0.6030  Non0_acc_2: 0.1210  Non0_F1_score: 0.0781  Acc_3: 0.5561  F1_score_3: 0.6033 
2021-01-27 00:36:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8641 
2021-01-27 00:36:55:INFO:TRAIN-(misa) (5/24/1)>> loss: 0.2631  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9634  Non0_F1_score: 0.9634  Mult_acc_5: 0.7617  Mult_acc_7: 0.7072  MAE: 0.2887  Corr: 0.9709 
2021-01-27 00:36:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8203  Non0_acc_2: 0.8148  Non0_F1_score: 0.8186  Mult_acc_5: 0.5153  Mult_acc_7: 0.4148  MAE: 0.7713  Corr: 0.7887  Loss: 1.1655 
2021-01-27 00:37:01:INFO:TRAIN-(misa) (6/10/2)>> loss: 1.0110  Has0_acc_2: 0.5319  Has0_F1_score: 0.5574  Non0_acc_2: 0.1365  Non0_F1_score: 0.1042  Acc_3: 0.5249  F1_score_3: 0.5579 
2021-01-27 00:37:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8623 
2021-01-27 00:37:06:INFO:TRAIN-(misa) (6/25/1)>> loss: 0.2762  Has0_acc_2: 0.9416  Has0_F1_score: 0.9415  Non0_acc_2: 0.9545  Non0_F1_score: 0.9546  Mult_acc_5: 0.7399  Mult_acc_7: 0.6822  MAE: 0.3151  Corr: 0.9653 
2021-01-27 00:37:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8194  Non0_F1_score: 0.8188  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.7656  Corr: 0.7916  Loss: 1.0994 
2021-01-27 00:37:12:INFO:TRAIN-(misa) (7/11/2)>> loss: 0.9785  Has0_acc_2: 0.5701  Has0_F1_score: 0.6051  Non0_acc_2: 0.1340  Non0_F1_score: 0.0911  Acc_3: 0.5646  F1_score_3: 0.6068 
2021-01-27 00:37:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5852  Has0_F1_score: 0.6415  Non0_acc_2: 0.1065  Non0_F1_score: 0.0599  Acc_3: 0.5852  F1_score_3: 0.6467  Loss: 0.8610 
2021-01-27 00:37:17:INFO:TRAIN-(misa) (7/26/1)>> loss: 0.2076  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9643  Non0_F1_score: 0.9642  Mult_acc_5: 0.7928  Mult_acc_7: 0.7422  MAE: 0.2546  Corr: 0.9772 
2021-01-27 00:37:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4803  Mult_acc_7: 0.3974  MAE: 0.7543  Corr: 0.7951  Loss: 1.0108 
2021-01-27 00:37:23:INFO:TRAIN-(misa) (8/12/2)>> loss: 0.9858  Has0_acc_2: 0.5802  Has0_F1_score: 0.5908  Non0_acc_2: 0.1925  Non0_F1_score: 0.1671  Acc_3: 0.5685  F1_score_3: 0.5893 
2021-01-27 00:37:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8601 
2021-01-27 00:37:26:INFO:TEST-(misa) >>  Has0_acc_2: 0.4169  Has0_F1_score: 0.5621  Non0_acc_2: 0.0213  Non0_F1_score: 0.0020  Acc_3: 0.4169  F1_score_3: 0.5623  Loss: 0.8817 
2021-01-27 00:37:26:INFO:Start running misa...
2021-01-27 00:37:26:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1113}>
2021-01-27 00:37:26:INFO:Let's use 1 GPUs!
2021-01-27 00:37:26:INFO:train samples: (1284,)
2021-01-27 00:37:26:INFO:valid samples: (229,)
2021-01-27 00:37:26:INFO:test samples: (686,)
2021-01-27 00:37:26:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:37:26:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:37:26:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:37:26:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:37:26:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:37:26:INFO:loading file None
2021-01-27 00:37:26:INFO:loading file None
2021-01-27 00:37:26:INFO:loading file None
2021-01-27 00:37:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:37:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:37:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:37:29:INFO:TRAIN-(misa) (1/27/1)>> loss: 0.2025  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7921  Mult_acc_7: 0.7391  MAE: 0.2494  Corr: 0.9774 
2021-01-27 00:37:29:INFO:The model has 110621043 trainable parameters
2021-01-27 00:37:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8283  Non0_acc_2: 0.8241  Non0_F1_score: 0.8271  Mult_acc_5: 0.4541  Mult_acc_7: 0.3493  MAE: 0.8055  Corr: 0.7927  Loss: 1.1559 
2021-01-27 00:37:39:INFO:TRAIN-(misa) (1/1/3)>> loss: 3.1934  Has0_acc_2: 0.5678  Has0_F1_score: 0.5867  Non0_acc_2: 0.1543  Non0_F1_score: 0.1206  Acc_3: 0.5452  F1_score_3: 0.5731 
2021-01-27 00:37:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.5808  Has0_F1_score: 0.6822  Non0_acc_2: 0.0556  Non0_F1_score: 0.0156  Acc_3: 0.5808  F1_score_3: 0.6838  Loss: 0.8211 
2021-01-27 00:37:40:INFO:TRAIN-(misa) (2/28/1)>> loss: 0.2077  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9618  Non0_F1_score: 0.9619  Mult_acc_5: 0.7695  Mult_acc_7: 0.7181  MAE: 0.2759  Corr: 0.9739 
2021-01-27 00:37:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8082  Non0_acc_2: 0.8241  Non0_F1_score: 0.8253  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7620  Corr: 0.7900  Loss: 1.0311 
2021-01-27 00:37:51:INFO:TRAIN-(misa) (3/29/1)>> loss: 0.1787  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8123  Mult_acc_7: 0.7640  MAE: 0.2390  Corr: 0.9801 
2021-01-27 00:37:51:INFO:TRAIN-(misa) (1/2/3)>> loss: 2.1703  Has0_acc_2: 0.7313  Has0_F1_score: 0.7362  Non0_acc_2: 0.2811  Non0_F1_score: 0.2525  Acc_3: 0.7173  F1_score_3: 0.7361 
2021-01-27 00:37:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.4891  Mult_acc_7: 0.4017  MAE: 0.7300  Corr: 0.7961  Loss: 1.0156 
2021-01-27 00:37:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8035  Non0_acc_2: 0.3750  Non0_F1_score: 0.4134  Acc_3: 0.7555  F1_score_3: 0.7745  Loss: 0.6617 
2021-01-27 00:38:01:INFO:TRAIN-(misa) (4/30/1)>> loss: 0.1592  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8326  Mult_acc_7: 0.7827  MAE: 0.2215  Corr: 0.9827 
2021-01-27 00:38:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7949  Non0_acc_2: 0.8102  Non0_F1_score: 0.8113  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7525  Corr: 0.7904  Loss: 1.0743 
2021-01-27 00:38:03:INFO:TRAIN-(misa) (1/3/3)>> loss: 1.3517  Has0_acc_2: 0.8988  Has0_F1_score: 0.8989  Non0_acc_2: 0.4013  Non0_F1_score: 0.3984  Acc_3: 0.8746  F1_score_3: 0.8931 
2021-01-27 00:38:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7820  Non0_acc_2: 0.2639  Non0_F1_score: 0.2185  Acc_3: 0.7555  F1_score_3: 0.7841  Loss: 0.7165 
2021-01-27 00:38:12:INFO:TRAIN-(misa) (5/31/1)>> loss: 0.1446  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8372  Mult_acc_7: 0.7921  MAE: 0.2033  Corr: 0.9856 
2021-01-27 00:38:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7976  Non0_acc_2: 0.8241  Non0_F1_score: 0.8236  Mult_acc_5: 0.4716  Mult_acc_7: 0.3974  MAE: 0.7645  Corr: 0.7842  Loss: 1.0623 
2021-01-27 00:38:14:INFO:TRAIN-(misa) (2/4/3)>> loss: 0.8796  Has0_acc_2: 0.9424  Has0_F1_score: 0.9425  Non0_acc_2: 0.4281  Non0_F1_score: 0.4277  Acc_3: 0.9206  F1_score_3: 0.9399 
2021-01-27 00:38:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7828  Non0_acc_2: 0.2870  Non0_F1_score: 0.2559  Acc_3: 0.7598  F1_score_3: 0.7855  Loss: 0.8365 
2021-01-27 00:38:23:INFO:TRAIN-(misa) (6/32/1)>> loss: 0.1391  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9829  Non0_F1_score: 0.9830  Mult_acc_5: 0.8520  Mult_acc_7: 0.8084  MAE: 0.1957  Corr: 0.9863 
2021-01-27 00:38:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7883  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4498  Mult_acc_7: 0.3668  MAE: 0.7805  Corr: 0.7853  Loss: 1.0875 
2021-01-27 00:38:25:INFO:TRAIN-(misa) (3/5/3)>> loss: 0.6668  Has0_acc_2: 0.9634  Has0_F1_score: 0.9635  Non0_acc_2: 0.4354  Non0_F1_score: 0.4330  Acc_3: 0.9385  F1_score_3: 0.9582 
2021-01-27 00:38:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7471  Non0_acc_2: 0.2130  Non0_F1_score: 0.1519  Acc_3: 0.7205  F1_score_3: 0.7562  Loss: 1.4176 
2021-01-27 00:38:33:INFO:TRAIN-(misa) (7/33/1)>> loss: 0.1410  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8279  Mult_acc_7: 0.7850  MAE: 0.2110  Corr: 0.9846 
2021-01-27 00:38:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8273  Non0_acc_2: 0.8333  Non0_F1_score: 0.8357  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7696  Corr: 0.7889  Loss: 1.1729 
2021-01-27 00:38:36:INFO:TRAIN-(misa) (4/6/3)>> loss: 0.6577  Has0_acc_2: 0.9494  Has0_F1_score: 0.9495  Non0_acc_2: 0.4314  Non0_F1_score: 0.4298  Acc_3: 0.9291  F1_score_3: 0.9487 
2021-01-27 00:38:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8176  Non0_acc_2: 0.3241  Non0_F1_score: 0.3132  Acc_3: 0.7773  F1_score_3: 0.8005  Loss: 1.0289 
2021-01-27 00:38:44:INFO:TRAIN-(misa) (8/34/1)>> loss: 0.1423  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8240  Mult_acc_7: 0.7788  MAE: 0.2172  Corr: 0.9837 
2021-01-27 00:38:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.5153  Mult_acc_7: 0.4236  MAE: 0.7416  Corr: 0.7925  Loss: 1.0532 
2021-01-27 00:38:46:INFO:TRAIN-(misa) (5/7/3)>> loss: 0.5784  Has0_acc_2: 0.9525  Has0_F1_score: 0.9525  Non0_acc_2: 0.4370  Non0_F1_score: 0.4402  Acc_3: 0.9315  F1_score_3: 0.9472 
2021-01-27 00:38:46:INFO:TEST-(misa) >>  Has0_acc_2: 0.8061  Has0_F1_score: 0.8077  Non0_acc_2: 0.8262  Non0_F1_score: 0.8270  Mult_acc_5: 0.4767  Mult_acc_7: 0.4169  MAE: 0.7766  Corr: 0.7589  Loss: 1.0840 
2021-01-27 00:38:46:INFO:Start running misa...
2021-01-27 00:38:46:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1112}>
2021-01-27 00:38:46:INFO:Let's use 1 GPUs!
2021-01-27 00:38:46:INFO:train samples: (1284,)
2021-01-27 00:38:47:INFO:valid samples: (229,)
2021-01-27 00:38:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7900  Non0_acc_2: 0.3611  Non0_F1_score: 0.3883  Acc_3: 0.7555  F1_score_3: 0.7759  Loss: 0.9060 
2021-01-27 00:38:47:INFO:test samples: (686,)
2021-01-27 00:38:47:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:38:47:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:38:47:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:38:47:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:38:47:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:38:47:INFO:loading file None
2021-01-27 00:38:47:INFO:loading file None
2021-01-27 00:38:47:INFO:loading file None
2021-01-27 00:38:47:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:38:47:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:38:47:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:38:50:INFO:The model has 110620273 trainable parameters
2021-01-27 00:38:57:INFO:TRAIN-(misa) (6/8/3)>> loss: 0.4282  Has0_acc_2: 0.9727  Has0_F1_score: 0.9728  Non0_acc_2: 0.4435  Non0_F1_score: 0.4431  Acc_3: 0.9502  F1_score_3: 0.9687 
2021-01-27 00:38:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8048  Non0_acc_2: 0.3241  Non0_F1_score: 0.3150  Acc_3: 0.7729  F1_score_3: 0.7961  Loss: 0.9543 
2021-01-27 00:39:00:INFO:TRAIN-(misa) (1/1/2)>> loss: 4.2901  Has0_acc_2: 0.6347  Has0_F1_score: 0.6505  Non0_acc_2: 0.6320  Non0_F1_score: 0.6487  Mult_acc_5: 0.2204  Mult_acc_7: 0.2204  MAE: 1.2066  Corr: 0.3538 
2021-01-27 00:39:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7758  Non0_acc_2: 0.8148  Non0_F1_score: 0.8141  Mult_acc_5: 0.2533  Mult_acc_7: 0.2533  MAE: 1.0278  Corr: 0.7151  Loss: 1.5027 
2021-01-27 00:39:07:INFO:TRAIN-(misa) (7/9/3)>> loss: 0.3615  Has0_acc_2: 0.9782  Has0_F1_score: 0.9782  Non0_acc_2: 0.4452  Non0_F1_score: 0.4444  Acc_3: 0.9650  F1_score_3: 0.9735 
2021-01-27 00:39:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7736  Non0_acc_2: 0.2685  Non0_F1_score: 0.2358  Acc_3: 0.7424  F1_score_3: 0.7584  Loss: 1.3952 
2021-01-27 00:39:12:INFO:TRAIN-(misa) (1/2/2)>> loss: 2.5855  Has0_acc_2: 0.8107  Has0_F1_score: 0.8099  Non0_acc_2: 0.8318  Non0_F1_score: 0.8315  Mult_acc_5: 0.4276  Mult_acc_7: 0.4011  MAE: 0.7737  Corr: 0.7558 
2021-01-27 00:39:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7711  Non0_acc_2: 0.8102  Non0_F1_score: 0.8092  Mult_acc_5: 0.3668  Mult_acc_7: 0.3100  MAE: 0.9196  Corr: 0.7404  Loss: 1.3534 
2021-01-27 00:39:18:INFO:TRAIN-(misa) (8/10/3)>> loss: 0.3216  Has0_acc_2: 0.9704  Has0_F1_score: 0.9705  Non0_acc_2: 0.4452  Non0_F1_score: 0.4452  Acc_3: 0.9712  F1_score_3: 0.9749 
2021-01-27 00:39:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7796  Non0_acc_2: 0.2639  Non0_F1_score: 0.2243  Acc_3: 0.7380  F1_score_3: 0.7510  Loss: 1.4348 
2021-01-27 00:39:20:INFO:TEST-(misa) >>  Has0_acc_2: 0.8426  Has0_F1_score: 0.8438  Non0_acc_2: 0.5259  Non0_F1_score: 0.5466  Acc_3: 0.8120  F1_score_3: 0.8315  Loss: 0.6059 
2021-01-27 00:39:20:INFO:Start running misa...
2021-01-27 00:39:20:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1114}>
2021-01-27 00:39:20:INFO:Let's use 1 GPUs!
2021-01-27 00:39:21:INFO:train samples: (1284,)
2021-01-27 00:39:21:INFO:valid samples: (229,)
2021-01-27 00:39:21:INFO:test samples: (686,)
2021-01-27 00:39:21:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:39:21:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:39:21:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:39:21:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:39:21:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:39:21:INFO:loading file None
2021-01-27 00:39:21:INFO:loading file None
2021-01-27 00:39:21:INFO:loading file None
2021-01-27 00:39:21:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:39:21:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:39:21:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:39:24:INFO:TRAIN-(misa) (1/3/2)>> loss: 1.6787  Has0_acc_2: 0.8606  Has0_F1_score: 0.8601  Non0_acc_2: 0.8822  Non0_F1_score: 0.8821  Mult_acc_5: 0.4852  Mult_acc_7: 0.4408  MAE: 0.6374  Corr: 0.8485 
2021-01-27 00:39:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8090  Non0_acc_2: 0.8241  Non0_F1_score: 0.8262  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.8412  Corr: 0.7441  Loss: 1.4916 
2021-01-27 00:39:25:INFO:The model has 110621043 trainable parameters
2021-01-27 00:39:35:INFO:TRAIN-(misa) (2/4/2)>> loss: 1.1907  Has0_acc_2: 0.9011  Has0_F1_score: 0.9007  Non0_acc_2: 0.9139  Non0_F1_score: 0.9137  Mult_acc_5: 0.5436  Mult_acc_7: 0.4938  MAE: 0.5455  Corr: 0.8899 
2021-01-27 00:39:35:INFO:TRAIN-(misa) (1/1/4)>> loss: 3.4040  Has0_acc_2: 0.5202  Has0_F1_score: 0.5303  Non0_acc_2: 0.1657  Non0_F1_score: 0.1464  Acc_3: 0.5047  F1_score_3: 0.5228 
2021-01-27 00:39:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8389  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5109  Mult_acc_7: 0.4279  MAE: 0.7739  Corr: 0.7632  Loss: 1.1479 
2021-01-27 00:39:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8333 
2021-01-27 00:39:47:INFO:TRAIN-(misa) (1/5/2)>> loss: 0.8457  Has0_acc_2: 0.9143  Has0_F1_score: 0.9142  Non0_acc_2: 0.9301  Non0_F1_score: 0.9302  Mult_acc_5: 0.6207  Mult_acc_7: 0.5717  MAE: 0.4585  Corr: 0.9224 
2021-01-27 00:39:48:INFO:TRAIN-(misa) (1/2/4)>> loss: 2.3696  Has0_acc_2: 0.6363  Has0_F1_score: 0.6653  Non0_acc_2: 0.1657  Non0_F1_score: 0.1121  Acc_3: 0.6269  F1_score_3: 0.6657 
2021-01-27 00:39:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8027  Non0_acc_2: 0.8287  Non0_F1_score: 0.8291  Mult_acc_5: 0.5240  Mult_acc_7: 0.4410  MAE: 0.7705  Corr: 0.7543  Loss: 1.2349 
2021-01-27 00:39:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.7511  Has0_F1_score: 0.7580  Non0_acc_2: 0.2731  Non0_F1_score: 0.2417  Acc_3: 0.7380  F1_score_3: 0.7637  Loss: 0.7575 
2021-01-27 00:39:58:INFO:TRAIN-(misa) (2/6/2)>> loss: 0.6892  Has0_acc_2: 0.9206  Has0_F1_score: 0.9203  Non0_acc_2: 0.9391  Non0_F1_score: 0.9390  Mult_acc_5: 0.6519  Mult_acc_7: 0.5942  MAE: 0.4236  Corr: 0.9343 
2021-01-27 00:39:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7885  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4716  Mult_acc_7: 0.3799  MAE: 0.8318  Corr: 0.7746  Loss: 1.3611 
2021-01-27 00:40:00:INFO:TRAIN-(misa) (1/3/4)>> loss: 1.6227  Has0_acc_2: 0.8100  Has0_F1_score: 0.8126  Non0_acc_2: 0.3266  Non0_F1_score: 0.2986  Acc_3: 0.7928  F1_score_3: 0.8116 
2021-01-27 00:40:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7536  Non0_acc_2: 0.4120  Non0_F1_score: 0.5001  Acc_3: 0.6987  F1_score_3: 0.7210  Loss: 0.7261 
2021-01-27 00:40:09:INFO:TRAIN-(misa) (3/7/2)>> loss: 0.5849  Has0_acc_2: 0.9299  Has0_F1_score: 0.9296  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.6854  Mult_acc_7: 0.6223  MAE: 0.3823  Corr: 0.9465 
2021-01-27 00:40:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4978  Mult_acc_7: 0.3886  MAE: 0.7506  Corr: 0.7729  Loss: 1.1693 
2021-01-27 00:40:11:INFO:TRAIN-(misa) (1/4/4)>> loss: 1.1089  Has0_acc_2: 0.8762  Has0_F1_score: 0.8763  Non0_acc_2: 0.3964  Non0_F1_score: 0.3982  Acc_3: 0.8551  F1_score_3: 0.8731 
2021-01-27 00:40:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.3472  Non0_F1_score: 0.3510  Acc_3: 0.7860  F1_score_3: 0.8086  Loss: 0.6460 
2021-01-27 00:40:19:INFO:TRAIN-(misa) (4/8/2)>> loss: 0.4700  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9504  Non0_F1_score: 0.9504  Mult_acc_5: 0.7321  Mult_acc_7: 0.6745  MAE: 0.3303  Corr: 0.9607 
2021-01-27 00:40:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7452  Corr: 0.7700  Loss: 1.1427 
2021-01-27 00:40:23:INFO:TRAIN-(misa) (1/5/4)>> loss: 0.7214  Has0_acc_2: 0.9509  Has0_F1_score: 0.9510  Non0_acc_2: 0.4330  Non0_F1_score: 0.4318  Acc_3: 0.9315  F1_score_3: 0.9511 
2021-01-27 00:40:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7867  Non0_acc_2: 0.2639  Non0_F1_score: 0.2165  Acc_3: 0.7598  F1_score_3: 0.7888  Loss: 0.9281 
2021-01-27 00:40:31:INFO:TRAIN-(misa) (1/9/2)>> loss: 0.4462  Has0_acc_2: 0.9260  Has0_F1_score: 0.9259  Non0_acc_2: 0.9423  Non0_F1_score: 0.9423  Mult_acc_5: 0.7414  Mult_acc_7: 0.6846  MAE: 0.3418  Corr: 0.9577 
2021-01-27 00:40:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8065  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7610  Corr: 0.7678  Loss: 1.1851 
2021-01-27 00:40:34:INFO:TRAIN-(misa) (2/6/4)>> loss: 0.6883  Has0_acc_2: 0.9408  Has0_F1_score: 0.9409  Non0_acc_2: 0.4240  Non0_F1_score: 0.4206  Acc_3: 0.9190  F1_score_3: 0.9384 
2021-01-27 00:40:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7642  Has0_F1_score: 0.7650  Non0_acc_2: 0.3750  Non0_F1_score: 0.4261  Acc_3: 0.7205  F1_score_3: 0.7394  Loss: 1.0530 
2021-01-27 00:40:42:INFO:TRAIN-(misa) (2/10/2)>> loss: 0.3860  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7609  Mult_acc_7: 0.7017  MAE: 0.3093  Corr: 0.9661 
2021-01-27 00:40:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5240  Mult_acc_7: 0.4323  MAE: 0.7732  Corr: 0.7723  Loss: 1.1865 
2021-01-27 00:40:44:INFO:TRAIN-(misa) (3/7/4)>> loss: 0.6050  Has0_acc_2: 0.9408  Has0_F1_score: 0.9409  Non0_acc_2: 0.4322  Non0_F1_score: 0.4349  Acc_3: 0.9229  F1_score_3: 0.9412 
2021-01-27 00:40:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7795  Non0_acc_2: 0.3102  Non0_F1_score: 0.2979  Acc_3: 0.7555  F1_score_3: 0.7786  Loss: 0.9465 
2021-01-27 00:40:53:INFO:TRAIN-(misa) (3/11/2)>> loss: 0.3720  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.7220  Mult_acc_7: 0.6659  MAE: 0.3190  Corr: 0.9650 
2021-01-27 00:40:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8219  Non0_acc_2: 0.8380  Non0_F1_score: 0.8397  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7807  Corr: 0.7754  Loss: 1.2106 
2021-01-27 00:40:55:INFO:TRAIN-(misa) (4/8/4)>> loss: 0.5070  Has0_acc_2: 0.9525  Has0_F1_score: 0.9526  Non0_acc_2: 0.4322  Non0_F1_score: 0.4294  Acc_3: 0.9330  F1_score_3: 0.9527 
2021-01-27 00:40:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7931  Non0_acc_2: 0.3102  Non0_F1_score: 0.2924  Acc_3: 0.7686  F1_score_3: 0.7926  Loss: 0.9112 
2021-01-27 00:41:03:INFO:TRAIN-(misa) (4/12/2)>> loss: 0.3735  Has0_acc_2: 0.9307  Has0_F1_score: 0.9305  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7414  Mult_acc_7: 0.6846  MAE: 0.3229  Corr: 0.9636 
2021-01-27 00:41:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8419  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7731  Corr: 0.7910  Loss: 1.1736 
2021-01-27 00:41:06:INFO:TRAIN-(misa) (5/9/4)>> loss: 0.4036  Has0_acc_2: 0.9727  Has0_F1_score: 0.9728  Non0_acc_2: 0.4444  Non0_F1_score: 0.4444  Acc_3: 0.9556  F1_score_3: 0.9684 
2021-01-27 00:41:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7692  Non0_acc_2: 0.3750  Non0_F1_score: 0.4245  Acc_3: 0.7205  F1_score_3: 0.7368  Loss: 1.2664 
2021-01-27 00:41:14:INFO:TRAIN-(misa) (5/13/2)>> loss: 0.3642  Has0_acc_2: 0.9400  Has0_F1_score: 0.9398  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7282  Mult_acc_7: 0.6682  MAE: 0.3329  Corr: 0.9616 
2021-01-27 00:41:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5546  Mult_acc_7: 0.4803  MAE: 0.7228  Corr: 0.7817  Loss: 1.0852 
2021-01-27 00:41:16:INFO:TRAIN-(misa) (6/10/4)>> loss: 0.3340  Has0_acc_2: 0.9774  Has0_F1_score: 0.9774  Non0_acc_2: 0.4484  Non0_F1_score: 0.4496  Acc_3: 0.9759  F1_score_3: 0.9788 
2021-01-27 00:41:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7886  Non0_acc_2: 0.3102  Non0_F1_score: 0.2942  Acc_3: 0.7598  F1_score_3: 0.7820  Loss: 1.1495 
2021-01-27 00:41:26:INFO:TRAIN-(misa) (1/14/2)>> loss: 0.2936  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7773  Mult_acc_7: 0.7407  MAE: 0.2759  Corr: 0.9742 
2021-01-27 00:41:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7788  Corr: 0.7768  Loss: 1.2226 
2021-01-27 00:41:27:INFO:TRAIN-(misa) (7/11/4)>> loss: 0.2689  Has0_acc_2: 0.9751  Has0_F1_score: 0.9751  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9860  F1_score_3: 0.9865 
2021-01-27 00:41:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8082  Non0_acc_2: 0.3519  Non0_F1_score: 0.3593  Acc_3: 0.7860  F1_score_3: 0.8006  Loss: 1.0725 
2021-01-27 00:41:37:INFO:TRAIN-(misa) (2/15/2)>> loss: 0.2761  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.8076  Mult_acc_7: 0.7625  MAE: 0.2645  Corr: 0.9753 
2021-01-27 00:41:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5371  Mult_acc_7: 0.4367  MAE: 0.7477  Corr: 0.7861  Loss: 1.1208 
2021-01-27 00:41:37:INFO:TRAIN-(misa) (8/12/4)>> loss: 0.2615  Has0_acc_2: 0.9712  Has0_F1_score: 0.9712  Non0_acc_2: 0.4452  Non0_F1_score: 0.4452  Acc_3: 0.9883  F1_score_3: 0.9885 
2021-01-27 00:41:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.7598  Has0_F1_score: 0.7612  Non0_acc_2: 0.3843  Non0_F1_score: 0.4427  Acc_3: 0.7162  F1_score_3: 0.7214  Loss: 1.6144 
2021-01-27 00:41:40:INFO:TEST-(misa) >>  Has0_acc_2: 0.8353  Has0_F1_score: 0.8356  Non0_acc_2: 0.5122  Non0_F1_score: 0.5234  Acc_3: 0.8061  F1_score_3: 0.8249  Loss: 0.5753 
2021-01-27 00:41:40:INFO:Start running misa...
2021-01-27 00:41:40:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [1], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1115}>
2021-01-27 00:41:40:INFO:Let's use 1 GPUs!
2021-01-27 00:41:40:INFO:train samples: (1284,)
2021-01-27 00:41:41:INFO:valid samples: (229,)
2021-01-27 00:41:41:INFO:test samples: (686,)
2021-01-27 00:41:41:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:41:41:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:41:41:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:41:41:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:41:41:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:41:41:INFO:loading file None
2021-01-27 00:41:41:INFO:loading file None
2021-01-27 00:41:41:INFO:loading file None
2021-01-27 00:41:41:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:41:41:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:41:41:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:41:44:INFO:The model has 110621043 trainable parameters
2021-01-27 00:41:48:INFO:TRAIN-(misa) (3/16/2)>> loss: 0.3076  Has0_acc_2: 0.9315  Has0_F1_score: 0.9312  Non0_acc_2: 0.9488  Non0_F1_score: 0.9488  Mult_acc_5: 0.7664  Mult_acc_7: 0.7150  MAE: 0.3079  Corr: 0.9668 
2021-01-27 00:41:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8347  Non0_acc_2: 0.8519  Non0_F1_score: 0.8532  Mult_acc_5: 0.5546  Mult_acc_7: 0.4716  MAE: 0.7242  Corr: 0.7849  Loss: 1.0311 
2021-01-27 00:41:54:INFO:TRAIN-(misa) (1/1/5)>> loss: 3.1598  Has0_acc_2: 0.5467  Has0_F1_score: 0.5735  Non0_acc_2: 0.1340  Non0_F1_score: 0.0990  Acc_3: 0.5296  F1_score_3: 0.5600 
2021-01-27 00:41:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7354  Non0_acc_2: 0.2407  Non0_F1_score: 0.2011  Acc_3: 0.7074  F1_score_3: 0.7360  Loss: 0.8034 
2021-01-27 00:42:00:INFO:TRAIN-(misa) (1/17/2)>> loss: 0.2708  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7695  Mult_acc_7: 0.7173  MAE: 0.2671  Corr: 0.9744 
2021-01-27 00:42:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8333  Non0_F1_score: 0.8324  Mult_acc_5: 0.4323  Mult_acc_7: 0.3581  MAE: 0.7814  Corr: 0.7888  Loss: 1.1286 
2021-01-27 00:42:06:INFO:TRAIN-(misa) (1/2/5)>> loss: 2.1138  Has0_acc_2: 0.7866  Has0_F1_score: 0.7890  Non0_acc_2: 0.3184  Non0_F1_score: 0.2952  Acc_3: 0.7679  F1_score_3: 0.7860 
2021-01-27 00:42:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7793  Non0_acc_2: 0.3935  Non0_F1_score: 0.4564  Acc_3: 0.7293  F1_score_3: 0.7485  Loss: 0.6683 
2021-01-27 00:42:10:INFO:TRAIN-(misa) (2/18/2)>> loss: 0.2695  Has0_acc_2: 0.9369  Has0_F1_score: 0.9367  Non0_acc_2: 0.9561  Non0_F1_score: 0.9561  Mult_acc_5: 0.7749  Mult_acc_7: 0.7181  MAE: 0.2825  Corr: 0.9725 
2021-01-27 00:42:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8335  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5415  Mult_acc_7: 0.4541  MAE: 0.7010  Corr: 0.7935  Loss: 1.0085 
2021-01-27 00:42:19:INFO:TRAIN-(misa) (1/3/5)>> loss: 1.3744  Has0_acc_2: 0.9159  Has0_F1_score: 0.9159  Non0_acc_2: 0.4216  Non0_F1_score: 0.4291  Acc_3: 0.8917  F1_score_3: 0.9103 
2021-01-27 00:42:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.3472  Non0_F1_score: 0.3510  Acc_3: 0.7860  F1_score_3: 0.8079  Loss: 0.5874 
2021-01-27 00:42:23:INFO:TRAIN-(misa) (1/19/2)>> loss: 0.2369  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.7967  Mult_acc_7: 0.7492  MAE: 0.2452  Corr: 0.9787 
2021-01-27 00:42:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.5022  Mult_acc_7: 0.4148  MAE: 0.7517  Corr: 0.7968  Loss: 1.0295 
2021-01-27 00:42:31:INFO:TRAIN-(misa) (1/4/5)>> loss: 0.9227  Has0_acc_2: 0.9509  Has0_F1_score: 0.9510  Non0_acc_2: 0.4330  Non0_F1_score: 0.4334  Acc_3: 0.9283  F1_score_3: 0.9479 
2021-01-27 00:42:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8167  Non0_acc_2: 0.3843  Non0_F1_score: 0.4253  Acc_3: 0.7686  F1_score_3: 0.7881  Loss: 0.7201 
2021-01-27 00:42:33:INFO:TRAIN-(misa) (2/20/2)>> loss: 0.2280  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7975  Mult_acc_7: 0.7453  MAE: 0.2503  Corr: 0.9783 
2021-01-27 00:42:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7973  Non0_acc_2: 0.8333  Non0_F1_score: 0.8328  Mult_acc_5: 0.4978  Mult_acc_7: 0.4148  MAE: 0.7378  Corr: 0.7941  Loss: 1.0003 
2021-01-27 00:42:42:INFO:TRAIN-(misa) (2/5/5)>> loss: 0.7368  Has0_acc_2: 0.9688  Has0_F1_score: 0.9689  Non0_acc_2: 0.4411  Non0_F1_score: 0.4419  Acc_3: 0.9431  F1_score_3: 0.9629 
2021-01-27 00:42:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.7380  Has0_F1_score: 0.7518  Non0_acc_2: 0.2269  Non0_F1_score: 0.1754  Acc_3: 0.7162  F1_score_3: 0.7489  Loss: 1.0998 
2021-01-27 00:42:46:INFO:TRAIN-(misa) (1/21/2)>> loss: 0.2191  Has0_acc_2: 0.9463  Has0_F1_score: 0.9462  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.8115  Mult_acc_7: 0.7640  MAE: 0.2434  Corr: 0.9786 
2021-01-27 00:42:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8302  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5459  Mult_acc_7: 0.4410  MAE: 0.7123  Corr: 0.8033  Loss: 1.0369 
2021-01-27 00:42:53:INFO:TRAIN-(misa) (3/6/5)>> loss: 0.5961  Has0_acc_2: 0.9766  Has0_F1_score: 0.9767  Non0_acc_2: 0.4403  Non0_F1_score: 0.4375  Acc_3: 0.9486  F1_score_3: 0.9685 
2021-01-27 00:42:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7917  Non0_acc_2: 0.3935  Non0_F1_score: 0.4518  Acc_3: 0.7424  F1_score_3: 0.7616  Loss: 1.0597 
2021-01-27 00:42:56:INFO:TRAIN-(misa) (2/22/2)>> loss: 0.2157  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8146  Mult_acc_7: 0.7780  MAE: 0.2435  Corr: 0.9786 
2021-01-27 00:42:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5502  Mult_acc_7: 0.4585  MAE: 0.7095  Corr: 0.7975  Loss: 0.9586 
2021-01-27 00:43:03:INFO:TRAIN-(misa) (4/7/5)>> loss: 0.5110  Has0_acc_2: 0.9751  Has0_F1_score: 0.9751  Non0_acc_2: 0.4435  Non0_F1_score: 0.4439  Acc_3: 0.9494  F1_score_3: 0.9682 
2021-01-27 00:43:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7900  Non0_acc_2: 0.3472  Non0_F1_score: 0.3668  Acc_3: 0.7467  F1_score_3: 0.7649  Loss: 1.2120 
2021-01-27 00:43:08:INFO:TRAIN-(misa) (1/23/2)>> loss: 0.2066  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8030  Mult_acc_7: 0.7562  MAE: 0.2425  Corr: 0.9791 
2021-01-27 00:43:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7886  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4236  Mult_acc_7: 0.3450  MAE: 0.8223  Corr: 0.7866  Loss: 1.2561 
2021-01-27 00:43:14:INFO:TRAIN-(misa) (5/8/5)>> loss: 0.5103  Has0_acc_2: 0.9696  Has0_F1_score: 0.9697  Non0_acc_2: 0.4411  Non0_F1_score: 0.4419  Acc_3: 0.9470  F1_score_3: 0.9607 
2021-01-27 00:43:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7733  Non0_acc_2: 0.3194  Non0_F1_score: 0.3212  Acc_3: 0.7293  F1_score_3: 0.7422  Loss: 1.0866 
2021-01-27 00:43:19:INFO:TRAIN-(misa) (2/24/2)>> loss: 0.2242  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9634  Non0_F1_score: 0.9634  Mult_acc_5: 0.7812  Mult_acc_7: 0.7336  MAE: 0.2700  Corr: 0.9747 
2021-01-27 00:43:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8400  Non0_acc_2: 0.8519  Non0_F1_score: 0.8540  Mult_acc_5: 0.5240  Mult_acc_7: 0.4323  MAE: 0.7162  Corr: 0.8028  Loss: 0.9941 
2021-01-27 00:43:25:INFO:TRAIN-(misa) (6/9/5)>> loss: 0.3867  Has0_acc_2: 0.9805  Has0_F1_score: 0.9806  Non0_acc_2: 0.4452  Non0_F1_score: 0.4440  Acc_3: 0.9712  F1_score_3: 0.9763 
2021-01-27 00:43:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7782  Non0_acc_2: 0.3796  Non0_F1_score: 0.4313  Acc_3: 0.7205  F1_score_3: 0.7352  Loss: 1.3429 
2021-01-27 00:43:30:INFO:TRAIN-(misa) (3/25/2)>> loss: 0.1969  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8092  Mult_acc_7: 0.7710  MAE: 0.2393  Corr: 0.9800 
2021-01-27 00:43:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8657  Non0_F1_score: 0.8661  Mult_acc_5: 0.5415  Mult_acc_7: 0.4585  MAE: 0.7199  Corr: 0.7956  Loss: 1.0313 
2021-01-27 00:43:36:INFO:TRAIN-(misa) (7/10/5)>> loss: 0.3552  Has0_acc_2: 0.9735  Has0_F1_score: 0.9736  Non0_acc_2: 0.4444  Non0_F1_score: 0.4448  Acc_3: 0.9743  F1_score_3: 0.9764 
2021-01-27 00:43:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7692  Non0_acc_2: 0.3750  Non0_F1_score: 0.4245  Acc_3: 0.7205  F1_score_3: 0.7368  Loss: 1.5542 
2021-01-27 00:43:40:INFO:TRAIN-(misa) (4/26/2)>> loss: 0.1816  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8146  Mult_acc_7: 0.7702  MAE: 0.2236  Corr: 0.9823 
2021-01-27 00:43:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7513  Corr: 0.7914  Loss: 1.0206 
2021-01-27 00:43:47:INFO:TRAIN-(misa) (8/11/5)>> loss: 0.3603  Has0_acc_2: 0.9618  Has0_F1_score: 0.9619  Non0_acc_2: 0.4387  Non0_F1_score: 0.4383  Acc_3: 0.9720  F1_score_3: 0.9726 
2021-01-27 00:43:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7739  Non0_acc_2: 0.3148  Non0_F1_score: 0.3114  Acc_3: 0.7467  F1_score_3: 0.7597  Loss: 1.4459 
2021-01-27 00:43:50:INFO:TEST-(misa) >>  Has0_acc_2: 0.8163  Has0_F1_score: 0.8157  Non0_acc_2: 0.4878  Non0_F1_score: 0.4859  Acc_3: 0.7886  F1_score_3: 0.8062  Loss: 0.5643 
2021-01-27 00:43:50:INFO:Results are saved to results/results/mosi-misa-classification.csv...
2021-01-27 00:43:51:INFO:TRAIN-(misa) (5/27/2)>> loss: 0.1695  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8388  Mult_acc_7: 0.7952  MAE: 0.2108  Corr: 0.9843 
2021-01-27 00:43:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8425  Non0_acc_2: 0.8657  Non0_F1_score: 0.8663  Mult_acc_5: 0.5721  Mult_acc_7: 0.4934  MAE: 0.6980  Corr: 0.8026  Loss: 1.0226 
2021-01-27 00:44:02:INFO:TRAIN-(misa) (6/28/2)>> loss: 0.1788  Has0_acc_2: 0.9587  Has0_F1_score: 0.9587  Non0_acc_2: 0.9764  Non0_F1_score: 0.9765  Mult_acc_5: 0.8154  Mult_acc_7: 0.7710  MAE: 0.2194  Corr: 0.9830 
2021-01-27 00:44:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8333  Non0_acc_2: 0.8611  Non0_F1_score: 0.8613  Mult_acc_5: 0.5459  Mult_acc_7: 0.4541  MAE: 0.7121  Corr: 0.7984  Loss: 0.9891 
2021-01-27 00:44:12:INFO:TRAIN-(misa) (7/29/2)>> loss: 0.1666  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8372  Mult_acc_7: 0.7858  MAE: 0.2108  Corr: 0.9839 
2021-01-27 00:44:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8283  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7318  Corr: 0.7939  Loss: 0.9872 
2021-01-27 00:44:23:INFO:TRAIN-(misa) (8/30/2)>> loss: 0.1588  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8466  Mult_acc_7: 0.8076  MAE: 0.2004  Corr: 0.9857 
2021-01-27 00:44:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7107  Corr: 0.8021  Loss: 0.9906 
2021-01-27 00:44:25:INFO:TEST-(misa) >>  Has0_acc_2: 0.8120  Has0_F1_score: 0.8116  Non0_acc_2: 0.8262  Non0_F1_score: 0.8253  Mult_acc_5: 0.4723  Mult_acc_7: 0.4184  MAE: 0.7934  Corr: 0.7818  Loss: 1.1198 
2021-01-27 00:44:25:INFO:Start running misa...
2021-01-27 00:44:25:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1113}>
2021-01-27 00:44:25:INFO:Let's use 1 GPUs!
2021-01-27 00:44:26:INFO:train samples: (1284,)
2021-01-27 00:44:26:INFO:valid samples: (229,)
2021-01-27 00:44:27:INFO:test samples: (686,)
2021-01-27 00:44:27:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:44:27:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:44:27:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:44:27:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:44:27:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:44:27:INFO:loading file None
2021-01-27 00:44:27:INFO:loading file None
2021-01-27 00:44:27:INFO:loading file None
2021-01-27 00:44:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:44:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:44:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:44:30:INFO:The model has 110620273 trainable parameters
2021-01-27 00:44:39:INFO:TRAIN-(misa) (1/1/3)>> loss: 4.4529  Has0_acc_2: 0.6643  Has0_F1_score: 0.6746  Non0_acc_2: 0.6637  Non0_F1_score: 0.6747  Mult_acc_5: 0.2188  Mult_acc_7: 0.2181  MAE: 1.1959  Corr: 0.3847 
2021-01-27 00:44:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.6900  Has0_F1_score: 0.6958  Non0_acc_2: 0.7222  Non0_F1_score: 0.7276  Mult_acc_5: 0.2576  Mult_acc_7: 0.2533  MAE: 1.1829  Corr: 0.6161  Loss: 1.9636 
2021-01-27 00:44:51:INFO:TRAIN-(misa) (1/2/3)>> loss: 2.7509  Has0_acc_2: 0.8037  Has0_F1_score: 0.8029  Non0_acc_2: 0.8213  Non0_F1_score: 0.8210  Mult_acc_5: 0.3699  Mult_acc_7: 0.3512  MAE: 0.8224  Corr: 0.7293 
2021-01-27 00:44:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7839  Non0_acc_2: 0.8148  Non0_F1_score: 0.8138  Mult_acc_5: 0.4541  Mult_acc_7: 0.3755  MAE: 0.8745  Corr: 0.7215  Loss: 1.3699 
2021-01-27 00:45:02:INFO:TRAIN-(misa) (1/3/3)>> loss: 1.7993  Has0_acc_2: 0.8598  Has0_F1_score: 0.8592  Non0_acc_2: 0.8765  Non0_F1_score: 0.8763  Mult_acc_5: 0.4798  Mult_acc_7: 0.4424  MAE: 0.6483  Corr: 0.8419 
2021-01-27 00:45:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8105  Non0_acc_2: 0.8426  Non0_F1_score: 0.8419  Mult_acc_5: 0.4410  Mult_acc_7: 0.3406  MAE: 0.8173  Corr: 0.7720  Loss: 1.1182 
2021-01-27 00:45:14:INFO:TRAIN-(misa) (1/4/3)>> loss: 1.2024  Has0_acc_2: 0.8917  Has0_F1_score: 0.8913  Non0_acc_2: 0.9106  Non0_F1_score: 0.9105  Mult_acc_5: 0.5740  Mult_acc_7: 0.5288  MAE: 0.5097  Corr: 0.9018 
2021-01-27 00:45:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.4716  Mult_acc_7: 0.3624  MAE: 0.7879  Corr: 0.7804  Loss: 1.1243 
2021-01-27 00:45:25:INFO:TRAIN-(misa) (2/5/3)>> loss: 0.8780  Has0_acc_2: 0.9221  Has0_F1_score: 0.9220  Non0_acc_2: 0.9423  Non0_F1_score: 0.9424  Mult_acc_5: 0.6207  Mult_acc_7: 0.5600  MAE: 0.4423  Corr: 0.9304 
2021-01-27 00:45:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.8061  Non0_acc_2: 0.7963  Non0_F1_score: 0.8034  Mult_acc_5: 0.4803  Mult_acc_7: 0.3668  MAE: 0.8877  Corr: 0.7677  Loss: 1.3893 
2021-01-27 00:45:35:INFO:TRAIN-(misa) (3/6/3)>> loss: 0.7063  Has0_acc_2: 0.9151  Has0_F1_score: 0.9149  Non0_acc_2: 0.9285  Non0_F1_score: 0.9285  Mult_acc_5: 0.6768  Mult_acc_7: 0.6192  MAE: 0.4015  Corr: 0.9416 
2021-01-27 00:45:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.8333  Non0_F1_score: 0.8345  Mult_acc_5: 0.5022  Mult_acc_7: 0.3930  MAE: 0.7828  Corr: 0.7784  Loss: 1.1280 
2021-01-27 00:45:45:INFO:TRAIN-(misa) (4/7/3)>> loss: 0.5767  Has0_acc_2: 0.9330  Has0_F1_score: 0.9329  Non0_acc_2: 0.9496  Non0_F1_score: 0.9497  Mult_acc_5: 0.6994  Mult_acc_7: 0.6417  MAE: 0.3595  Corr: 0.9545 
2021-01-27 00:45:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7732  Corr: 0.7854  Loss: 1.0708 
2021-01-27 00:45:57:INFO:TRAIN-(misa) (1/8/3)>> loss: 0.5162  Has0_acc_2: 0.9346  Has0_F1_score: 0.9344  Non0_acc_2: 0.9513  Non0_F1_score: 0.9512  Mult_acc_5: 0.7227  Mult_acc_7: 0.6612  MAE: 0.3389  Corr: 0.9587 
2021-01-27 00:45:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.5066  Mult_acc_7: 0.3799  MAE: 0.7823  Corr: 0.7884  Loss: 1.1610 
2021-01-27 00:46:07:INFO:TRAIN-(misa) (2/9/3)>> loss: 0.4889  Has0_acc_2: 0.9260  Has0_F1_score: 0.9258  Non0_acc_2: 0.9464  Non0_F1_score: 0.9464  Mult_acc_5: 0.7220  Mult_acc_7: 0.6519  MAE: 0.3537  Corr: 0.9558 
2021-01-27 00:46:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.7598  Has0_F1_score: 0.7591  Non0_acc_2: 0.7963  Non0_F1_score: 0.7960  Mult_acc_5: 0.4323  Mult_acc_7: 0.3231  MAE: 0.8693  Corr: 0.7757  Loss: 1.3533 
2021-01-27 00:46:18:INFO:TRAIN-(misa) (3/10/3)>> loss: 0.4783  Has0_acc_2: 0.9393  Has0_F1_score: 0.9391  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7212  Mult_acc_7: 0.6620  MAE: 0.3510  Corr: 0.9563 
2021-01-27 00:46:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8237  Non0_acc_2: 0.8241  Non0_F1_score: 0.8271  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.8065  Corr: 0.7899  Loss: 1.2029 
2021-01-27 00:46:28:INFO:TRAIN-(misa) (4/11/3)>> loss: 0.4574  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9553  Non0_F1_score: 0.9553  Mult_acc_5: 0.6893  Mult_acc_7: 0.6340  MAE: 0.3553  Corr: 0.9543 
2021-01-27 00:46:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8148  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.5240  Mult_acc_7: 0.4192  MAE: 0.7598  Corr: 0.7901  Loss: 1.0695 
2021-01-27 00:46:40:INFO:TRAIN-(misa) (1/12/3)>> loss: 0.3848  Has0_acc_2: 0.9385  Has0_F1_score: 0.9383  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7484  Mult_acc_7: 0.6947  MAE: 0.3118  Corr: 0.9644 
2021-01-27 00:46:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8223  Non0_acc_2: 0.8380  Non0_F1_score: 0.8401  Mult_acc_5: 0.5371  Mult_acc_7: 0.4323  MAE: 0.7518  Corr: 0.7946  Loss: 1.0748 
2021-01-27 00:46:50:INFO:TRAIN-(misa) (2/13/3)>> loss: 0.3504  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7422  Mult_acc_7: 0.6893  MAE: 0.2970  Corr: 0.9676 
2021-01-27 00:46:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5284  Mult_acc_7: 0.4148  MAE: 0.7518  Corr: 0.7931  Loss: 1.1819 
2021-01-27 00:47:00:INFO:TRAIN-(misa) (3/14/3)>> loss: 0.3579  Has0_acc_2: 0.9416  Has0_F1_score: 0.9415  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7484  Mult_acc_7: 0.7033  MAE: 0.3118  Corr: 0.9652 
2021-01-27 00:47:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8060  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4629  Mult_acc_7: 0.3581  MAE: 0.7871  Corr: 0.7918  Loss: 1.1428 
2021-01-27 00:47:11:INFO:TRAIN-(misa) (4/15/3)>> loss: 0.3352  Has0_acc_2: 0.9385  Has0_F1_score: 0.9383  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7383  Mult_acc_7: 0.6893  MAE: 0.3062  Corr: 0.9665 
2021-01-27 00:47:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.7031  Has0_F1_score: 0.7073  Non0_acc_2: 0.7407  Non0_F1_score: 0.7443  Mult_acc_5: 0.3581  Mult_acc_7: 0.2838  MAE: 1.0728  Corr: 0.7679  Loss: 1.9670 
2021-01-27 00:47:21:INFO:TRAIN-(misa) (5/16/3)>> loss: 0.3834  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9399  Non0_F1_score: 0.9398  Mult_acc_5: 0.7048  Mult_acc_7: 0.6456  MAE: 0.3614  Corr: 0.9545 
2021-01-27 00:47:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8211  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5109  Mult_acc_7: 0.3886  MAE: 0.7664  Corr: 0.7950  Loss: 1.1253 
2021-01-27 00:47:31:INFO:TRAIN-(misa) (6/17/3)>> loss: 0.3196  Has0_acc_2: 0.9229  Has0_F1_score: 0.9226  Non0_acc_2: 0.9431  Non0_F1_score: 0.9431  Mult_acc_5: 0.7360  Mult_acc_7: 0.6931  MAE: 0.3146  Corr: 0.9655 
2021-01-27 00:47:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7868  Corr: 0.7733  Loss: 1.1283 
2021-01-27 00:47:42:INFO:TRAIN-(misa) (7/18/3)>> loss: 0.2709  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.7843  Mult_acc_7: 0.7391  MAE: 0.2658  Corr: 0.9752 
2021-01-27 00:47:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7508  Corr: 0.7848  Loss: 1.1154 
2021-01-27 00:47:52:INFO:TRAIN-(misa) (8/19/3)>> loss: 0.2661  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.7827  Mult_acc_7: 0.7352  MAE: 0.2650  Corr: 0.9755 
2021-01-27 00:47:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7884  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.8232  Corr: 0.7852  Loss: 1.1630 
2021-01-27 00:47:54:INFO:TEST-(misa) >>  Has0_acc_2: 0.8222  Has0_F1_score: 0.8247  Non0_acc_2: 0.8460  Non0_F1_score: 0.8476  Mult_acc_5: 0.4971  Mult_acc_7: 0.4359  MAE: 0.7529  Corr: 0.7750  Loss: 1.0276 
2021-01-27 00:47:54:INFO:Start running misa...
2021-01-27 00:47:54:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1114}>
2021-01-27 00:47:54:INFO:Let's use 1 GPUs!
2021-01-27 00:47:55:INFO:train samples: (1284,)
2021-01-27 00:47:55:INFO:valid samples: (229,)
2021-01-27 00:47:56:INFO:test samples: (686,)
2021-01-27 00:47:56:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:47:56:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:47:56:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:47:56:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:47:56:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:47:56:INFO:loading file None
2021-01-27 00:47:56:INFO:loading file None
2021-01-27 00:47:56:INFO:loading file None
2021-01-27 00:47:56:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:47:56:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:47:56:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:47:59:INFO:The model has 110620273 trainable parameters
2021-01-27 00:48:08:INFO:TRAIN-(misa) (1/1/4)>> loss: 4.6547  Has0_acc_2: 0.6254  Has0_F1_score: 0.6454  Non0_acc_2: 0.6271  Non0_F1_score: 0.6490  Mult_acc_5: 0.2188  Mult_acc_7: 0.2188  MAE: 1.2350  Corr: 0.3228 
2021-01-27 00:48:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7664  Non0_acc_2: 0.8009  Non0_F1_score: 0.7998  Mult_acc_5: 0.2882  Mult_acc_7: 0.2882  MAE: 1.0614  Corr: 0.6911  Loss: 1.5593 
2021-01-27 00:48:20:INFO:TRAIN-(misa) (1/2/4)>> loss: 2.9005  Has0_acc_2: 0.8154  Has0_F1_score: 0.8151  Non0_acc_2: 0.8310  Non0_F1_score: 0.8312  Mult_acc_5: 0.3559  Mult_acc_7: 0.3388  MAE: 0.8218  Corr: 0.7341 
2021-01-27 00:48:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7265  Non0_acc_2: 0.7593  Non0_F1_score: 0.7609  Mult_acc_5: 0.3450  Mult_acc_7: 0.2926  MAE: 1.0437  Corr: 0.7689  Loss: 1.6734 
2021-01-27 00:48:30:INFO:TRAIN-(misa) (2/3/4)>> loss: 1.9138  Has0_acc_2: 0.8629  Has0_F1_score: 0.8625  Non0_acc_2: 0.8773  Non0_F1_score: 0.8772  Mult_acc_5: 0.4431  Mult_acc_7: 0.4097  MAE: 0.6814  Corr: 0.8250 
2021-01-27 00:48:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.4629  Mult_acc_7: 0.3668  MAE: 0.8457  Corr: 0.7266  Loss: 1.3204 
2021-01-27 00:48:42:INFO:TRAIN-(misa) (1/4/4)>> loss: 1.2020  Has0_acc_2: 0.9003  Has0_F1_score: 0.9001  Non0_acc_2: 0.9180  Non0_F1_score: 0.9180  Mult_acc_5: 0.6012  Mult_acc_7: 0.5498  MAE: 0.4931  Corr: 0.9075 
2021-01-27 00:48:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7982  Non0_acc_2: 0.8194  Non0_F1_score: 0.8196  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.7937  Corr: 0.7638  Loss: 1.1292 
2021-01-27 00:48:54:INFO:TRAIN-(misa) (1/5/4)>> loss: 0.8312  Has0_acc_2: 0.9151  Has0_F1_score: 0.9150  Non0_acc_2: 0.9318  Non0_F1_score: 0.9319  Mult_acc_5: 0.6495  Mult_acc_7: 0.5896  MAE: 0.4288  Corr: 0.9319 
2021-01-27 00:48:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7710  Non0_acc_2: 0.8056  Non0_F1_score: 0.8046  Mult_acc_5: 0.4803  Mult_acc_7: 0.3843  MAE: 0.8222  Corr: 0.7712  Loss: 1.2173 
2021-01-27 00:49:05:INFO:TRAIN-(misa) (2/6/4)>> loss: 0.6654  Has0_acc_2: 0.9276  Has0_F1_score: 0.9273  Non0_acc_2: 0.9464  Non0_F1_score: 0.9463  Mult_acc_5: 0.6776  Mult_acc_7: 0.6238  MAE: 0.3855  Corr: 0.9464 
2021-01-27 00:49:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8016  Non0_acc_2: 0.8380  Non0_F1_score: 0.8372  Mult_acc_5: 0.4803  Mult_acc_7: 0.3843  MAE: 0.7681  Corr: 0.7835  Loss: 1.1237 
2021-01-27 00:49:16:INFO:TRAIN-(misa) (1/7/4)>> loss: 0.5885  Has0_acc_2: 0.9276  Has0_F1_score: 0.9273  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.6752  Mult_acc_7: 0.6199  MAE: 0.3824  Corr: 0.9465 
2021-01-27 00:49:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7642  Has0_F1_score: 0.7630  Non0_acc_2: 0.8009  Non0_F1_score: 0.8003  Mult_acc_5: 0.4367  Mult_acc_7: 0.2926  MAE: 0.9912  Corr: 0.7756  Loss: 1.6547 
2021-01-27 00:49:27:INFO:TRAIN-(misa) (2/8/4)>> loss: 0.6312  Has0_acc_2: 0.9252  Has0_F1_score: 0.9250  Non0_acc_2: 0.9374  Non0_F1_score: 0.9374  Mult_acc_5: 0.6410  Mult_acc_7: 0.5841  MAE: 0.4256  Corr: 0.9346 
2021-01-27 00:49:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.5066  Mult_acc_7: 0.4192  MAE: 0.7645  Corr: 0.7742  Loss: 1.1430 
2021-01-27 00:49:37:INFO:TRAIN-(misa) (3/9/4)>> loss: 0.4832  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7040  Mult_acc_7: 0.6456  MAE: 0.3603  Corr: 0.9541 
2021-01-27 00:49:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8197  Non0_acc_2: 0.8194  Non0_F1_score: 0.8228  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7847  Corr: 0.7897  Loss: 1.1495 
2021-01-27 00:49:48:INFO:TRAIN-(misa) (4/10/4)>> loss: 0.4886  Has0_acc_2: 0.9206  Has0_F1_score: 0.9205  Non0_acc_2: 0.9374  Non0_F1_score: 0.9375  Mult_acc_5: 0.6916  Mult_acc_7: 0.6215  MAE: 0.3855  Corr: 0.9485 
2021-01-27 00:49:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8018  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7489  Corr: 0.7810  Loss: 1.0999 
2021-01-27 00:49:59:INFO:TRAIN-(misa) (1/11/4)>> loss: 0.4348  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7508  Mult_acc_7: 0.6939  MAE: 0.3335  Corr: 0.9596 
2021-01-27 00:50:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.8194  Non0_F1_score: 0.8202  Mult_acc_5: 0.5328  Mult_acc_7: 0.4367  MAE: 0.7344  Corr: 0.7917  Loss: 1.1265 
2021-01-27 00:50:10:INFO:TRAIN-(misa) (2/12/4)>> loss: 0.4372  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6908  Mult_acc_7: 0.6308  MAE: 0.3767  Corr: 0.9509 
2021-01-27 00:50:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7604  Corr: 0.7658  Loss: 1.2281 
2021-01-27 00:50:20:INFO:TRAIN-(misa) (3/13/4)>> loss: 0.3607  Has0_acc_2: 0.9424  Has0_F1_score: 0.9423  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7609  Mult_acc_7: 0.7103  MAE: 0.3037  Corr: 0.9678 
2021-01-27 00:50:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5153  Mult_acc_7: 0.4279  MAE: 0.7401  Corr: 0.7790  Loss: 1.0819 
2021-01-27 00:50:33:INFO:TRAIN-(misa) (1/14/4)>> loss: 0.3693  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7484  Mult_acc_7: 0.6916  MAE: 0.3187  Corr: 0.9647 
2021-01-27 00:50:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8016  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.5415  Mult_acc_7: 0.4323  MAE: 0.7687  Corr: 0.7780  Loss: 1.1957 
2021-01-27 00:50:43:INFO:TRAIN-(misa) (2/15/4)>> loss: 0.3113  Has0_acc_2: 0.9377  Has0_F1_score: 0.9375  Non0_acc_2: 0.9561  Non0_F1_score: 0.9561  Mult_acc_5: 0.7609  Mult_acc_7: 0.7087  MAE: 0.2915  Corr: 0.9701 
2021-01-27 00:50:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8241  Non0_F1_score: 0.8235  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7398  Corr: 0.7777  Loss: 1.1382 
2021-01-27 00:50:54:INFO:TRAIN-(misa) (3/16/4)>> loss: 0.3024  Has0_acc_2: 0.9502  Has0_F1_score: 0.9501  Non0_acc_2: 0.9626  Non0_F1_score: 0.9626  Mult_acc_5: 0.7656  Mult_acc_7: 0.7188  MAE: 0.2842  Corr: 0.9706 
2021-01-27 00:50:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7803  Non0_acc_2: 0.8194  Non0_F1_score: 0.8188  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.8444  Corr: 0.7668  Loss: 1.4065 
2021-01-27 00:51:05:INFO:TRAIN-(misa) (4/17/4)>> loss: 0.3133  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7601  Mult_acc_7: 0.7072  MAE: 0.3024  Corr: 0.9672 
2021-01-27 00:51:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8027  Non0_acc_2: 0.8194  Non0_F1_score: 0.8196  Mult_acc_5: 0.5459  Mult_acc_7: 0.4454  MAE: 0.7400  Corr: 0.7773  Loss: 1.1339 
2021-01-27 00:51:15:INFO:TRAIN-(misa) (5/18/4)>> loss: 0.2863  Has0_acc_2: 0.9502  Has0_F1_score: 0.9501  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.7773  Mult_acc_7: 0.7360  MAE: 0.2823  Corr: 0.9718 
2021-01-27 00:51:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8176  Non0_acc_2: 0.8148  Non0_F1_score: 0.8205  Mult_acc_5: 0.4934  Mult_acc_7: 0.3624  MAE: 0.8313  Corr: 0.7816  Loss: 1.2647 
2021-01-27 00:51:26:INFO:TRAIN-(misa) (6/19/4)>> loss: 0.3017  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.7399  Mult_acc_7: 0.6924  MAE: 0.3125  Corr: 0.9660 
2021-01-27 00:51:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8025  Non0_acc_2: 0.8241  Non0_F1_score: 0.8241  Mult_acc_5: 0.5502  Mult_acc_7: 0.4236  MAE: 0.7653  Corr: 0.7751  Loss: 1.2364 
2021-01-27 00:51:37:INFO:TRAIN-(misa) (7/20/4)>> loss: 0.2795  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9626  Non0_F1_score: 0.9626  Mult_acc_5: 0.7570  Mult_acc_7: 0.7103  MAE: 0.2868  Corr: 0.9713 
2021-01-27 00:51:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8287  Non0_F1_score: 0.8279  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.7389  Corr: 0.7805  Loss: 1.0638 
2021-01-27 00:51:48:INFO:TRAIN-(misa) (1/21/4)>> loss: 0.2438  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.7967  Mult_acc_7: 0.7547  MAE: 0.2519  Corr: 0.9781 
2021-01-27 00:51:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5633  Mult_acc_7: 0.4498  MAE: 0.7318  Corr: 0.7817  Loss: 1.1314 
2021-01-27 00:51:59:INFO:TRAIN-(misa) (2/22/4)>> loss: 0.2570  Has0_acc_2: 0.9494  Has0_F1_score: 0.9492  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7702  Mult_acc_7: 0.7165  MAE: 0.2872  Corr: 0.9712 
2021-01-27 00:52:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8148  Non0_acc_2: 0.8472  Non0_F1_score: 0.8464  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7540  Corr: 0.7798  Loss: 1.1792 
2021-01-27 00:52:10:INFO:TRAIN-(misa) (3/23/4)>> loss: 0.2343  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7913  Mult_acc_7: 0.7508  MAE: 0.2610  Corr: 0.9758 
2021-01-27 00:52:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8106  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5459  Mult_acc_7: 0.4498  MAE: 0.7212  Corr: 0.7767  Loss: 1.0653 
2021-01-27 00:52:20:INFO:TRAIN-(misa) (4/24/4)>> loss: 0.2019  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8014  Mult_acc_7: 0.7617  MAE: 0.2309  Corr: 0.9813 
2021-01-27 00:52:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7455  Corr: 0.7728  Loss: 1.1259 
2021-01-27 00:52:31:INFO:TRAIN-(misa) (5/25/4)>> loss: 0.2134  Has0_acc_2: 0.9486  Has0_F1_score: 0.9484  Non0_acc_2: 0.9708  Non0_F1_score: 0.9707  Mult_acc_5: 0.8061  Mult_acc_7: 0.7648  MAE: 0.2501  Corr: 0.9779 
2021-01-27 00:52:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7999  Non0_acc_2: 0.8148  Non0_F1_score: 0.8165  Mult_acc_5: 0.5328  Mult_acc_7: 0.4279  MAE: 0.7501  Corr: 0.7754  Loss: 1.1017 
2021-01-27 00:52:41:INFO:TRAIN-(misa) (6/26/4)>> loss: 0.2074  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.8131  Mult_acc_7: 0.7671  MAE: 0.2485  Corr: 0.9783 
2021-01-27 00:52:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8239  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5153  Mult_acc_7: 0.4236  MAE: 0.7412  Corr: 0.7803  Loss: 1.0598 
2021-01-27 00:52:53:INFO:TRAIN-(misa) (1/27/4)>> loss: 0.2027  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.7913  Mult_acc_7: 0.7414  MAE: 0.2416  Corr: 0.9800 
2021-01-27 00:52:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8090  Non0_acc_2: 0.8194  Non0_F1_score: 0.8214  Mult_acc_5: 0.5502  Mult_acc_7: 0.4541  MAE: 0.7273  Corr: 0.7826  Loss: 1.1099 
2021-01-27 00:53:04:INFO:TRAIN-(misa) (2/28/4)>> loss: 0.1919  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8100  Mult_acc_7: 0.7625  MAE: 0.2329  Corr: 0.9810 
2021-01-27 00:53:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.5328  Mult_acc_7: 0.4454  MAE: 0.7238  Corr: 0.7790  Loss: 1.1030 
2021-01-27 00:53:16:INFO:TRAIN-(misa) (3/29/4)>> loss: 0.1749  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8310  Mult_acc_7: 0.7960  MAE: 0.2147  Corr: 0.9835 
2021-01-27 00:53:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.5153  Mult_acc_7: 0.4323  MAE: 0.7464  Corr: 0.7673  Loss: 1.1478 
2021-01-27 00:53:27:INFO:TRAIN-(misa) (4/30/4)>> loss: 0.1603  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8466  Mult_acc_7: 0.8022  MAE: 0.2060  Corr: 0.9849 
2021-01-27 00:53:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8070  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5284  Mult_acc_7: 0.4498  MAE: 0.7503  Corr: 0.7629  Loss: 1.2467 
2021-01-27 00:53:38:INFO:TRAIN-(misa) (5/31/4)>> loss: 0.1575  Has0_acc_2: 0.9727  Has0_F1_score: 0.9727  Non0_acc_2: 0.9894  Non0_F1_score: 0.9894  Mult_acc_5: 0.8411  Mult_acc_7: 0.7936  MAE: 0.2031  Corr: 0.9855 
2021-01-27 00:53:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8241  Non0_F1_score: 0.8235  Mult_acc_5: 0.4934  Mult_acc_7: 0.4061  MAE: 0.7686  Corr: 0.7643  Loss: 1.1202 
2021-01-27 00:53:49:INFO:TRAIN-(misa) (6/32/4)>> loss: 0.1685  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.8053  Mult_acc_7: 0.7601  MAE: 0.2314  Corr: 0.9816 
2021-01-27 00:53:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7807  Non0_acc_2: 0.8056  Non0_F1_score: 0.8058  Mult_acc_5: 0.4891  Mult_acc_7: 0.4061  MAE: 0.7684  Corr: 0.7614  Loss: 1.1223 
2021-01-27 00:53:59:INFO:TRAIN-(misa) (7/33/4)>> loss: 0.1497  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8474  Mult_acc_7: 0.8123  MAE: 0.2035  Corr: 0.9858 
2021-01-27 00:54:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7931  Non0_acc_2: 0.8194  Non0_F1_score: 0.8189  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7605  Corr: 0.7696  Loss: 1.1259 
2021-01-27 00:54:10:INFO:TRAIN-(misa) (8/34/4)>> loss: 0.1438  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8660  Mult_acc_7: 0.8294  MAE: 0.1845  Corr: 0.9877 
2021-01-27 00:54:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7892  Non0_acc_2: 0.8148  Non0_F1_score: 0.8148  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7491  Corr: 0.7711  Loss: 1.1010 
2021-01-27 00:54:13:INFO:TEST-(misa) >>  Has0_acc_2: 0.8047  Has0_F1_score: 0.8053  Non0_acc_2: 0.8216  Non0_F1_score: 0.8216  Mult_acc_5: 0.4636  Mult_acc_7: 0.4067  MAE: 0.7884  Corr: 0.7560  Loss: 1.1413 
2021-01-27 00:54:13:INFO:Start running misa...
2021-01-27 00:54:13:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results', 'gpu_ids': [0], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'rnncell': 'lstm', 'update_epochs': 1, 'batch_size': 64, 'use_cmd_sim': True, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 1.0, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 0.0, 'recon_weight': 1.0, 'grad_clip': 1.0, 'weight_decay': 0.0, 'seed': 1115}>
2021-01-27 00:54:13:INFO:Let's use 1 GPUs!
2021-01-27 00:54:13:INFO:train samples: (1284,)
2021-01-27 00:54:14:INFO:valid samples: (229,)
2021-01-27 00:54:14:INFO:test samples: (686,)
2021-01-27 00:54:14:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-27 00:54:14:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-27 00:54:14:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-27 00:54:14:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-27 00:54:14:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-27 00:54:14:INFO:loading file None
2021-01-27 00:54:14:INFO:loading file None
2021-01-27 00:54:14:INFO:loading file None
2021-01-27 00:54:14:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-27 00:54:14:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-27 00:54:14:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-27 00:54:18:INFO:The model has 110620273 trainable parameters
2021-01-27 00:54:28:INFO:TRAIN-(misa) (1/1/5)>> loss: 4.3330  Has0_acc_2: 0.6340  Has0_F1_score: 0.6412  Non0_acc_2: 0.6385  Non0_F1_score: 0.6471  Mult_acc_5: 0.2118  Mult_acc_7: 0.2111  MAE: 1.1868  Corr: 0.3854 
2021-01-27 00:54:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7999  Non0_acc_2: 0.8009  Non0_F1_score: 0.8067  Mult_acc_5: 0.3319  Mult_acc_7: 0.2707  MAE: 1.0654  Corr: 0.6519  Loss: 1.8546 
2021-01-27 00:54:41:INFO:TRAIN-(misa) (1/2/5)>> loss: 2.7335  Has0_acc_2: 0.8185  Has0_F1_score: 0.8178  Non0_acc_2: 0.8351  Non0_F1_score: 0.8348  Mult_acc_5: 0.3995  Mult_acc_7: 0.3785  MAE: 0.8086  Corr: 0.7277 
2021-01-27 00:54:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8017  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4105  Mult_acc_7: 0.3362  MAE: 0.9001  Corr: 0.7123  Loss: 1.4486 
2021-01-27 00:54:53:INFO:TRAIN-(misa) (1/3/5)>> loss: 1.7401  Has0_acc_2: 0.8785  Has0_F1_score: 0.8781  Non0_acc_2: 0.8952  Non0_F1_score: 0.8951  Mult_acc_5: 0.5241  Mult_acc_7: 0.4751  MAE: 0.5958  Corr: 0.8614 
2021-01-27 00:54:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7709  Non0_acc_2: 0.8056  Non0_F1_score: 0.8045  Mult_acc_5: 0.3930  Mult_acc_7: 0.3319  MAE: 0.8541  Corr: 0.7446  Loss: 1.3117 
2021-01-27 00:55:04:INFO:TRAIN-(misa) (1/4/5)>> loss: 1.2413  Has0_acc_2: 0.9034  Has0_F1_score: 0.9033  Non0_acc_2: 0.9196  Non0_F1_score: 0.9196  Mult_acc_5: 0.5724  Mult_acc_7: 0.5234  MAE: 0.5008  Corr: 0.9071 
2021-01-27 00:55:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8018  Non0_acc_2: 0.8333  Non0_F1_score: 0.8328  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.8082  Corr: 0.7528  Loss: 1.3411 
2021-01-27 00:55:15:INFO:TRAIN-(misa) (2/5/5)>> loss: 0.9410  Has0_acc_2: 0.9097  Has0_F1_score: 0.9094  Non0_acc_2: 0.9277  Non0_F1_score: 0.9276  Mult_acc_5: 0.6067  Mult_acc_7: 0.5483  MAE: 0.4645  Corr: 0.9240 
2021-01-27 00:55:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8084  Non0_acc_2: 0.8009  Non0_F1_score: 0.8060  Mult_acc_5: 0.4585  Mult_acc_7: 0.3581  MAE: 0.9117  Corr: 0.7628  Loss: 1.4895 
2021-01-27 00:55:25:INFO:TRAIN-(misa) (3/6/5)>> loss: 0.9031  Has0_acc_2: 0.9182  Has0_F1_score: 0.9183  Non0_acc_2: 0.9253  Non0_F1_score: 0.9254  Mult_acc_5: 0.5981  Mult_acc_7: 0.5397  MAE: 0.4916  Corr: 0.9156 
2021-01-27 00:55:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.7973  Corr: 0.7634  Loss: 1.1687 
2021-01-27 00:55:37:INFO:TRAIN-(misa) (1/7/5)>> loss: 0.6400  Has0_acc_2: 0.9276  Has0_F1_score: 0.9274  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.7087  Mult_acc_7: 0.6534  MAE: 0.3650  Corr: 0.9519 
2021-01-27 00:55:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7534  Corr: 0.7774  Loss: 1.1588 
2021-01-27 00:55:49:INFO:TRAIN-(misa) (1/8/5)>> loss: 0.5430  Has0_acc_2: 0.9369  Has0_F1_score: 0.9367  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7305  Mult_acc_7: 0.6682  MAE: 0.3394  Corr: 0.9597 
2021-01-27 00:55:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7541  Corr: 0.7769  Loss: 1.0653 
2021-01-27 00:56:00:INFO:TRAIN-(misa) (1/9/5)>> loss: 0.5105  Has0_acc_2: 0.9307  Has0_F1_score: 0.9305  Non0_acc_2: 0.9488  Non0_F1_score: 0.9488  Mult_acc_5: 0.7266  Mult_acc_7: 0.6690  MAE: 0.3339  Corr: 0.9598 
2021-01-27 00:56:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5328  Mult_acc_7: 0.4454  MAE: 0.7427  Corr: 0.7777  Loss: 1.1103 
2021-01-27 00:56:11:INFO:TRAIN-(misa) (2/10/5)>> loss: 0.4724  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9504  Non0_F1_score: 0.9505  Mult_acc_5: 0.7259  Mult_acc_7: 0.6612  MAE: 0.3403  Corr: 0.9597 
2021-01-27 00:56:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7760  Corr: 0.7659  Loss: 1.1978 
2021-01-27 00:56:22:INFO:TRAIN-(misa) (3/11/5)>> loss: 0.4259  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9578  Non0_F1_score: 0.9577  Mult_acc_5: 0.7679  Mult_acc_7: 0.7079  MAE: 0.3169  Corr: 0.9637 
2021-01-27 00:56:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7681  Corr: 0.7733  Loss: 1.1605 
2021-01-27 00:56:32:INFO:TRAIN-(misa) (4/12/5)>> loss: 0.3841  Has0_acc_2: 0.9361  Has0_F1_score: 0.9360  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7484  Mult_acc_7: 0.6947  MAE: 0.3166  Corr: 0.9654 
2021-01-27 00:56:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8404  Non0_acc_2: 0.8472  Non0_F1_score: 0.8496  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.8095  Corr: 0.7808  Loss: 1.2491 
2021-01-27 00:56:43:INFO:TRAIN-(misa) (5/13/5)>> loss: 0.3809  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9488  Non0_F1_score: 0.9488  Mult_acc_5: 0.7336  Mult_acc_7: 0.6830  MAE: 0.3247  Corr: 0.9630 
2021-01-27 00:56:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.8463  Corr: 0.7558  Loss: 1.2921 
2021-01-27 00:56:54:INFO:TRAIN-(misa) (6/14/5)>> loss: 0.3372  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7484  Mult_acc_7: 0.7002  MAE: 0.2845  Corr: 0.9712 
2021-01-27 00:56:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7253  Corr: 0.7859  Loss: 1.0423 
2021-01-27 00:57:07:INFO:TRAIN-(misa) (1/15/5)>> loss: 0.2951  Has0_acc_2: 0.9540  Has0_F1_score: 0.9540  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.7975  Mult_acc_7: 0.7461  MAE: 0.2533  Corr: 0.9774 
2021-01-27 00:57:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8314  Non0_acc_2: 0.8426  Non0_F1_score: 0.8449  Mult_acc_5: 0.5109  Mult_acc_7: 0.4105  MAE: 0.7945  Corr: 0.7769  Loss: 1.2659 
2021-01-27 00:57:18:INFO:TRAIN-(misa) (2/16/5)>> loss: 0.3313  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9553  Non0_F1_score: 0.9554  Mult_acc_5: 0.7702  Mult_acc_7: 0.7118  MAE: 0.2990  Corr: 0.9684 
2021-01-27 00:57:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5546  Mult_acc_7: 0.4585  MAE: 0.7352  Corr: 0.7851  Loss: 1.0885 
2021-01-27 00:57:29:INFO:TRAIN-(misa) (3/17/5)>> loss: 0.2738  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.7905  Mult_acc_7: 0.7407  MAE: 0.2521  Corr: 0.9777 
2021-01-27 00:57:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8450  Non0_acc_2: 0.8472  Non0_F1_score: 0.8496  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7656  Corr: 0.7908  Loss: 1.1699 
2021-01-27 00:57:40:INFO:TRAIN-(misa) (4/18/5)>> loss: 0.2859  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7578  Mult_acc_7: 0.7087  MAE: 0.2764  Corr: 0.9734 
2021-01-27 00:57:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5459  Mult_acc_7: 0.4629  MAE: 0.7128  Corr: 0.7957  Loss: 1.0730 
2021-01-27 00:57:51:INFO:TRAIN-(misa) (5/19/5)>> loss: 0.2557  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.8107  Mult_acc_7: 0.7539  MAE: 0.2487  Corr: 0.9778 
2021-01-27 00:57:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8314  Non0_acc_2: 0.8241  Non0_F1_score: 0.8302  Mult_acc_5: 0.4629  Mult_acc_7: 0.3668  MAE: 0.8290  Corr: 0.7925  Loss: 1.1932 
2021-01-27 00:58:02:INFO:TRAIN-(misa) (6/20/5)>> loss: 0.2866  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7562  Mult_acc_7: 0.6986  MAE: 0.2948  Corr: 0.9696 
2021-01-27 00:58:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8132  Non0_acc_2: 0.8241  Non0_F1_score: 0.8257  Mult_acc_5: 0.5197  Mult_acc_7: 0.4279  MAE: 0.7557  Corr: 0.7869  Loss: 1.0680 
2021-01-27 00:58:12:INFO:TRAIN-(misa) (7/21/5)>> loss: 0.2327  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8123  Mult_acc_7: 0.7702  MAE: 0.2340  Corr: 0.9803 
2021-01-27 00:58:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5328  Mult_acc_7: 0.4410  MAE: 0.7346  Corr: 0.7873  Loss: 1.0536 
2021-01-27 00:58:24:INFO:TRAIN-(misa) (8/22/5)>> loss: 0.2248  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8139  Mult_acc_7: 0.7702  MAE: 0.2462  Corr: 0.9789 
2021-01-27 00:58:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5459  Mult_acc_7: 0.4585  MAE: 0.7205  Corr: 0.7914  Loss: 1.0098 
2021-01-27 00:58:36:INFO:TRAIN-(misa) (1/23/5)>> loss: 0.2094  Has0_acc_2: 0.9626  Has0_F1_score: 0.9626  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8209  Mult_acc_7: 0.7773  MAE: 0.2182  Corr: 0.9832 
2021-01-27 00:58:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7233  Corr: 0.7918  Loss: 1.0343 
2021-01-27 00:58:47:INFO:TRAIN-(misa) (2/24/5)>> loss: 0.2126  Has0_acc_2: 0.9572  Has0_F1_score: 0.9570  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8232  Mult_acc_7: 0.7710  MAE: 0.2306  Corr: 0.9819 
2021-01-27 00:58:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8166  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7367  Corr: 0.7892  Loss: 1.1073 
2021-01-27 00:58:58:INFO:TRAIN-(misa) (3/25/5)>> loss: 0.2221  Has0_acc_2: 0.9533  Has0_F1_score: 0.9532  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8139  Mult_acc_7: 0.7531  MAE: 0.2521  Corr: 0.9778 
2021-01-27 00:58:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5415  Mult_acc_7: 0.4541  MAE: 0.7355  Corr: 0.7872  Loss: 1.1145 
2021-01-27 00:59:08:INFO:TRAIN-(misa) (4/26/5)>> loss: 0.1905  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8349  Mult_acc_7: 0.7843  MAE: 0.2158  Corr: 0.9831 
2021-01-27 00:59:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7659  Corr: 0.7902  Loss: 1.0749 
2021-01-27 00:59:18:INFO:TRAIN-(misa) (5/27/5)>> loss: 0.2088  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.8069  Mult_acc_7: 0.7640  MAE: 0.2489  Corr: 0.9785 
2021-01-27 00:59:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8070  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5546  Mult_acc_7: 0.4672  MAE: 0.7180  Corr: 0.7931  Loss: 0.9881 
2021-01-27 00:59:30:INFO:TRAIN-(misa) (1/28/5)>> loss: 0.1807  Has0_acc_2: 0.9572  Has0_F1_score: 0.9570  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8349  Mult_acc_7: 0.7905  MAE: 0.2106  Corr: 0.9840 
2021-01-27 00:59:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7384  Corr: 0.7881  Loss: 1.0818 
2021-01-27 00:59:41:INFO:TRAIN-(misa) (2/29/5)>> loss: 0.1784  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8248  Mult_acc_7: 0.7788  MAE: 0.2125  Corr: 0.9838 
2021-01-27 00:59:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5109  Mult_acc_7: 0.4279  MAE: 0.7416  Corr: 0.7956  Loss: 1.0191 
2021-01-27 00:59:51:INFO:TRAIN-(misa) (3/30/5)>> loss: 0.1775  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8069  Mult_acc_7: 0.7593  MAE: 0.2190  Corr: 0.9830 
2021-01-27 00:59:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7142  Corr: 0.7959  Loss: 1.0135 
2021-01-27 01:00:01:INFO:TRAIN-(misa) (4/31/5)>> loss: 0.1638  Has0_acc_2: 0.9657  Has0_F1_score: 0.9657  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8474  Mult_acc_7: 0.8045  MAE: 0.2006  Corr: 0.9852 
2021-01-27 01:00:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8565  Non0_F1_score: 0.8577  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7177  Corr: 0.7968  Loss: 1.0033 
2021-01-27 01:00:12:INFO:TRAIN-(misa) (5/32/5)>> loss: 0.1563  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8442  Mult_acc_7: 0.8084  MAE: 0.1973  Corr: 0.9862 
2021-01-27 01:00:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7278  Corr: 0.7905  Loss: 1.0519 
2021-01-27 01:00:23:INFO:TRAIN-(misa) (6/33/5)>> loss: 0.1515  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8520  Mult_acc_7: 0.8123  MAE: 0.1904  Corr: 0.9868 
2021-01-27 01:00:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8121  Non0_acc_2: 0.8333  Non0_F1_score: 0.8342  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7579  Corr: 0.7864  Loss: 1.1456 
2021-01-27 01:00:33:INFO:TRAIN-(misa) (7/34/5)>> loss: 0.1683  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8318  Mult_acc_7: 0.7812  MAE: 0.2212  Corr: 0.9831 
2021-01-27 01:00:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8302  Non0_acc_2: 0.8519  Non0_F1_score: 0.8532  Mult_acc_5: 0.5502  Mult_acc_7: 0.4541  MAE: 0.7165  Corr: 0.7929  Loss: 1.0602 
2021-01-27 01:00:44:INFO:TRAIN-(misa) (8/35/5)>> loss: 0.1459  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8427  Mult_acc_7: 0.7967  MAE: 0.1947  Corr: 0.9868 
2021-01-27 01:00:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8426  Non0_F1_score: 0.8437  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7326  Corr: 0.7882  Loss: 1.0438 
2021-01-27 01:00:46:INFO:TEST-(misa) >>  Has0_acc_2: 0.8163  Has0_F1_score: 0.8169  Non0_acc_2: 0.8338  Non0_F1_score: 0.8338  Mult_acc_5: 0.4854  Mult_acc_7: 0.4242  MAE: 0.7500  Corr: 0.7860  Loss: 1.0296 
2021-01-27 01:00:46:INFO:Results are saved to results/results/mosi-misa-regression.csv...
2021-01-28 01:00:40:ERROR:name 'logger' is not defined
2021-01-28 04:19:22:INFO:########################################misa-(1/50)########################################
2021-01-28 04:19:22:INFO:batch_size:16
2021-01-28 04:19:22:INFO:learning_rate:0.0001
2021-01-28 04:19:22:INFO:hidden_size:128
2021-01-28 04:19:22:INFO:dropout:0.0
2021-01-28 04:19:22:INFO:reverse_grad_weight:0.8
2021-01-28 04:19:22:INFO:diff_weight:0.5
2021-01-28 04:19:22:INFO:sim_weight:0.5
2021-01-28 04:19:22:INFO:sp_weight:0.0
2021-01-28 04:19:22:INFO:recon_weight:1.0
2021-01-28 04:19:22:INFO:grad_clip:-1.0
2021-01-28 04:19:22:INFO:weight_decay:5e-05
2021-01-28 04:19:22:INFO:##########################################################################################
2021-01-28 04:19:22:INFO:Start running misa...
2021-01-28 04:19:22:INFO:Find gpu: 2, with memory: 7529627648 left!
2021-01-28 04:19:22:INFO:Let's use 1 GPUs!
2021-01-28 04:19:22:INFO:train samples: (1284,)
2021-01-28 04:19:23:INFO:valid samples: (229,)
2021-01-28 04:19:23:INFO:test samples: (686,)
2021-01-28 04:19:23:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 04:19:23:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 04:19:23:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 04:19:23:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 04:19:23:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 04:19:23:INFO:loading file None
2021-01-28 04:19:23:INFO:loading file None
2021-01-28 04:19:23:INFO:loading file None
2021-01-28 04:19:23:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 04:19:23:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 04:19:23:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 04:19:29:INFO:The model has 110620273 trainable parameters
2021-01-28 04:19:29:ERROR:CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 7.77 GiB total capacity; 793.57 MiB already allocated; 9.50 MiB free; 24.43 MiB cached)
2021-01-28 09:50:53:INFO:########################################misa-(1/50)########################################
2021-01-28 09:50:53:INFO:batch_size:64
2021-01-28 09:50:53:INFO:learning_rate:0.001
2021-01-28 09:50:53:INFO:hidden_size:256
2021-01-28 09:50:53:INFO:dropout:0.5
2021-01-28 09:50:53:INFO:reverse_grad_weight:0.5
2021-01-28 09:50:53:INFO:diff_weight:0.5
2021-01-28 09:50:53:INFO:sim_weight:0.5
2021-01-28 09:50:53:INFO:sp_weight:1.0
2021-01-28 09:50:53:INFO:recon_weight:0.8
2021-01-28 09:50:53:INFO:grad_clip:-1.0
2021-01-28 09:50:53:INFO:weight_decay:0.0
2021-01-28 09:50:53:INFO:##########################################################################################
2021-01-28 09:50:53:INFO:Start running misa...
2021-01-28 09:50:53:INFO:Find gpu: 3, with memory: 11337728 left!
2021-01-28 09:50:53:INFO:Let's use 1 GPUs!
2021-01-28 09:50:54:INFO:train samples: (1284,)
2021-01-28 09:50:54:INFO:valid samples: (229,)
2021-01-28 09:50:55:INFO:test samples: (686,)
2021-01-28 09:50:55:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 09:50:55:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 09:50:55:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 09:50:55:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 09:50:55:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 09:50:55:INFO:loading file None
2021-01-28 09:50:55:INFO:loading file None
2021-01-28 09:50:55:INFO:loading file None
2021-01-28 09:50:55:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 09:50:55:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 09:50:55:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 09:51:02:INFO:The model has 112685553 trainable parameters
2021-01-28 09:51:12:INFO:TRAIN-(misa) (1/1/1)>> loss: 6.9854  Has0_acc_2: 0.5093  Has0_F1_score: 0.5111  Non0_acc_2: 0.5028  Non0_F1_score: 0.5055  Mult_acc_5: 0.2150  Mult_acc_7: 0.1893  MAE: 1.8563  Corr: -0.0470 
2021-01-28 09:51:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.1397  Mult_acc_7: 0.1397  MAE: 1.6946  Corr: 0.1027  Loss: 3.9602 
2021-01-28 09:51:22:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.2411  Has0_acc_2: 0.5008  Has0_F1_score: 0.4985  Non0_acc_2: 0.5028  Non0_F1_score: 0.5018  Mult_acc_5: 0.1815  Mult_acc_7: 0.1799  MAE: 1.3975  Corr: 0.0217 
2021-01-28 09:51:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.5368  Corr: 0.0669  Loss: 3.1805 
2021-01-28 09:51:34:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.6768  Has0_acc_2: 0.5343  Has0_F1_score: 0.5739  Non0_acc_2: 0.5232  Non0_F1_score: 0.5642  Mult_acc_5: 0.2002  Mult_acc_7: 0.2002  MAE: 1.3526  Corr: -0.0262 
2021-01-28 09:51:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4273  Corr: 0.0764  Loss: 2.7869 
2021-01-28 17:03:13:INFO:########################################misa-(1/50)########################################
2021-01-28 17:03:13:INFO:batch_size:64
2021-01-28 17:03:13:INFO:learning_rate:0.001
2021-01-28 17:03:13:INFO:hidden_size:256
2021-01-28 17:03:13:INFO:dropout:0.2
2021-01-28 17:03:13:INFO:reverse_grad_weight:0.5
2021-01-28 17:03:13:INFO:diff_weight:0.1
2021-01-28 17:03:13:INFO:sim_weight:0.5
2021-01-28 17:03:13:INFO:sp_weight:0.0
2021-01-28 17:03:13:INFO:recon_weight:0.5
2021-01-28 17:03:13:INFO:grad_clip:-1.0
2021-01-28 17:03:13:INFO:weight_decay:5e-05
2021-01-28 17:03:13:INFO:##########################################################################################
2021-01-28 17:03:13:INFO:Start running misa...
2021-01-28 17:03:13:INFO:Find gpu: 1, with memory: 1947009024 left!
2021-01-28 17:03:13:INFO:Let's use 1 GPUs!
2021-01-28 17:03:13:INFO:train samples: (1284,)
2021-01-28 17:03:14:INFO:valid samples: (229,)
2021-01-28 17:03:14:INFO:test samples: (686,)
2021-01-28 17:03:14:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:03:14:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:03:14:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:03:14:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:03:14:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:03:14:INFO:loading file None
2021-01-28 17:03:14:INFO:loading file None
2021-01-28 17:03:14:INFO:loading file None
2021-01-28 17:03:14:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:03:14:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:03:14:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:03:18:INFO:The model has 112685553 trainable parameters
2021-01-28 17:03:28:INFO:TRAIN-(misa) (1/1/1)>> loss: 8.4596  Has0_acc_2: 0.5241  Has0_F1_score: 0.5264  Non0_acc_2: 0.5223  Non0_F1_score: 0.5258  Mult_acc_5: 0.2025  Mult_acc_7: 0.1729  MAE: 2.0493  Corr: 0.0056 
2021-01-28 17:03:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.1397  Mult_acc_7: 0.1397  MAE: 1.7231  Corr: 0.1113  Loss: 4.1155 
2021-01-28 17:03:40:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.2293  Has0_acc_2: 0.5491  Has0_F1_score: 0.5628  Non0_acc_2: 0.5443  Non0_F1_score: 0.5593  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.3774  Corr: -0.0018 
2021-01-28 17:03:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.5075  Corr: 0.0866  Loss: 3.0477 
2021-01-28 17:03:51:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.6984  Has0_acc_2: 0.5187  Has0_F1_score: 0.5206  Non0_acc_2: 0.5142  Non0_F1_score: 0.5171  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.3481  Corr: -0.0207 
2021-01-28 17:03:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4171  Corr: 0.0802  Loss: 2.7724 
2021-01-28 17:04:03:INFO:TRAIN-(misa) (1/4/1)>> loss: 2.5288  Has0_acc_2: 0.5358  Has0_F1_score: 0.5436  Non0_acc_2: 0.5353  Non0_F1_score: 0.5448  Mult_acc_5: 0.1854  Mult_acc_7: 0.1854  MAE: 1.3327  Corr: -0.0092 
2021-01-28 17:04:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4163  Corr: 0.0776  Loss: 2.6707 
2021-01-28 17:04:18:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.4295  Has0_acc_2: 0.5709  Has0_F1_score: 0.7205  Non0_acc_2: 0.5524  Non0_F1_score: 0.7051  Mult_acc_5: 0.1846  Mult_acc_7: 0.1846  MAE: 1.3222  Corr: 0.0064 
2021-01-28 17:04:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4250  Corr: 0.0716  Loss: 2.7547 
2021-01-28 17:04:29:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3843  Has0_acc_2: 0.5545  Has0_F1_score: 0.6497  Non0_acc_2: 0.5370  Non0_F1_score: 0.6337  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3298  Corr: -0.0383 
2021-01-28 17:04:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4128  Corr: 0.0681  Loss: 2.7037 
2021-01-28 17:04:39:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3138  Has0_acc_2: 0.5693  Has0_F1_score: 0.7142  Non0_acc_2: 0.5508  Non0_F1_score: 0.6985  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3185  Corr: -0.0006 
2021-01-28 17:04:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4226  Corr: 0.0725  Loss: 2.7095 
2021-01-28 17:04:49:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.2904  Has0_acc_2: 0.5717  Has0_F1_score: 0.7258  Non0_acc_2: 0.5532  Non0_F1_score: 0.7106  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3208  Corr: -0.0143 
2021-01-28 17:04:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4169  Corr: 0.0750  Loss: 2.6862 
2021-01-28 17:04:59:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.2973  Has0_acc_2: 0.5693  Has0_F1_score: 0.7222  Non0_acc_2: 0.5508  Non0_F1_score: 0.7069  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3157  Corr: 0.0420 
2021-01-28 17:05:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4248  Corr: 0.0897  Loss: 2.7614 
2021-01-28 17:05:10:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.3570  Has0_acc_2: 0.5654  Has0_F1_score: 0.7149  Non0_acc_2: 0.5475  Non0_F1_score: 0.7005  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3186  Corr: 0.0156 
2021-01-28 17:05:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4148  Corr: 0.0983  Loss: 2.6978 
2021-01-28 17:05:20:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.4854  Has0_acc_2: 0.5685  Has0_F1_score: 0.7210  Non0_acc_2: 0.5500  Non0_F1_score: 0.7056  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3168  Corr: 0.0103 
2021-01-28 17:05:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4261  Corr: 0.1224  Loss: 2.7973 
2021-01-28 17:05:30:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.3308  Has0_acc_2: 0.5654  Has0_F1_score: 0.7083  Non0_acc_2: 0.5475  Non0_F1_score: 0.6936  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3163  Corr: 0.0241 
2021-01-28 17:05:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4150  Corr: 0.1085  Loss: 2.6731 
2021-01-28 17:05:33:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4791  Corr: 0.0903  Loss: 2.8922 
2021-01-28 17:05:33:INFO:Start saving results...
2021-01-28 17:05:33:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:05:33:INFO:########################################misa-(2/50)########################################
2021-01-28 17:05:33:INFO:batch_size:64
2021-01-28 17:05:33:INFO:learning_rate:0.0001
2021-01-28 17:05:33:INFO:hidden_size:256
2021-01-28 17:05:33:INFO:dropout:0.0
2021-01-28 17:05:33:INFO:reverse_grad_weight:1.0
2021-01-28 17:05:33:INFO:diff_weight:0.5
2021-01-28 17:05:33:INFO:sim_weight:0.5
2021-01-28 17:05:33:INFO:sp_weight:0.0
2021-01-28 17:05:33:INFO:recon_weight:0.5
2021-01-28 17:05:33:INFO:grad_clip:-1.0
2021-01-28 17:05:33:INFO:weight_decay:0.0
2021-01-28 17:05:33:INFO:##########################################################################################
2021-01-28 17:05:33:INFO:Start running misa...
2021-01-28 17:05:33:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:05:33:INFO:Let's use 1 GPUs!
2021-01-28 17:05:33:INFO:train samples: (1284,)
2021-01-28 17:05:33:INFO:valid samples: (229,)
2021-01-28 17:05:34:INFO:test samples: (686,)
2021-01-28 17:05:34:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:05:34:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:05:34:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:05:34:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:05:34:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:05:34:INFO:loading file None
2021-01-28 17:05:34:INFO:loading file None
2021-01-28 17:05:34:INFO:loading file None
2021-01-28 17:05:34:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:05:34:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:05:34:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:05:37:INFO:The model has 112685553 trainable parameters
2021-01-28 17:05:47:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.8070  Has0_acc_2: 0.5623  Has0_F1_score: 0.5813  Non0_acc_2: 0.5556  Non0_F1_score: 0.5758  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.2708  Corr: 0.2090 
2021-01-28 17:05:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.7555  Has0_F1_score: 0.7538  Non0_acc_2: 0.7685  Non0_F1_score: 0.7680  Mult_acc_5: 0.3013  Mult_acc_7: 0.3013  MAE: 1.1863  Corr: 0.6050  Loss: 1.9505 
2021-01-28 17:05:58:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4669  Has0_acc_2: 0.7843  Has0_F1_score: 0.7832  Non0_acc_2: 0.8018  Non0_F1_score: 0.8013  Mult_acc_5: 0.3302  Mult_acc_7: 0.3178  MAE: 0.9079  Corr: 0.6774 
2021-01-28 17:05:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8426  Non0_F1_score: 0.8417  Mult_acc_5: 0.4323  Mult_acc_7: 0.3493  MAE: 0.8621  Corr: 0.7495  Loss: 1.2591 
2021-01-28 17:06:10:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.5842  Has0_acc_2: 0.8637  Has0_F1_score: 0.8631  Non0_acc_2: 0.8846  Non0_F1_score: 0.8844  Mult_acc_5: 0.4782  Mult_acc_7: 0.4416  MAE: 0.6375  Corr: 0.8451 
2021-01-28 17:06:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.4541  Mult_acc_7: 0.3581  MAE: 0.7802  Corr: 0.7828  Loss: 1.1058 
2021-01-28 17:06:22:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.1201  Has0_acc_2: 0.9034  Has0_F1_score: 0.9031  Non0_acc_2: 0.9277  Non0_F1_score: 0.9276  Mult_acc_5: 0.5794  Mult_acc_7: 0.5350  MAE: 0.5119  Corr: 0.8989 
2021-01-28 17:06:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8215  Non0_acc_2: 0.8194  Non0_F1_score: 0.8247  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.8351  Corr: 0.7857  Loss: 1.2670 
2021-01-28 17:06:33:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.8027  Has0_acc_2: 0.9229  Has0_F1_score: 0.9227  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6394  Mult_acc_7: 0.5888  MAE: 0.4338  Corr: 0.9287 
2021-01-28 17:06:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.4672  Mult_acc_7: 0.3712  MAE: 0.7616  Corr: 0.7860  Loss: 1.0389 
2021-01-28 17:06:44:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.5673  Has0_acc_2: 0.9299  Has0_F1_score: 0.9297  Non0_acc_2: 0.9529  Non0_F1_score: 0.9528  Mult_acc_5: 0.7438  Mult_acc_7: 0.6924  MAE: 0.3377  Corr: 0.9580 
2021-01-28 17:06:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8287  Non0_F1_score: 0.8284  Mult_acc_5: 0.4498  Mult_acc_7: 0.3537  MAE: 0.7635  Corr: 0.7857  Loss: 1.0299 
2021-01-28 17:06:55:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.4404  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7882  Mult_acc_7: 0.7399  MAE: 0.2809  Corr: 0.9699 
2021-01-28 17:06:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8248  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.4847  Mult_acc_7: 0.3755  MAE: 0.7381  Corr: 0.7915  Loss: 1.0362 
2021-01-28 17:07:06:INFO:TRAIN-(misa) (2/8/1)>> loss: 0.3491  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8209  Mult_acc_7: 0.7749  MAE: 0.2213  Corr: 0.9820 
2021-01-28 17:07:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7309  Corr: 0.7913  Loss: 1.0655 
2021-01-28 17:07:16:INFO:TRAIN-(misa) (3/9/1)>> loss: 0.2909  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8380  Mult_acc_7: 0.7928  MAE: 0.1900  Corr: 0.9865 
2021-01-28 17:07:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7311  Corr: 0.7907  Loss: 1.0506 
2021-01-28 17:07:26:INFO:TRAIN-(misa) (4/10/1)>> loss: 0.2608  Has0_acc_2: 0.9696  Has0_F1_score: 0.9696  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8567  Mult_acc_7: 0.8170  MAE: 0.1758  Corr: 0.9890 
2021-01-28 17:07:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8335  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.4891  Mult_acc_7: 0.3581  MAE: 0.7420  Corr: 0.7910  Loss: 1.0779 
2021-01-28 17:07:37:INFO:TRAIN-(misa) (5/11/1)>> loss: 0.2450  Has0_acc_2: 0.9681  Has0_F1_score: 0.9680  Non0_acc_2: 0.9894  Non0_F1_score: 0.9894  Mult_acc_5: 0.8676  Mult_acc_7: 0.8357  MAE: 0.1709  Corr: 0.9876 
2021-01-28 17:07:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8331  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5109  Mult_acc_7: 0.3930  MAE: 0.7379  Corr: 0.7888  Loss: 1.0558 
2021-01-28 17:07:47:INFO:TRAIN-(misa) (6/12/1)>> loss: 0.2101  Has0_acc_2: 0.9696  Has0_F1_score: 0.9695  Non0_acc_2: 0.9919  Non0_F1_score: 0.9919  Mult_acc_5: 0.8629  Mult_acc_7: 0.8357  MAE: 0.1670  Corr: 0.9901 
2021-01-28 17:07:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.4934  Mult_acc_7: 0.3755  MAE: 0.7384  Corr: 0.7907  Loss: 1.0364 
2021-01-28 17:07:57:INFO:TRAIN-(misa) (7/13/1)>> loss: 0.2059  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8544  Mult_acc_7: 0.8271  MAE: 0.1745  Corr: 0.9893 
2021-01-28 17:07:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5066  Mult_acc_7: 0.3930  MAE: 0.7295  Corr: 0.7962  Loss: 1.0192 
2021-01-28 17:08:09:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.1912  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8645  Mult_acc_7: 0.8333  MAE: 0.1698  Corr: 0.9898 
2021-01-28 17:08:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5066  Mult_acc_7: 0.3974  MAE: 0.7194  Corr: 0.7991  Loss: 0.9844 
2021-01-28 17:08:20:INFO:TRAIN-(misa) (1/15/1)>> loss: 0.1887  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8528  Mult_acc_7: 0.8318  MAE: 0.1678  Corr: 0.9898 
2021-01-28 17:08:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5284  Mult_acc_7: 0.4017  MAE: 0.7372  Corr: 0.8018  Loss: 1.0977 
2021-01-28 17:08:30:INFO:TRAIN-(misa) (2/16/1)>> loss: 0.1837  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8536  Mult_acc_7: 0.8209  MAE: 0.1719  Corr: 0.9895 
2021-01-28 17:08:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8389  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5240  Mult_acc_7: 0.4105  MAE: 0.7182  Corr: 0.8028  Loss: 0.9896 
2021-01-28 17:08:40:INFO:TRAIN-(misa) (3/17/1)>> loss: 0.1691  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8653  Mult_acc_7: 0.8372  MAE: 0.1712  Corr: 0.9898 
2021-01-28 17:08:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5328  Mult_acc_7: 0.4236  MAE: 0.7100  Corr: 0.8045  Loss: 0.9872 
2021-01-28 17:08:51:INFO:TRAIN-(misa) (4/18/1)>> loss: 0.1598  Has0_acc_2: 0.9743  Has0_F1_score: 0.9742  Non0_acc_2: 0.9903  Non0_F1_score: 0.9903  Mult_acc_5: 0.8629  Mult_acc_7: 0.8349  MAE: 0.1561  Corr: 0.9913 
2021-01-28 17:08:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8431  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.5109  Mult_acc_7: 0.4105  MAE: 0.7164  Corr: 0.8036  Loss: 1.0230 
2021-01-28 17:09:01:INFO:TRAIN-(misa) (5/19/1)>> loss: 0.1480  Has0_acc_2: 0.9720  Has0_F1_score: 0.9719  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8777  Mult_acc_7: 0.8528  MAE: 0.1524  Corr: 0.9919 
2021-01-28 17:09:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8376  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7047  Corr: 0.8048  Loss: 0.9555 
2021-01-28 17:09:13:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.1343  Has0_acc_2: 0.9688  Has0_F1_score: 0.9687  Non0_acc_2: 0.9927  Non0_F1_score: 0.9927  Mult_acc_5: 0.8871  Mult_acc_7: 0.8668  MAE: 0.1369  Corr: 0.9934 
2021-01-28 17:09:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5284  Mult_acc_7: 0.4105  MAE: 0.7214  Corr: 0.8037  Loss: 0.9927 
2021-01-28 17:09:22:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.1338  Has0_acc_2: 0.9688  Has0_F1_score: 0.9688  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8855  Mult_acc_7: 0.8629  MAE: 0.1446  Corr: 0.9926 
2021-01-28 17:09:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8288  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5284  Mult_acc_7: 0.4192  MAE: 0.7129  Corr: 0.8032  Loss: 1.0209 
2021-01-28 17:09:32:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.1258  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8808  Mult_acc_7: 0.8614  MAE: 0.1375  Corr: 0.9932 
2021-01-28 17:09:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5197  Mult_acc_7: 0.4061  MAE: 0.7222  Corr: 0.8023  Loss: 1.0508 
2021-01-28 17:09:42:INFO:TRAIN-(misa) (4/23/1)>> loss: 0.1398  Has0_acc_2: 0.9665  Has0_F1_score: 0.9665  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8676  Mult_acc_7: 0.8427  MAE: 0.1735  Corr: 0.9892 
2021-01-28 17:09:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.4934  Mult_acc_7: 0.4017  MAE: 0.7613  Corr: 0.8037  Loss: 1.0717 
2021-01-28 17:09:52:INFO:TRAIN-(misa) (5/24/1)>> loss: 0.1369  Has0_acc_2: 0.9564  Has0_F1_score: 0.9562  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8575  Mult_acc_7: 0.8341  MAE: 0.1693  Corr: 0.9901 
2021-01-28 17:09:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8248  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7114  Corr: 0.8051  Loss: 0.9579 
2021-01-28 17:10:03:INFO:TRAIN-(misa) (6/25/1)>> loss: 0.1341  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8777  Mult_acc_7: 0.8536  MAE: 0.1681  Corr: 0.9904 
2021-01-28 17:10:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8215  Non0_acc_2: 0.8333  Non0_F1_score: 0.8345  Mult_acc_5: 0.5240  Mult_acc_7: 0.4279  MAE: 0.7211  Corr: 0.8060  Loss: 0.9953 
2021-01-28 17:10:13:INFO:TRAIN-(misa) (7/26/1)>> loss: 0.1263  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8808  Mult_acc_7: 0.8474  MAE: 0.1514  Corr: 0.9920 
2021-01-28 17:10:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.5109  Mult_acc_7: 0.3930  MAE: 0.7208  Corr: 0.8054  Loss: 0.9637 
2021-01-28 17:10:24:INFO:TRAIN-(misa) (8/27/1)>> loss: 0.1168  Has0_acc_2: 0.9696  Has0_F1_score: 0.9696  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.8808  Mult_acc_7: 0.8536  MAE: 0.1457  Corr: 0.9924 
2021-01-28 17:10:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5153  Mult_acc_7: 0.4279  MAE: 0.7183  Corr: 0.7985  Loss: 0.9400 
2021-01-28 17:10:35:INFO:TRAIN-(misa) (1/28/1)>> loss: 0.1126  Has0_acc_2: 0.9673  Has0_F1_score: 0.9672  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8583  Mult_acc_7: 0.8341  MAE: 0.1449  Corr: 0.9927 
2021-01-28 17:10:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5240  Mult_acc_7: 0.4236  MAE: 0.7241  Corr: 0.7983  Loss: 1.0393 
2021-01-28 17:10:46:INFO:TRAIN-(misa) (2/29/1)>> loss: 0.1195  Has0_acc_2: 0.9650  Has0_F1_score: 0.9649  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8575  Mult_acc_7: 0.8333  MAE: 0.1597  Corr: 0.9911 
2021-01-28 17:10:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8389  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5153  Mult_acc_7: 0.4017  MAE: 0.7217  Corr: 0.8059  Loss: 0.9834 
2021-01-28 17:10:56:INFO:TRAIN-(misa) (3/30/1)>> loss: 0.1161  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8653  Mult_acc_7: 0.8466  MAE: 0.1620  Corr: 0.9908 
2021-01-28 17:10:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5328  Mult_acc_7: 0.4192  MAE: 0.7006  Corr: 0.8086  Loss: 1.0250 
2021-01-28 17:11:06:INFO:TRAIN-(misa) (4/31/1)>> loss: 0.1086  Has0_acc_2: 0.9650  Has0_F1_score: 0.9649  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8964  Mult_acc_7: 0.8715  MAE: 0.1442  Corr: 0.9927 
2021-01-28 17:11:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8328  Non0_acc_2: 0.8565  Non0_F1_score: 0.8561  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7078  Corr: 0.8074  Loss: 0.9317 
2021-01-28 17:11:18:INFO:TRAIN-(misa) (1/32/1)>> loss: 0.1116  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8746  Mult_acc_7: 0.8497  MAE: 0.1568  Corr: 0.9912 
2021-01-28 17:11:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8328  Non0_acc_2: 0.8565  Non0_F1_score: 0.8561  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7071  Corr: 0.8062  Loss: 0.9434 
2021-01-28 17:11:29:INFO:TRAIN-(misa) (2/33/1)>> loss: 0.1060  Has0_acc_2: 0.9704  Has0_F1_score: 0.9704  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8660  Mult_acc_7: 0.8442  MAE: 0.1550  Corr: 0.9919 
2021-01-28 17:11:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8241  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5197  Mult_acc_7: 0.4279  MAE: 0.7141  Corr: 0.8036  Loss: 0.9531 
2021-01-28 17:11:39:INFO:TRAIN-(misa) (3/34/1)>> loss: 0.1054  Has0_acc_2: 0.9673  Has0_F1_score: 0.9672  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8847  Mult_acc_7: 0.8637  MAE: 0.1439  Corr: 0.9929 
2021-01-28 17:11:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8264  Non0_acc_2: 0.8380  Non0_F1_score: 0.8397  Mult_acc_5: 0.5197  Mult_acc_7: 0.4017  MAE: 0.7169  Corr: 0.8060  Loss: 1.0243 
2021-01-28 17:11:49:INFO:TRAIN-(misa) (4/35/1)>> loss: 0.1006  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8793  Mult_acc_7: 0.8590  MAE: 0.1447  Corr: 0.9927 
2021-01-28 17:11:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8335  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.6942  Corr: 0.8108  Loss: 0.9827 
2021-01-28 17:12:00:INFO:TRAIN-(misa) (5/36/1)>> loss: 0.0920  Has0_acc_2: 0.9696  Has0_F1_score: 0.9695  Non0_acc_2: 0.9943  Non0_F1_score: 0.9943  Mult_acc_5: 0.8925  Mult_acc_7: 0.8762  MAE: 0.1235  Corr: 0.9947 
2021-01-28 17:12:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.5415  Mult_acc_7: 0.4367  MAE: 0.6923  Corr: 0.8117  Loss: 0.9405 
2021-01-28 17:12:10:INFO:TRAIN-(misa) (6/37/1)>> loss: 0.0844  Has0_acc_2: 0.9759  Has0_F1_score: 0.9758  Non0_acc_2: 0.9935  Non0_F1_score: 0.9935  Mult_acc_5: 0.9112  Mult_acc_7: 0.8972  MAE: 0.1093  Corr: 0.9958 
2021-01-28 17:12:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5328  Mult_acc_7: 0.4192  MAE: 0.7016  Corr: 0.8092  Loss: 0.9057 
2021-01-28 17:12:21:INFO:TRAIN-(misa) (1/38/1)>> loss: 0.0800  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9919  Non0_F1_score: 0.9919  Mult_acc_5: 0.9182  Mult_acc_7: 0.9065  MAE: 0.1071  Corr: 0.9960 
2021-01-28 17:12:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8376  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7039  Corr: 0.8081  Loss: 0.9242 
2021-01-28 17:12:31:INFO:TRAIN-(misa) (2/39/1)>> loss: 0.0854  Has0_acc_2: 0.9836  Has0_F1_score: 0.9836  Non0_acc_2: 0.9968  Non0_F1_score: 0.9968  Mult_acc_5: 0.8847  Mult_acc_7: 0.8707  MAE: 0.1264  Corr: 0.9945 
2021-01-28 17:12:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8417  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5197  Mult_acc_7: 0.4105  MAE: 0.7087  Corr: 0.8071  Loss: 0.9792 
2021-01-28 17:12:42:INFO:TRAIN-(misa) (3/40/1)>> loss: 0.0917  Has0_acc_2: 0.9657  Has0_F1_score: 0.9656  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8886  Mult_acc_7: 0.8676  MAE: 0.1390  Corr: 0.9933 
2021-01-28 17:12:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7017  Corr: 0.8079  Loss: 0.9337 
2021-01-28 17:12:52:INFO:TRAIN-(misa) (4/41/1)>> loss: 0.0831  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9943  Non0_F1_score: 0.9943  Mult_acc_5: 0.8855  Mult_acc_7: 0.8699  MAE: 0.1240  Corr: 0.9946 
2021-01-28 17:12:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5240  Mult_acc_7: 0.4192  MAE: 0.6994  Corr: 0.8092  Loss: 0.9582 
2021-01-28 17:13:03:INFO:TRAIN-(misa) (5/42/1)>> loss: 0.0754  Has0_acc_2: 0.9759  Has0_F1_score: 0.9758  Non0_acc_2: 0.9919  Non0_F1_score: 0.9919  Mult_acc_5: 0.9120  Mult_acc_7: 0.8956  MAE: 0.1041  Corr: 0.9962 
2021-01-28 17:13:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8376  Non0_acc_2: 0.8611  Non0_F1_score: 0.8611  Mult_acc_5: 0.5502  Mult_acc_7: 0.4454  MAE: 0.6951  Corr: 0.8114  Loss: 0.9329 
2021-01-28 17:13:13:INFO:TRAIN-(misa) (6/43/1)>> loss: 0.0799  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.9042  Mult_acc_7: 0.8910  MAE: 0.1230  Corr: 0.9947 
2021-01-28 17:13:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.5240  Mult_acc_7: 0.4367  MAE: 0.6988  Corr: 0.8130  Loss: 0.9377 
2021-01-28 17:13:23:INFO:TRAIN-(misa) (7/44/1)>> loss: 0.0819  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.9011  Mult_acc_7: 0.8808  MAE: 0.1296  Corr: 0.9944 
2021-01-28 17:13:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8335  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5371  Mult_acc_7: 0.4541  MAE: 0.6927  Corr: 0.8130  Loss: 0.9642 
2021-01-28 17:13:33:INFO:TRAIN-(misa) (8/45/1)>> loss: 0.0814  Has0_acc_2: 0.9696  Has0_F1_score: 0.9695  Non0_acc_2: 0.9935  Non0_F1_score: 0.9935  Mult_acc_5: 0.8886  Mult_acc_7: 0.8707  MAE: 0.1196  Corr: 0.9951 
2021-01-28 17:13:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5633  Mult_acc_7: 0.4585  MAE: 0.6873  Corr: 0.8128  Loss: 0.8798 
2021-01-28 17:13:45:INFO:TRAIN-(misa) (1/46/1)>> loss: 0.0721  Has0_acc_2: 0.9790  Has0_F1_score: 0.9789  Non0_acc_2: 0.9976  Non0_F1_score: 0.9976  Mult_acc_5: 0.9136  Mult_acc_7: 0.9026  MAE: 0.1074  Corr: 0.9960 
2021-01-28 17:13:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.6904  Corr: 0.8132  Loss: 0.9830 
2021-01-28 17:13:56:INFO:TRAIN-(misa) (2/47/1)>> loss: 0.0733  Has0_acc_2: 0.9735  Has0_F1_score: 0.9735  Non0_acc_2: 0.9943  Non0_F1_score: 0.9943  Mult_acc_5: 0.9081  Mult_acc_7: 0.8910  MAE: 0.1075  Corr: 0.9960 
2021-01-28 17:13:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8417  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5328  Mult_acc_7: 0.4192  MAE: 0.6914  Corr: 0.8136  Loss: 0.9438 
2021-01-28 17:14:06:INFO:TRAIN-(misa) (3/48/1)>> loss: 0.0677  Has0_acc_2: 0.9782  Has0_F1_score: 0.9781  Non0_acc_2: 0.9943  Non0_F1_score: 0.9943  Mult_acc_5: 0.9198  Mult_acc_7: 0.9065  MAE: 0.1028  Corr: 0.9964 
2021-01-28 17:14:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8460  Non0_acc_2: 0.8704  Non0_F1_score: 0.8701  Mult_acc_5: 0.5240  Mult_acc_7: 0.4279  MAE: 0.6944  Corr: 0.8140  Loss: 0.9381 
2021-01-28 17:14:16:INFO:TRAIN-(misa) (4/49/1)>> loss: 0.0743  Has0_acc_2: 0.9751  Has0_F1_score: 0.9750  Non0_acc_2: 0.9951  Non0_F1_score: 0.9951  Mult_acc_5: 0.9143  Mult_acc_7: 0.8988  MAE: 0.1136  Corr: 0.9956 
2021-01-28 17:14:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8417  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5502  Mult_acc_7: 0.4629  MAE: 0.6919  Corr: 0.8117  Loss: 0.9887 
2021-01-28 17:14:27:INFO:TRAIN-(misa) (5/50/1)>> loss: 0.0711  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9919  Non0_F1_score: 0.9919  Mult_acc_5: 0.9073  Mult_acc_7: 0.8949  MAE: 0.1087  Corr: 0.9960 
2021-01-28 17:14:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8417  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5459  Mult_acc_7: 0.4541  MAE: 0.6968  Corr: 0.8123  Loss: 0.9226 
2021-01-28 17:14:38:INFO:TRAIN-(misa) (6/51/1)>> loss: 0.0694  Has0_acc_2: 0.9759  Has0_F1_score: 0.9758  Non0_acc_2: 0.9951  Non0_F1_score: 0.9951  Mult_acc_5: 0.9050  Mult_acc_7: 0.8933  MAE: 0.1085  Corr: 0.9959 
2021-01-28 17:14:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5371  Mult_acc_7: 0.4236  MAE: 0.6935  Corr: 0.8138  Loss: 0.9774 
2021-01-28 17:14:48:INFO:TRAIN-(misa) (7/52/1)>> loss: 0.0714  Has0_acc_2: 0.9743  Has0_F1_score: 0.9742  Non0_acc_2: 0.9903  Non0_F1_score: 0.9902  Mult_acc_5: 0.8988  Mult_acc_7: 0.8847  MAE: 0.1199  Corr: 0.9951 
2021-01-28 17:14:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7001  Corr: 0.8144  Loss: 1.0906 
2021-01-28 17:14:59:INFO:TRAIN-(misa) (8/53/1)>> loss: 0.0784  Has0_acc_2: 0.9681  Has0_F1_score: 0.9680  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8746  Mult_acc_7: 0.8583  MAE: 0.1394  Corr: 0.9935 
2021-01-28 17:14:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5284  Mult_acc_7: 0.4148  MAE: 0.6936  Corr: 0.8158  Loss: 1.0451 
2021-01-28 17:15:01:INFO:TEST-(misa) >>  Has0_acc_2: 0.8178  Has0_F1_score: 0.8178  Non0_acc_2: 0.8308  Non0_F1_score: 0.8303  Mult_acc_5: 0.5073  Mult_acc_7: 0.4519  MAE: 0.7410  Corr: 0.7870  Loss: 1.0275 
2021-01-28 17:15:01:INFO:Start saving results...
2021-01-28 17:15:01:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:15:01:INFO:########################################misa-(3/50)########################################
2021-01-28 17:15:01:INFO:batch_size:64
2021-01-28 17:15:01:INFO:learning_rate:0.001
2021-01-28 17:15:01:INFO:hidden_size:128
2021-01-28 17:15:01:INFO:dropout:0.2
2021-01-28 17:15:01:INFO:reverse_grad_weight:1.0
2021-01-28 17:15:01:INFO:diff_weight:0.1
2021-01-28 17:15:01:INFO:sim_weight:0.8
2021-01-28 17:15:01:INFO:sp_weight:0.0
2021-01-28 17:15:01:INFO:recon_weight:1.0
2021-01-28 17:15:01:INFO:grad_clip:-1.0
2021-01-28 17:15:01:INFO:weight_decay:0.002
2021-01-28 17:15:01:INFO:##########################################################################################
2021-01-28 17:15:01:INFO:Start running misa...
2021-01-28 17:15:01:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:15:01:INFO:Let's use 1 GPUs!
2021-01-28 17:15:01:INFO:train samples: (1284,)
2021-01-28 17:15:02:INFO:valid samples: (229,)
2021-01-28 17:15:02:INFO:test samples: (686,)
2021-01-28 17:15:02:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:15:02:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:15:02:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:15:02:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:15:02:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:15:02:INFO:loading file None
2021-01-28 17:15:02:INFO:loading file None
2021-01-28 17:15:02:INFO:loading file None
2021-01-28 17:15:02:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:15:02:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:15:02:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:15:05:INFO:The model has 110620273 trainable parameters
2021-01-28 17:15:14:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.8131  Has0_acc_2: 0.5506  Has0_F1_score: 0.5667  Non0_acc_2: 0.5435  Non0_F1_score: 0.5606  Mult_acc_5: 0.2002  Mult_acc_7: 0.1776  MAE: 1.4680  Corr: 0.0326 
2021-01-28 17:15:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7409  Non0_acc_2: 0.5741  Non0_F1_score: 0.7213  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4336  Corr: 0.0731  Loss: 2.7688 
2021-01-28 17:15:26:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.8464  Has0_acc_2: 0.5592  Has0_F1_score: 0.6525  Non0_acc_2: 0.5467  Non0_F1_score: 0.6433  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3182  Corr: 0.0308 
2021-01-28 17:15:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4140  Corr: 0.0957  Loss: 2.7268 
2021-01-28 17:15:38:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.5732  Has0_acc_2: 0.5514  Has0_F1_score: 0.6109  Non0_acc_2: 0.5361  Non0_F1_score: 0.5966  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3266  Corr: 0.0230 
2021-01-28 17:15:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.4164  Corr: 0.1061  Loss: 2.7382 
2021-01-28 17:15:48:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.4571  Has0_acc_2: 0.5709  Has0_F1_score: 0.6803  Non0_acc_2: 0.5548  Non0_F1_score: 0.6668  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3251  Corr: -0.0116 
2021-01-28 17:15:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4194  Corr: 0.1075  Loss: 2.7792 
2021-01-28 17:15:59:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.3775  Has0_acc_2: 0.5646  Has0_F1_score: 0.7137  Non0_acc_2: 0.5467  Non0_F1_score: 0.6992  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3209  Corr: -0.0039 
2021-01-28 17:15:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4162  Corr: 0.1277  Loss: 2.6687 
2021-01-28 17:16:10:INFO:TRAIN-(misa) (1/6/1)>> loss: 2.3679  Has0_acc_2: 0.5701  Has0_F1_score: 0.7153  Non0_acc_2: 0.5532  Non0_F1_score: 0.7022  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3227  Corr: -0.0213 
2021-01-28 17:16:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4197  Corr: 0.1058  Loss: 2.7403 
2021-01-28 17:16:20:INFO:TRAIN-(misa) (2/7/1)>> loss: 2.4175  Has0_acc_2: 0.5685  Has0_F1_score: 0.7224  Non0_acc_2: 0.5516  Non0_F1_score: 0.7095  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3184  Corr: -0.0096 
2021-01-28 17:16:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4208  Corr: 0.1128  Loss: 2.8279 
2021-01-28 17:16:31:INFO:TRAIN-(misa) (3/8/1)>> loss: 2.2752  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3242  Corr: -0.0398 
2021-01-28 17:16:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4209  Corr: 0.1211  Loss: 2.6919 
2021-01-28 17:16:41:INFO:TRAIN-(misa) (4/9/1)>> loss: 2.4142  Has0_acc_2: 0.5654  Has0_F1_score: 0.7057  Non0_acc_2: 0.5475  Non0_F1_score: 0.6909  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3215  Corr: 0.0054 
2021-01-28 17:16:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4169  Corr: 0.1153  Loss: 2.7331 
2021-01-28 17:16:52:INFO:TRAIN-(misa) (5/10/1)>> loss: 2.3667  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3167  Corr: 0.0376 
2021-01-28 17:16:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4176  Corr: 0.1234  Loss: 2.7815 
2021-01-28 17:17:02:INFO:TRAIN-(misa) (6/11/1)>> loss: 2.3307  Has0_acc_2: 0.5693  Has0_F1_score: 0.7250  Non0_acc_2: 0.5508  Non0_F1_score: 0.7097  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3152  Corr: 0.0371 
2021-01-28 17:17:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4178  Corr: 0.1000  Loss: 2.7218 
2021-01-28 17:17:12:INFO:TRAIN-(misa) (7/12/1)>> loss: 2.3244  Has0_acc_2: 0.5701  Has0_F1_score: 0.7248  Non0_acc_2: 0.5516  Non0_F1_score: 0.7095  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3160  Corr: 0.0508 
2021-01-28 17:17:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4199  Corr: 0.1059  Loss: 2.7136 
2021-01-28 17:17:23:INFO:TRAIN-(misa) (8/13/1)>> loss: 2.3185  Has0_acc_2: 0.5678  Has0_F1_score: 0.7212  Non0_acc_2: 0.5491  Non0_F1_score: 0.7058  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3202  Corr: -0.0395 
2021-01-28 17:17:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4168  Corr: 0.1246  Loss: 2.6826 
2021-01-28 17:17:26:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4775  Corr: 0.1657  Loss: 2.8896 
2021-01-28 17:17:26:INFO:Start saving results...
2021-01-28 17:17:26:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:17:26:INFO:########################################misa-(4/50)########################################
2021-01-28 17:17:26:INFO:batch_size:16
2021-01-28 17:17:26:INFO:learning_rate:0.0001
2021-01-28 17:17:26:INFO:hidden_size:64
2021-01-28 17:17:26:INFO:dropout:0.0
2021-01-28 17:17:26:INFO:reverse_grad_weight:0.5
2021-01-28 17:17:26:INFO:diff_weight:0.5
2021-01-28 17:17:26:INFO:sim_weight:1.0
2021-01-28 17:17:26:INFO:sp_weight:0.0
2021-01-28 17:17:26:INFO:recon_weight:1.0
2021-01-28 17:17:26:INFO:grad_clip:1.0
2021-01-28 17:17:26:INFO:weight_decay:0.002
2021-01-28 17:17:26:INFO:##########################################################################################
2021-01-28 17:17:26:INFO:Start running misa...
2021-01-28 17:17:26:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:17:26:INFO:Let's use 1 GPUs!
2021-01-28 17:17:26:INFO:train samples: (1284,)
2021-01-28 17:17:26:INFO:valid samples: (229,)
2021-01-28 17:17:27:INFO:test samples: (686,)
2021-01-28 17:17:27:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:17:27:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:17:27:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:17:27:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:17:27:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:17:27:INFO:loading file None
2021-01-28 17:17:27:INFO:loading file None
2021-01-28 17:17:27:INFO:loading file None
2021-01-28 17:17:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:17:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:17:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:17:30:INFO:The model has 109943985 trainable parameters
2021-01-28 17:17:47:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.5726  Has0_acc_2: 0.7212  Has0_F1_score: 0.7241  Non0_acc_2: 0.7287  Non0_F1_score: 0.7324  Mult_acc_5: 0.2640  Mult_acc_7: 0.2617  MAE: 1.0353  Corr: 0.5767 
2021-01-28 17:17:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7710  Non0_acc_2: 0.8102  Non0_F1_score: 0.8092  Mult_acc_5: 0.3581  Mult_acc_7: 0.3013  MAE: 0.9209  Corr: 0.7364  Loss: 1.3029 
2021-01-28 17:18:06:INFO:TRAIN-(misa) (1/2/1)>> loss: 1.9244  Has0_acc_2: 0.8559  Has0_F1_score: 0.8554  Non0_acc_2: 0.8708  Non0_F1_score: 0.8706  Mult_acc_5: 0.4836  Mult_acc_7: 0.4463  MAE: 0.6329  Corr: 0.8400 
2021-01-28 17:18:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7162  Has0_F1_score: 0.7162  Non0_acc_2: 0.7546  Non0_F1_score: 0.7548  Mult_acc_5: 0.4105  Mult_acc_7: 0.3319  MAE: 0.9603  Corr: 0.6911  Loss: 1.6199 
2021-01-28 17:18:24:INFO:TRAIN-(misa) (2/3/1)>> loss: 1.2077  Has0_acc_2: 0.8925  Has0_F1_score: 0.8921  Non0_acc_2: 0.9163  Non0_F1_score: 0.9163  Mult_acc_5: 0.6145  Mult_acc_7: 0.5662  MAE: 0.4790  Corr: 0.9103 
2021-01-28 17:18:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8389  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5153  Mult_acc_7: 0.4148  MAE: 0.7998  Corr: 0.7793  Loss: 1.1718 
2021-01-28 17:18:44:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.7901  Has0_acc_2: 0.9354  Has0_F1_score: 0.9352  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.6698  Mult_acc_7: 0.6176  MAE: 0.3903  Corr: 0.9441 
2021-01-28 17:18:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.5022  Mult_acc_7: 0.3886  MAE: 0.7388  Corr: 0.7982  Loss: 1.0052 
2021-01-28 17:19:03:INFO:TRAIN-(misa) (1/5/1)>> loss: 0.5436  Has0_acc_2: 0.9245  Has0_F1_score: 0.9243  Non0_acc_2: 0.9423  Non0_F1_score: 0.9423  Mult_acc_5: 0.7477  Mult_acc_7: 0.6963  MAE: 0.3248  Corr: 0.9614 
2021-01-28 17:19:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.4978  Mult_acc_7: 0.4105  MAE: 0.7221  Corr: 0.7996  Loss: 0.9676 
2021-01-28 17:19:22:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.4753  Has0_acc_2: 0.9182  Has0_F1_score: 0.9180  Non0_acc_2: 0.9399  Non0_F1_score: 0.9399  Mult_acc_5: 0.7235  Mult_acc_7: 0.6745  MAE: 0.3386  Corr: 0.9583 
2021-01-28 17:19:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8472  Non0_F1_score: 0.8476  Mult_acc_5: 0.5022  Mult_acc_7: 0.4148  MAE: 0.7370  Corr: 0.7966  Loss: 1.0510 
2021-01-28 17:19:40:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.3667  Has0_acc_2: 0.9393  Has0_F1_score: 0.9391  Non0_acc_2: 0.9586  Non0_F1_score: 0.9586  Mult_acc_5: 0.7445  Mult_acc_7: 0.7009  MAE: 0.2942  Corr: 0.9698 
2021-01-28 17:19:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7156  Corr: 0.8017  Loss: 0.9822 
2021-01-28 17:19:58:INFO:TRAIN-(misa) (3/8/1)>> loss: 0.3205  Has0_acc_2: 0.9416  Has0_F1_score: 0.9415  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7555  Mult_acc_7: 0.7072  MAE: 0.2909  Corr: 0.9704 
2021-01-28 17:19:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7274  Corr: 0.8008  Loss: 1.0065 
2021-01-28 17:20:16:INFO:TRAIN-(misa) (4/9/1)>> loss: 0.2588  Has0_acc_2: 0.9408  Has0_F1_score: 0.9406  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7998  Mult_acc_7: 0.7609  MAE: 0.2457  Corr: 0.9782 
2021-01-28 17:20:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.5284  Mult_acc_7: 0.4323  MAE: 0.7324  Corr: 0.7953  Loss: 1.0133 
2021-01-28 17:20:34:INFO:TRAIN-(misa) (5/10/1)>> loss: 0.2443  Has0_acc_2: 0.9393  Has0_F1_score: 0.9391  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7757  Mult_acc_7: 0.7313  MAE: 0.2581  Corr: 0.9765 
2021-01-28 17:20:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.5022  Mult_acc_7: 0.3886  MAE: 0.7215  Corr: 0.8061  Loss: 1.0001 
2021-01-28 17:20:52:INFO:TRAIN-(misa) (6/11/1)>> loss: 0.2271  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9699  Non0_F1_score: 0.9700  Mult_acc_5: 0.7897  Mult_acc_7: 0.7570  MAE: 0.2518  Corr: 0.9770 
2021-01-28 17:20:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8341  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.5284  Mult_acc_7: 0.4323  MAE: 0.7229  Corr: 0.8068  Loss: 1.2059 
2021-01-28 17:21:10:INFO:TRAIN-(misa) (7/12/1)>> loss: 0.1926  Has0_acc_2: 0.9494  Has0_F1_score: 0.9492  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.8061  Mult_acc_7: 0.7695  MAE: 0.2210  Corr: 0.9822 
2021-01-28 17:21:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8565  Non0_F1_score: 0.8559  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.7287  Corr: 0.8060  Loss: 1.0315 
2021-01-28 17:21:28:INFO:TRAIN-(misa) (8/13/1)>> loss: 0.1700  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8139  Mult_acc_7: 0.7913  MAE: 0.2075  Corr: 0.9846 
2021-01-28 17:21:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8565  Non0_F1_score: 0.8559  Mult_acc_5: 0.5022  Mult_acc_7: 0.4279  MAE: 0.7170  Corr: 0.8043  Loss: 1.0529 
2021-01-28 17:21:31:INFO:TEST-(misa) >>  Has0_acc_2: 0.8003  Has0_F1_score: 0.8001  Non0_acc_2: 0.8186  Non0_F1_score: 0.8178  Mult_acc_5: 0.4723  Mult_acc_7: 0.4169  MAE: 0.8017  Corr: 0.7670  Loss: 1.1670 
2021-01-28 17:21:31:INFO:Start saving results...
2021-01-28 17:21:31:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:21:31:INFO:########################################misa-(5/50)########################################
2021-01-28 17:21:31:INFO:batch_size:64
2021-01-28 17:21:31:INFO:learning_rate:0.0001
2021-01-28 17:21:31:INFO:hidden_size:128
2021-01-28 17:21:31:INFO:dropout:0.0
2021-01-28 17:21:31:INFO:reverse_grad_weight:0.8
2021-01-28 17:21:31:INFO:diff_weight:0.1
2021-01-28 17:21:31:INFO:sim_weight:0.5
2021-01-28 17:21:31:INFO:sp_weight:0.0
2021-01-28 17:21:31:INFO:recon_weight:0.5
2021-01-28 17:21:31:INFO:grad_clip:1.0
2021-01-28 17:21:31:INFO:weight_decay:5e-05
2021-01-28 17:21:31:INFO:##########################################################################################
2021-01-28 17:21:31:INFO:Start running misa...
2021-01-28 17:21:31:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:21:31:INFO:Let's use 1 GPUs!
2021-01-28 17:21:37:INFO:train samples: (1284,)
2021-01-28 17:21:37:INFO:valid samples: (229,)
2021-01-28 17:21:37:INFO:test samples: (686,)
2021-01-28 17:21:37:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:21:37:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:21:37:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:21:37:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:21:37:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:21:37:INFO:loading file None
2021-01-28 17:21:37:INFO:loading file None
2021-01-28 17:21:37:INFO:loading file None
2021-01-28 17:21:37:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:21:37:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:21:37:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:21:41:INFO:The model has 110620273 trainable parameters
2021-01-28 17:21:51:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.3405  Has0_acc_2: 0.6573  Has0_F1_score: 0.6662  Non0_acc_2: 0.6564  Non0_F1_score: 0.6660  Mult_acc_5: 0.2072  Mult_acc_7: 0.2072  MAE: 1.2341  Corr: 0.3465 
2021-01-28 17:21:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8022  Non0_acc_2: 0.8241  Non0_F1_score: 0.8238  Mult_acc_5: 0.2620  Mult_acc_7: 0.2620  MAE: 1.1010  Corr: 0.6524  Loss: 1.8131 
2021-01-28 17:22:03:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.1411  Has0_acc_2: 0.8178  Has0_F1_score: 0.8169  Non0_acc_2: 0.8318  Non0_F1_score: 0.8315  Mult_acc_5: 0.3185  Mult_acc_7: 0.3092  MAE: 0.8329  Corr: 0.7342 
2021-01-28 17:22:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.4410  Mult_acc_7: 0.3712  MAE: 0.8440  Corr: 0.7399  Loss: 1.2564 
2021-01-28 17:22:15:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.5327  Has0_acc_2: 0.8762  Has0_F1_score: 0.8756  Non0_acc_2: 0.9017  Non0_F1_score: 0.9015  Mult_acc_5: 0.5109  Mult_acc_7: 0.4766  MAE: 0.6069  Corr: 0.8514 
2021-01-28 17:22:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8331  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.4803  Mult_acc_7: 0.3755  MAE: 0.7902  Corr: 0.7687  Loss: 1.1135 
2021-01-28 17:22:26:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.1213  Has0_acc_2: 0.9089  Has0_F1_score: 0.9085  Non0_acc_2: 0.9293  Non0_F1_score: 0.9293  Mult_acc_5: 0.6114  Mult_acc_7: 0.5685  MAE: 0.4608  Corr: 0.9159 
2021-01-28 17:22:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8160  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.4672  Mult_acc_7: 0.3799  MAE: 0.7800  Corr: 0.7723  Loss: 1.1604 
2021-01-28 17:22:37:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.8047  Has0_acc_2: 0.9377  Has0_F1_score: 0.9376  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7150  Mult_acc_7: 0.6651  MAE: 0.3553  Corr: 0.9505 
2021-01-28 17:22:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8136  Non0_acc_2: 0.8241  Non0_F1_score: 0.8262  Mult_acc_5: 0.4716  Mult_acc_7: 0.3668  MAE: 0.7845  Corr: 0.7689  Loss: 1.1659 
2021-01-28 17:22:47:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.6184  Has0_acc_2: 0.9322  Has0_F1_score: 0.9320  Non0_acc_2: 0.9561  Non0_F1_score: 0.9561  Mult_acc_5: 0.7531  Mult_acc_7: 0.7025  MAE: 0.3054  Corr: 0.9658 
2021-01-28 17:22:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8084  Non0_acc_2: 0.8009  Non0_F1_score: 0.8060  Mult_acc_5: 0.4803  Mult_acc_7: 0.3755  MAE: 0.8214  Corr: 0.7809  Loss: 1.2193 
2021-01-28 17:22:57:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.4851  Has0_acc_2: 0.9470  Has0_F1_score: 0.9470  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7710  Mult_acc_7: 0.7212  MAE: 0.2775  Corr: 0.9726 
2021-01-28 17:22:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.4541  Mult_acc_7: 0.3581  MAE: 0.7672  Corr: 0.7803  Loss: 1.2091 
2021-01-28 17:23:07:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.3914  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8053  Mult_acc_7: 0.7547  MAE: 0.2431  Corr: 0.9787 
2021-01-28 17:23:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8200  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7461  Corr: 0.7863  Loss: 1.0412 
2021-01-28 17:23:19:INFO:TRAIN-(misa) (1/9/1)>> loss: 0.3200  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8037  Mult_acc_7: 0.7648  MAE: 0.2190  Corr: 0.9829 
2021-01-28 17:23:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8419  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.5197  Mult_acc_7: 0.4236  MAE: 0.7415  Corr: 0.7881  Loss: 1.0133 
2021-01-28 17:23:30:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.2844  Has0_acc_2: 0.9579  Has0_F1_score: 0.9578  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8388  Mult_acc_7: 0.8022  MAE: 0.2130  Corr: 0.9837 
2021-01-28 17:23:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5240  Mult_acc_7: 0.4192  MAE: 0.7415  Corr: 0.7924  Loss: 1.0445 
2021-01-28 17:23:41:INFO:TRAIN-(misa) (2/11/1)>> loss: 0.2536  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8232  Mult_acc_7: 0.7913  MAE: 0.2013  Corr: 0.9860 
2021-01-28 17:23:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8241  Non0_acc_2: 0.8519  Non0_F1_score: 0.8517  Mult_acc_5: 0.4847  Mult_acc_7: 0.3843  MAE: 0.7425  Corr: 0.7862  Loss: 1.0374 
2021-01-28 17:23:51:INFO:TRAIN-(misa) (3/12/1)>> loss: 0.2243  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8497  Mult_acc_7: 0.8217  MAE: 0.1820  Corr: 0.9883 
2021-01-28 17:23:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.4978  Mult_acc_7: 0.3974  MAE: 0.7481  Corr: 0.7892  Loss: 1.1570 
2021-01-28 17:24:01:INFO:TRAIN-(misa) (4/13/1)>> loss: 0.1976  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8629  Mult_acc_7: 0.8294  MAE: 0.1678  Corr: 0.9899 
2021-01-28 17:24:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8335  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.5022  Mult_acc_7: 0.3930  MAE: 0.7447  Corr: 0.7858  Loss: 1.0260 
2021-01-28 17:24:11:INFO:TRAIN-(misa) (5/14/1)>> loss: 0.1786  Has0_acc_2: 0.9688  Has0_F1_score: 0.9688  Non0_acc_2: 0.9903  Non0_F1_score: 0.9903  Mult_acc_5: 0.8668  Mult_acc_7: 0.8388  MAE: 0.1648  Corr: 0.9908 
2021-01-28 17:24:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8333  Non0_F1_score: 0.8328  Mult_acc_5: 0.5284  Mult_acc_7: 0.4279  MAE: 0.7413  Corr: 0.7862  Loss: 1.0646 
2021-01-28 17:24:22:INFO:TRAIN-(misa) (6/15/1)>> loss: 0.1819  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8583  Mult_acc_7: 0.8271  MAE: 0.1855  Corr: 0.9883 
2021-01-28 17:24:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8248  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5153  Mult_acc_7: 0.3930  MAE: 0.7353  Corr: 0.7861  Loss: 1.0446 
2021-01-28 17:24:32:INFO:TRAIN-(misa) (7/16/1)>> loss: 0.1770  Has0_acc_2: 0.9579  Has0_F1_score: 0.9578  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8442  Mult_acc_7: 0.8170  MAE: 0.1972  Corr: 0.9861 
2021-01-28 17:24:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5328  Mult_acc_7: 0.4192  MAE: 0.7273  Corr: 0.7891  Loss: 1.0448 
2021-01-28 17:24:43:INFO:TRAIN-(misa) (8/17/1)>> loss: 0.1637  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8458  Mult_acc_7: 0.8224  MAE: 0.1850  Corr: 0.9878 
2021-01-28 17:24:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.5197  Mult_acc_7: 0.4236  MAE: 0.7396  Corr: 0.7879  Loss: 0.9975 
2021-01-28 17:24:54:INFO:TRAIN-(misa) (1/18/1)>> loss: 0.1574  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8170  Mult_acc_7: 0.7913  MAE: 0.1864  Corr: 0.9882 
2021-01-28 17:24:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.4978  Mult_acc_7: 0.3843  MAE: 0.7481  Corr: 0.7920  Loss: 1.0550 
2021-01-28 17:25:04:INFO:TRAIN-(misa) (2/19/1)>> loss: 0.1613  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8326  Mult_acc_7: 0.8014  MAE: 0.1996  Corr: 0.9863 
2021-01-28 17:25:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7501  Corr: 0.7899  Loss: 1.0669 
2021-01-28 17:25:15:INFO:TRAIN-(misa) (3/20/1)>> loss: 0.1580  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8248  Mult_acc_7: 0.7928  MAE: 0.2065  Corr: 0.9859 
2021-01-28 17:25:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5415  Mult_acc_7: 0.4323  MAE: 0.7348  Corr: 0.7924  Loss: 1.1221 
2021-01-28 17:25:25:INFO:TRAIN-(misa) (4/21/1)>> loss: 0.1458  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8497  Mult_acc_7: 0.8178  MAE: 0.1805  Corr: 0.9885 
2021-01-28 17:25:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8328  Non0_acc_2: 0.8565  Non0_F1_score: 0.8561  Mult_acc_5: 0.5459  Mult_acc_7: 0.4498  MAE: 0.7334  Corr: 0.7890  Loss: 1.0579 
2021-01-28 17:25:35:INFO:TRAIN-(misa) (5/22/1)>> loss: 0.1311  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8692  Mult_acc_7: 0.8388  MAE: 0.1634  Corr: 0.9908 
2021-01-28 17:25:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5197  Mult_acc_7: 0.4105  MAE: 0.7469  Corr: 0.7926  Loss: 1.0678 
2021-01-28 17:25:47:INFO:TRAIN-(misa) (6/23/1)>> loss: 0.1218  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8598  Mult_acc_7: 0.8403  MAE: 0.1591  Corr: 0.9912 
2021-01-28 17:25:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7266  Corr: 0.7903  Loss: 1.0103 
2021-01-28 17:25:57:INFO:TRAIN-(misa) (7/24/1)>> loss: 0.1168  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8785  Mult_acc_7: 0.8528  MAE: 0.1478  Corr: 0.9924 
2021-01-28 17:25:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8419  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7194  Corr: 0.7955  Loss: 1.0529 
2021-01-28 17:26:07:INFO:TRAIN-(misa) (8/25/1)>> loss: 0.1216  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8707  Mult_acc_7: 0.8489  MAE: 0.1697  Corr: 0.9899 
2021-01-28 17:26:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8223  Non0_acc_2: 0.8333  Non0_F1_score: 0.8353  Mult_acc_5: 0.5328  Mult_acc_7: 0.4148  MAE: 0.7264  Corr: 0.8019  Loss: 1.0542 
2021-01-28 17:26:10:INFO:TEST-(misa) >>  Has0_acc_2: 0.8120  Has0_F1_score: 0.8118  Non0_acc_2: 0.8308  Non0_F1_score: 0.8300  Mult_acc_5: 0.4665  Mult_acc_7: 0.4096  MAE: 0.7969  Corr: 0.7729  Loss: 1.1281 
2021-01-28 17:26:10:INFO:Start saving results...
2021-01-28 17:26:10:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:26:10:INFO:########################################misa-(6/50)########################################
2021-01-28 17:26:10:INFO:batch_size:64
2021-01-28 17:26:10:INFO:learning_rate:0.001
2021-01-28 17:26:10:INFO:hidden_size:128
2021-01-28 17:26:10:INFO:dropout:0.5
2021-01-28 17:26:10:INFO:reverse_grad_weight:1.0
2021-01-28 17:26:10:INFO:diff_weight:0.1
2021-01-28 17:26:10:INFO:sim_weight:0.5
2021-01-28 17:26:10:INFO:sp_weight:0.0
2021-01-28 17:26:10:INFO:recon_weight:0.8
2021-01-28 17:26:10:INFO:grad_clip:-1.0
2021-01-28 17:26:10:INFO:weight_decay:0.002
2021-01-28 17:26:10:INFO:##########################################################################################
2021-01-28 17:26:10:INFO:Start running misa...
2021-01-28 17:26:10:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:26:10:INFO:Let's use 1 GPUs!
2021-01-28 17:26:10:INFO:train samples: (1284,)
2021-01-28 17:26:11:INFO:valid samples: (229,)
2021-01-28 17:26:11:INFO:test samples: (686,)
2021-01-28 17:26:11:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:26:11:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:26:11:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:26:11:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:26:11:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:26:11:INFO:loading file None
2021-01-28 17:26:11:INFO:loading file None
2021-01-28 17:26:11:INFO:loading file None
2021-01-28 17:26:11:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:26:11:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:26:11:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:26:14:INFO:The model has 110620273 trainable parameters
2021-01-28 17:26:24:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.0963  Has0_acc_2: 0.5537  Has0_F1_score: 0.5668  Non0_acc_2: 0.5500  Non0_F1_score: 0.5644  Mult_acc_5: 0.2025  Mult_acc_7: 0.1893  MAE: 1.4282  Corr: 0.0389 
2021-01-28 17:26:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4142  Corr: 0.0769  Loss: 2.7060 
2021-01-28 17:26:35:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.7871  Has0_acc_2: 0.5397  Has0_F1_score: 0.5733  Non0_acc_2: 0.5313  Non0_F1_score: 0.5665  Mult_acc_5: 0.1970  Mult_acc_7: 0.1970  MAE: 1.3333  Corr: 0.0034 
2021-01-28 17:26:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1659  Mult_acc_7: 0.1659  MAE: 1.4171  Corr: 0.0975  Loss: 2.7557 
2021-01-28 17:26:45:INFO:TRAIN-(misa) (2/3/1)>> loss: 2.5116  Has0_acc_2: 0.5288  Has0_F1_score: 0.5396  Non0_acc_2: 0.5207  Non0_F1_score: 0.5323  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3304  Corr: 0.0348 
2021-01-28 17:26:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4154  Corr: 0.0954  Loss: 2.7298 
2021-01-28 17:26:55:INFO:TRAIN-(misa) (3/4/1)>> loss: 2.3953  Has0_acc_2: 0.5639  Has0_F1_score: 0.6810  Non0_acc_2: 0.5483  Non0_F1_score: 0.6687  Mult_acc_5: 0.1861  Mult_acc_7: 0.1861  MAE: 1.3199  Corr: 0.0282 
2021-01-28 17:26:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4298  Corr: 0.1225  Loss: 2.8172 
2021-01-28 17:27:06:INFO:TRAIN-(misa) (4/5/1)>> loss: 2.3413  Has0_acc_2: 0.5662  Has0_F1_score: 0.6449  Non0_acc_2: 0.5540  Non0_F1_score: 0.6353  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3192  Corr: 0.0296 
2021-01-28 17:27:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4170  Corr: 0.1576  Loss: 2.6693 
2021-01-28 17:27:17:INFO:TRAIN-(misa) (1/6/1)>> loss: 2.3648  Has0_acc_2: 0.5693  Has0_F1_score: 0.7181  Non0_acc_2: 0.5516  Non0_F1_score: 0.7039  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3226  Corr: -0.0216 
2021-01-28 17:27:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4191  Corr: 0.1736  Loss: 2.7376 
2021-01-28 17:27:27:INFO:TRAIN-(misa) (2/7/1)>> loss: 2.3728  Has0_acc_2: 0.5584  Has0_F1_score: 0.7056  Non0_acc_2: 0.5410  Non0_F1_score: 0.6919  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3222  Corr: 0.0060 
2021-01-28 17:27:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4198  Corr: 0.1951  Loss: 2.8264 
2021-01-28 17:27:38:INFO:TRAIN-(misa) (3/8/1)>> loss: 2.2702  Has0_acc_2: 0.5709  Has0_F1_score: 0.7232  Non0_acc_2: 0.5524  Non0_F1_score: 0.7079  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3316  Corr: -0.0633 
2021-01-28 17:27:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4241  Corr: 0.1990  Loss: 2.7028 
2021-01-28 17:27:48:INFO:TRAIN-(misa) (4/9/1)>> loss: 2.3876  Has0_acc_2: 0.5646  Has0_F1_score: 0.7071  Non0_acc_2: 0.5475  Non0_F1_score: 0.6936  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3242  Corr: -0.0233 
2021-01-28 17:27:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4211  Corr: 0.1582  Loss: 2.7461 
2021-01-28 17:27:58:INFO:TRAIN-(misa) (5/10/1)>> loss: 2.3715  Has0_acc_2: 0.5678  Has0_F1_score: 0.7185  Non0_acc_2: 0.5500  Non0_F1_score: 0.7042  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3209  Corr: -0.0004 
2021-01-28 17:27:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4180  Corr: 0.1300  Loss: 2.7825 
2021-01-28 17:28:08:INFO:TRAIN-(misa) (6/11/1)>> loss: 2.2957  Has0_acc_2: 0.5701  Has0_F1_score: 0.7193  Non0_acc_2: 0.5516  Non0_F1_score: 0.7039  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3144  Corr: 0.0488 
2021-01-28 17:28:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4199  Corr: 0.1056  Loss: 2.7267 
2021-01-28 17:28:18:INFO:TRAIN-(misa) (7/12/1)>> loss: 2.3221  Has0_acc_2: 0.5662  Has0_F1_score: 0.7188  Non0_acc_2: 0.5483  Non0_F1_score: 0.7045  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3202  Corr: -0.0017 
2021-01-28 17:28:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4200  Corr: 0.1210  Loss: 2.7138 
2021-01-28 17:28:28:INFO:TRAIN-(misa) (8/13/1)>> loss: 2.3235  Has0_acc_2: 0.5592  Has0_F1_score: 0.6927  Non0_acc_2: 0.5402  Non0_F1_score: 0.6761  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3251  Corr: -0.0405 
2021-01-28 17:28:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4210  Corr: 0.1174  Loss: 2.6948 
2021-01-28 17:28:30:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4742  Corr: 0.1428  Loss: 2.8740 
2021-01-28 17:28:30:INFO:Start saving results...
2021-01-28 17:28:30:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:28:30:INFO:########################################misa-(7/50)########################################
2021-01-28 17:28:30:INFO:batch_size:64
2021-01-28 17:28:30:INFO:learning_rate:0.0005
2021-01-28 17:28:30:INFO:hidden_size:256
2021-01-28 17:28:30:INFO:dropout:0.2
2021-01-28 17:28:30:INFO:reverse_grad_weight:1.0
2021-01-28 17:28:30:INFO:diff_weight:0.5
2021-01-28 17:28:30:INFO:sim_weight:0.5
2021-01-28 17:28:30:INFO:sp_weight:0.0
2021-01-28 17:28:30:INFO:recon_weight:0.5
2021-01-28 17:28:30:INFO:grad_clip:0.8
2021-01-28 17:28:30:INFO:weight_decay:0.0
2021-01-28 17:28:30:INFO:##########################################################################################
2021-01-28 17:28:30:INFO:Start running misa...
2021-01-28 17:28:30:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:28:30:INFO:Let's use 1 GPUs!
2021-01-28 17:28:31:INFO:train samples: (1284,)
2021-01-28 17:28:31:INFO:valid samples: (229,)
2021-01-28 17:28:32:INFO:test samples: (686,)
2021-01-28 17:28:32:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:28:32:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:28:32:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:28:32:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:28:32:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:28:32:INFO:loading file None
2021-01-28 17:28:32:INFO:loading file None
2021-01-28 17:28:32:INFO:loading file None
2021-01-28 17:28:32:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:28:32:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:28:32:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:28:35:INFO:The model has 112685553 trainable parameters
2021-01-28 17:28:44:INFO:TRAIN-(misa) (1/1/1)>> loss: 6.0526  Has0_acc_2: 0.5055  Has0_F1_score: 0.5088  Non0_acc_2: 0.4988  Non0_F1_score: 0.5030  Mult_acc_5: 0.1768  Mult_acc_7: 0.1604  MAE: 1.7684  Corr: -0.0337 
2021-01-28 17:28:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4320  Corr: 0.0980  Loss: 2.7831 
2021-01-28 17:28:56:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.1040  Has0_acc_2: 0.5047  Has0_F1_score: 0.5156  Non0_acc_2: 0.4955  Non0_F1_score: 0.5073  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.3460  Corr: -0.0321 
2021-01-28 17:28:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4137  Corr: 0.0838  Loss: 2.6658 
2021-01-28 17:29:08:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.6263  Has0_acc_2: 0.5537  Has0_F1_score: 0.6208  Non0_acc_2: 0.5418  Non0_F1_score: 0.6112  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3222  Corr: -0.0026 
2021-01-28 17:29:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4122  Corr: 0.1056  Loss: 2.7398 
2021-01-28 17:29:18:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.5352  Has0_acc_2: 0.5732  Has0_F1_score: 0.6626  Non0_acc_2: 0.5589  Non0_F1_score: 0.6506  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3186  Corr: 0.0241 
2021-01-28 17:29:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4134  Corr: 0.1163  Loss: 2.6918 
2021-01-28 17:29:28:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.4394  Has0_acc_2: 0.5717  Has0_F1_score: 0.6990  Non0_acc_2: 0.5548  Non0_F1_score: 0.6852  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.3158  Corr: 0.0257 
2021-01-28 17:29:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4168  Corr: 0.1184  Loss: 2.7310 
2021-01-28 17:29:38:INFO:TRAIN-(misa) (4/6/1)>> loss: 2.3996  Has0_acc_2: 0.5678  Has0_F1_score: 0.7131  Non0_acc_2: 0.5491  Non0_F1_score: 0.6974  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3154  Corr: 0.0284 
2021-01-28 17:29:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4177  Corr: 0.1154  Loss: 2.6963 
2021-01-28 17:29:49:INFO:TRAIN-(misa) (5/7/1)>> loss: 2.3497  Has0_acc_2: 0.5639  Has0_F1_score: 0.6788  Non0_acc_2: 0.5475  Non0_F1_score: 0.6652  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3231  Corr: -0.0032 
2021-01-28 17:29:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4165  Corr: 0.1189  Loss: 2.6910 
2021-01-28 17:29:59:INFO:TRAIN-(misa) (6/8/1)>> loss: 2.3255  Has0_acc_2: 0.5600  Has0_F1_score: 0.6939  Non0_acc_2: 0.5426  Non0_F1_score: 0.6797  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3234  Corr: -0.0168 
2021-01-28 17:29:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4149  Corr: 0.1191  Loss: 2.6789 
2021-01-28 17:30:09:INFO:TRAIN-(misa) (7/9/1)>> loss: 2.3293  Has0_acc_2: 0.5646  Has0_F1_score: 0.7058  Non0_acc_2: 0.5475  Non0_F1_score: 0.6922  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3150  Corr: 0.0528 
2021-01-28 17:30:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4250  Corr: 0.1222  Loss: 2.7609 
2021-01-28 17:30:19:INFO:TRAIN-(misa) (8/10/1)>> loss: 2.3539  Has0_acc_2: 0.5701  Has0_F1_score: 0.7127  Non0_acc_2: 0.5524  Non0_F1_score: 0.6982  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3152  Corr: 0.0576 
2021-01-28 17:30:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4174  Corr: 0.1268  Loss: 2.6926 
2021-01-28 17:30:22:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.5163  Corr: 0.0746  Loss: 3.0729 
2021-01-28 17:30:22:INFO:Start saving results...
2021-01-28 17:30:22:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:30:22:INFO:########################################misa-(8/50)########################################
2021-01-28 17:30:22:INFO:batch_size:64
2021-01-28 17:30:22:INFO:learning_rate:0.0005
2021-01-28 17:30:22:INFO:hidden_size:64
2021-01-28 17:30:22:INFO:dropout:0.2
2021-01-28 17:30:22:INFO:reverse_grad_weight:0.8
2021-01-28 17:30:22:INFO:diff_weight:0.5
2021-01-28 17:30:22:INFO:sim_weight:1.0
2021-01-28 17:30:22:INFO:sp_weight:0.0
2021-01-28 17:30:22:INFO:recon_weight:0.8
2021-01-28 17:30:22:INFO:grad_clip:1.0
2021-01-28 17:30:22:INFO:weight_decay:5e-05
2021-01-28 17:30:22:INFO:##########################################################################################
2021-01-28 17:30:22:INFO:Start running misa...
2021-01-28 17:30:22:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:30:22:INFO:Let's use 1 GPUs!
2021-01-28 17:30:22:INFO:train samples: (1284,)
2021-01-28 17:30:22:INFO:valid samples: (229,)
2021-01-28 17:30:23:INFO:test samples: (686,)
2021-01-28 17:30:23:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:30:23:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:30:23:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:30:23:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:30:23:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:30:23:INFO:loading file None
2021-01-28 17:30:23:INFO:loading file None
2021-01-28 17:30:23:INFO:loading file None
2021-01-28 17:30:23:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:30:23:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:30:23:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:30:26:INFO:The model has 109943985 trainable parameters
2021-01-28 17:30:36:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.5386  Has0_acc_2: 0.5319  Has0_F1_score: 0.5620  Non0_acc_2: 0.5215  Non0_F1_score: 0.5527  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3396  Corr: 0.0036 
2021-01-28 17:30:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4106  Corr: 0.1428  Loss: 2.7031 
2021-01-28 17:30:47:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.6365  Has0_acc_2: 0.5498  Has0_F1_score: 0.6302  Non0_acc_2: 0.5378  Non0_F1_score: 0.6211  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3170  Corr: 0.0444 
2021-01-28 17:30:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4102  Corr: 0.2056  Loss: 2.7508 
2021-01-28 17:30:57:INFO:TRAIN-(misa) (2/3/1)>> loss: 3.1617  Has0_acc_2: 0.5444  Has0_F1_score: 0.5938  Non0_acc_2: 0.5313  Non0_F1_score: 0.5819  Mult_acc_5: 0.1846  Mult_acc_7: 0.1846  MAE: 1.3277  Corr: 0.0073 
2021-01-28 17:30:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4310  Corr: 0.2422  Loss: 2.7585 
2021-01-28 17:31:07:INFO:TRAIN-(misa) (3/4/1)>> loss: 2.7408  Has0_acc_2: 0.5678  Has0_F1_score: 0.6899  Non0_acc_2: 0.5516  Non0_F1_score: 0.6769  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3190  Corr: 0.0209 
2021-01-28 17:31:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4162  Corr: 0.2383  Loss: 2.6871 
2021-01-28 17:31:19:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.5840  Has0_acc_2: 0.5685  Has0_F1_score: 0.7117  Non0_acc_2: 0.5508  Non0_F1_score: 0.6971  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3161  Corr: 0.0260 
2021-01-28 17:31:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4138  Corr: 0.2118  Loss: 2.7179 
2021-01-28 17:31:29:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.5242  Has0_acc_2: 0.5678  Has0_F1_score: 0.6833  Non0_acc_2: 0.5524  Non0_F1_score: 0.6711  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3211  Corr: -0.0049 
2021-01-28 17:31:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4188  Corr: 0.2123  Loss: 2.6988 
2021-01-28 17:31:40:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.4327  Has0_acc_2: 0.5701  Has0_F1_score: 0.7220  Non0_acc_2: 0.5516  Non0_F1_score: 0.7067  Mult_acc_5: 0.1877  Mult_acc_7: 0.1877  MAE: 1.3173  Corr: 0.0251 
2021-01-28 17:31:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4204  Corr: 0.1954  Loss: 2.8270 
2021-01-28 17:31:50:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.4368  Has0_acc_2: 0.5662  Has0_F1_score: 0.7188  Non0_acc_2: 0.5475  Non0_F1_score: 0.7033  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3195  Corr: 0.0003 
2021-01-28 17:31:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4199  Corr: 0.1832  Loss: 2.6994 
2021-01-28 17:32:00:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.3663  Has0_acc_2: 0.5569  Has0_F1_score: 0.6597  Non0_acc_2: 0.5418  Non0_F1_score: 0.6475  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3224  Corr: -0.0168 
2021-01-28 17:32:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4126  Corr: 0.1749  Loss: 2.7526 
2021-01-28 17:32:10:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.5612  Has0_acc_2: 0.5693  Has0_F1_score: 0.7222  Non0_acc_2: 0.5508  Non0_F1_score: 0.7069  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3249  Corr: -0.0350 
2021-01-28 17:32:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4257  Corr: 0.1699  Loss: 2.7804 
2021-01-28 17:32:20:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.4749  Has0_acc_2: 0.5717  Has0_F1_score: 0.7230  Non0_acc_2: 0.5532  Non0_F1_score: 0.7077  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3180  Corr: 0.0373 
2021-01-28 17:32:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4166  Corr: 0.1411  Loss: 2.7219 
2021-01-28 17:32:30:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.3748  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3191  Corr: -0.0328 
2021-01-28 17:32:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4160  Corr: 0.1288  Loss: 2.6864 
2021-01-28 17:32:41:INFO:TRAIN-(misa) (1/13/1)>> loss: 2.4239  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3211  Corr: -0.0269 
2021-01-28 17:32:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4201  Corr: 0.0899  Loss: 2.7518 
2021-01-28 17:32:52:INFO:TRAIN-(misa) (2/14/1)>> loss: 2.4759  Has0_acc_2: 0.5670  Has0_F1_score: 0.7018  Non0_acc_2: 0.5508  Non0_F1_score: 0.6892  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3220  Corr: -0.0092 
2021-01-28 17:32:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4162  Corr: 0.1000  Loss: 2.7389 
2021-01-28 17:33:02:INFO:TRAIN-(misa) (3/15/1)>> loss: 2.4597  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3218  Corr: -0.0482 
2021-01-28 17:33:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4208  Corr: 0.0742  Loss: 2.7607 
2021-01-28 17:33:13:INFO:TRAIN-(misa) (4/16/1)>> loss: 2.4412  Has0_acc_2: 0.5701  Has0_F1_score: 0.7248  Non0_acc_2: 0.5516  Non0_F1_score: 0.7095  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3194  Corr: -0.0107 
2021-01-28 17:33:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4200  Corr: 0.0757  Loss: 2.7108 
2021-01-28 17:33:23:INFO:TRAIN-(misa) (5/17/1)>> loss: 2.3802  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3206  Corr: -0.0293 
2021-01-28 17:33:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4180  Corr: 0.0589  Loss: 2.7195 
2021-01-28 17:33:34:INFO:TRAIN-(misa) (6/18/1)>> loss: 2.3924  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3192  Corr: -0.0061 
2021-01-28 17:33:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4196  Corr: 0.0491  Loss: 2.7893 
2021-01-28 17:33:44:INFO:TRAIN-(misa) (7/19/1)>> loss: 2.3284  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3208  Corr: -0.0234 
2021-01-28 17:33:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4186  Corr: 0.0921  Loss: 2.7158 
2021-01-28 17:33:55:INFO:TRAIN-(misa) (8/20/1)>> loss: 2.3959  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3218  Corr: -0.0465 
2021-01-28 17:33:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4189  Corr: 0.0919  Loss: 2.7449 
2021-01-28 17:33:58:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4804  Corr: 0.0965  Loss: 2.9019 
2021-01-28 17:33:58:INFO:Start saving results...
2021-01-28 17:33:58:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:33:58:INFO:########################################misa-(9/50)########################################
2021-01-28 17:33:58:INFO:batch_size:16
2021-01-28 17:33:58:INFO:learning_rate:0.0005
2021-01-28 17:33:58:INFO:hidden_size:64
2021-01-28 17:33:58:INFO:dropout:0.5
2021-01-28 17:33:58:INFO:reverse_grad_weight:0.5
2021-01-28 17:33:58:INFO:diff_weight:0.3
2021-01-28 17:33:58:INFO:sim_weight:1.0
2021-01-28 17:33:58:INFO:sp_weight:0.0
2021-01-28 17:33:58:INFO:recon_weight:1.0
2021-01-28 17:33:58:INFO:grad_clip:1.0
2021-01-28 17:33:58:INFO:weight_decay:0.0
2021-01-28 17:33:58:INFO:##########################################################################################
2021-01-28 17:33:58:INFO:Start running misa...
2021-01-28 17:33:58:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:33:58:INFO:Let's use 1 GPUs!
2021-01-28 17:33:59:INFO:train samples: (1284,)
2021-01-28 17:33:59:INFO:valid samples: (229,)
2021-01-28 17:34:00:INFO:test samples: (686,)
2021-01-28 17:34:00:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:34:00:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:34:00:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:34:00:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:34:00:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:34:00:INFO:loading file None
2021-01-28 17:34:00:INFO:loading file None
2021-01-28 17:34:00:INFO:loading file None
2021-01-28 17:34:00:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:34:00:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:34:00:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:34:03:INFO:The model has 109943985 trainable parameters
2021-01-28 17:34:20:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.4960  Has0_acc_2: 0.5413  Has0_F1_score: 0.5734  Non0_acc_2: 0.5394  Non0_F1_score: 0.5745  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.3283  Corr: 0.0286 
2021-01-28 17:34:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4109  Corr: 0.0937  Loss: 2.7142 
2021-01-28 17:34:40:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5025  Has0_acc_2: 0.5553  Has0_F1_score: 0.6258  Non0_acc_2: 0.5418  Non0_F1_score: 0.6143  Mult_acc_5: 0.1830  Mult_acc_7: 0.1830  MAE: 1.3126  Corr: 0.0685 
2021-01-28 17:34:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4148  Corr: 0.1411  Loss: 2.7105 
2021-01-28 17:35:00:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4220  Has0_acc_2: 0.5576  Has0_F1_score: 0.6137  Non0_acc_2: 0.5435  Non0_F1_score: 0.6006  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3286  Corr: 0.0181 
2021-01-28 17:35:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4200  Corr: 0.1682  Loss: 2.7817 
2021-01-28 17:35:18:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3472  Has0_acc_2: 0.5600  Has0_F1_score: 0.6320  Non0_acc_2: 0.5467  Non0_F1_score: 0.6207  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3164  Corr: 0.0505 
2021-01-28 17:35:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4196  Corr: 0.1603  Loss: 2.6858 
2021-01-28 17:35:38:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3707  Has0_acc_2: 0.5569  Has0_F1_score: 0.6475  Non0_acc_2: 0.5418  Non0_F1_score: 0.6347  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3270  Corr: -0.0195 
2021-01-28 17:35:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4201  Corr: 0.1771  Loss: 2.7557 
2021-01-28 17:35:57:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3523  Has0_acc_2: 0.5631  Has0_F1_score: 0.6843  Non0_acc_2: 0.5475  Non0_F1_score: 0.6721  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3231  Corr: -0.0393 
2021-01-28 17:35:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4222  Corr: 0.1610  Loss: 2.7571 
2021-01-28 17:36:15:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3150  Has0_acc_2: 0.5709  Has0_F1_score: 0.7219  Non0_acc_2: 0.5524  Non0_F1_score: 0.7065  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3168  Corr: 0.0286 
2021-01-28 17:36:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4206  Corr: 0.1493  Loss: 2.7282 
2021-01-28 17:36:34:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.3367  Has0_acc_2: 0.5748  Has0_F1_score: 0.6869  Non0_acc_2: 0.5565  Non0_F1_score: 0.6702  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3252  Corr: -0.0345 
2021-01-28 17:36:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4221  Corr: 0.1311  Loss: 2.6975 
2021-01-28 17:36:52:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.2946  Has0_acc_2: 0.5537  Has0_F1_score: 0.6347  Non0_acc_2: 0.5426  Non0_F1_score: 0.6269  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3147  Corr: 0.0611 
2021-01-28 17:36:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4145  Corr: 0.1290  Loss: 2.7584 
2021-01-28 17:37:10:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.3759  Has0_acc_2: 0.5576  Has0_F1_score: 0.6343  Non0_acc_2: 0.5402  Non0_F1_score: 0.6177  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3252  Corr: -0.0041 
2021-01-28 17:37:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4203  Corr: 0.0515  Loss: 2.7034 
2021-01-28 17:37:28:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.3512  Has0_acc_2: 0.5452  Has0_F1_score: 0.6281  Non0_acc_2: 0.5313  Non0_F1_score: 0.6167  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3244  Corr: -0.0133 
2021-01-28 17:37:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4175  Corr: 0.0575  Loss: 2.8159 
2021-01-28 17:37:46:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.3130  Has0_acc_2: 0.5623  Has0_F1_score: 0.6889  Non0_acc_2: 0.5451  Non0_F1_score: 0.6746  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3190  Corr: 0.0052 
2021-01-28 17:37:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4169  Corr: 0.0742  Loss: 2.6411 
2021-01-28 17:38:06:INFO:TRAIN-(misa) (1/13/1)>> loss: 2.3279  Has0_acc_2: 0.5584  Has0_F1_score: 0.6928  Non0_acc_2: 0.5394  Non0_F1_score: 0.6762  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.3257  Corr: -0.0216 
2021-01-28 17:38:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4204  Corr: 0.0724  Loss: 2.7162 
2021-01-28 17:38:24:INFO:TRAIN-(misa) (2/14/1)>> loss: 2.3276  Has0_acc_2: 0.5569  Has0_F1_score: 0.6833  Non0_acc_2: 0.5410  Non0_F1_score: 0.6711  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3230  Corr: 0.0013 
2021-01-28 17:38:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4191  Corr: 0.0639  Loss: 2.7165 
2021-01-28 17:38:43:INFO:TRAIN-(misa) (3/15/1)>> loss: 2.3397  Has0_acc_2: 0.5553  Has0_F1_score: 0.6677  Non0_acc_2: 0.5410  Non0_F1_score: 0.6571  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3281  Corr: -0.0524 
2021-01-28 17:38:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4232  Corr: 0.0810  Loss: 2.7572 
2021-01-28 17:39:01:INFO:TRAIN-(misa) (4/16/1)>> loss: 2.3313  Has0_acc_2: 0.5631  Has0_F1_score: 0.6985  Non0_acc_2: 0.5451  Non0_F1_score: 0.6833  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3244  Corr: -0.0353 
2021-01-28 17:39:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4249  Corr: 0.0834  Loss: 2.7394 
2021-01-28 17:39:20:INFO:TRAIN-(misa) (5/17/1)>> loss: 2.3204  Has0_acc_2: 0.5600  Has0_F1_score: 0.6776  Non0_acc_2: 0.5418  Non0_F1_score: 0.6616  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3250  Corr: -0.0414 
2021-01-28 17:39:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4247  Corr: 0.0805  Loss: 2.7565 
2021-01-28 17:39:38:INFO:TRAIN-(misa) (6/18/1)>> loss: 2.3154  Has0_acc_2: 0.5709  Has0_F1_score: 0.7113  Non0_acc_2: 0.5540  Non0_F1_score: 0.6980  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3208  Corr: -0.0236 
2021-01-28 17:39:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4202  Corr: 0.0790  Loss: 2.7817 
2021-01-28 17:39:56:INFO:TRAIN-(misa) (7/19/1)>> loss: 2.3233  Has0_acc_2: 0.5693  Has0_F1_score: 0.7250  Non0_acc_2: 0.5508  Non0_F1_score: 0.7097  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3277  Corr: -0.0581 
2021-01-28 17:39:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4268  Corr: 0.0892  Loss: 2.7585 
2021-01-28 17:40:14:INFO:TRAIN-(misa) (8/20/1)>> loss: 2.3084  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3180  Corr: 0.0218 
2021-01-28 17:40:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4179  Corr: 0.0790  Loss: 2.6341 
2021-01-28 17:40:33:INFO:TRAIN-(misa) (1/21/1)>> loss: 2.3168  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3201  Corr: -0.0103 
2021-01-28 17:40:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4254  Corr: 0.0876  Loss: 2.7143 
2021-01-28 17:40:51:INFO:TRAIN-(misa) (2/22/1)>> loss: 2.3135  Has0_acc_2: 0.5693  Has0_F1_score: 0.7236  Non0_acc_2: 0.5516  Non0_F1_score: 0.7095  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3254  Corr: -0.0300 
2021-01-28 17:40:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4209  Corr: 0.0558  Loss: 2.7678 
2021-01-28 17:41:11:INFO:TRAIN-(misa) (3/23/1)>> loss: 2.2922  Has0_acc_2: 0.5607  Has0_F1_score: 0.6855  Non0_acc_2: 0.5451  Non0_F1_score: 0.6734  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3193  Corr: 0.0353 
2021-01-28 17:41:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4160  Corr: 0.0274  Loss: 2.7682 
2021-01-28 17:41:29:INFO:TRAIN-(misa) (4/24/1)>> loss: 2.3067  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.3192  Corr: -0.0068 
2021-01-28 17:41:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4223  Corr: 0.0202  Loss: 2.7217 
2021-01-28 17:41:48:INFO:TRAIN-(misa) (5/25/1)>> loss: 2.3067  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3203  Corr: -0.0134 
2021-01-28 17:41:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4233  Corr: 0.0212  Loss: 2.7022 
2021-01-28 17:42:07:INFO:TRAIN-(misa) (6/26/1)>> loss: 2.3011  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3168  Corr: 0.0252 
2021-01-28 17:42:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4211  Corr: -0.0266  Loss: 2.7102 
2021-01-28 17:42:25:INFO:TRAIN-(misa) (7/27/1)>> loss: 2.2916  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3228  Corr: -0.0078 
2021-01-28 17:42:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4216  Corr: -0.0788  Loss: 2.6511 
2021-01-28 17:42:43:INFO:TRAIN-(misa) (8/28/1)>> loss: 2.3294  Has0_acc_2: 0.5685  Has0_F1_score: 0.7238  Non0_acc_2: 0.5500  Non0_F1_score: 0.7085  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3258  Corr: -0.0466 
2021-01-28 17:42:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4221  Corr: -0.0685  Loss: 2.7637 
2021-01-28 17:42:48:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4689  Corr: 0.1163  Loss: 2.8480 
2021-01-28 17:42:48:INFO:Start saving results...
2021-01-28 17:42:48:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:42:48:INFO:########################################misa-(10/50)########################################
2021-01-28 17:42:48:INFO:batch_size:16
2021-01-28 17:42:48:INFO:learning_rate:0.0005
2021-01-28 17:42:48:INFO:hidden_size:256
2021-01-28 17:42:48:INFO:dropout:0.2
2021-01-28 17:42:48:INFO:reverse_grad_weight:1.0
2021-01-28 17:42:48:INFO:diff_weight:0.3
2021-01-28 17:42:48:INFO:sim_weight:0.8
2021-01-28 17:42:48:INFO:sp_weight:0.0
2021-01-28 17:42:48:INFO:recon_weight:0.5
2021-01-28 17:42:48:INFO:grad_clip:1.0
2021-01-28 17:42:48:INFO:weight_decay:5e-05
2021-01-28 17:42:48:INFO:##########################################################################################
2021-01-28 17:42:48:INFO:Start running misa...
2021-01-28 17:42:48:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:42:48:INFO:Let's use 1 GPUs!
2021-01-28 17:42:53:INFO:train samples: (1284,)
2021-01-28 17:42:54:INFO:valid samples: (229,)
2021-01-28 17:42:55:INFO:test samples: (686,)
2021-01-28 17:42:55:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:42:55:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:42:55:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:42:55:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:42:55:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:42:55:INFO:loading file None
2021-01-28 17:42:55:INFO:loading file None
2021-01-28 17:42:55:INFO:loading file None
2021-01-28 17:42:55:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:42:55:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:42:55:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:42:59:INFO:The model has 112685553 trainable parameters
2021-01-28 17:43:16:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.5028  Has0_acc_2: 0.5241  Has0_F1_score: 0.5492  Non0_acc_2: 0.5191  Non0_F1_score: 0.5463  Mult_acc_5: 0.1947  Mult_acc_7: 0.1916  MAE: 1.3819  Corr: 0.0369 
2021-01-28 17:43:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4144  Corr: 0.1293  Loss: 2.6988 
2021-01-28 17:43:36:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4979  Has0_acc_2: 0.5358  Has0_F1_score: 0.5723  Non0_acc_2: 0.5240  Non0_F1_score: 0.5615  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3213  Corr: 0.0598 
2021-01-28 17:43:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.6963  Non0_acc_2: 0.6111  Non0_F1_score: 0.6749  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4323  Corr: 0.1425  Loss: 2.7721 
2021-01-28 17:43:54:INFO:TRAIN-(misa) (2/3/1)>> loss: 2.4387  Has0_acc_2: 0.5452  Has0_F1_score: 0.5649  Non0_acc_2: 0.5370  Non0_F1_score: 0.5577  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3144  Corr: 0.0565 
2021-01-28 17:43:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.4143  Corr: 0.1477  Loss: 2.7644 
2021-01-28 17:44:12:INFO:TRAIN-(misa) (3/4/1)>> loss: 2.3862  Has0_acc_2: 0.5530  Has0_F1_score: 0.6280  Non0_acc_2: 0.5378  Non0_F1_score: 0.6145  Mult_acc_5: 0.1970  Mult_acc_7: 0.1970  MAE: 1.3135  Corr: 0.0569 
2021-01-28 17:44:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4072  Corr: 0.1360  Loss: 2.6629 
2021-01-28 17:44:32:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3674  Has0_acc_2: 0.5654  Has0_F1_score: 0.5960  Non0_acc_2: 0.5556  Non0_F1_score: 0.5873  Mult_acc_5: 0.1854  Mult_acc_7: 0.1854  MAE: 1.3054  Corr: 0.1223 
2021-01-28 17:44:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4063  Corr: 0.1348  Loss: 2.7233 
2021-01-28 17:44:50:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.2943  Has0_acc_2: 0.5997  Has0_F1_score: 0.6216  Non0_acc_2: 0.5938  Non0_F1_score: 0.6168  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.2760  Corr: 0.1939 
2021-01-28 17:44:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.4049  Corr: 0.1444  Loss: 2.8307 
2021-01-28 17:45:10:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3254  Has0_acc_2: 0.5857  Has0_F1_score: 0.6165  Non0_acc_2: 0.5760  Non0_F1_score: 0.6076  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.2995  Corr: 0.1464 
2021-01-28 17:45:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7329  Non0_acc_2: 0.5787  Non0_F1_score: 0.7129  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4029  Corr: 0.1236  Loss: 2.7408 
2021-01-28 17:45:28:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.2343  Has0_acc_2: 0.6005  Has0_F1_score: 0.6308  Non0_acc_2: 0.5906  Non0_F1_score: 0.6216  Mult_acc_5: 0.2002  Mult_acc_7: 0.1994  MAE: 1.2715  Corr: 0.2273 
2021-01-28 17:45:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6946  Non0_acc_2: 0.5926  Non0_F1_score: 0.6728  Mult_acc_5: 0.2183  Mult_acc_7: 0.2183  MAE: 1.3962  Corr: 0.1055  Loss: 2.7581 
2021-01-28 17:45:48:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.1639  Has0_acc_2: 0.6168  Has0_F1_score: 0.6557  Non0_acc_2: 0.6068  Non0_F1_score: 0.6465  Mult_acc_5: 0.1939  Mult_acc_7: 0.1931  MAE: 1.2444  Corr: 0.2853 
2021-01-28 17:45:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.6548  Non0_acc_2: 0.6019  Non0_F1_score: 0.6371  Mult_acc_5: 0.2183  Mult_acc_7: 0.2183  MAE: 1.4060  Corr: 0.1135  Loss: 2.6939 
2021-01-28 17:46:07:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.1408  Has0_acc_2: 0.6215  Has0_F1_score: 0.6429  Non0_acc_2: 0.6149  Non0_F1_score: 0.6370  Mult_acc_5: 0.1994  Mult_acc_7: 0.1986  MAE: 1.2363  Corr: 0.3030 
2021-01-28 17:46:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7201  Non0_acc_2: 0.5926  Non0_F1_score: 0.6996  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.4014  Corr: 0.1158  Loss: 2.6719 
2021-01-28 17:46:27:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.1429  Has0_acc_2: 0.6153  Has0_F1_score: 0.6455  Non0_acc_2: 0.6076  Non0_F1_score: 0.6388  Mult_acc_5: 0.2017  Mult_acc_7: 0.2009  MAE: 1.2344  Corr: 0.3124 
2021-01-28 17:46:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6908  Non0_acc_2: 0.6111  Non0_F1_score: 0.6749  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3923  Corr: 0.1119  Loss: 2.7399 
2021-01-28 17:46:46:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.0546  Has0_acc_2: 0.6340  Has0_F1_score: 0.6519  Non0_acc_2: 0.6271  Non0_F1_score: 0.6455  Mult_acc_5: 0.2290  Mult_acc_7: 0.2251  MAE: 1.2093  Corr: 0.3509 
2021-01-28 17:46:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6495  Non0_acc_2: 0.6065  Non0_F1_score: 0.6426  Mult_acc_5: 0.2140  Mult_acc_7: 0.2009  MAE: 1.3996  Corr: 0.1348  Loss: 2.8284 
2021-01-28 17:46:49:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4838  Corr: 0.1165  Loss: 2.9408 
2021-01-28 17:46:49:INFO:Start saving results...
2021-01-28 17:46:49:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:46:49:INFO:########################################misa-(11/50)########################################
2021-01-28 17:46:49:INFO:batch_size:16
2021-01-28 17:46:49:INFO:learning_rate:0.0001
2021-01-28 17:46:49:INFO:hidden_size:128
2021-01-28 17:46:49:INFO:dropout:0.0
2021-01-28 17:46:49:INFO:reverse_grad_weight:1.0
2021-01-28 17:46:49:INFO:diff_weight:0.1
2021-01-28 17:46:49:INFO:sim_weight:1.0
2021-01-28 17:46:49:INFO:sp_weight:0.0
2021-01-28 17:46:49:INFO:recon_weight:0.5
2021-01-28 17:46:49:INFO:grad_clip:-1.0
2021-01-28 17:46:49:INFO:weight_decay:0.002
2021-01-28 17:46:49:INFO:##########################################################################################
2021-01-28 17:46:49:INFO:Start running misa...
2021-01-28 17:46:49:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:46:49:INFO:Let's use 1 GPUs!
2021-01-28 17:46:50:INFO:train samples: (1284,)
2021-01-28 17:46:51:INFO:valid samples: (229,)
2021-01-28 17:46:51:INFO:test samples: (686,)
2021-01-28 17:46:51:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:46:51:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:46:51:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:46:51:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:46:51:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:46:51:INFO:loading file None
2021-01-28 17:46:51:INFO:loading file None
2021-01-28 17:46:51:INFO:loading file None
2021-01-28 17:46:51:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:46:51:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:46:51:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:46:55:INFO:The model has 110620273 trainable parameters
2021-01-28 17:47:12:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.2463  Has0_acc_2: 0.7056  Has0_F1_score: 0.7070  Non0_acc_2: 0.7149  Non0_F1_score: 0.7172  Mult_acc_5: 0.2578  Mult_acc_7: 0.2484  MAE: 1.0858  Corr: 0.4971 
2021-01-28 17:47:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8016  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.3537  Mult_acc_7: 0.3188  MAE: 0.9370  Corr: 0.7054  Loss: 1.4928 
2021-01-28 17:47:31:INFO:TRAIN-(misa) (1/2/1)>> loss: 1.5112  Has0_acc_2: 0.8458  Has0_F1_score: 0.8451  Non0_acc_2: 0.8619  Non0_F1_score: 0.8616  Mult_acc_5: 0.4611  Mult_acc_7: 0.4338  MAE: 0.6841  Corr: 0.8045 
2021-01-28 17:47:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8060  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.4236  Mult_acc_7: 0.3319  MAE: 0.8465  Corr: 0.7443  Loss: 1.3785 
2021-01-28 17:47:50:INFO:TRAIN-(misa) (1/3/1)>> loss: 0.8287  Has0_acc_2: 0.8917  Has0_F1_score: 0.8914  Non0_acc_2: 0.9074  Non0_F1_score: 0.9073  Mult_acc_5: 0.5950  Mult_acc_7: 0.5475  MAE: 0.4927  Corr: 0.9100 
2021-01-28 17:47:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.4454  Mult_acc_7: 0.3668  MAE: 0.8245  Corr: 0.7673  Loss: 1.1326 
2021-01-28 17:48:10:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.5785  Has0_acc_2: 0.9229  Has0_F1_score: 0.9227  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6807  Mult_acc_7: 0.6293  MAE: 0.3856  Corr: 0.9441 
2021-01-28 17:48:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.8146  Corr: 0.7652  Loss: 1.1518 
2021-01-28 17:48:28:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.4323  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7430  Mult_acc_7: 0.6947  MAE: 0.3274  Corr: 0.9601 
2021-01-28 17:48:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8565  Non0_F1_score: 0.8573  Mult_acc_5: 0.4978  Mult_acc_7: 0.3974  MAE: 0.7743  Corr: 0.7813  Loss: 1.0809 
2021-01-28 17:48:47:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.3570  Has0_acc_2: 0.9393  Has0_F1_score: 0.9390  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7547  Mult_acc_7: 0.7025  MAE: 0.2854  Corr: 0.9698 
2021-01-28 17:48:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5240  Mult_acc_7: 0.4148  MAE: 0.7798  Corr: 0.7772  Loss: 1.1574 
2021-01-28 17:49:05:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.2895  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7944  Mult_acc_7: 0.7539  MAE: 0.2515  Corr: 0.9772 
2021-01-28 17:49:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8383  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.5240  Mult_acc_7: 0.4498  MAE: 0.7524  Corr: 0.7816  Loss: 1.0402 
2021-01-28 17:49:25:INFO:TRAIN-(misa) (1/8/1)>> loss: 0.2407  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8333  Mult_acc_7: 0.7913  MAE: 0.2163  Corr: 0.9834 
2021-01-28 17:49:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.4978  Mult_acc_7: 0.4148  MAE: 0.7511  Corr: 0.7862  Loss: 1.0413 
2021-01-28 17:49:42:INFO:TRAIN-(misa) (2/9/1)>> loss: 0.2281  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8232  Mult_acc_7: 0.7913  MAE: 0.2161  Corr: 0.9836 
2021-01-28 17:49:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8264  Non0_acc_2: 0.8380  Non0_F1_score: 0.8397  Mult_acc_5: 0.4891  Mult_acc_7: 0.3886  MAE: 0.7834  Corr: 0.7807  Loss: 1.2631 
2021-01-28 17:50:01:INFO:TRAIN-(misa) (3/10/1)>> loss: 0.2148  Has0_acc_2: 0.9587  Has0_F1_score: 0.9587  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8232  Mult_acc_7: 0.7796  MAE: 0.2097  Corr: 0.9841 
2021-01-28 17:50:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4585  Mult_acc_7: 0.3668  MAE: 0.7814  Corr: 0.7850  Loss: 1.0976 
2021-01-28 17:50:19:INFO:TRAIN-(misa) (4/11/1)>> loss: 0.1867  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.8442  Mult_acc_7: 0.8092  MAE: 0.1880  Corr: 0.9874 
2021-01-28 17:50:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8192  Non0_acc_2: 0.8565  Non0_F1_score: 0.8558  Mult_acc_5: 0.4716  Mult_acc_7: 0.3974  MAE: 0.7797  Corr: 0.7814  Loss: 1.1696 
2021-01-28 17:50:38:INFO:TRAIN-(misa) (5/12/1)>> loss: 0.1696  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8707  Mult_acc_7: 0.8419  MAE: 0.1717  Corr: 0.9895 
2021-01-28 17:50:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5066  Mult_acc_7: 0.4236  MAE: 0.7740  Corr: 0.7715  Loss: 1.0896 
2021-01-28 17:50:56:INFO:TRAIN-(misa) (6/13/1)>> loss: 0.1537  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8762  Mult_acc_7: 0.8489  MAE: 0.1620  Corr: 0.9908 
2021-01-28 17:50:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8070  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5240  Mult_acc_7: 0.4410  MAE: 0.7474  Corr: 0.7807  Loss: 1.0675 
2021-01-28 17:51:14:INFO:TRAIN-(misa) (7/14/1)>> loss: 0.1540  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8481  Mult_acc_7: 0.8240  MAE: 0.1726  Corr: 0.9894 
2021-01-28 17:51:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8239  Non0_acc_2: 0.8611  Non0_F1_score: 0.8608  Mult_acc_5: 0.5022  Mult_acc_7: 0.4061  MAE: 0.7551  Corr: 0.7855  Loss: 1.0411 
2021-01-28 17:51:32:INFO:TRAIN-(misa) (8/15/1)>> loss: 0.1415  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8715  Mult_acc_7: 0.8466  MAE: 0.1642  Corr: 0.9905 
2021-01-28 17:51:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8166  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.4934  Mult_acc_7: 0.3843  MAE: 0.7657  Corr: 0.7835  Loss: 1.1130 
2021-01-28 17:51:36:INFO:TEST-(misa) >>  Has0_acc_2: 0.8149  Has0_F1_score: 0.8146  Non0_acc_2: 0.8293  Non0_F1_score: 0.8284  Mult_acc_5: 0.4475  Mult_acc_7: 0.4038  MAE: 0.7933  Corr: 0.7659  Loss: 1.1569 
2021-01-28 17:51:36:INFO:Start saving results...
2021-01-28 17:51:36:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:51:36:INFO:########################################misa-(12/50)########################################
2021-01-28 17:51:36:INFO:batch_size:32
2021-01-28 17:51:36:INFO:learning_rate:0.0001
2021-01-28 17:51:36:INFO:hidden_size:256
2021-01-28 17:51:36:INFO:dropout:0.2
2021-01-28 17:51:36:INFO:reverse_grad_weight:0.8
2021-01-28 17:51:36:INFO:diff_weight:0.3
2021-01-28 17:51:36:INFO:sim_weight:1.0
2021-01-28 17:51:36:INFO:sp_weight:0.0
2021-01-28 17:51:36:INFO:recon_weight:1.0
2021-01-28 17:51:36:INFO:grad_clip:1.0
2021-01-28 17:51:36:INFO:weight_decay:0.0
2021-01-28 17:51:36:INFO:##########################################################################################
2021-01-28 17:51:36:INFO:Start running misa...
2021-01-28 17:51:36:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:51:36:INFO:Let's use 1 GPUs!
2021-01-28 17:51:36:INFO:train samples: (1284,)
2021-01-28 17:51:37:INFO:valid samples: (229,)
2021-01-28 17:51:38:INFO:test samples: (686,)
2021-01-28 17:51:38:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:51:38:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:51:38:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:51:38:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:51:38:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:51:38:INFO:loading file None
2021-01-28 17:51:38:INFO:loading file None
2021-01-28 17:51:38:INFO:loading file None
2021-01-28 17:51:38:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:51:38:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:51:38:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:51:41:INFO:The model has 112685553 trainable parameters
2021-01-28 17:51:54:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.5934  Has0_acc_2: 0.6534  Has0_F1_score: 0.6569  Non0_acc_2: 0.6548  Non0_F1_score: 0.6590  Mult_acc_5: 0.2531  Mult_acc_7: 0.2469  MAE: 1.1320  Corr: 0.4432 
2021-01-28 17:51:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8060  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.4017  Mult_acc_7: 0.3362  MAE: 0.9156  Corr: 0.7193  Loss: 1.2824 
2021-01-28 17:52:09:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.2514  Has0_acc_2: 0.8481  Has0_F1_score: 0.8475  Non0_acc_2: 0.8676  Non0_F1_score: 0.8673  Mult_acc_5: 0.4579  Mult_acc_7: 0.4213  MAE: 0.7175  Corr: 0.7923 
2021-01-28 17:52:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.8084  Corr: 0.7617  Loss: 1.0415 
2021-01-28 17:52:23:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.1510  Has0_acc_2: 0.8847  Has0_F1_score: 0.8842  Non0_acc_2: 0.9082  Non0_F1_score: 0.9081  Mult_acc_5: 0.5974  Mult_acc_7: 0.5537  MAE: 0.4971  Corr: 0.9046 
2021-01-28 17:52:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7973  Non0_acc_2: 0.8241  Non0_F1_score: 0.8233  Mult_acc_5: 0.5066  Mult_acc_7: 0.4192  MAE: 0.8164  Corr: 0.7439  Loss: 1.3632 
2021-01-28 17:52:36:INFO:TRAIN-(misa) (2/4/1)>> loss: 0.7774  Has0_acc_2: 0.9206  Has0_F1_score: 0.9203  Non0_acc_2: 0.9374  Non0_F1_score: 0.9374  Mult_acc_5: 0.6667  Mult_acc_7: 0.6059  MAE: 0.3942  Corr: 0.9428 
2021-01-28 17:52:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8426  Non0_F1_score: 0.8417  Mult_acc_5: 0.4629  Mult_acc_7: 0.3581  MAE: 0.8276  Corr: 0.7673  Loss: 1.3279 
2021-01-28 17:52:49:INFO:TRAIN-(misa) (3/5/1)>> loss: 0.5860  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9586  Non0_F1_score: 0.9586  Mult_acc_5: 0.7329  Mult_acc_7: 0.6807  MAE: 0.3265  Corr: 0.9602 
2021-01-28 17:52:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8331  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7470  Corr: 0.7809  Loss: 0.9765 
2021-01-28 17:53:03:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.4759  Has0_acc_2: 0.9533  Has0_F1_score: 0.9532  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7765  Mult_acc_7: 0.7305  MAE: 0.2769  Corr: 0.9718 
2021-01-28 17:53:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7466  Corr: 0.7856  Loss: 1.1341 
2021-01-28 17:53:16:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.4059  Has0_acc_2: 0.9400  Has0_F1_score: 0.9398  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.7936  Mult_acc_7: 0.7523  MAE: 0.2498  Corr: 0.9776 
2021-01-28 17:53:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7448  Corr: 0.7885  Loss: 0.9682 
2021-01-28 17:53:30:INFO:TRAIN-(misa) (1/8/1)>> loss: 0.3867  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9569  Non0_F1_score: 0.9569  Mult_acc_5: 0.7812  Mult_acc_7: 0.7321  MAE: 0.2663  Corr: 0.9747 
2021-01-28 17:53:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7360  Corr: 0.7925  Loss: 1.1769 
2021-01-28 17:53:43:INFO:TRAIN-(misa) (2/9/1)>> loss: 0.3365  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8263  Mult_acc_7: 0.7858  MAE: 0.2236  Corr: 0.9823 
2021-01-28 17:53:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8611  Non0_F1_score: 0.8616  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7466  Corr: 0.7938  Loss: 1.0280 
2021-01-28 17:53:56:INFO:TRAIN-(misa) (3/10/1)>> loss: 0.3113  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8061  Mult_acc_7: 0.7695  MAE: 0.2252  Corr: 0.9822 
2021-01-28 17:53:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8326  Non0_acc_2: 0.8565  Non0_F1_score: 0.8558  Mult_acc_5: 0.4934  Mult_acc_7: 0.4017  MAE: 0.7605  Corr: 0.7841  Loss: 1.1610 
2021-01-28 17:54:09:INFO:TRAIN-(misa) (4/11/1)>> loss: 0.2904  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8232  Mult_acc_7: 0.7827  MAE: 0.2172  Corr: 0.9832 
2021-01-28 17:54:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8428  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7481  Corr: 0.7861  Loss: 1.1476 
2021-01-28 17:54:22:INFO:TRAIN-(misa) (5/12/1)>> loss: 0.2800  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8263  Mult_acc_7: 0.7897  MAE: 0.2256  Corr: 0.9823 
2021-01-28 17:54:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5371  Mult_acc_7: 0.4323  MAE: 0.7395  Corr: 0.7926  Loss: 1.0333 
2021-01-28 17:54:35:INFO:TRAIN-(misa) (6/13/1)>> loss: 0.2639  Has0_acc_2: 0.9494  Has0_F1_score: 0.9492  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.8139  Mult_acc_7: 0.7773  MAE: 0.2068  Corr: 0.9848 
2021-01-28 17:54:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8281  Non0_acc_2: 0.8565  Non0_F1_score: 0.8558  Mult_acc_5: 0.5109  Mult_acc_7: 0.4061  MAE: 0.7396  Corr: 0.7942  Loss: 0.9666 
2021-01-28 17:54:48:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2268  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8497  Mult_acc_7: 0.8131  MAE: 0.1819  Corr: 0.9886 
2021-01-28 17:54:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7173  Corr: 0.8004  Loss: 1.0251 
2021-01-28 17:55:01:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2176  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8614  Mult_acc_7: 0.8279  MAE: 0.1775  Corr: 0.9893 
2021-01-28 17:55:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5284  Mult_acc_7: 0.4454  MAE: 0.7203  Corr: 0.7990  Loss: 1.2065 
2021-01-28 17:55:14:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2145  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8676  Mult_acc_7: 0.8450  MAE: 0.1778  Corr: 0.9889 
2021-01-28 17:55:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5415  Mult_acc_7: 0.4541  MAE: 0.7218  Corr: 0.7931  Loss: 1.0508 
2021-01-28 17:55:27:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.1979  Has0_acc_2: 0.9681  Has0_F1_score: 0.9680  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8559  Mult_acc_7: 0.8201  MAE: 0.1688  Corr: 0.9899 
2021-01-28 17:55:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8192  Non0_acc_2: 0.8519  Non0_F1_score: 0.8510  Mult_acc_5: 0.4891  Mult_acc_7: 0.4061  MAE: 0.7496  Corr: 0.7928  Loss: 1.0631 
2021-01-28 17:55:40:INFO:TRAIN-(misa) (5/18/1)>> loss: 0.2008  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.8598  Mult_acc_7: 0.8287  MAE: 0.1748  Corr: 0.9891 
2021-01-28 17:55:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8286  Non0_acc_2: 0.8519  Non0_F1_score: 0.8517  Mult_acc_5: 0.5153  Mult_acc_7: 0.4017  MAE: 0.7408  Corr: 0.7943  Loss: 1.1551 
2021-01-28 17:55:54:INFO:TRAIN-(misa) (6/19/1)>> loss: 0.1838  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8598  Mult_acc_7: 0.8372  MAE: 0.1643  Corr: 0.9905 
2021-01-28 17:55:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5502  Mult_acc_7: 0.4585  MAE: 0.7206  Corr: 0.7982  Loss: 0.9418 
2021-01-28 17:56:08:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.1652  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8902  Mult_acc_7: 0.8637  MAE: 0.1453  Corr: 0.9926 
2021-01-28 17:56:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5371  Mult_acc_7: 0.4279  MAE: 0.7211  Corr: 0.7994  Loss: 0.9223 
2021-01-28 17:56:23:INFO:TRAIN-(misa) (1/21/1)>> loss: 0.1666  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9903  Non0_F1_score: 0.9903  Mult_acc_5: 0.8777  Mult_acc_7: 0.8442  MAE: 0.1570  Corr: 0.9915 
2021-01-28 17:56:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.5328  Mult_acc_7: 0.4236  MAE: 0.7328  Corr: 0.7950  Loss: 1.0202 
2021-01-28 17:56:36:INFO:TRAIN-(misa) (2/22/1)>> loss: 0.1602  Has0_acc_2: 0.9673  Has0_F1_score: 0.9672  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8816  Mult_acc_7: 0.8598  MAE: 0.1554  Corr: 0.9915 
2021-01-28 17:56:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8329  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5153  Mult_acc_7: 0.4061  MAE: 0.7215  Corr: 0.8000  Loss: 0.9451 
2021-01-28 17:56:49:INFO:TRAIN-(misa) (3/23/1)>> loss: 0.1520  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8785  Mult_acc_7: 0.8536  MAE: 0.1499  Corr: 0.9920 
2021-01-28 17:56:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8200  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5066  Mult_acc_7: 0.4192  MAE: 0.7246  Corr: 0.7975  Loss: 1.0111 
2021-01-28 17:57:02:INFO:TRAIN-(misa) (4/24/1)>> loss: 0.1598  Has0_acc_2: 0.9688  Has0_F1_score: 0.9688  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8723  Mult_acc_7: 0.8419  MAE: 0.1601  Corr: 0.9909 
2021-01-28 17:57:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7244  Corr: 0.7996  Loss: 0.9971 
2021-01-28 17:57:16:INFO:TRAIN-(misa) (5/25/1)>> loss: 0.1472  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8769  Mult_acc_7: 0.8458  MAE: 0.1485  Corr: 0.9923 
2021-01-28 17:57:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5502  Mult_acc_7: 0.4541  MAE: 0.7112  Corr: 0.8031  Loss: 0.9076 
2021-01-28 17:57:31:INFO:TRAIN-(misa) (1/26/1)>> loss: 0.1534  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8614  Mult_acc_7: 0.8318  MAE: 0.1653  Corr: 0.9905 
2021-01-28 17:57:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7263  Corr: 0.7984  Loss: 0.9466 
2021-01-28 17:57:44:INFO:TRAIN-(misa) (2/27/1)>> loss: 0.1478  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8840  Mult_acc_7: 0.8528  MAE: 0.1615  Corr: 0.9908 
2021-01-28 17:57:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.4803  Mult_acc_7: 0.4061  MAE: 0.7295  Corr: 0.7986  Loss: 0.9047 
2021-01-28 17:57:58:INFO:TRAIN-(misa) (1/28/1)>> loss: 0.1424  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8801  Mult_acc_7: 0.8567  MAE: 0.1539  Corr: 0.9919 
2021-01-28 17:57:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5109  Mult_acc_7: 0.4061  MAE: 0.7324  Corr: 0.7980  Loss: 0.9174 
2021-01-28 17:58:11:INFO:TRAIN-(misa) (2/29/1)>> loss: 0.1388  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9903  Non0_F1_score: 0.9903  Mult_acc_5: 0.8769  Mult_acc_7: 0.8489  MAE: 0.1517  Corr: 0.9919 
2021-01-28 17:58:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7212  Corr: 0.7983  Loss: 1.1547 
2021-01-28 17:58:25:INFO:TRAIN-(misa) (3/30/1)>> loss: 0.1274  Has0_acc_2: 0.9735  Has0_F1_score: 0.9735  Non0_acc_2: 0.9927  Non0_F1_score: 0.9927  Mult_acc_5: 0.8972  Mult_acc_7: 0.8762  MAE: 0.1360  Corr: 0.9936 
2021-01-28 17:58:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5109  Mult_acc_7: 0.4105  MAE: 0.7308  Corr: 0.7939  Loss: 0.9470 
2021-01-28 17:58:37:INFO:TRAIN-(misa) (4/31/1)>> loss: 0.1257  Has0_acc_2: 0.9688  Has0_F1_score: 0.9688  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.8855  Mult_acc_7: 0.8575  MAE: 0.1476  Corr: 0.9924 
2021-01-28 17:58:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.5284  Mult_acc_7: 0.4148  MAE: 0.7309  Corr: 0.7946  Loss: 0.9619 
2021-01-28 17:58:50:INFO:TRAIN-(misa) (5/32/1)>> loss: 0.1267  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8715  Mult_acc_7: 0.8396  MAE: 0.1485  Corr: 0.9923 
2021-01-28 17:58:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8215  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7304  Corr: 0.7972  Loss: 0.9116 
2021-01-28 17:59:03:INFO:TRAIN-(misa) (6/33/1)>> loss: 0.1214  Has0_acc_2: 0.9735  Has0_F1_score: 0.9735  Non0_acc_2: 0.9927  Non0_F1_score: 0.9927  Mult_acc_5: 0.8949  Mult_acc_7: 0.8684  MAE: 0.1427  Corr: 0.9929 
2021-01-28 17:59:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8241  Non0_acc_2: 0.8519  Non0_F1_score: 0.8517  Mult_acc_5: 0.5328  Mult_acc_7: 0.4454  MAE: 0.7206  Corr: 0.8005  Loss: 0.9685 
2021-01-28 17:59:16:INFO:TRAIN-(misa) (7/34/1)>> loss: 0.1316  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8840  Mult_acc_7: 0.8575  MAE: 0.1552  Corr: 0.9914 
2021-01-28 17:59:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5284  Mult_acc_7: 0.4192  MAE: 0.7164  Corr: 0.7992  Loss: 0.9420 
2021-01-28 17:59:29:INFO:TRAIN-(misa) (8/35/1)>> loss: 0.1315  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8692  Mult_acc_7: 0.8388  MAE: 0.1663  Corr: 0.9906 
2021-01-28 17:59:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8239  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7292  Corr: 0.7992  Loss: 0.9428 
2021-01-28 17:59:32:INFO:TEST-(misa) >>  Has0_acc_2: 0.8222  Has0_F1_score: 0.8219  Non0_acc_2: 0.8338  Non0_F1_score: 0.8331  Mult_acc_5: 0.4694  Mult_acc_7: 0.4155  MAE: 0.7717  Corr: 0.7924  Loss: 1.0395 
2021-01-28 17:59:32:INFO:Start saving results...
2021-01-28 17:59:32:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 17:59:32:INFO:########################################misa-(13/50)########################################
2021-01-28 17:59:32:INFO:batch_size:16
2021-01-28 17:59:32:INFO:learning_rate:0.0001
2021-01-28 17:59:32:INFO:hidden_size:256
2021-01-28 17:59:32:INFO:dropout:0.2
2021-01-28 17:59:32:INFO:reverse_grad_weight:0.5
2021-01-28 17:59:32:INFO:diff_weight:0.3
2021-01-28 17:59:32:INFO:sim_weight:0.8
2021-01-28 17:59:32:INFO:sp_weight:1.0
2021-01-28 17:59:32:INFO:recon_weight:1.0
2021-01-28 17:59:32:INFO:grad_clip:0.8
2021-01-28 17:59:32:INFO:weight_decay:0.0
2021-01-28 17:59:32:INFO:##########################################################################################
2021-01-28 17:59:32:INFO:Start running misa...
2021-01-28 17:59:32:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 17:59:32:INFO:Let's use 1 GPUs!
2021-01-28 17:59:33:INFO:train samples: (1284,)
2021-01-28 17:59:34:INFO:valid samples: (229,)
2021-01-28 17:59:34:INFO:test samples: (686,)
2021-01-28 17:59:34:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 17:59:34:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 17:59:34:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 17:59:34:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 17:59:34:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 17:59:34:INFO:loading file None
2021-01-28 17:59:34:INFO:loading file None
2021-01-28 17:59:34:INFO:loading file None
2021-01-28 17:59:34:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 17:59:34:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 17:59:34:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 17:59:38:INFO:The model has 112685553 trainable parameters
2021-01-28 17:59:55:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.4338  Has0_acc_2: 0.7103  Has0_F1_score: 0.7102  Non0_acc_2: 0.7197  Non0_F1_score: 0.7204  Mult_acc_5: 0.3170  Mult_acc_7: 0.3037  MAE: 0.9991  Corr: 0.5779 
2021-01-28 17:59:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8273  Non0_acc_2: 0.8426  Non0_F1_score: 0.8453  Mult_acc_5: 0.4148  Mult_acc_7: 0.3319  MAE: 0.8630  Corr: 0.7543  Loss: 1.1847 
2021-01-28 18:00:14:INFO:TRAIN-(misa) (1/2/1)>> loss: 1.3939  Has0_acc_2: 0.8474  Has0_F1_score: 0.8471  Non0_acc_2: 0.8611  Non0_F1_score: 0.8612  Mult_acc_5: 0.5039  Mult_acc_7: 0.4681  MAE: 0.6465  Corr: 0.8296 
2021-01-28 18:00:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7715  Non0_acc_2: 0.8056  Non0_F1_score: 0.8049  Mult_acc_5: 0.4236  Mult_acc_7: 0.3406  MAE: 0.9360  Corr: 0.7606  Loss: 1.3891 
2021-01-28 18:00:32:INFO:TRAIN-(misa) (2/3/1)>> loss: 0.8186  Has0_acc_2: 0.8956  Has0_F1_score: 0.8953  Non0_acc_2: 0.9171  Non0_F1_score: 0.9171  Mult_acc_5: 0.5950  Mult_acc_7: 0.5483  MAE: 0.4847  Corr: 0.9098 
2021-01-28 18:00:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5371  Mult_acc_7: 0.4192  MAE: 0.7503  Corr: 0.7738  Loss: 1.2124 
2021-01-28 18:00:50:INFO:TRAIN-(misa) (3/4/1)>> loss: 0.5327  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9553  Non0_F1_score: 0.9553  Mult_acc_5: 0.6713  Mult_acc_7: 0.6137  MAE: 0.3776  Corr: 0.9475 
2021-01-28 18:00:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8200  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5153  Mult_acc_7: 0.3974  MAE: 0.7648  Corr: 0.7698  Loss: 1.1698 
2021-01-28 18:01:09:INFO:TRAIN-(misa) (1/5/1)>> loss: 0.4776  Has0_acc_2: 0.9260  Has0_F1_score: 0.9258  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6815  Mult_acc_7: 0.6254  MAE: 0.3677  Corr: 0.9499 
2021-01-28 18:01:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8105  Non0_acc_2: 0.8380  Non0_F1_score: 0.8372  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7784  Corr: 0.7709  Loss: 1.1483 
2021-01-28 18:01:28:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.3730  Has0_acc_2: 0.9393  Has0_F1_score: 0.9391  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7227  Mult_acc_7: 0.6729  MAE: 0.3121  Corr: 0.9648 
2021-01-28 18:01:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.4978  Mult_acc_7: 0.3755  MAE: 0.7692  Corr: 0.7850  Loss: 1.2150 
2021-01-28 18:01:46:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.3067  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7991  Mult_acc_7: 0.7445  MAE: 0.2602  Corr: 0.9751 
2021-01-28 18:01:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8396  Non0_acc_2: 0.8565  Non0_F1_score: 0.8584  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7972  Corr: 0.7880  Loss: 1.1922 
2021-01-28 18:02:04:INFO:TRAIN-(misa) (3/8/1)>> loss: 0.2787  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9708  Non0_F1_score: 0.9707  Mult_acc_5: 0.8030  Mult_acc_7: 0.7578  MAE: 0.2550  Corr: 0.9769 
2021-01-28 18:02:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5328  Mult_acc_7: 0.4410  MAE: 0.7360  Corr: 0.7834  Loss: 1.1272 
2021-01-28 18:02:23:INFO:TRAIN-(misa) (1/9/1)>> loss: 0.2329  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8139  Mult_acc_7: 0.7702  MAE: 0.2201  Corr: 0.9827 
2021-01-28 18:02:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8328  Non0_acc_2: 0.8565  Non0_F1_score: 0.8561  Mult_acc_5: 0.5459  Mult_acc_7: 0.4323  MAE: 0.7371  Corr: 0.7829  Loss: 1.0954 
2021-01-28 18:02:43:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.2044  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8505  Mult_acc_7: 0.8123  MAE: 0.1991  Corr: 0.9859 
2021-01-28 18:02:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.4978  Mult_acc_7: 0.3886  MAE: 0.7588  Corr: 0.7861  Loss: 1.0683 
2021-01-28 18:03:03:INFO:TRAIN-(misa) (1/11/1)>> loss: 0.1992  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8178  Mult_acc_7: 0.7718  MAE: 0.2096  Corr: 0.9845 
2021-01-28 18:03:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8421  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5371  Mult_acc_7: 0.4148  MAE: 0.7471  Corr: 0.7906  Loss: 1.0562 
2021-01-28 18:03:22:INFO:TRAIN-(misa) (1/12/1)>> loss: 0.1911  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8341  Mult_acc_7: 0.7936  MAE: 0.2092  Corr: 0.9848 
2021-01-28 18:03:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.5109  Mult_acc_7: 0.4105  MAE: 0.7306  Corr: 0.7902  Loss: 0.9818 
2021-01-28 18:03:41:INFO:TRAIN-(misa) (1/13/1)>> loss: 0.1797  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8380  Mult_acc_7: 0.8037  MAE: 0.2020  Corr: 0.9860 
2021-01-28 18:03:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.5459  Mult_acc_7: 0.4323  MAE: 0.7371  Corr: 0.7897  Loss: 1.1031 
2021-01-28 18:03:59:INFO:TRAIN-(misa) (2/14/1)>> loss: 0.1936  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.8287  Mult_acc_7: 0.7889  MAE: 0.2279  Corr: 0.9820 
2021-01-28 18:04:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8380  Non0_F1_score: 0.8372  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7458  Corr: 0.7860  Loss: 1.0530 
2021-01-28 18:04:17:INFO:TRAIN-(misa) (3/15/1)>> loss: 0.1652  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8489  Mult_acc_7: 0.8170  MAE: 0.1947  Corr: 0.9866 
2021-01-28 18:04:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8288  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5590  Mult_acc_7: 0.4672  MAE: 0.7165  Corr: 0.7916  Loss: 1.1277 
2021-01-28 18:04:34:INFO:TRAIN-(misa) (4/16/1)>> loss: 0.1479  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9821  Non0_F1_score: 0.9821  Mult_acc_5: 0.8505  Mult_acc_7: 0.8131  MAE: 0.1803  Corr: 0.9885 
2021-01-28 18:04:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8611  Non0_F1_score: 0.8618  Mult_acc_5: 0.5371  Mult_acc_7: 0.4498  MAE: 0.7007  Corr: 0.8004  Loss: 0.9968 
2021-01-28 18:04:51:INFO:TRAIN-(misa) (5/17/1)>> loss: 0.1376  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8637  Mult_acc_7: 0.8326  MAE: 0.1722  Corr: 0.9897 
2021-01-28 18:04:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7177  Corr: 0.7922  Loss: 1.0012 
2021-01-28 18:05:09:INFO:TRAIN-(misa) (6/18/1)>> loss: 0.1324  Has0_acc_2: 0.9751  Has0_F1_score: 0.9750  Non0_acc_2: 0.9927  Non0_F1_score: 0.9927  Mult_acc_5: 0.8544  Mult_acc_7: 0.8248  MAE: 0.1648  Corr: 0.9901 
2021-01-28 18:05:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.4803  Mult_acc_7: 0.3799  MAE: 0.7390  Corr: 0.7881  Loss: 1.0825 
2021-01-28 18:05:26:INFO:TRAIN-(misa) (7/19/1)>> loss: 0.1378  Has0_acc_2: 0.9650  Has0_F1_score: 0.9649  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8505  Mult_acc_7: 0.8123  MAE: 0.1876  Corr: 0.9881 
2021-01-28 18:05:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8327  Non0_acc_2: 0.8611  Non0_F1_score: 0.8606  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7284  Corr: 0.7920  Loss: 1.0117 
2021-01-28 18:05:44:INFO:TRAIN-(misa) (8/20/1)>> loss: 0.1306  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8637  Mult_acc_7: 0.8326  MAE: 0.1792  Corr: 0.9889 
2021-01-28 18:05:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5415  Mult_acc_7: 0.4279  MAE: 0.7225  Corr: 0.7924  Loss: 1.0182 
2021-01-28 18:05:48:INFO:TEST-(misa) >>  Has0_acc_2: 0.8192  Has0_F1_score: 0.8191  Non0_acc_2: 0.8354  Non0_F1_score: 0.8347  Mult_acc_5: 0.4796  Mult_acc_7: 0.4300  MAE: 0.7534  Corr: 0.7886  Loss: 1.0110 
2021-01-28 18:05:48:INFO:Start saving results...
2021-01-28 18:05:48:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:05:48:INFO:########################################misa-(14/50)########################################
2021-01-28 18:05:48:INFO:batch_size:32
2021-01-28 18:05:48:INFO:learning_rate:0.0001
2021-01-28 18:05:48:INFO:hidden_size:64
2021-01-28 18:05:48:INFO:dropout:0.0
2021-01-28 18:05:48:INFO:reverse_grad_weight:0.5
2021-01-28 18:05:48:INFO:diff_weight:0.1
2021-01-28 18:05:48:INFO:sim_weight:0.5
2021-01-28 18:05:48:INFO:sp_weight:0.0
2021-01-28 18:05:48:INFO:recon_weight:0.5
2021-01-28 18:05:48:INFO:grad_clip:-1.0
2021-01-28 18:05:48:INFO:weight_decay:0.002
2021-01-28 18:05:48:INFO:##########################################################################################
2021-01-28 18:05:48:INFO:Start running misa...
2021-01-28 18:05:49:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:05:49:INFO:Let's use 1 GPUs!
2021-01-28 18:05:49:INFO:train samples: (1284,)
2021-01-28 18:05:50:INFO:valid samples: (229,)
2021-01-28 18:05:50:INFO:test samples: (686,)
2021-01-28 18:05:50:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:05:50:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:05:50:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:05:50:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:05:50:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:05:50:INFO:loading file None
2021-01-28 18:05:50:INFO:loading file None
2021-01-28 18:05:50:INFO:loading file None
2021-01-28 18:05:50:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:05:50:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:05:50:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:05:54:INFO:The model has 109943985 trainable parameters
2021-01-28 18:06:06:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.0206  Has0_acc_2: 0.6846  Has0_F1_score: 0.6994  Non0_acc_2: 0.6881  Non0_F1_score: 0.7041  Mult_acc_5: 0.2212  Mult_acc_7: 0.2212  MAE: 1.1725  Corr: 0.4758 
2021-01-28 18:06:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8426  Non0_F1_score: 0.8417  Mult_acc_5: 0.2795  Mult_acc_7: 0.2795  MAE: 0.9933  Corr: 0.7173  Loss: 1.3974 
2021-01-28 18:06:19:INFO:TRAIN-(misa) (1/2/1)>> loss: 1.8143  Has0_acc_2: 0.8372  Has0_F1_score: 0.8366  Non0_acc_2: 0.8562  Non0_F1_score: 0.8560  Mult_acc_5: 0.3917  Mult_acc_7: 0.3762  MAE: 0.7340  Corr: 0.7867 
2021-01-28 18:06:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8328  Non0_acc_2: 0.8611  Non0_F1_score: 0.8608  Mult_acc_5: 0.4279  Mult_acc_7: 0.3624  MAE: 0.8470  Corr: 0.7637  Loss: 1.1421 
2021-01-28 18:06:33:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.2937  Has0_acc_2: 0.8816  Has0_F1_score: 0.8811  Non0_acc_2: 0.9033  Non0_F1_score: 0.9032  Mult_acc_5: 0.5280  Mult_acc_7: 0.4899  MAE: 0.5789  Corr: 0.8684 
2021-01-28 18:06:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8019  Non0_acc_2: 0.8287  Non0_F1_score: 0.8282  Mult_acc_5: 0.4541  Mult_acc_7: 0.3712  MAE: 0.8120  Corr: 0.7672  Loss: 1.0713 
2021-01-28 18:06:47:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.9760  Has0_acc_2: 0.9089  Has0_F1_score: 0.9086  Non0_acc_2: 0.9285  Non0_F1_score: 0.9284  Mult_acc_5: 0.6153  Mult_acc_7: 0.5685  MAE: 0.4634  Corr: 0.9149 
2021-01-28 18:06:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8281  Non0_acc_2: 0.8611  Non0_F1_score: 0.8605  Mult_acc_5: 0.4891  Mult_acc_7: 0.3799  MAE: 0.7893  Corr: 0.7820  Loss: 1.0748 
2021-01-28 18:07:00:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.7237  Has0_acc_2: 0.9330  Has0_F1_score: 0.9329  Non0_acc_2: 0.9504  Non0_F1_score: 0.9505  Mult_acc_5: 0.6900  Mult_acc_7: 0.6386  MAE: 0.3667  Corr: 0.9465 
2021-01-28 18:07:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8109  Non0_acc_2: 0.8380  Non0_F1_score: 0.8377  Mult_acc_5: 0.4847  Mult_acc_7: 0.3974  MAE: 0.7758  Corr: 0.7763  Loss: 0.9995 
2021-01-28 18:07:13:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.5484  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7718  Mult_acc_7: 0.7188  MAE: 0.2951  Corr: 0.9672 
2021-01-28 18:07:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8288  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5066  Mult_acc_7: 0.4017  MAE: 0.7573  Corr: 0.7893  Loss: 1.0670 
2021-01-28 18:07:26:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.4524  Has0_acc_2: 0.9354  Has0_F1_score: 0.9352  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7850  Mult_acc_7: 0.7375  MAE: 0.2757  Corr: 0.9710 
2021-01-28 18:07:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8152  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.7633  Corr: 0.7797  Loss: 1.0926 
2021-01-28 18:07:38:INFO:TRAIN-(misa) (3/8/1)>> loss: 0.3567  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.8061  Mult_acc_7: 0.7586  MAE: 0.2404  Corr: 0.9789 
2021-01-28 18:07:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.4760  Mult_acc_7: 0.3668  MAE: 0.7623  Corr: 0.7819  Loss: 1.0432 
2021-01-28 18:07:50:INFO:TRAIN-(misa) (4/9/1)>> loss: 0.3036  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8084  Mult_acc_7: 0.7687  MAE: 0.2327  Corr: 0.9805 
2021-01-28 18:07:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8470  Non0_acc_2: 0.8657  Non0_F1_score: 0.8663  Mult_acc_5: 0.4978  Mult_acc_7: 0.4017  MAE: 0.7524  Corr: 0.7926  Loss: 1.0747 
2021-01-28 18:08:03:INFO:TRAIN-(misa) (5/10/1)>> loss: 0.2666  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.8162  Mult_acc_7: 0.7741  MAE: 0.2276  Corr: 0.9814 
2021-01-28 18:08:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.7324  Corr: 0.7953  Loss: 1.0208 
2021-01-28 18:08:16:INFO:TRAIN-(misa) (6/11/1)>> loss: 0.2330  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8100  Mult_acc_7: 0.7702  MAE: 0.2215  Corr: 0.9831 
2021-01-28 18:08:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.4716  Mult_acc_7: 0.3668  MAE: 0.7505  Corr: 0.7932  Loss: 1.5360 
2021-01-28 18:08:29:INFO:TRAIN-(misa) (7/12/1)>> loss: 0.2082  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8201  Mult_acc_7: 0.7882  MAE: 0.2121  Corr: 0.9843 
2021-01-28 18:08:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8657  Non0_F1_score: 0.8658  Mult_acc_5: 0.4847  Mult_acc_7: 0.3799  MAE: 0.7298  Corr: 0.7966  Loss: 1.0371 
2021-01-28 18:08:41:INFO:TRAIN-(misa) (8/13/1)>> loss: 0.1783  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8489  Mult_acc_7: 0.8154  MAE: 0.1912  Corr: 0.9871 
2021-01-28 18:08:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8286  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.4891  Mult_acc_7: 0.4017  MAE: 0.7352  Corr: 0.7971  Loss: 1.1103 
2021-01-28 18:08:44:INFO:TEST-(misa) >>  Has0_acc_2: 0.8061  Has0_F1_score: 0.8065  Non0_acc_2: 0.8262  Non0_F1_score: 0.8259  Mult_acc_5: 0.4752  Mult_acc_7: 0.4140  MAE: 0.7823  Corr: 0.7678  Loss: 1.0923 
2021-01-28 18:08:44:INFO:Start saving results...
2021-01-28 18:08:44:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:08:44:INFO:########################################misa-(15/50)########################################
2021-01-28 18:08:44:INFO:batch_size:16
2021-01-28 18:08:44:INFO:learning_rate:0.0005
2021-01-28 18:08:44:INFO:hidden_size:64
2021-01-28 18:08:44:INFO:dropout:0.0
2021-01-28 18:08:44:INFO:reverse_grad_weight:0.5
2021-01-28 18:08:44:INFO:diff_weight:0.3
2021-01-28 18:08:44:INFO:sim_weight:0.8
2021-01-28 18:08:44:INFO:sp_weight:0.0
2021-01-28 18:08:44:INFO:recon_weight:1.0
2021-01-28 18:08:44:INFO:grad_clip:0.8
2021-01-28 18:08:44:INFO:weight_decay:0.002
2021-01-28 18:08:44:INFO:##########################################################################################
2021-01-28 18:08:44:INFO:Start running misa...
2021-01-28 18:08:44:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:08:44:INFO:Let's use 1 GPUs!
2021-01-28 18:08:44:INFO:train samples: (1284,)
2021-01-28 18:08:45:INFO:valid samples: (229,)
2021-01-28 18:08:45:INFO:test samples: (686,)
2021-01-28 18:08:45:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:08:45:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:08:45:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:08:45:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:08:45:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:08:45:INFO:loading file None
2021-01-28 18:08:45:INFO:loading file None
2021-01-28 18:08:45:INFO:loading file None
2021-01-28 18:08:45:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:08:45:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:08:45:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:08:48:INFO:The model has 109943985 trainable parameters
2021-01-28 18:09:04:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.3732  Has0_acc_2: 0.5911  Has0_F1_score: 0.6144  Non0_acc_2: 0.5825  Non0_F1_score: 0.6064  Mult_acc_5: 0.2009  Mult_acc_7: 0.2002  MAE: 1.2830  Corr: 0.1893 
2021-01-28 18:09:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.4056  Corr: 0.1582  Loss: 2.6909 
2021-01-28 18:09:23:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4349  Has0_acc_2: 0.5911  Has0_F1_score: 0.6566  Non0_acc_2: 0.5792  Non0_F1_score: 0.6465  Mult_acc_5: 0.1861  Mult_acc_7: 0.1861  MAE: 1.2973  Corr: 0.1732 
2021-01-28 18:09:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7201  Non0_acc_2: 0.5926  Non0_F1_score: 0.6996  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.3926  Corr: 0.1662  Loss: 2.6275 
2021-01-28 18:09:42:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.2932  Has0_acc_2: 0.6153  Has0_F1_score: 0.6459  Non0_acc_2: 0.6060  Non0_F1_score: 0.6373  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.2671  Corr: 0.2263 
2021-01-28 18:09:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7057  Non0_acc_2: 0.6204  Non0_F1_score: 0.6908  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3916  Corr: 0.1586  Loss: 2.6949 
2021-01-28 18:10:00:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.2237  Has0_acc_2: 0.5958  Has0_F1_score: 0.6138  Non0_acc_2: 0.5873  Non0_F1_score: 0.6058  Mult_acc_5: 0.1970  Mult_acc_7: 0.1970  MAE: 1.2628  Corr: 0.2592 
2021-01-28 18:10:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.1616  Mult_acc_7: 0.1616  MAE: 1.4023  Corr: 0.1783  Loss: 2.6999 
2021-01-28 18:10:17:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.1649  Has0_acc_2: 0.6316  Has0_F1_score: 0.6495  Non0_acc_2: 0.6223  Non0_F1_score: 0.6403  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2268  Corr: 0.3071 
2021-01-28 18:10:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3905  Corr: 0.1974  Loss: 2.6892 
2021-01-28 18:10:35:INFO:TRAIN-(misa) (4/6/1)>> loss: 2.1267  Has0_acc_2: 0.6192  Has0_F1_score: 0.6389  Non0_acc_2: 0.6133  Non0_F1_score: 0.6338  Mult_acc_5: 0.2087  Mult_acc_7: 0.2079  MAE: 1.2250  Corr: 0.3230 
2021-01-28 18:10:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3980  Corr: 0.2239  Loss: 2.7463 
2021-01-28 18:10:52:INFO:TRAIN-(misa) (5/7/1)>> loss: 2.0947  Has0_acc_2: 0.6332  Has0_F1_score: 0.6495  Non0_acc_2: 0.6271  Non0_F1_score: 0.6440  Mult_acc_5: 0.2126  Mult_acc_7: 0.2103  MAE: 1.2153  Corr: 0.3437 
2021-01-28 18:10:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7061  Non0_acc_2: 0.6019  Non0_F1_score: 0.6850  Mult_acc_5: 0.1965  Mult_acc_7: 0.1921  MAE: 1.3704  Corr: 0.1959  Loss: 2.6448 
2021-01-28 18:11:10:INFO:TRAIN-(misa) (6/8/1)>> loss: 2.0230  Has0_acc_2: 0.6464  Has0_F1_score: 0.6544  Non0_acc_2: 0.6385  Non0_F1_score: 0.6465  Mult_acc_5: 0.2079  Mult_acc_7: 0.2056  MAE: 1.1889  Corr: 0.3836 
2021-01-28 18:11:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7201  Non0_acc_2: 0.5926  Non0_F1_score: 0.6996  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3762  Corr: 0.2026  Loss: 2.6530 
2021-01-28 18:11:28:INFO:TRAIN-(misa) (7/9/1)>> loss: 1.9862  Has0_acc_2: 0.6488  Has0_F1_score: 0.6597  Non0_acc_2: 0.6458  Non0_F1_score: 0.6574  Mult_acc_5: 0.2336  Mult_acc_7: 0.2313  MAE: 1.1705  Corr: 0.4070 
2021-01-28 18:11:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.7269  Non0_acc_2: 0.6065  Non0_F1_score: 0.7070  Mult_acc_5: 0.2009  Mult_acc_7: 0.1878  MAE: 1.3923  Corr: 0.1880  Loss: 2.8677 
2021-01-28 18:11:45:INFO:TRAIN-(misa) (8/10/1)>> loss: 1.9552  Has0_acc_2: 0.6503  Has0_F1_score: 0.6597  Non0_acc_2: 0.6458  Non0_F1_score: 0.6556  Mult_acc_5: 0.2212  Mult_acc_7: 0.2173  MAE: 1.1467  Corr: 0.4369 
2021-01-28 18:11:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6535  Non0_acc_2: 0.6204  Non0_F1_score: 0.6467  Mult_acc_5: 0.2271  Mult_acc_7: 0.2227  MAE: 1.3466  Corr: 0.2231  Loss: 2.5644 
2021-01-28 18:12:04:INFO:TRAIN-(misa) (1/11/1)>> loss: 1.9273  Has0_acc_2: 0.6480  Has0_F1_score: 0.6544  Non0_acc_2: 0.6434  Non0_F1_score: 0.6502  Mult_acc_5: 0.2383  Mult_acc_7: 0.2336  MAE: 1.1467  Corr: 0.4386 
2021-01-28 18:12:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7451  Non0_acc_2: 0.5926  Non0_F1_score: 0.7260  Mult_acc_5: 0.2533  Mult_acc_7: 0.2183  MAE: 1.4654  Corr: 0.1994  Loss: 3.5560 
2021-01-28 18:12:21:INFO:TRAIN-(misa) (2/12/1)>> loss: 1.8984  Has0_acc_2: 0.6620  Has0_F1_score: 0.6710  Non0_acc_2: 0.6588  Non0_F1_score: 0.6683  Mult_acc_5: 0.2329  Mult_acc_7: 0.2298  MAE: 1.1333  Corr: 0.4504 
2021-01-28 18:12:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.5502  Has0_F1_score: 0.5468  Non0_acc_2: 0.5648  Non0_F1_score: 0.5630  Mult_acc_5: 0.2314  Mult_acc_7: 0.2314  MAE: 1.4026  Corr: 0.1866  Loss: 2.7369 
2021-01-28 18:12:39:INFO:TRAIN-(misa) (3/13/1)>> loss: 1.8282  Has0_acc_2: 0.6815  Has0_F1_score: 0.6856  Non0_acc_2: 0.6775  Non0_F1_score: 0.6819  Mult_acc_5: 0.2477  Mult_acc_7: 0.2430  MAE: 1.1064  Corr: 0.4852 
2021-01-28 18:12:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6602  Non0_acc_2: 0.6250  Non0_F1_score: 0.6595  Mult_acc_5: 0.2271  Mult_acc_7: 0.2183  MAE: 1.3637  Corr: 0.2017  Loss: 2.7729 
2021-01-28 18:12:56:INFO:TRAIN-(misa) (4/14/1)>> loss: 1.8846  Has0_acc_2: 0.6745  Has0_F1_score: 0.6813  Non0_acc_2: 0.6734  Non0_F1_score: 0.6808  Mult_acc_5: 0.2414  Mult_acc_7: 0.2344  MAE: 1.1198  Corr: 0.4651 
2021-01-28 18:12:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7381  Non0_acc_2: 0.6019  Non0_F1_score: 0.7187  Mult_acc_5: 0.2533  Mult_acc_7: 0.2227  MAE: 1.4424  Corr: 0.2070  Loss: 3.1144 
2021-01-28 18:13:13:INFO:TRAIN-(misa) (5/15/1)>> loss: 1.7675  Has0_acc_2: 0.6807  Has0_F1_score: 0.6865  Non0_acc_2: 0.6791  Non0_F1_score: 0.6854  Mult_acc_5: 0.2632  Mult_acc_7: 0.2570  MAE: 1.0824  Corr: 0.5088 
2021-01-28 18:13:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.6732  Non0_acc_2: 0.6296  Non0_F1_score: 0.6677  Mult_acc_5: 0.2358  Mult_acc_7: 0.2183  MAE: 1.3725  Corr: 0.1985  Loss: 2.8105 
2021-01-28 18:13:31:INFO:TRAIN-(misa) (6/16/1)>> loss: 1.6966  Has0_acc_2: 0.7040  Has0_F1_score: 0.7098  Non0_acc_2: 0.7027  Non0_F1_score: 0.7087  Mult_acc_5: 0.2796  Mult_acc_7: 0.2726  MAE: 1.0542  Corr: 0.5404 
2021-01-28 18:13:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.6823  Non0_acc_2: 0.6204  Non0_F1_score: 0.6718  Mult_acc_5: 0.2533  Mult_acc_7: 0.2227  MAE: 1.3924  Corr: 0.2251  Loss: 2.8669 
2021-01-28 18:13:47:INFO:TRAIN-(misa) (7/17/1)>> loss: 1.7058  Has0_acc_2: 0.7087  Has0_F1_score: 0.7123  Non0_acc_2: 0.7076  Non0_F1_score: 0.7114  Mult_acc_5: 0.2648  Mult_acc_7: 0.2586  MAE: 1.0612  Corr: 0.5285 
2021-01-28 18:13:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6298  Non0_acc_2: 0.6019  Non0_F1_score: 0.6272  Mult_acc_5: 0.2445  Mult_acc_7: 0.2227  MAE: 1.3957  Corr: 0.1851  Loss: 2.9216 
2021-01-28 18:14:05:INFO:TRAIN-(misa) (8/18/1)>> loss: 1.6823  Has0_acc_2: 0.7173  Has0_F1_score: 0.7223  Non0_acc_2: 0.7165  Non0_F1_score: 0.7218  Mult_acc_5: 0.2710  Mult_acc_7: 0.2625  MAE: 1.0530  Corr: 0.5444 
2021-01-28 18:14:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.7042  Non0_acc_2: 0.6111  Non0_F1_score: 0.6833  Mult_acc_5: 0.2707  Mult_acc_7: 0.2402  MAE: 1.4109  Corr: 0.2000  Loss: 3.0074 
2021-01-28 18:14:08:INFO:TEST-(misa) >>  Has0_acc_2: 0.5583  Has0_F1_score: 0.5745  Non0_acc_2: 0.5518  Non0_F1_score: 0.5667  Mult_acc_5: 0.1822  Mult_acc_7: 0.1808  MAE: 1.3938  Corr: 0.2268  Loss: 2.7382 
2021-01-28 18:14:08:INFO:Start saving results...
2021-01-28 18:14:08:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:14:09:INFO:########################################misa-(16/50)########################################
2021-01-28 18:14:09:INFO:batch_size:16
2021-01-28 18:14:09:INFO:learning_rate:0.0005
2021-01-28 18:14:09:INFO:hidden_size:256
2021-01-28 18:14:09:INFO:dropout:0.5
2021-01-28 18:14:09:INFO:reverse_grad_weight:0.8
2021-01-28 18:14:09:INFO:diff_weight:0.5
2021-01-28 18:14:09:INFO:sim_weight:1.0
2021-01-28 18:14:09:INFO:sp_weight:0.0
2021-01-28 18:14:09:INFO:recon_weight:0.5
2021-01-28 18:14:09:INFO:grad_clip:0.8
2021-01-28 18:14:09:INFO:weight_decay:0.0
2021-01-28 18:14:09:INFO:##########################################################################################
2021-01-28 18:14:09:INFO:Start running misa...
2021-01-28 18:14:09:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:14:09:INFO:Let's use 1 GPUs!
2021-01-28 18:14:09:INFO:train samples: (1284,)
2021-01-28 18:14:09:INFO:valid samples: (229,)
2021-01-28 18:14:09:INFO:test samples: (686,)
2021-01-28 18:14:09:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:14:09:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:14:09:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:14:09:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:14:09:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:14:09:INFO:loading file None
2021-01-28 18:14:09:INFO:loading file None
2021-01-28 18:14:09:INFO:loading file None
2021-01-28 18:14:09:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:14:09:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:14:09:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:14:13:INFO:The model has 112685553 trainable parameters
2021-01-28 18:14:30:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.6786  Has0_acc_2: 0.5413  Has0_F1_score: 0.5603  Non0_acc_2: 0.5394  Non0_F1_score: 0.5606  Mult_acc_5: 0.1947  Mult_acc_7: 0.1900  MAE: 1.3855  Corr: 0.0487 
2021-01-28 18:14:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4149  Corr: 0.1305  Loss: 2.6997 
2021-01-28 18:14:49:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5816  Has0_acc_2: 0.5257  Has0_F1_score: 0.5575  Non0_acc_2: 0.5167  Non0_F1_score: 0.5501  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3345  Corr: 0.0482 
2021-01-28 18:14:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.4236  Has0_F1_score: 0.5644  Non0_acc_2: 0.4491  Non0_F1_score: 0.5880  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4389  Corr: 0.1434  Loss: 2.8055 
2021-01-28 18:15:07:INFO:TRAIN-(misa) (2/3/1)>> loss: 2.5158  Has0_acc_2: 0.5467  Has0_F1_score: 0.5619  Non0_acc_2: 0.5386  Non0_F1_score: 0.5546  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3297  Corr: 0.0173 
2021-01-28 18:15:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4165  Corr: 0.1589  Loss: 2.7566 
2021-01-28 18:15:24:INFO:TRAIN-(misa) (3/4/1)>> loss: 2.4344  Has0_acc_2: 0.5327  Has0_F1_score: 0.6096  Non0_acc_2: 0.5199  Non0_F1_score: 0.5995  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.3262  Corr: -0.0026 
2021-01-28 18:15:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4128  Corr: 0.1489  Loss: 2.7010 
2021-01-28 18:15:42:INFO:TRAIN-(misa) (4/5/1)>> loss: 2.4472  Has0_acc_2: 0.5405  Has0_F1_score: 0.6277  Non0_acc_2: 0.5248  Non0_F1_score: 0.6141  Mult_acc_5: 0.1877  Mult_acc_7: 0.1877  MAE: 1.3344  Corr: -0.0450 
2021-01-28 18:15:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4208  Corr: 0.1538  Loss: 2.7358 
2021-01-28 18:16:00:INFO:TRAIN-(misa) (5/6/1)>> loss: 2.3879  Has0_acc_2: 0.5662  Has0_F1_score: 0.6994  Non0_acc_2: 0.5475  Non0_F1_score: 0.6831  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3246  Corr: -0.0269 
2021-01-28 18:16:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4228  Corr: 0.1364  Loss: 2.8284 
2021-01-28 18:16:17:INFO:TRAIN-(misa) (6/7/1)>> loss: 2.3569  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3226  Corr: -0.0093 
2021-01-28 18:16:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4200  Corr: 0.1335  Loss: 2.7740 
2021-01-28 18:16:34:INFO:TRAIN-(misa) (7/8/1)>> loss: 2.3381  Has0_acc_2: 0.5646  Has0_F1_score: 0.7008  Non0_acc_2: 0.5475  Non0_F1_score: 0.6870  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3188  Corr: 0.0226 
2021-01-28 18:16:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4191  Corr: 0.1421  Loss: 2.7889 
2021-01-28 18:16:51:INFO:TRAIN-(misa) (8/9/1)>> loss: 2.3529  Has0_acc_2: 0.5592  Has0_F1_score: 0.6340  Non0_acc_2: 0.5467  Non0_F1_score: 0.6239  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3215  Corr: 0.0101 
2021-01-28 18:16:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4216  Corr: 0.1103  Loss: 2.7060 
2021-01-28 18:16:55:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4746  Corr: 0.1375  Loss: 2.8780 
2021-01-28 18:16:55:INFO:Start saving results...
2021-01-28 18:16:55:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:16:55:INFO:########################################misa-(17/50)########################################
2021-01-28 18:16:55:INFO:batch_size:64
2021-01-28 18:16:55:INFO:learning_rate:0.0001
2021-01-28 18:16:55:INFO:hidden_size:128
2021-01-28 18:16:55:INFO:dropout:0.5
2021-01-28 18:16:55:INFO:reverse_grad_weight:0.5
2021-01-28 18:16:55:INFO:diff_weight:0.5
2021-01-28 18:16:55:INFO:sim_weight:0.5
2021-01-28 18:16:55:INFO:sp_weight:0.0
2021-01-28 18:16:55:INFO:recon_weight:0.5
2021-01-28 18:16:55:INFO:grad_clip:0.8
2021-01-28 18:16:55:INFO:weight_decay:0.002
2021-01-28 18:16:55:INFO:##########################################################################################
2021-01-28 18:16:55:INFO:Start running misa...
2021-01-28 18:16:55:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:16:55:INFO:Let's use 1 GPUs!
2021-01-28 18:16:55:INFO:train samples: (1284,)
2021-01-28 18:16:56:INFO:valid samples: (229,)
2021-01-28 18:16:56:INFO:test samples: (686,)
2021-01-28 18:16:56:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:16:56:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:16:56:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:16:56:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:16:56:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:16:56:INFO:loading file None
2021-01-28 18:16:56:INFO:loading file None
2021-01-28 18:16:56:INFO:loading file None
2021-01-28 18:16:56:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:16:56:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:16:56:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:16:59:INFO:The model has 110620273 trainable parameters
2021-01-28 18:17:08:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.6069  Has0_acc_2: 0.5763  Has0_F1_score: 0.5984  Non0_acc_2: 0.5678  Non0_F1_score: 0.5907  Mult_acc_5: 0.1994  Mult_acc_7: 0.1994  MAE: 1.2898  Corr: 0.1426 
2021-01-28 18:17:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5939  Has0_F1_score: 0.7343  Non0_acc_2: 0.5694  Non0_F1_score: 0.7143  Mult_acc_5: 0.2707  Mult_acc_7: 0.2707  MAE: 1.2696  Corr: 0.6102  Loss: 2.2994 
2021-01-28 18:17:19:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5780  Has0_acc_2: 0.7492  Has0_F1_score: 0.7518  Non0_acc_2: 0.7587  Non0_F1_score: 0.7620  Mult_acc_5: 0.2757  Mult_acc_7: 0.2734  MAE: 0.9853  Corr: 0.6552 
2021-01-28 18:17:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.4105  Mult_acc_7: 0.3406  MAE: 0.9004  Corr: 0.7260  Loss: 1.3350 
2021-01-28 18:17:31:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.7954  Has0_acc_2: 0.8598  Has0_F1_score: 0.8592  Non0_acc_2: 0.8790  Non0_F1_score: 0.8787  Mult_acc_5: 0.4548  Mult_acc_7: 0.4260  MAE: 0.6791  Corr: 0.8177 
2021-01-28 18:17:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8060  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.4279  Mult_acc_7: 0.3450  MAE: 0.8291  Corr: 0.7706  Loss: 1.1494 
2021-01-28 18:17:42:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.3431  Has0_acc_2: 0.8824  Has0_F1_score: 0.8821  Non0_acc_2: 0.9001  Non0_F1_score: 0.9001  Mult_acc_5: 0.5530  Mult_acc_7: 0.5093  MAE: 0.5449  Corr: 0.8877 
2021-01-28 18:17:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8030  Non0_acc_2: 0.8241  Non0_F1_score: 0.8246  Mult_acc_5: 0.4629  Mult_acc_7: 0.3799  MAE: 0.8040  Corr: 0.7566  Loss: 1.2330 
2021-01-28 18:17:52:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.0362  Has0_acc_2: 0.9073  Has0_F1_score: 0.9071  Non0_acc_2: 0.9285  Non0_F1_score: 0.9285  Mult_acc_5: 0.5981  Mult_acc_7: 0.5491  MAE: 0.4604  Corr: 0.9205 
2021-01-28 18:17:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8067  Non0_acc_2: 0.8287  Non0_F1_score: 0.8286  Mult_acc_5: 0.4716  Mult_acc_7: 0.3799  MAE: 0.7807  Corr: 0.7641  Loss: 1.1520 
2021-01-28 18:18:02:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.7981  Has0_acc_2: 0.9174  Has0_F1_score: 0.9172  Non0_acc_2: 0.9366  Non0_F1_score: 0.9366  Mult_acc_5: 0.6776  Mult_acc_7: 0.6160  MAE: 0.3947  Corr: 0.9439 
2021-01-28 18:18:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8287  Non0_F1_score: 0.8288  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.7687  Corr: 0.7655  Loss: 1.1721 
2021-01-28 18:18:13:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.7039  Has0_acc_2: 0.9393  Has0_F1_score: 0.9392  Non0_acc_2: 0.9561  Non0_F1_score: 0.9562  Mult_acc_5: 0.6916  Mult_acc_7: 0.6355  MAE: 0.3662  Corr: 0.9512 
2021-01-28 18:18:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7845  Corr: 0.7685  Loss: 1.2685 
2021-01-28 18:18:23:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.5770  Has0_acc_2: 0.9315  Has0_F1_score: 0.9313  Non0_acc_2: 0.9456  Non0_F1_score: 0.9456  Mult_acc_5: 0.7087  Mult_acc_7: 0.6519  MAE: 0.3508  Corr: 0.9570 
2021-01-28 18:18:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8193  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.4585  Mult_acc_7: 0.3668  MAE: 0.8017  Corr: 0.7645  Loss: 1.1887 
2021-01-28 18:18:34:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4564  Has0_acc_2: 0.9361  Has0_F1_score: 0.9360  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7274  Mult_acc_7: 0.6721  MAE: 0.3276  Corr: 0.9629 
2021-01-28 18:18:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8022  Non0_acc_2: 0.8241  Non0_F1_score: 0.8238  Mult_acc_5: 0.5371  Mult_acc_7: 0.4367  MAE: 0.7419  Corr: 0.7773  Loss: 1.0899 
2021-01-28 18:18:45:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.4245  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9456  Non0_F1_score: 0.9456  Mult_acc_5: 0.7251  Mult_acc_7: 0.6760  MAE: 0.3399  Corr: 0.9582 
2021-01-28 18:18:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8268  Non0_acc_2: 0.8287  Non0_F1_score: 0.8305  Mult_acc_5: 0.5022  Mult_acc_7: 0.3886  MAE: 0.8334  Corr: 0.7779  Loss: 1.2956 
2021-01-28 18:18:56:INFO:TRAIN-(misa) (2/11/1)>> loss: 0.4044  Has0_acc_2: 0.9283  Has0_F1_score: 0.9283  Non0_acc_2: 0.9464  Non0_F1_score: 0.9465  Mult_acc_5: 0.7118  Mult_acc_7: 0.6628  MAE: 0.3507  Corr: 0.9576 
2021-01-28 18:18:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8160  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.4803  Mult_acc_7: 0.3755  MAE: 0.7878  Corr: 0.7736  Loss: 1.1419 
2021-01-28 18:19:06:INFO:TRAIN-(misa) (3/12/1)>> loss: 0.3581  Has0_acc_2: 0.9330  Has0_F1_score: 0.9329  Non0_acc_2: 0.9488  Non0_F1_score: 0.9489  Mult_acc_5: 0.7578  Mult_acc_7: 0.7040  MAE: 0.3143  Corr: 0.9639 
2021-01-28 18:19:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7985  Non0_acc_2: 0.8194  Non0_F1_score: 0.8199  Mult_acc_5: 0.4978  Mult_acc_7: 0.4017  MAE: 0.7483  Corr: 0.7841  Loss: 1.1334 
2021-01-28 18:19:16:INFO:TRAIN-(misa) (4/13/1)>> loss: 0.3103  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9602  Non0_F1_score: 0.9602  Mult_acc_5: 0.7780  Mult_acc_7: 0.7313  MAE: 0.2918  Corr: 0.9707 
2021-01-28 18:19:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8065  Non0_acc_2: 0.8287  Non0_F1_score: 0.8284  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7474  Corr: 0.7855  Loss: 1.0574 
2021-01-28 18:19:28:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2896  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7749  Mult_acc_7: 0.7274  MAE: 0.2771  Corr: 0.9730 
2021-01-28 18:19:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8132  Non0_acc_2: 0.8287  Non0_F1_score: 0.8305  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7852  Corr: 0.7852  Loss: 1.1546 
2021-01-28 18:19:38:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2757  Has0_acc_2: 0.9548  Has0_F1_score: 0.9548  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7710  Mult_acc_7: 0.7173  MAE: 0.2839  Corr: 0.9719 
2021-01-28 18:19:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.4760  Mult_acc_7: 0.3843  MAE: 0.7474  Corr: 0.7846  Loss: 1.0847 
2021-01-28 18:19:49:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2800  Has0_acc_2: 0.9346  Has0_F1_score: 0.9344  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7445  Mult_acc_7: 0.6846  MAE: 0.3001  Corr: 0.9685 
2021-01-28 18:19:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8287  Non0_F1_score: 0.8291  Mult_acc_5: 0.5284  Mult_acc_7: 0.4454  MAE: 0.7252  Corr: 0.7889  Loss: 1.0382 
2021-01-28 18:20:00:INFO:TRAIN-(misa) (1/17/1)>> loss: 0.2412  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.7780  Mult_acc_7: 0.7305  MAE: 0.2637  Corr: 0.9759 
2021-01-28 18:20:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8215  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7561  Corr: 0.7882  Loss: 1.0902 
2021-01-28 18:20:11:INFO:TRAIN-(misa) (2/18/1)>> loss: 0.2331  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9602  Non0_F1_score: 0.9602  Mult_acc_5: 0.7780  Mult_acc_7: 0.7321  MAE: 0.2751  Corr: 0.9740 
2021-01-28 18:20:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8128  Non0_acc_2: 0.8287  Non0_F1_score: 0.8301  Mult_acc_5: 0.4847  Mult_acc_7: 0.3799  MAE: 0.7664  Corr: 0.7904  Loss: 1.0967 
2021-01-28 18:20:21:INFO:TRAIN-(misa) (3/19/1)>> loss: 0.2248  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7913  Mult_acc_7: 0.7360  MAE: 0.2687  Corr: 0.9753 
2021-01-28 18:20:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8177  Non0_acc_2: 0.8333  Non0_F1_score: 0.8353  Mult_acc_5: 0.4934  Mult_acc_7: 0.3930  MAE: 0.7634  Corr: 0.7914  Loss: 1.1144 
2021-01-28 18:20:32:INFO:TRAIN-(misa) (4/20/1)>> loss: 0.2165  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.7593  Mult_acc_7: 0.7165  MAE: 0.2686  Corr: 0.9757 
2021-01-28 18:20:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.5066  Mult_acc_7: 0.3930  MAE: 0.7461  Corr: 0.7879  Loss: 1.1663 
2021-01-28 18:20:42:INFO:TRAIN-(misa) (5/21/1)>> loss: 0.2009  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.8022  Mult_acc_7: 0.7656  MAE: 0.2486  Corr: 0.9781 
2021-01-28 18:20:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8121  Non0_acc_2: 0.8333  Non0_F1_score: 0.8342  Mult_acc_5: 0.5284  Mult_acc_7: 0.4323  MAE: 0.7279  Corr: 0.7888  Loss: 1.0725 
2021-01-28 18:20:52:INFO:TRAIN-(misa) (6/22/1)>> loss: 0.1809  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8123  Mult_acc_7: 0.7749  MAE: 0.2353  Corr: 0.9810 
2021-01-28 18:20:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8062  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7346  Corr: 0.7841  Loss: 1.0944 
2021-01-28 18:21:02:INFO:TRAIN-(misa) (7/23/1)>> loss: 0.2214  Has0_acc_2: 0.9361  Has0_F1_score: 0.9359  Non0_acc_2: 0.9578  Non0_F1_score: 0.9577  Mult_acc_5: 0.7601  Mult_acc_7: 0.7064  MAE: 0.2934  Corr: 0.9707 
2021-01-28 18:21:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8160  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7292  Corr: 0.7899  Loss: 1.0192 
2021-01-28 18:21:14:INFO:TRAIN-(misa) (1/24/1)>> loss: 0.1851  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8045  Mult_acc_7: 0.7593  MAE: 0.2468  Corr: 0.9783 
2021-01-28 18:21:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8112  Non0_acc_2: 0.8333  Non0_F1_score: 0.8333  Mult_acc_5: 0.4934  Mult_acc_7: 0.3886  MAE: 0.7444  Corr: 0.7876  Loss: 1.1323 
2021-01-28 18:21:24:INFO:TRAIN-(misa) (2/25/1)>> loss: 0.1705  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8154  Mult_acc_7: 0.7679  MAE: 0.2299  Corr: 0.9816 
2021-01-28 18:21:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7443  Corr: 0.7881  Loss: 1.0685 
2021-01-28 18:21:34:INFO:TRAIN-(misa) (3/26/1)>> loss: 0.1628  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8154  Mult_acc_7: 0.7695  MAE: 0.2331  Corr: 0.9816 
2021-01-28 18:21:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5109  Mult_acc_7: 0.4061  MAE: 0.7529  Corr: 0.7834  Loss: 1.1302 
2021-01-28 18:21:44:INFO:TRAIN-(misa) (4/27/1)>> loss: 0.1672  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.7936  Mult_acc_7: 0.7477  MAE: 0.2418  Corr: 0.9796 
2021-01-28 18:21:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8082  Non0_acc_2: 0.8241  Non0_F1_score: 0.8253  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7488  Corr: 0.7921  Loss: 1.0665 
2021-01-28 18:21:54:INFO:TRAIN-(misa) (5/28/1)>> loss: 0.1537  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8107  Mult_acc_7: 0.7695  MAE: 0.2294  Corr: 0.9819 
2021-01-28 18:21:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.8241  Non0_F1_score: 0.8250  Mult_acc_5: 0.5240  Mult_acc_7: 0.4279  MAE: 0.7401  Corr: 0.7916  Loss: 1.0435 
2021-01-28 18:22:05:INFO:TRAIN-(misa) (6/29/1)>> loss: 0.1570  Has0_acc_2: 0.9572  Has0_F1_score: 0.9570  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8201  Mult_acc_7: 0.7765  MAE: 0.2372  Corr: 0.9808 
2021-01-28 18:22:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5240  Mult_acc_7: 0.4323  MAE: 0.7329  Corr: 0.7884  Loss: 1.0463 
2021-01-28 18:22:14:INFO:TRAIN-(misa) (7/30/1)>> loss: 0.1388  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8326  Mult_acc_7: 0.7913  MAE: 0.2077  Corr: 0.9851 
2021-01-28 18:22:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8241  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7372  Corr: 0.7882  Loss: 1.1126 
2021-01-28 18:22:25:INFO:TRAIN-(misa) (8/31/1)>> loss: 0.1391  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9773  Non0_F1_score: 0.9772  Mult_acc_5: 0.8209  Mult_acc_7: 0.7835  MAE: 0.2139  Corr: 0.9839 
2021-01-28 18:22:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.4978  Mult_acc_7: 0.3974  MAE: 0.7375  Corr: 0.7919  Loss: 1.0588 
2021-01-28 18:22:27:INFO:TEST-(misa) >>  Has0_acc_2: 0.8192  Has0_F1_score: 0.8194  Non0_acc_2: 0.8369  Non0_F1_score: 0.8365  Mult_acc_5: 0.4913  Mult_acc_7: 0.4344  MAE: 0.7434  Corr: 0.7881  Loss: 1.0076 
2021-01-28 18:22:27:INFO:Start saving results...
2021-01-28 18:22:27:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:22:27:INFO:########################################misa-(18/50)########################################
2021-01-28 18:22:27:INFO:batch_size:64
2021-01-28 18:22:27:INFO:learning_rate:0.001
2021-01-28 18:22:27:INFO:hidden_size:256
2021-01-28 18:22:27:INFO:dropout:0.5
2021-01-28 18:22:27:INFO:reverse_grad_weight:0.5
2021-01-28 18:22:27:INFO:diff_weight:0.5
2021-01-28 18:22:27:INFO:sim_weight:0.5
2021-01-28 18:22:27:INFO:sp_weight:1.0
2021-01-28 18:22:27:INFO:recon_weight:1.0
2021-01-28 18:22:27:INFO:grad_clip:-1.0
2021-01-28 18:22:27:INFO:weight_decay:0.002
2021-01-28 18:22:27:INFO:##########################################################################################
2021-01-28 18:22:27:INFO:Start running misa...
2021-01-28 18:22:27:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:22:27:INFO:Let's use 1 GPUs!
2021-01-28 18:22:27:INFO:train samples: (1284,)
2021-01-28 18:22:28:INFO:valid samples: (229,)
2021-01-28 18:22:28:INFO:test samples: (686,)
2021-01-28 18:22:28:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:22:28:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:22:28:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:22:28:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:22:28:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:22:28:INFO:loading file None
2021-01-28 18:22:28:INFO:loading file None
2021-01-28 18:22:28:INFO:loading file None
2021-01-28 18:22:28:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:22:28:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:22:28:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:22:31:INFO:The model has 112685553 trainable parameters
2021-01-28 18:22:41:INFO:TRAIN-(misa) (1/1/1)>> loss: 6.7913  Has0_acc_2: 0.5093  Has0_F1_score: 0.5134  Non0_acc_2: 0.5028  Non0_F1_score: 0.5079  Mult_acc_5: 0.2103  Mult_acc_7: 0.1854  MAE: 1.8154  Corr: -0.0464 
2021-01-28 18:22:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.1397  Mult_acc_7: 0.1397  MAE: 1.6425  Corr: 0.0938  Loss: 3.6908 
2021-01-28 18:22:52:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.2796  Has0_acc_2: 0.4938  Has0_F1_score: 0.4914  Non0_acc_2: 0.4955  Non0_F1_score: 0.4943  Mult_acc_5: 0.1893  Mult_acc_7: 0.1877  MAE: 1.4067  Corr: 0.0196 
2021-01-28 18:22:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.5038  Corr: 0.0936  Loss: 3.0320 
2021-01-28 18:23:04:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.6565  Has0_acc_2: 0.5296  Has0_F1_score: 0.5847  Non0_acc_2: 0.5158  Non0_F1_score: 0.5724  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3507  Corr: -0.0261 
2021-01-28 18:23:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4345  Corr: 0.0955  Loss: 2.8313 
2021-01-28 18:23:15:INFO:TRAIN-(misa) (1/4/1)>> loss: 2.4855  Has0_acc_2: 0.5436  Has0_F1_score: 0.5566  Non0_acc_2: 0.5345  Non0_F1_score: 0.5481  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3224  Corr: 0.0273 
2021-01-28 18:23:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4157  Corr: 0.1057  Loss: 2.7054 
2021-01-28 18:23:27:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.4172  Has0_acc_2: 0.5646  Has0_F1_score: 0.6947  Non0_acc_2: 0.5475  Non0_F1_score: 0.6806  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3228  Corr: 0.0039 
2021-01-28 18:23:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4240  Corr: 0.1273  Loss: 2.7513 
2021-01-28 18:23:37:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3616  Has0_acc_2: 0.5670  Has0_F1_score: 0.7068  Non0_acc_2: 0.5491  Non0_F1_score: 0.6920  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3221  Corr: -0.0114 
2021-01-28 18:23:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4161  Corr: 0.1401  Loss: 2.6972 
2021-01-28 18:23:48:INFO:TRAIN-(misa) (1/7/1)>> loss: 2.3098  Has0_acc_2: 0.5662  Has0_F1_score: 0.7082  Non0_acc_2: 0.5475  Non0_F1_score: 0.6922  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3217  Corr: -0.0148 
2021-01-28 18:23:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4209  Corr: 0.1723  Loss: 2.7053 
2021-01-28 18:23:58:INFO:TRAIN-(misa) (2/8/1)>> loss: 2.2743  Has0_acc_2: 0.5701  Has0_F1_score: 0.7234  Non0_acc_2: 0.5516  Non0_F1_score: 0.7081  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3212  Corr: -0.0270 
2021-01-28 18:23:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4155  Corr: 0.1396  Loss: 2.6848 
2021-01-28 18:24:10:INFO:TRAIN-(misa) (1/9/1)>> loss: 2.3078  Has0_acc_2: 0.5709  Has0_F1_score: 0.7260  Non0_acc_2: 0.5524  Non0_F1_score: 0.7108  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3203  Corr: -0.0143 
2021-01-28 18:24:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4253  Corr: 0.1961  Loss: 2.7631 
2021-01-28 18:24:20:INFO:TRAIN-(misa) (2/10/1)>> loss: 2.3338  Has0_acc_2: 0.5646  Has0_F1_score: 0.7137  Non0_acc_2: 0.5467  Non0_F1_score: 0.6992  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3199  Corr: 0.0147 
2021-01-28 18:24:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4184  Corr: 0.1819  Loss: 2.6984 
2021-01-28 18:24:29:INFO:TRAIN-(misa) (3/11/1)>> loss: 2.4611  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3218  Corr: -0.0301 
2021-01-28 18:24:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4192  Corr: 0.1615  Loss: 2.7704 
2021-01-28 18:24:40:INFO:TRAIN-(misa) (4/12/1)>> loss: 2.3465  Has0_acc_2: 0.5717  Has0_F1_score: 0.7258  Non0_acc_2: 0.5532  Non0_F1_score: 0.7106  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3227  Corr: -0.0410 
2021-01-28 18:24:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4221  Corr: 0.1554  Loss: 2.6840 
2021-01-28 18:24:51:INFO:TRAIN-(misa) (1/13/1)>> loss: 2.2543  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3210  Corr: 0.0007 
2021-01-28 18:24:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4185  Corr: 0.1623  Loss: 2.7247 
2021-01-28 18:25:01:INFO:TRAIN-(misa) (2/14/1)>> loss: 2.2682  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3181  Corr: 0.0114 
2021-01-28 18:25:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4203  Corr: 0.1799  Loss: 2.6578 
2021-01-28 18:25:13:INFO:TRAIN-(misa) (1/15/1)>> loss: 2.2381  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3223  Corr: -0.0375 
2021-01-28 18:25:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4205  Corr: 0.1773  Loss: 2.8093 
2021-01-28 18:25:23:INFO:TRAIN-(misa) (2/16/1)>> loss: 2.2528  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3168  Corr: 0.0067 
2021-01-28 18:25:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4179  Corr: 0.1775  Loss: 2.6783 
2021-01-28 18:25:33:INFO:TRAIN-(misa) (3/17/1)>> loss: 2.3078  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3195  Corr: 0.0004 
2021-01-28 18:25:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4193  Corr: 0.1755  Loss: 2.7136 
2021-01-28 18:25:43:INFO:TRAIN-(misa) (4/18/1)>> loss: 2.3568  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3214  Corr: -0.0217 
2021-01-28 18:25:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4196  Corr: 0.1281  Loss: 2.7587 
2021-01-28 18:25:53:INFO:TRAIN-(misa) (5/19/1)>> loss: 2.2906  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3188  Corr: 0.0134 
2021-01-28 18:25:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4193  Corr: 0.1306  Loss: 2.7654 
2021-01-28 18:26:03:INFO:TRAIN-(misa) (6/20/1)>> loss: 2.4256  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3206  Corr: -0.0112 
2021-01-28 18:26:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4191  Corr: 0.1499  Loss: 2.6582 
2021-01-28 18:26:13:INFO:TRAIN-(misa) (7/21/1)>> loss: 2.3632  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3213  Corr: -0.0434 
2021-01-28 18:26:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4204  Corr: 0.1481  Loss: 2.7453 
2021-01-28 18:26:23:INFO:TRAIN-(misa) (8/22/1)>> loss: 2.3150  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3187  Corr: 0.0208 
2021-01-28 18:26:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4181  Corr: 0.1455  Loss: 2.7175 
2021-01-28 18:26:26:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4566  Corr: 0.0838  Loss: 2.8011 
2021-01-28 18:26:26:INFO:Start saving results...
2021-01-28 18:26:26:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:26:26:INFO:########################################misa-(19/50)########################################
2021-01-28 18:26:26:INFO:batch_size:32
2021-01-28 18:26:26:INFO:learning_rate:0.0005
2021-01-28 18:26:26:INFO:hidden_size:128
2021-01-28 18:26:26:INFO:dropout:0.0
2021-01-28 18:26:26:INFO:reverse_grad_weight:1.0
2021-01-28 18:26:26:INFO:diff_weight:0.1
2021-01-28 18:26:26:INFO:sim_weight:1.0
2021-01-28 18:26:26:INFO:sp_weight:1.0
2021-01-28 18:26:26:INFO:recon_weight:1.0
2021-01-28 18:26:26:INFO:grad_clip:0.8
2021-01-28 18:26:26:INFO:weight_decay:0.002
2021-01-28 18:26:26:INFO:##########################################################################################
2021-01-28 18:26:26:INFO:Start running misa...
2021-01-28 18:26:26:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:26:26:INFO:Let's use 1 GPUs!
2021-01-28 18:26:26:INFO:train samples: (1284,)
2021-01-28 18:26:27:INFO:valid samples: (229,)
2021-01-28 18:26:27:INFO:test samples: (686,)
2021-01-28 18:26:27:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:26:27:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:26:27:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:26:27:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:26:27:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:26:27:INFO:loading file None
2021-01-28 18:26:27:INFO:loading file None
2021-01-28 18:26:27:INFO:loading file None
2021-01-28 18:26:27:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:26:27:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:26:27:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:26:30:INFO:The model has 110620273 trainable parameters
2021-01-28 18:26:42:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.0982  Has0_acc_2: 0.5358  Has0_F1_score: 0.5743  Non0_acc_2: 0.5232  Non0_F1_score: 0.5626  Mult_acc_5: 0.1807  Mult_acc_7: 0.1807  MAE: 1.3499  Corr: -0.0090 
2021-01-28 18:26:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.4111  Corr: 0.1191  Loss: 2.7058 
2021-01-28 18:26:55:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.6233  Has0_acc_2: 0.5654  Has0_F1_score: 0.6277  Non0_acc_2: 0.5548  Non0_F1_score: 0.6194  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3027  Corr: 0.1220 
2021-01-28 18:26:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.4042  Corr: 0.1351  Loss: 2.5506 
2021-01-28 18:27:10:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.3992  Has0_acc_2: 0.6160  Has0_F1_score: 0.6477  Non0_acc_2: 0.6044  Non0_F1_score: 0.6363  Mult_acc_5: 0.1854  Mult_acc_7: 0.1854  MAE: 1.2772  Corr: 0.2150 
2021-01-28 18:27:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6423  Non0_acc_2: 0.6019  Non0_F1_score: 0.6295  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.4039  Corr: 0.1425  Loss: 2.7004 
2021-01-28 18:27:22:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3482  Has0_acc_2: 0.6075  Has0_F1_score: 0.6283  Non0_acc_2: 0.6011  Non0_F1_score: 0.6228  Mult_acc_5: 0.1846  Mult_acc_7: 0.1846  MAE: 1.2660  Corr: 0.2299 
2021-01-28 18:27:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7465  Non0_acc_2: 0.5833  Non0_F1_score: 0.7273  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.4021  Corr: 0.1772  Loss: 2.8229 
2021-01-28 18:27:35:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.2875  Has0_acc_2: 0.6059  Has0_F1_score: 0.6292  Non0_acc_2: 0.6019  Non0_F1_score: 0.6266  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.2604  Corr: 0.2506 
2021-01-28 18:27:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7329  Non0_acc_2: 0.5787  Non0_F1_score: 0.7129  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3910  Corr: 0.1811  Loss: 2.5099 
2021-01-28 18:27:49:INFO:TRAIN-(misa) (1/6/1)>> loss: 2.1537  Has0_acc_2: 0.6269  Has0_F1_score: 0.6482  Non0_acc_2: 0.6182  Non0_F1_score: 0.6398  Mult_acc_5: 0.2134  Mult_acc_7: 0.2134  MAE: 1.2260  Corr: 0.3226 
2021-01-28 18:27:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7465  Non0_acc_2: 0.5833  Non0_F1_score: 0.7273  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.3938  Corr: 0.2124  Loss: 2.7790 
2021-01-28 18:28:02:INFO:TRAIN-(misa) (2/7/1)>> loss: 2.2116  Has0_acc_2: 0.6129  Has0_F1_score: 0.6333  Non0_acc_2: 0.6044  Non0_F1_score: 0.6252  Mult_acc_5: 0.2040  Mult_acc_7: 0.2033  MAE: 1.2447  Corr: 0.2849 
2021-01-28 18:28:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7300  Non0_acc_2: 0.6250  Non0_F1_score: 0.7105  Mult_acc_5: 0.2052  Mult_acc_7: 0.1921  MAE: 1.3808  Corr: 0.2148  Loss: 2.7920 
2021-01-28 18:28:15:INFO:TRAIN-(misa) (3/8/1)>> loss: 2.1917  Has0_acc_2: 0.6005  Has0_F1_score: 0.6107  Non0_acc_2: 0.5979  Non0_F1_score: 0.6091  Mult_acc_5: 0.2103  Mult_acc_7: 0.2103  MAE: 1.2394  Corr: 0.2893 
2021-01-28 18:28:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4094  Corr: 0.2301  Loss: 2.6866 
2021-01-28 18:28:27:INFO:TRAIN-(misa) (4/9/1)>> loss: 2.1731  Has0_acc_2: 0.6199  Has0_F1_score: 0.6445  Non0_acc_2: 0.6109  Non0_F1_score: 0.6359  Mult_acc_5: 0.1893  Mult_acc_7: 0.1885  MAE: 1.2273  Corr: 0.3216 
2021-01-28 18:28:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7322  Non0_acc_2: 0.5880  Non0_F1_score: 0.7123  Mult_acc_5: 0.1790  Mult_acc_7: 0.1659  MAE: 1.3903  Corr: 0.2243  Loss: 2.7177 
2021-01-28 18:28:40:INFO:TRAIN-(misa) (5/10/1)>> loss: 2.1543  Has0_acc_2: 0.6363  Has0_F1_score: 0.6545  Non0_acc_2: 0.6320  Non0_F1_score: 0.6510  Mult_acc_5: 0.1986  Mult_acc_7: 0.1963  MAE: 1.2115  Corr: 0.3459 
2021-01-28 18:28:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.6418  Non0_acc_2: 0.6019  Non0_F1_score: 0.6344  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3624  Corr: 0.2289  Loss: 2.6427 
2021-01-28 18:28:53:INFO:TRAIN-(misa) (6/11/1)>> loss: 2.0306  Has0_acc_2: 0.6472  Has0_F1_score: 0.6598  Non0_acc_2: 0.6426  Non0_F1_score: 0.6557  Mult_acc_5: 0.2173  Mult_acc_7: 0.2134  MAE: 1.1756  Corr: 0.4022 
2021-01-28 18:28:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.5561  Non0_acc_2: 0.5648  Non0_F1_score: 0.5791  Mult_acc_5: 0.2358  Mult_acc_7: 0.2358  MAE: 1.4240  Corr: 0.2175  Loss: 2.8244 
2021-01-28 18:29:05:INFO:TRAIN-(misa) (7/12/1)>> loss: 2.1599  Has0_acc_2: 0.6285  Has0_F1_score: 0.6343  Non0_acc_2: 0.6263  Non0_F1_score: 0.6328  Mult_acc_5: 0.2072  Mult_acc_7: 0.2056  MAE: 1.2174  Corr: 0.3316 
2021-01-28 18:29:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.7085  Non0_acc_2: 0.6157  Non0_F1_score: 0.6937  Mult_acc_5: 0.1965  Mult_acc_7: 0.1921  MAE: 1.3650  Corr: 0.2279  Loss: 2.6126 
2021-01-28 18:29:18:INFO:TRAIN-(misa) (8/13/1)>> loss: 1.9334  Has0_acc_2: 0.6636  Has0_F1_score: 0.6735  Non0_acc_2: 0.6580  Non0_F1_score: 0.6682  Mult_acc_5: 0.2204  Mult_acc_7: 0.2173  MAE: 1.1568  Corr: 0.4340 
2021-01-28 18:29:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6531  Non0_acc_2: 0.5972  Non0_F1_score: 0.6465  Mult_acc_5: 0.2402  Mult_acc_7: 0.2140  MAE: 1.3672  Corr: 0.2280  Loss: 2.9631 
2021-01-28 18:29:21:INFO:TEST-(misa) >>  Has0_acc_2: 0.4738  Has0_F1_score: 0.5802  Non0_acc_2: 0.4527  Non0_F1_score: 0.5588  Mult_acc_5: 0.1501  Mult_acc_7: 0.1501  MAE: 1.5022  Corr: 0.1644  Loss: 3.1095 
2021-01-28 18:29:21:INFO:Start saving results...
2021-01-28 18:29:21:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:29:21:INFO:########################################misa-(20/50)########################################
2021-01-28 18:29:21:INFO:batch_size:32
2021-01-28 18:29:21:INFO:learning_rate:0.0001
2021-01-28 18:29:21:INFO:hidden_size:256
2021-01-28 18:29:21:INFO:dropout:0.0
2021-01-28 18:29:21:INFO:reverse_grad_weight:1.0
2021-01-28 18:29:21:INFO:diff_weight:0.5
2021-01-28 18:29:21:INFO:sim_weight:1.0
2021-01-28 18:29:21:INFO:sp_weight:1.0
2021-01-28 18:29:21:INFO:recon_weight:1.0
2021-01-28 18:29:21:INFO:grad_clip:-1.0
2021-01-28 18:29:21:INFO:weight_decay:0.0
2021-01-28 18:29:21:INFO:##########################################################################################
2021-01-28 18:29:21:INFO:Start running misa...
2021-01-28 18:29:21:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:29:21:INFO:Let's use 1 GPUs!
2021-01-28 18:29:21:INFO:train samples: (1284,)
2021-01-28 18:29:21:INFO:valid samples: (229,)
2021-01-28 18:29:21:INFO:test samples: (686,)
2021-01-28 18:29:21:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:29:21:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:29:21:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:29:21:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:29:21:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:29:21:INFO:loading file None
2021-01-28 18:29:21:INFO:loading file None
2021-01-28 18:29:21:INFO:loading file None
2021-01-28 18:29:21:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:29:21:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:29:21:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:29:24:INFO:The model has 112685553 trainable parameters
2021-01-28 18:29:36:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.5433  Has0_acc_2: 0.6581  Has0_F1_score: 0.6633  Non0_acc_2: 0.6645  Non0_F1_score: 0.6709  Mult_acc_5: 0.2368  Mult_acc_7: 0.2321  MAE: 1.1159  Corr: 0.4587 
2021-01-28 18:29:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7884  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.3624  Mult_acc_7: 0.3100  MAE: 0.9619  Corr: 0.7146  Loss: 1.3790 
2021-01-28 18:29:50:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.2830  Has0_acc_2: 0.8302  Has0_F1_score: 0.8295  Non0_acc_2: 0.8473  Non0_F1_score: 0.8470  Mult_acc_5: 0.4424  Mult_acc_7: 0.4073  MAE: 0.7350  Corr: 0.7825 
2021-01-28 18:29:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.4585  Mult_acc_7: 0.3799  MAE: 0.7989  Corr: 0.7776  Loss: 0.9782 
2021-01-28 18:30:04:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.1784  Has0_acc_2: 0.8832  Has0_F1_score: 0.8826  Non0_acc_2: 0.9050  Non0_F1_score: 0.9048  Mult_acc_5: 0.5755  Mult_acc_7: 0.5296  MAE: 0.5078  Corr: 0.9022 
2021-01-28 18:30:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8111  Non0_acc_2: 0.8148  Non0_F1_score: 0.8186  Mult_acc_5: 0.4454  Mult_acc_7: 0.3581  MAE: 0.8488  Corr: 0.7505  Loss: 1.2423 
2021-01-28 18:30:16:INFO:TRAIN-(misa) (2/4/1)>> loss: 0.7524  Has0_acc_2: 0.9299  Has0_F1_score: 0.9297  Non0_acc_2: 0.9504  Non0_F1_score: 0.9505  Mult_acc_5: 0.7048  Mult_acc_7: 0.6503  MAE: 0.3700  Corr: 0.9511 
2021-01-28 18:30:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8472  Non0_F1_score: 0.8466  Mult_acc_5: 0.4716  Mult_acc_7: 0.3712  MAE: 0.7795  Corr: 0.7706  Loss: 1.1781 
2021-01-28 18:30:29:INFO:TRAIN-(misa) (3/5/1)>> loss: 0.5649  Has0_acc_2: 0.9393  Has0_F1_score: 0.9391  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7508  Mult_acc_7: 0.6978  MAE: 0.3120  Corr: 0.9649 
2021-01-28 18:30:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8060  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.4410  Mult_acc_7: 0.3450  MAE: 0.7933  Corr: 0.7631  Loss: 1.0926 
2021-01-28 18:30:41:INFO:TRAIN-(misa) (4/6/1)>> loss: 0.4557  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7905  Mult_acc_7: 0.7477  MAE: 0.2530  Corr: 0.9769 
2021-01-28 18:30:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8472  Non0_F1_score: 0.8476  Mult_acc_5: 0.4629  Mult_acc_7: 0.3624  MAE: 0.7705  Corr: 0.7814  Loss: 1.1649 
2021-01-28 18:30:54:INFO:TRAIN-(misa) (5/7/1)>> loss: 0.3782  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8185  Mult_acc_7: 0.7773  MAE: 0.2198  Corr: 0.9826 
2021-01-28 18:30:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8152  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4454  Mult_acc_7: 0.3493  MAE: 0.7615  Corr: 0.7757  Loss: 1.0346 
2021-01-28 18:31:07:INFO:TRAIN-(misa) (6/8/1)>> loss: 0.3439  Has0_acc_2: 0.9579  Has0_F1_score: 0.9578  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8076  Mult_acc_7: 0.7749  MAE: 0.2200  Corr: 0.9826 
2021-01-28 18:31:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.4934  Mult_acc_7: 0.3930  MAE: 0.7689  Corr: 0.7779  Loss: 1.2581 
2021-01-28 18:31:20:INFO:TRAIN-(misa) (7/9/1)>> loss: 0.3223  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8318  Mult_acc_7: 0.7975  MAE: 0.2133  Corr: 0.9836 
2021-01-28 18:31:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8400  Non0_acc_2: 0.8472  Non0_F1_score: 0.8492  Mult_acc_5: 0.5022  Mult_acc_7: 0.4061  MAE: 0.7676  Corr: 0.7870  Loss: 1.0277 
2021-01-28 18:31:33:INFO:TRAIN-(misa) (8/10/1)>> loss: 0.2904  Has0_acc_2: 0.9618  Has0_F1_score: 0.9618  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8372  Mult_acc_7: 0.8030  MAE: 0.1956  Corr: 0.9864 
2021-01-28 18:31:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.4672  Mult_acc_7: 0.3624  MAE: 0.7597  Corr: 0.7824  Loss: 1.1008 
2021-01-28 18:31:36:INFO:TEST-(misa) >>  Has0_acc_2: 0.8134  Has0_F1_score: 0.8133  Non0_acc_2: 0.8277  Non0_F1_score: 0.8271  Mult_acc_5: 0.4227  Mult_acc_7: 0.3848  MAE: 0.8159  Corr: 0.7603  Loss: 1.1490 
2021-01-28 18:31:36:INFO:Start saving results...
2021-01-28 18:31:36:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:31:36:INFO:########################################misa-(21/50)########################################
2021-01-28 18:31:36:INFO:batch_size:64
2021-01-28 18:31:36:INFO:learning_rate:0.0001
2021-01-28 18:31:36:INFO:hidden_size:128
2021-01-28 18:31:36:INFO:dropout:0.2
2021-01-28 18:31:36:INFO:reverse_grad_weight:0.8
2021-01-28 18:31:36:INFO:diff_weight:0.3
2021-01-28 18:31:36:INFO:sim_weight:0.8
2021-01-28 18:31:36:INFO:sp_weight:0.0
2021-01-28 18:31:36:INFO:recon_weight:0.8
2021-01-28 18:31:36:INFO:grad_clip:1.0
2021-01-28 18:31:36:INFO:weight_decay:0.002
2021-01-28 18:31:36:INFO:##########################################################################################
2021-01-28 18:31:36:INFO:Start running misa...
2021-01-28 18:31:36:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:31:36:INFO:Let's use 1 GPUs!
2021-01-28 18:31:36:INFO:train samples: (1284,)
2021-01-28 18:31:37:INFO:valid samples: (229,)
2021-01-28 18:31:37:INFO:test samples: (686,)
2021-01-28 18:31:37:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:31:37:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:31:37:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:31:37:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:31:37:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:31:37:INFO:loading file None
2021-01-28 18:31:37:INFO:loading file None
2021-01-28 18:31:37:INFO:loading file None
2021-01-28 18:31:37:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:31:37:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:31:37:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:31:41:INFO:The model has 110620273 trainable parameters
2021-01-28 18:31:50:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.1939  Has0_acc_2: 0.6051  Has0_F1_score: 0.6243  Non0_acc_2: 0.6003  Non0_F1_score: 0.6205  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2626  Corr: 0.2678 
2021-01-28 18:31:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.7336  Has0_F1_score: 0.7498  Non0_acc_2: 0.7269  Non0_F1_score: 0.7435  Mult_acc_5: 0.2620  Mult_acc_7: 0.2620  MAE: 1.1304  Corr: 0.6556  Loss: 1.9080 
2021-01-28 18:32:02:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.8274  Has0_acc_2: 0.8154  Has0_F1_score: 0.8152  Non0_acc_2: 0.8278  Non0_F1_score: 0.8280  Mult_acc_5: 0.3287  Mult_acc_7: 0.3240  MAE: 0.8471  Corr: 0.7331 
2021-01-28 18:32:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7885  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4148  Mult_acc_7: 0.3450  MAE: 0.8742  Corr: 0.7382  Loss: 1.2753 
2021-01-28 18:32:14:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.0085  Has0_acc_2: 0.8692  Has0_F1_score: 0.8685  Non0_acc_2: 0.8879  Non0_F1_score: 0.8876  Mult_acc_5: 0.4938  Mult_acc_7: 0.4595  MAE: 0.6070  Corr: 0.8529 
2021-01-28 18:32:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7760  Corr: 0.7781  Loss: 1.0592 
2021-01-28 18:32:26:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.5276  Has0_acc_2: 0.8980  Has0_F1_score: 0.8978  Non0_acc_2: 0.9171  Non0_F1_score: 0.9172  Mult_acc_5: 0.5833  Mult_acc_7: 0.5296  MAE: 0.4968  Corr: 0.9047 
2021-01-28 18:32:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7958  Non0_acc_2: 0.8148  Non0_F1_score: 0.8170  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7957  Corr: 0.7617  Loss: 1.2106 
2021-01-28 18:32:36:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.1650  Has0_acc_2: 0.9237  Has0_F1_score: 0.9235  Non0_acc_2: 0.9399  Non0_F1_score: 0.9399  Mult_acc_5: 0.6410  Mult_acc_7: 0.5927  MAE: 0.4183  Corr: 0.9362 
2021-01-28 18:32:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.4541  Mult_acc_7: 0.3581  MAE: 0.7928  Corr: 0.7780  Loss: 1.1996 
2021-01-28 18:32:46:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.9062  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9529  Non0_F1_score: 0.9529  Mult_acc_5: 0.7033  Mult_acc_7: 0.6410  MAE: 0.3488  Corr: 0.9553 
2021-01-28 18:32:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7929  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.4629  Mult_acc_7: 0.3624  MAE: 0.7954  Corr: 0.7783  Loss: 1.1341 
2021-01-28 18:32:56:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.7170  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7352  Mult_acc_7: 0.6760  MAE: 0.3161  Corr: 0.9647 
2021-01-28 18:32:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7929  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.4716  Mult_acc_7: 0.3712  MAE: 0.7804  Corr: 0.7782  Loss: 1.1674 
2021-01-28 18:33:06:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.5828  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7827  Mult_acc_7: 0.7329  MAE: 0.2848  Corr: 0.9712 
2021-01-28 18:33:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7839  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4498  Mult_acc_7: 0.3624  MAE: 0.8029  Corr: 0.7739  Loss: 1.1117 
2021-01-28 18:33:16:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4899  Has0_acc_2: 0.9486  Has0_F1_score: 0.9484  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7944  Mult_acc_7: 0.7461  MAE: 0.2772  Corr: 0.9732 
2021-01-28 18:33:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5328  Mult_acc_7: 0.4105  MAE: 0.7529  Corr: 0.7839  Loss: 1.1072 
2021-01-28 18:33:27:INFO:TRAIN-(misa) (7/10/1)>> loss: 0.4272  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7819  Mult_acc_7: 0.7383  MAE: 0.2624  Corr: 0.9755 
2021-01-28 18:33:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.4934  Mult_acc_7: 0.3799  MAE: 0.7716  Corr: 0.7830  Loss: 1.0969 
2021-01-28 18:33:37:INFO:TRAIN-(misa) (8/11/1)>> loss: 0.3941  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.7718  Mult_acc_7: 0.7274  MAE: 0.2688  Corr: 0.9752 
2021-01-28 18:33:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7884  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4847  Mult_acc_7: 0.3755  MAE: 0.7853  Corr: 0.7766  Loss: 1.1766 
2021-01-28 18:33:40:INFO:TEST-(misa) >>  Has0_acc_2: 0.8236  Has0_F1_score: 0.8239  Non0_acc_2: 0.8445  Non0_F1_score: 0.8442  Mult_acc_5: 0.4708  Mult_acc_7: 0.4155  MAE: 0.7739  Corr: 0.7746  Loss: 1.0386 
2021-01-28 18:33:40:INFO:Start saving results...
2021-01-28 18:33:40:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:33:40:INFO:########################################misa-(22/50)########################################
2021-01-28 18:33:40:INFO:batch_size:32
2021-01-28 18:33:40:INFO:learning_rate:0.001
2021-01-28 18:33:40:INFO:hidden_size:64
2021-01-28 18:33:40:INFO:dropout:0.5
2021-01-28 18:33:40:INFO:reverse_grad_weight:1.0
2021-01-28 18:33:40:INFO:diff_weight:0.1
2021-01-28 18:33:40:INFO:sim_weight:0.5
2021-01-28 18:33:40:INFO:sp_weight:0.0
2021-01-28 18:33:40:INFO:recon_weight:1.0
2021-01-28 18:33:40:INFO:grad_clip:1.0
2021-01-28 18:33:40:INFO:weight_decay:5e-05
2021-01-28 18:33:40:INFO:##########################################################################################
2021-01-28 18:33:40:INFO:Start running misa...
2021-01-28 18:33:40:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:33:40:INFO:Let's use 1 GPUs!
2021-01-28 18:33:40:INFO:train samples: (1284,)
2021-01-28 18:33:41:INFO:valid samples: (229,)
2021-01-28 18:33:41:INFO:test samples: (686,)
2021-01-28 18:33:41:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:33:41:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:33:41:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:33:41:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:33:41:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:33:41:INFO:loading file None
2021-01-28 18:33:41:INFO:loading file None
2021-01-28 18:33:41:INFO:loading file None
2021-01-28 18:33:41:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:33:41:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:33:41:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:33:45:INFO:The model has 109943985 trainable parameters
2021-01-28 18:33:57:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.3681  Has0_acc_2: 0.5343  Has0_F1_score: 0.5675  Non0_acc_2: 0.5272  Non0_F1_score: 0.5625  Mult_acc_5: 0.1877  Mult_acc_7: 0.1877  MAE: 1.3386  Corr: 0.0129 
2021-01-28 18:33:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4135  Corr: 0.1793  Loss: 2.7356 
2021-01-28 18:34:11:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4945  Has0_acc_2: 0.5358  Has0_F1_score: 0.5974  Non0_acc_2: 0.5256  Non0_F1_score: 0.5899  Mult_acc_5: 0.1846  Mult_acc_7: 0.1846  MAE: 1.3347  Corr: -0.0269 
2021-01-28 18:34:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4133  Corr: 0.2111  Loss: 2.6358 
2021-01-28 18:34:25:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.3522  Has0_acc_2: 0.5623  Has0_F1_score: 0.6366  Non0_acc_2: 0.5508  Non0_F1_score: 0.6277  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3182  Corr: 0.0373 
2021-01-28 18:34:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4192  Corr: 0.0872  Loss: 2.8361 
2021-01-28 18:34:38:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3329  Has0_acc_2: 0.5428  Has0_F1_score: 0.6038  Non0_acc_2: 0.5305  Non0_F1_score: 0.5934  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3258  Corr: -0.0150 
2021-01-28 18:34:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4160  Corr: 0.0197  Loss: 2.6083 
2021-01-28 18:34:52:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3352  Has0_acc_2: 0.5584  Has0_F1_score: 0.6618  Non0_acc_2: 0.5410  Non0_F1_score: 0.6464  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3242  Corr: -0.0196 
2021-01-28 18:34:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4202  Corr: 0.0810  Loss: 2.7933 
2021-01-28 18:35:05:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3208  Has0_acc_2: 0.5670  Has0_F1_score: 0.6780  Non0_acc_2: 0.5491  Non0_F1_score: 0.6620  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3211  Corr: -0.0137 
2021-01-28 18:35:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4226  Corr: 0.1256  Loss: 2.7850 
2021-01-28 18:35:17:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3000  Has0_acc_2: 0.5662  Has0_F1_score: 0.7056  Non0_acc_2: 0.5483  Non0_F1_score: 0.6908  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3205  Corr: 0.0074 
2021-01-28 18:35:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4204  Corr: 0.1385  Loss: 2.7210 
2021-01-28 18:35:30:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.2844  Has0_acc_2: 0.5670  Has0_F1_score: 0.7133  Non0_acc_2: 0.5491  Non0_F1_score: 0.6988  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3150  Corr: 0.0476 
2021-01-28 18:35:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4211  Corr: 0.1475  Loss: 2.6435 
2021-01-28 18:35:43:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.2916  Has0_acc_2: 0.5639  Has0_F1_score: 0.6799  Non0_acc_2: 0.5467  Non0_F1_score: 0.6652  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3270  Corr: -0.0626 
2021-01-28 18:35:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4195  Corr: 0.1585  Loss: 2.7356 
2021-01-28 18:35:56:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.3688  Has0_acc_2: 0.5631  Has0_F1_score: 0.7010  Non0_acc_2: 0.5443  Non0_F1_score: 0.6847  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3201  Corr: 0.0065 
2021-01-28 18:35:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4200  Corr: 0.1479  Loss: 2.6659 
2021-01-28 18:36:09:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.3374  Has0_acc_2: 0.5693  Has0_F1_score: 0.7155  Non0_acc_2: 0.5508  Non0_F1_score: 0.6999  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3209  Corr: 0.0017 
2021-01-28 18:36:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4198  Corr: 0.1436  Loss: 2.9257 
2021-01-28 18:36:22:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.2997  Has0_acc_2: 0.5709  Has0_F1_score: 0.7232  Non0_acc_2: 0.5524  Non0_F1_score: 0.7079  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3223  Corr: -0.0346 
2021-01-28 18:36:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4176  Corr: 0.0856  Loss: 2.5399 
2021-01-28 18:36:36:INFO:TRAIN-(misa) (1/13/1)>> loss: 2.3094  Has0_acc_2: 0.5693  Has0_F1_score: 0.7222  Non0_acc_2: 0.5508  Non0_F1_score: 0.7069  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3195  Corr: 0.0034 
2021-01-28 18:36:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4192  Corr: 0.1111  Loss: 2.6889 
2021-01-28 18:36:48:INFO:TRAIN-(misa) (2/14/1)>> loss: 2.3490  Has0_acc_2: 0.5654  Has0_F1_score: 0.7045  Non0_acc_2: 0.5483  Non0_F1_score: 0.6908  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3273  Corr: -0.0637 
2021-01-28 18:36:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4199  Corr: 0.1119  Loss: 2.7074 
2021-01-28 18:37:01:INFO:TRAIN-(misa) (3/15/1)>> loss: 2.3367  Has0_acc_2: 0.5717  Has0_F1_score: 0.7138  Non0_acc_2: 0.5540  Non0_F1_score: 0.6993  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3233  Corr: -0.0173 
2021-01-28 18:37:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4233  Corr: 0.0696  Loss: 2.7796 
2021-01-28 18:37:14:INFO:TRAIN-(misa) (4/16/1)>> loss: 2.3292  Has0_acc_2: 0.5693  Has0_F1_score: 0.7208  Non0_acc_2: 0.5508  Non0_F1_score: 0.7054  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3201  Corr: -0.0169 
2021-01-28 18:37:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4208  Corr: 0.0466  Loss: 2.7148 
2021-01-28 18:37:28:INFO:TRAIN-(misa) (5/17/1)>> loss: 2.3065  Has0_acc_2: 0.5670  Has0_F1_score: 0.7214  Non0_acc_2: 0.5491  Non0_F1_score: 0.7072  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3251  Corr: -0.0369 
2021-01-28 18:37:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4248  Corr: -0.0760  Loss: 2.7712 
2021-01-28 18:37:41:INFO:TRAIN-(misa) (6/18/1)>> loss: 2.3023  Has0_acc_2: 0.5685  Has0_F1_score: 0.6980  Non0_acc_2: 0.5516  Non0_F1_score: 0.6841  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3186  Corr: 0.0196 
2021-01-28 18:37:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4188  Corr: -0.0519  Loss: 2.8391 
2021-01-28 18:37:54:INFO:TRAIN-(misa) (7/19/1)>> loss: 2.2897  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3238  Corr: -0.0408 
2021-01-28 18:37:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4230  Corr: -0.0363  Loss: 2.7430 
2021-01-28 18:38:07:INFO:TRAIN-(misa) (8/20/1)>> loss: 2.3113  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3206  Corr: -0.0217 
2021-01-28 18:38:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4201  Corr: -0.0419  Loss: 2.5220 
2021-01-28 18:38:21:INFO:TRAIN-(misa) (1/21/1)>> loss: 2.3006  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3199  Corr: 0.0030 
2021-01-28 18:38:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4196  Corr: -0.0326  Loss: 2.6726 
2021-01-28 18:38:34:INFO:TRAIN-(misa) (2/22/1)>> loss: 2.2968  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3233  Corr: -0.0275 
2021-01-28 18:38:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4200  Corr: -0.0261  Loss: 2.8124 
2021-01-28 18:38:47:INFO:TRAIN-(misa) (3/23/1)>> loss: 2.2825  Has0_acc_2: 0.5709  Has0_F1_score: 0.7192  Non0_acc_2: 0.5532  Non0_F1_score: 0.7049  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3212  Corr: 0.0131 
2021-01-28 18:38:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4166  Corr: -0.1543  Loss: 2.8307 
2021-01-28 18:38:59:INFO:TRAIN-(misa) (4/24/1)>> loss: 2.3080  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1846  Mult_acc_7: 0.1846  MAE: 1.3213  Corr: -0.0151 
2021-01-28 18:39:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4212  Corr: -0.0724  Loss: 2.6991 
2021-01-28 18:39:12:INFO:TRAIN-(misa) (5/25/1)>> loss: 2.3025  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1963  Mult_acc_7: 0.1963  MAE: 1.3176  Corr: 0.0038 
2021-01-28 18:39:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4242  Corr: -0.0798  Loss: 2.6575 
2021-01-28 18:39:25:INFO:TRAIN-(misa) (6/26/1)>> loss: 2.3094  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3220  Corr: 0.0066 
2021-01-28 18:39:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4195  Corr: -0.0684  Loss: 2.6695 
2021-01-28 18:39:38:INFO:TRAIN-(misa) (7/27/1)>> loss: 2.2626  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3216  Corr: -0.0205 
2021-01-28 18:39:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4182  Corr: -0.0350  Loss: 2.5223 
2021-01-28 18:39:51:INFO:TRAIN-(misa) (8/28/1)>> loss: 2.3080  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3155  Corr: 0.0445 
2021-01-28 18:39:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4166  Corr: -0.0993  Loss: 2.7522 
2021-01-28 18:39:54:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4579  Corr: 0.1326  Loss: 2.8045 
2021-01-28 18:39:54:INFO:Start saving results...
2021-01-28 18:39:54:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:39:54:INFO:########################################misa-(23/50)########################################
2021-01-28 18:39:54:INFO:batch_size:16
2021-01-28 18:39:54:INFO:learning_rate:0.0001
2021-01-28 18:39:54:INFO:hidden_size:128
2021-01-28 18:39:54:INFO:dropout:0.0
2021-01-28 18:39:54:INFO:reverse_grad_weight:1.0
2021-01-28 18:39:54:INFO:diff_weight:0.5
2021-01-28 18:39:54:INFO:sim_weight:0.5
2021-01-28 18:39:54:INFO:sp_weight:1.0
2021-01-28 18:39:54:INFO:recon_weight:0.5
2021-01-28 18:39:54:INFO:grad_clip:-1.0
2021-01-28 18:39:54:INFO:weight_decay:0.0
2021-01-28 18:39:54:INFO:##########################################################################################
2021-01-28 18:39:54:INFO:Start running misa...
2021-01-28 18:39:54:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:39:54:INFO:Let's use 1 GPUs!
2021-01-28 18:39:54:INFO:train samples: (1284,)
2021-01-28 18:39:55:INFO:valid samples: (229,)
2021-01-28 18:39:56:INFO:test samples: (686,)
2021-01-28 18:39:56:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:39:56:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:39:56:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:39:56:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:39:56:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:39:56:INFO:loading file None
2021-01-28 18:39:56:INFO:loading file None
2021-01-28 18:39:56:INFO:loading file None
2021-01-28 18:39:56:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:39:56:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:39:56:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:39:59:INFO:The model has 110620273 trainable parameters
2021-01-28 18:40:15:INFO:TRAIN-(misa) (1/1/1)>> loss: 2.9040  Has0_acc_2: 0.6768  Has0_F1_score: 0.6802  Non0_acc_2: 0.6848  Non0_F1_score: 0.6893  Mult_acc_5: 0.2617  Mult_acc_7: 0.2547  MAE: 1.1131  Corr: 0.4471 
2021-01-28 18:40:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7712  Non0_acc_2: 0.8056  Non0_F1_score: 0.8053  Mult_acc_5: 0.3581  Mult_acc_7: 0.3231  MAE: 1.0046  Corr: 0.6882  Loss: 1.6425 
2021-01-28 18:40:33:INFO:TRAIN-(misa) (1/2/1)>> loss: 1.5279  Has0_acc_2: 0.8217  Has0_F1_score: 0.8208  Non0_acc_2: 0.8383  Non0_F1_score: 0.8379  Mult_acc_5: 0.4112  Mult_acc_7: 0.3894  MAE: 0.7614  Corr: 0.7662 
2021-01-28 18:40:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7963  Non0_acc_2: 0.8241  Non0_F1_score: 0.8271  Mult_acc_5: 0.3581  Mult_acc_7: 0.2969  MAE: 0.9297  Corr: 0.7338  Loss: 1.3599 
2021-01-28 18:40:51:INFO:TRAIN-(misa) (1/3/1)>> loss: 0.8665  Has0_acc_2: 0.8917  Has0_F1_score: 0.8913  Non0_acc_2: 0.9058  Non0_F1_score: 0.9056  Mult_acc_5: 0.5670  Mult_acc_7: 0.5257  MAE: 0.5555  Corr: 0.8764 
2021-01-28 18:40:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8200  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.4760  Mult_acc_7: 0.3886  MAE: 0.7831  Corr: 0.7640  Loss: 1.1113 
2021-01-28 18:41:10:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.5446  Has0_acc_2: 0.9104  Has0_F1_score: 0.9101  Non0_acc_2: 0.9326  Non0_F1_score: 0.9325  Mult_acc_5: 0.6402  Mult_acc_7: 0.5935  MAE: 0.4296  Corr: 0.9299 
2021-01-28 18:41:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.4629  Mult_acc_7: 0.3668  MAE: 0.7728  Corr: 0.7783  Loss: 1.0753 
2021-01-28 18:41:30:INFO:TRAIN-(misa) (1/5/1)>> loss: 0.4186  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9456  Non0_F1_score: 0.9456  Mult_acc_5: 0.6970  Mult_acc_7: 0.6480  MAE: 0.3744  Corr: 0.9475 
2021-01-28 18:41:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8341  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.4891  Mult_acc_7: 0.4017  MAE: 0.7750  Corr: 0.7808  Loss: 1.0269 
2021-01-28 18:41:49:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.2908  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7570  Mult_acc_7: 0.7025  MAE: 0.2975  Corr: 0.9678 
2021-01-28 18:41:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.7761  Corr: 0.7725  Loss: 1.0957 
2021-01-28 18:42:06:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.2131  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8123  Mult_acc_7: 0.7656  MAE: 0.2424  Corr: 0.9790 
2021-01-28 18:42:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8565  Non0_F1_score: 0.8577  Mult_acc_5: 0.5153  Mult_acc_7: 0.4236  MAE: 0.7440  Corr: 0.7840  Loss: 1.0381 
2021-01-28 18:42:24:INFO:TRAIN-(misa) (3/8/1)>> loss: 0.1870  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8123  Mult_acc_7: 0.7679  MAE: 0.2248  Corr: 0.9816 
2021-01-28 18:42:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8166  Non0_acc_2: 0.8426  Non0_F1_score: 0.8437  Mult_acc_5: 0.5066  Mult_acc_7: 0.4192  MAE: 0.7629  Corr: 0.7753  Loss: 1.0849 
2021-01-28 18:42:40:INFO:TRAIN-(misa) (4/9/1)>> loss: 0.1707  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.8271  Mult_acc_7: 0.7835  MAE: 0.2109  Corr: 0.9834 
2021-01-28 18:42:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7755  Corr: 0.7664  Loss: 1.1955 
2021-01-28 18:42:57:INFO:TRAIN-(misa) (5/10/1)>> loss: 0.1518  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8442  Mult_acc_7: 0.8092  MAE: 0.2013  Corr: 0.9854 
2021-01-28 18:42:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7396  Corr: 0.7810  Loss: 1.0669 
2021-01-28 18:43:14:INFO:TRAIN-(misa) (6/11/1)>> loss: 0.1328  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8388  Mult_acc_7: 0.8069  MAE: 0.1841  Corr: 0.9876 
2021-01-28 18:43:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8383  Non0_acc_2: 0.8611  Non0_F1_score: 0.8618  Mult_acc_5: 0.5109  Mult_acc_7: 0.3974  MAE: 0.7197  Corr: 0.7898  Loss: 1.0822 
2021-01-28 18:43:31:INFO:TRAIN-(misa) (7/12/1)>> loss: 0.1189  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8544  Mult_acc_7: 0.8232  MAE: 0.1703  Corr: 0.9898 
2021-01-28 18:43:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8565  Non0_F1_score: 0.8559  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7605  Corr: 0.7747  Loss: 1.0813 
2021-01-28 18:43:49:INFO:TRAIN-(misa) (8/13/1)>> loss: 0.1184  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8427  Mult_acc_7: 0.8100  MAE: 0.1780  Corr: 0.9887 
2021-01-28 18:43:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8657  Non0_F1_score: 0.8656  Mult_acc_5: 0.5022  Mult_acc_7: 0.4061  MAE: 0.7258  Corr: 0.7872  Loss: 1.0143 
2021-01-28 18:44:09:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.1092  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8614  Mult_acc_7: 0.8326  MAE: 0.1716  Corr: 0.9897 
2021-01-28 18:44:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8193  Non0_acc_2: 0.8565  Non0_F1_score: 0.8559  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7533  Corr: 0.7812  Loss: 1.1320 
2021-01-28 18:44:25:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.1161  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9699  Non0_F1_score: 0.9699  Mult_acc_5: 0.8396  Mult_acc_7: 0.8076  MAE: 0.1871  Corr: 0.9874 
2021-01-28 18:44:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.7824  Corr: 0.7737  Loss: 1.1707 
2021-01-28 18:44:42:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.0998  Has0_acc_2: 0.9712  Has0_F1_score: 0.9711  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8559  Mult_acc_7: 0.8318  MAE: 0.1649  Corr: 0.9905 
2021-01-28 18:44:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5109  Mult_acc_7: 0.4061  MAE: 0.7320  Corr: 0.7901  Loss: 1.0165 
2021-01-28 18:44:59:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.0926  Has0_acc_2: 0.9696  Has0_F1_score: 0.9696  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8777  Mult_acc_7: 0.8520  MAE: 0.1587  Corr: 0.9911 
2021-01-28 18:44:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8333  Non0_F1_score: 0.8324  Mult_acc_5: 0.4236  Mult_acc_7: 0.3319  MAE: 0.7855  Corr: 0.7815  Loss: 1.0697 
2021-01-28 18:45:15:INFO:TRAIN-(misa) (5/18/1)>> loss: 0.0916  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8621  Mult_acc_7: 0.8380  MAE: 0.1611  Corr: 0.9908 
2021-01-28 18:45:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7247  Corr: 0.7947  Loss: 1.0000 
2021-01-28 18:45:34:INFO:TRAIN-(misa) (1/19/1)>> loss: 0.0850  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8863  Mult_acc_7: 0.8653  MAE: 0.1515  Corr: 0.9918 
2021-01-28 18:45:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7436  Corr: 0.7883  Loss: 1.0691 
2021-01-28 18:45:52:INFO:TRAIN-(misa) (2/20/1)>> loss: 0.0769  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8777  Mult_acc_7: 0.8528  MAE: 0.1410  Corr: 0.9929 
2021-01-28 18:45:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8519  Non0_F1_score: 0.8517  Mult_acc_5: 0.4891  Mult_acc_7: 0.3843  MAE: 0.7489  Corr: 0.7849  Loss: 1.0336 
2021-01-28 18:46:09:INFO:TRAIN-(misa) (3/21/1)>> loss: 0.0926  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8528  Mult_acc_7: 0.8255  MAE: 0.1731  Corr: 0.9894 
2021-01-28 18:46:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8264  Non0_acc_2: 0.8426  Non0_F1_score: 0.8445  Mult_acc_5: 0.4978  Mult_acc_7: 0.4105  MAE: 0.7452  Corr: 0.7877  Loss: 1.0286 
2021-01-28 18:46:25:INFO:TRAIN-(misa) (4/22/1)>> loss: 0.0853  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8723  Mult_acc_7: 0.8435  MAE: 0.1601  Corr: 0.9908 
2021-01-28 18:46:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7481  Corr: 0.7891  Loss: 1.0307 
2021-01-28 18:46:42:INFO:TRAIN-(misa) (5/23/1)>> loss: 0.0864  Has0_acc_2: 0.9533  Has0_F1_score: 0.9532  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8567  Mult_acc_7: 0.8372  MAE: 0.1664  Corr: 0.9899 
2021-01-28 18:46:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5066  Mult_acc_7: 0.4192  MAE: 0.7323  Corr: 0.7942  Loss: 1.0586 
2021-01-28 18:46:59:INFO:TRAIN-(misa) (6/24/1)>> loss: 0.0716  Has0_acc_2: 0.9673  Has0_F1_score: 0.9672  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8855  Mult_acc_7: 0.8676  MAE: 0.1385  Corr: 0.9931 
2021-01-28 18:47:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8194  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7425  Corr: 0.7888  Loss: 1.0346 
2021-01-28 18:47:16:INFO:TRAIN-(misa) (7/25/1)>> loss: 0.0747  Has0_acc_2: 0.9650  Has0_F1_score: 0.9649  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8769  Mult_acc_7: 0.8583  MAE: 0.1530  Corr: 0.9919 
2021-01-28 18:47:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7980  Non0_acc_2: 0.8287  Non0_F1_score: 0.8288  Mult_acc_5: 0.4934  Mult_acc_7: 0.4061  MAE: 0.7560  Corr: 0.7854  Loss: 1.0287 
2021-01-28 18:47:33:INFO:TRAIN-(misa) (8/26/1)>> loss: 0.0702  Has0_acc_2: 0.9696  Has0_F1_score: 0.9696  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8832  Mult_acc_7: 0.8645  MAE: 0.1427  Corr: 0.9928 
2021-01-28 18:47:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4498  Mult_acc_7: 0.3712  MAE: 0.7504  Corr: 0.7888  Loss: 1.0542 
2021-01-28 18:47:37:INFO:TEST-(misa) >>  Has0_acc_2: 0.8149  Has0_F1_score: 0.8158  Non0_acc_2: 0.8369  Non0_F1_score: 0.8371  Mult_acc_5: 0.4723  Mult_acc_7: 0.4198  MAE: 0.7664  Corr: 0.7714  Loss: 1.1037 
2021-01-28 18:47:37:INFO:Start saving results...
2021-01-28 18:47:37:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:47:37:INFO:########################################misa-(24/50)########################################
2021-01-28 18:47:37:INFO:batch_size:16
2021-01-28 18:47:37:INFO:learning_rate:0.0001
2021-01-28 18:47:37:INFO:hidden_size:64
2021-01-28 18:47:37:INFO:dropout:0.5
2021-01-28 18:47:37:INFO:reverse_grad_weight:1.0
2021-01-28 18:47:37:INFO:diff_weight:0.3
2021-01-28 18:47:37:INFO:sim_weight:0.8
2021-01-28 18:47:37:INFO:sp_weight:0.0
2021-01-28 18:47:37:INFO:recon_weight:1.0
2021-01-28 18:47:37:INFO:grad_clip:0.8
2021-01-28 18:47:37:INFO:weight_decay:0.002
2021-01-28 18:47:37:INFO:##########################################################################################
2021-01-28 18:47:37:INFO:Start running misa...
2021-01-28 18:47:37:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:47:37:INFO:Let's use 1 GPUs!
2021-01-28 18:47:37:INFO:train samples: (1284,)
2021-01-28 18:47:38:INFO:valid samples: (229,)
2021-01-28 18:47:38:INFO:test samples: (686,)
2021-01-28 18:47:38:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:47:38:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:47:38:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:47:38:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:47:38:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:47:38:INFO:loading file None
2021-01-28 18:47:38:INFO:loading file None
2021-01-28 18:47:38:INFO:loading file None
2021-01-28 18:47:38:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:47:38:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:47:38:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:47:42:INFO:The model has 109943985 trainable parameters
2021-01-28 18:47:58:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.6220  Has0_acc_2: 0.6924  Has0_F1_score: 0.6976  Non0_acc_2: 0.7002  Non0_F1_score: 0.7066  Mult_acc_5: 0.2414  Mult_acc_7: 0.2391  MAE: 1.1042  Corr: 0.4988 
2021-01-28 18:47:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7751  Non0_acc_2: 0.8056  Non0_F1_score: 0.8045  Mult_acc_5: 0.3974  Mult_acc_7: 0.3493  MAE: 0.9510  Corr: 0.6799  Loss: 1.4274 
2021-01-28 18:48:16:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.1200  Has0_acc_2: 0.8310  Has0_F1_score: 0.8302  Non0_acc_2: 0.8522  Non0_F1_score: 0.8519  Mult_acc_5: 0.4034  Mult_acc_7: 0.3801  MAE: 0.7519  Corr: 0.7770 
2021-01-28 18:48:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7293  Has0_F1_score: 0.7268  Non0_acc_2: 0.7546  Non0_F1_score: 0.7533  Mult_acc_5: 0.3799  Mult_acc_7: 0.3231  MAE: 0.9505  Corr: 0.6776  Loss: 1.4872 
2021-01-28 18:48:34:INFO:TRAIN-(misa) (2/3/1)>> loss: 1.4507  Has0_acc_2: 0.8715  Has0_F1_score: 0.8710  Non0_acc_2: 0.8887  Non0_F1_score: 0.8885  Mult_acc_5: 0.4899  Mult_acc_7: 0.4611  MAE: 0.6084  Corr: 0.8535 
2021-01-28 18:48:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8237  Non0_acc_2: 0.8287  Non0_F1_score: 0.8319  Mult_acc_5: 0.4454  Mult_acc_7: 0.3493  MAE: 0.8609  Corr: 0.7510  Loss: 1.2996 
2021-01-28 18:48:53:INFO:TRAIN-(misa) (1/4/1)>> loss: 0.9925  Has0_acc_2: 0.9089  Has0_F1_score: 0.9086  Non0_acc_2: 0.9269  Non0_F1_score: 0.9269  Mult_acc_5: 0.5460  Mult_acc_7: 0.5055  MAE: 0.5189  Corr: 0.8993 
2021-01-28 18:48:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8383  Non0_acc_2: 0.8472  Non0_F1_score: 0.8476  Mult_acc_5: 0.4803  Mult_acc_7: 0.3799  MAE: 0.7657  Corr: 0.7818  Loss: 1.0605 
2021-01-28 18:49:12:INFO:TRAIN-(misa) (1/5/1)>> loss: 0.6819  Has0_acc_2: 0.9198  Has0_F1_score: 0.9196  Non0_acc_2: 0.9391  Non0_F1_score: 0.9391  Mult_acc_5: 0.6363  Mult_acc_7: 0.5818  MAE: 0.4338  Corr: 0.9315 
2021-01-28 18:49:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7709  Non0_acc_2: 0.8102  Non0_F1_score: 0.8091  Mult_acc_5: 0.4410  Mult_acc_7: 0.3537  MAE: 0.8552  Corr: 0.7719  Loss: 1.1689 
2021-01-28 18:49:29:INFO:TRAIN-(misa) (2/6/1)>> loss: 0.5650  Has0_acc_2: 0.9182  Has0_F1_score: 0.9180  Non0_acc_2: 0.9350  Non0_F1_score: 0.9350  Mult_acc_5: 0.6488  Mult_acc_7: 0.5911  MAE: 0.4219  Corr: 0.9367 
2021-01-28 18:49:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8438  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.7553  Corr: 0.7899  Loss: 1.0547 
2021-01-28 18:49:49:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.4527  Has0_acc_2: 0.9291  Has0_F1_score: 0.9290  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.7009  Mult_acc_7: 0.6355  MAE: 0.3748  Corr: 0.9493 
2021-01-28 18:49:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7798  Non0_acc_2: 0.8148  Non0_F1_score: 0.8139  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.8023  Corr: 0.7759  Loss: 1.1945 
2021-01-28 18:50:06:INFO:TRAIN-(misa) (2/8/1)>> loss: 0.3788  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7111  Mult_acc_7: 0.6526  MAE: 0.3516  Corr: 0.9559 
2021-01-28 18:50:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7426  Corr: 0.7879  Loss: 1.0155 
2021-01-28 18:50:25:INFO:TRAIN-(misa) (1/9/1)>> loss: 0.3257  Has0_acc_2: 0.9346  Has0_F1_score: 0.9344  Non0_acc_2: 0.9496  Non0_F1_score: 0.9496  Mult_acc_5: 0.7336  Mult_acc_7: 0.6729  MAE: 0.3295  Corr: 0.9609 
2021-01-28 18:50:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4934  Mult_acc_7: 0.4061  MAE: 0.7332  Corr: 0.8004  Loss: 0.9840 
2021-01-28 18:50:45:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.2949  Has0_acc_2: 0.9377  Has0_F1_score: 0.9375  Non0_acc_2: 0.9578  Non0_F1_score: 0.9577  Mult_acc_5: 0.7523  Mult_acc_7: 0.6939  MAE: 0.3179  Corr: 0.9632 
2021-01-28 18:50:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5371  Mult_acc_7: 0.4498  MAE: 0.7279  Corr: 0.7956  Loss: 1.0303 
2021-01-28 18:51:02:INFO:TRAIN-(misa) (2/11/1)>> loss: 0.2751  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9626  Non0_F1_score: 0.9626  Mult_acc_5: 0.7282  Mult_acc_7: 0.6713  MAE: 0.3262  Corr: 0.9638 
2021-01-28 18:51:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8383  Non0_acc_2: 0.8472  Non0_F1_score: 0.8476  Mult_acc_5: 0.4978  Mult_acc_7: 0.3974  MAE: 0.7495  Corr: 0.7908  Loss: 1.2497 
2021-01-28 18:51:19:INFO:TRAIN-(misa) (3/12/1)>> loss: 0.2681  Has0_acc_2: 0.9361  Has0_F1_score: 0.9360  Non0_acc_2: 0.9553  Non0_F1_score: 0.9553  Mult_acc_5: 0.7508  Mult_acc_7: 0.6893  MAE: 0.3180  Corr: 0.9643 
2021-01-28 18:51:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8283  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7258  Corr: 0.7953  Loss: 1.0416 
2021-01-28 18:51:38:INFO:TRAIN-(misa) (4/13/1)>> loss: 0.2250  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7586  Mult_acc_7: 0.7002  MAE: 0.2919  Corr: 0.9702 
2021-01-28 18:51:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8241  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5459  Mult_acc_7: 0.4367  MAE: 0.7331  Corr: 0.7942  Loss: 1.0723 
2021-01-28 18:51:55:INFO:TRAIN-(misa) (5/14/1)>> loss: 0.1907  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7952  Mult_acc_7: 0.7438  MAE: 0.2669  Corr: 0.9753 
2021-01-28 18:51:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8194  Non0_acc_2: 0.8472  Non0_F1_score: 0.8466  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7306  Corr: 0.8011  Loss: 0.9770 
2021-01-28 18:52:14:INFO:TRAIN-(misa) (1/15/1)>> loss: 0.1985  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7850  Mult_acc_7: 0.7274  MAE: 0.2788  Corr: 0.9731 
2021-01-28 18:52:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8421  Non0_acc_2: 0.8657  Non0_F1_score: 0.8658  Mult_acc_5: 0.5153  Mult_acc_7: 0.4279  MAE: 0.7126  Corr: 0.8085  Loss: 1.1220 
2021-01-28 18:52:31:INFO:TRAIN-(misa) (2/16/1)>> loss: 0.1834  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.7850  Mult_acc_7: 0.7305  MAE: 0.2615  Corr: 0.9754 
2021-01-28 18:52:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8132  Non0_acc_2: 0.8194  Non0_F1_score: 0.8209  Mult_acc_5: 0.4934  Mult_acc_7: 0.4061  MAE: 0.7462  Corr: 0.7969  Loss: 1.0519 
2021-01-28 18:52:48:INFO:TRAIN-(misa) (3/17/1)>> loss: 0.1800  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7952  Mult_acc_7: 0.7414  MAE: 0.2627  Corr: 0.9754 
2021-01-28 18:52:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.4891  Mult_acc_7: 0.4061  MAE: 0.7188  Corr: 0.8061  Loss: 1.0455 
2021-01-28 18:53:06:INFO:TRAIN-(misa) (4/18/1)>> loss: 0.1859  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.7819  Mult_acc_7: 0.7243  MAE: 0.2765  Corr: 0.9729 
2021-01-28 18:53:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4541  Mult_acc_7: 0.3712  MAE: 0.7548  Corr: 0.7935  Loss: 1.1388 
2021-01-28 18:53:23:INFO:TRAIN-(misa) (5/19/1)>> loss: 0.1638  Has0_acc_2: 0.9579  Has0_F1_score: 0.9578  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.7998  Mult_acc_7: 0.7500  MAE: 0.2562  Corr: 0.9770 
2021-01-28 18:53:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.4716  Mult_acc_7: 0.4017  MAE: 0.7198  Corr: 0.8068  Loss: 0.9258 
2021-01-28 18:53:43:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.1526  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8030  Mult_acc_7: 0.7586  MAE: 0.2469  Corr: 0.9788 
2021-01-28 18:53:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7294  Corr: 0.8000  Loss: 0.9542 
2021-01-28 18:54:00:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.1555  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9651  Non0_F1_score: 0.9650  Mult_acc_5: 0.8053  Mult_acc_7: 0.7508  MAE: 0.2526  Corr: 0.9773 
2021-01-28 18:54:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8106  Non0_acc_2: 0.8333  Non0_F1_score: 0.8326  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.7218  Corr: 0.8019  Loss: 0.9809 
2021-01-28 18:54:18:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.1530  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7967  Mult_acc_7: 0.7445  MAE: 0.2495  Corr: 0.9776 
2021-01-28 18:54:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8148  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7411  Corr: 0.7985  Loss: 0.9756 
2021-01-28 18:54:35:INFO:TRAIN-(misa) (4/23/1)>> loss: 0.1486  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.8022  Mult_acc_7: 0.7516  MAE: 0.2482  Corr: 0.9784 
2021-01-28 18:54:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8193  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.4672  Mult_acc_7: 0.3799  MAE: 0.7503  Corr: 0.8039  Loss: 0.9708 
2021-01-28 18:54:52:INFO:TRAIN-(misa) (5/24/1)>> loss: 0.1649  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.7804  Mult_acc_7: 0.7274  MAE: 0.2690  Corr: 0.9743 
2021-01-28 18:54:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8329  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7123  Corr: 0.8037  Loss: 1.0422 
2021-01-28 18:55:09:INFO:TRAIN-(misa) (6/25/1)>> loss: 0.1542  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.7921  Mult_acc_7: 0.7422  MAE: 0.2560  Corr: 0.9768 
2021-01-28 18:55:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8153  Non0_acc_2: 0.8380  Non0_F1_score: 0.8377  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7296  Corr: 0.8000  Loss: 0.9675 
2021-01-28 18:55:27:INFO:TRAIN-(misa) (7/26/1)>> loss: 0.1456  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.8107  Mult_acc_7: 0.7664  MAE: 0.2467  Corr: 0.9785 
2021-01-28 18:55:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7165  Corr: 0.8037  Loss: 0.9366 
2021-01-28 18:55:45:INFO:TRAIN-(misa) (8/27/1)>> loss: 0.1304  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8131  Mult_acc_7: 0.7632  MAE: 0.2366  Corr: 0.9811 
2021-01-28 18:55:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.4716  Mult_acc_7: 0.3712  MAE: 0.7289  Corr: 0.8007  Loss: 0.9843 
2021-01-28 18:55:48:INFO:TEST-(misa) >>  Has0_acc_2: 0.8149  Has0_F1_score: 0.8157  Non0_acc_2: 0.8354  Non0_F1_score: 0.8355  Mult_acc_5: 0.4942  Mult_acc_7: 0.4431  MAE: 0.7615  Corr: 0.7638  Loss: 1.0882 
2021-01-28 18:55:48:INFO:Start saving results...
2021-01-28 18:55:48:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:55:48:INFO:########################################misa-(25/50)########################################
2021-01-28 18:55:48:INFO:batch_size:64
2021-01-28 18:55:48:INFO:learning_rate:0.0001
2021-01-28 18:55:48:INFO:hidden_size:128
2021-01-28 18:55:48:INFO:dropout:0.0
2021-01-28 18:55:48:INFO:reverse_grad_weight:0.5
2021-01-28 18:55:48:INFO:diff_weight:0.3
2021-01-28 18:55:48:INFO:sim_weight:0.5
2021-01-28 18:55:48:INFO:sp_weight:0.0
2021-01-28 18:55:48:INFO:recon_weight:1.0
2021-01-28 18:55:48:INFO:grad_clip:1.0
2021-01-28 18:55:48:INFO:weight_decay:0.0
2021-01-28 18:55:48:INFO:##########################################################################################
2021-01-28 18:55:48:INFO:Start running misa...
2021-01-28 18:55:48:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:55:48:INFO:Let's use 1 GPUs!
2021-01-28 18:55:49:INFO:train samples: (1284,)
2021-01-28 18:55:50:INFO:valid samples: (229,)
2021-01-28 18:55:50:INFO:test samples: (686,)
2021-01-28 18:55:50:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:55:50:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:55:50:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:55:50:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:55:50:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:55:50:INFO:loading file None
2021-01-28 18:55:50:INFO:loading file None
2021-01-28 18:55:50:INFO:loading file None
2021-01-28 18:55:50:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:55:50:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:55:50:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:55:54:INFO:The model has 110620273 trainable parameters
2021-01-28 18:56:03:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.9596  Has0_acc_2: 0.6433  Has0_F1_score: 0.6570  Non0_acc_2: 0.6385  Non0_F1_score: 0.6527  Mult_acc_5: 0.2048  Mult_acc_7: 0.2048  MAE: 1.2443  Corr: 0.3269 
2021-01-28 18:56:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8041  Non0_acc_2: 0.8102  Non0_F1_score: 0.8113  Mult_acc_5: 0.2620  Mult_acc_7: 0.2620  MAE: 1.1128  Corr: 0.6560  Loss: 1.8505 
2021-01-28 18:56:15:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.6436  Has0_acc_2: 0.8294  Has0_F1_score: 0.8290  Non0_acc_2: 0.8424  Non0_F1_score: 0.8424  Mult_acc_5: 0.3170  Mult_acc_7: 0.3084  MAE: 0.8282  Corr: 0.7477 
2021-01-28 18:56:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8333  Non0_F1_score: 0.8326  Mult_acc_5: 0.4323  Mult_acc_7: 0.3362  MAE: 0.8445  Corr: 0.7535  Loss: 1.1881 
2021-01-28 18:56:26:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.9231  Has0_acc_2: 0.8614  Has0_F1_score: 0.8607  Non0_acc_2: 0.8806  Non0_F1_score: 0.8803  Mult_acc_5: 0.5117  Mult_acc_7: 0.4743  MAE: 0.6014  Corr: 0.8595 
2021-01-28 18:56:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8112  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.7662  Corr: 0.7794  Loss: 1.0801 
2021-01-28 18:56:38:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.4644  Has0_acc_2: 0.9104  Has0_F1_score: 0.9101  Non0_acc_2: 0.9293  Non0_F1_score: 0.9293  Mult_acc_5: 0.6051  Mult_acc_7: 0.5576  MAE: 0.4671  Corr: 0.9181 
2021-01-28 18:56:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8268  Non0_acc_2: 0.8380  Non0_F1_score: 0.8401  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.8060  Corr: 0.7602  Loss: 1.2711 
2021-01-28 18:56:49:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.1128  Has0_acc_2: 0.9315  Has0_F1_score: 0.9313  Non0_acc_2: 0.9529  Non0_F1_score: 0.9529  Mult_acc_5: 0.6783  Mult_acc_7: 0.6262  MAE: 0.3853  Corr: 0.9444 
2021-01-28 18:56:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7976  Non0_acc_2: 0.8241  Non0_F1_score: 0.8236  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7686  Corr: 0.7723  Loss: 1.1393 
2021-01-28 18:56:59:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.8506  Has0_acc_2: 0.9338  Has0_F1_score: 0.9336  Non0_acc_2: 0.9553  Non0_F1_score: 0.9553  Mult_acc_5: 0.7578  Mult_acc_7: 0.7056  MAE: 0.3101  Corr: 0.9647 
2021-01-28 18:57:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8059  Non0_acc_2: 0.8102  Non0_F1_score: 0.8132  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.8090  Corr: 0.7765  Loss: 1.2041 
2021-01-28 18:57:10:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.6597  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9602  Non0_F1_score: 0.9602  Mult_acc_5: 0.7780  Mult_acc_7: 0.7329  MAE: 0.2632  Corr: 0.9748 
2021-01-28 18:57:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8065  Non0_acc_2: 0.8333  Non0_F1_score: 0.8331  Mult_acc_5: 0.5197  Mult_acc_7: 0.4105  MAE: 0.7667  Corr: 0.7776  Loss: 1.2279 
2021-01-28 18:57:20:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.5326  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7975  Mult_acc_7: 0.7539  MAE: 0.2549  Corr: 0.9767 
2021-01-28 18:57:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8065  Non0_acc_2: 0.8287  Non0_F1_score: 0.8284  Mult_acc_5: 0.5153  Mult_acc_7: 0.4061  MAE: 0.7569  Corr: 0.7743  Loss: 1.0778 
2021-01-28 18:57:32:INFO:TRAIN-(misa) (1/9/1)>> loss: 0.4334  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.7983  Mult_acc_7: 0.7547  MAE: 0.2498  Corr: 0.9779 
2021-01-28 18:57:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8379  Non0_acc_2: 0.8380  Non0_F1_score: 0.8421  Mult_acc_5: 0.4629  Mult_acc_7: 0.3581  MAE: 0.8148  Corr: 0.7772  Loss: 1.2077 
2021-01-28 18:57:42:INFO:TRAIN-(misa) (2/10/1)>> loss: 0.3906  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9626  Non0_F1_score: 0.9627  Mult_acc_5: 0.7827  Mult_acc_7: 0.7407  MAE: 0.2692  Corr: 0.9745 
2021-01-28 18:57:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5502  Mult_acc_7: 0.4454  MAE: 0.7457  Corr: 0.7820  Loss: 1.1325 
2021-01-28 18:57:53:INFO:TRAIN-(misa) (3/11/1)>> loss: 0.3119  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8294  Mult_acc_7: 0.7921  MAE: 0.2106  Corr: 0.9842 
2021-01-28 18:57:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5197  Mult_acc_7: 0.4279  MAE: 0.7383  Corr: 0.7803  Loss: 1.0697 
2021-01-28 18:58:04:INFO:TRAIN-(misa) (1/12/1)>> loss: 0.2844  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8349  Mult_acc_7: 0.8022  MAE: 0.2077  Corr: 0.9854 
2021-01-28 18:58:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7530  Corr: 0.7823  Loss: 1.2811 
2021-01-28 18:58:15:INFO:TRAIN-(misa) (2/13/1)>> loss: 0.2602  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8310  Mult_acc_7: 0.7874  MAE: 0.2094  Corr: 0.9846 
2021-01-28 18:58:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8355  Non0_acc_2: 0.8426  Non0_F1_score: 0.8445  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7453  Corr: 0.7862  Loss: 1.0268 
2021-01-28 18:58:26:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2915  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7531  Mult_acc_7: 0.7048  MAE: 0.2847  Corr: 0.9721 
2021-01-28 18:58:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5415  Mult_acc_7: 0.4410  MAE: 0.7460  Corr: 0.7822  Loss: 1.1173 
2021-01-28 18:58:36:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2642  Has0_acc_2: 0.9463  Has0_F1_score: 0.9462  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.7796  Mult_acc_7: 0.7313  MAE: 0.2608  Corr: 0.9768 
2021-01-28 18:58:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5284  Mult_acc_7: 0.4279  MAE: 0.7468  Corr: 0.7785  Loss: 1.1200 
2021-01-28 18:58:47:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2271  Has0_acc_2: 0.9455  Has0_F1_score: 0.9453  Non0_acc_2: 0.9643  Non0_F1_score: 0.9642  Mult_acc_5: 0.8115  Mult_acc_7: 0.7812  MAE: 0.2277  Corr: 0.9810 
2021-01-28 18:58:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.5153  Mult_acc_7: 0.4148  MAE: 0.7425  Corr: 0.7829  Loss: 1.0968 
2021-01-28 18:58:57:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.2166  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8170  Mult_acc_7: 0.7835  MAE: 0.2353  Corr: 0.9809 
2021-01-28 18:58:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8200  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7333  Corr: 0.7868  Loss: 1.0293 
2021-01-28 18:59:07:INFO:TRAIN-(misa) (5/18/1)>> loss: 0.2046  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8069  Mult_acc_7: 0.7726  MAE: 0.2230  Corr: 0.9824 
2021-01-28 18:59:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8121  Non0_acc_2: 0.8333  Non0_F1_score: 0.8342  Mult_acc_5: 0.5109  Mult_acc_7: 0.4017  MAE: 0.7408  Corr: 0.7883  Loss: 1.0718 
2021-01-28 18:59:17:INFO:TRAIN-(misa) (6/19/1)>> loss: 0.1778  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.8403  Mult_acc_7: 0.8092  MAE: 0.1954  Corr: 0.9866 
2021-01-28 18:59:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8163  Non0_acc_2: 0.8380  Non0_F1_score: 0.8386  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7319  Corr: 0.7872  Loss: 1.0646 
2021-01-28 18:59:27:INFO:TRAIN-(misa) (7/20/1)>> loss: 0.1875  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8349  Mult_acc_7: 0.8030  MAE: 0.2054  Corr: 0.9851 
2021-01-28 18:59:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8355  Non0_acc_2: 0.8472  Non0_F1_score: 0.8492  Mult_acc_5: 0.4847  Mult_acc_7: 0.3843  MAE: 0.7518  Corr: 0.7908  Loss: 1.1672 
2021-01-28 18:59:37:INFO:TRAIN-(misa) (8/21/1)>> loss: 0.1959  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7921  Mult_acc_7: 0.7570  MAE: 0.2373  Corr: 0.9803 
2021-01-28 18:59:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8419  Non0_acc_2: 0.8380  Non0_F1_score: 0.8415  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7771  Corr: 0.7862  Loss: 1.1203 
2021-01-28 18:59:40:INFO:TEST-(misa) >>  Has0_acc_2: 0.8178  Has0_F1_score: 0.8173  Non0_acc_2: 0.8277  Non0_F1_score: 0.8268  Mult_acc_5: 0.4577  Mult_acc_7: 0.4067  MAE: 0.7983  Corr: 0.7847  Loss: 1.1029 
2021-01-28 18:59:40:INFO:Start saving results...
2021-01-28 18:59:40:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 18:59:40:INFO:########################################misa-(26/50)########################################
2021-01-28 18:59:40:INFO:batch_size:16
2021-01-28 18:59:40:INFO:learning_rate:0.001
2021-01-28 18:59:40:INFO:hidden_size:64
2021-01-28 18:59:40:INFO:dropout:0.2
2021-01-28 18:59:40:INFO:reverse_grad_weight:1.0
2021-01-28 18:59:40:INFO:diff_weight:0.3
2021-01-28 18:59:40:INFO:sim_weight:0.8
2021-01-28 18:59:40:INFO:sp_weight:1.0
2021-01-28 18:59:40:INFO:recon_weight:1.0
2021-01-28 18:59:40:INFO:grad_clip:0.8
2021-01-28 18:59:40:INFO:weight_decay:5e-05
2021-01-28 18:59:40:INFO:##########################################################################################
2021-01-28 18:59:40:INFO:Start running misa...
2021-01-28 18:59:40:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 18:59:40:INFO:Let's use 1 GPUs!
2021-01-28 18:59:40:INFO:train samples: (1284,)
2021-01-28 18:59:41:INFO:valid samples: (229,)
2021-01-28 18:59:41:INFO:test samples: (686,)
2021-01-28 18:59:42:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 18:59:42:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 18:59:42:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 18:59:42:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 18:59:42:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 18:59:42:INFO:loading file None
2021-01-28 18:59:42:INFO:loading file None
2021-01-28 18:59:42:INFO:loading file None
2021-01-28 18:59:42:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 18:59:42:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 18:59:42:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 18:59:45:INFO:The model has 109943985 trainable parameters
2021-01-28 19:00:02:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.0192  Has0_acc_2: 0.5498  Has0_F1_score: 0.6186  Non0_acc_2: 0.5386  Non0_F1_score: 0.6100  Mult_acc_5: 0.1963  Mult_acc_7: 0.1963  MAE: 1.3298  Corr: 0.0288 
2021-01-28 19:00:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4109  Corr: 0.1576  Loss: 2.7224 
2021-01-28 19:00:21:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.3907  Has0_acc_2: 0.5561  Has0_F1_score: 0.6473  Non0_acc_2: 0.5435  Non0_F1_score: 0.6379  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3253  Corr: -0.0051 
2021-01-28 19:00:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4157  Corr: 0.2172  Loss: 2.6784 
2021-01-28 19:00:40:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.3796  Has0_acc_2: 0.5452  Has0_F1_score: 0.5984  Non0_acc_2: 0.5329  Non0_F1_score: 0.5878  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3328  Corr: -0.0072 
2021-01-28 19:00:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4187  Corr: 0.2016  Loss: 2.7723 
2021-01-28 19:00:58:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3395  Has0_acc_2: 0.5537  Has0_F1_score: 0.6441  Non0_acc_2: 0.5394  Non0_F1_score: 0.6323  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3255  Corr: -0.0231 
2021-01-28 19:00:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4188  Corr: 0.1517  Loss: 2.6816 
2021-01-28 19:01:15:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.3315  Has0_acc_2: 0.5701  Has0_F1_score: 0.7180  Non0_acc_2: 0.5516  Non0_F1_score: 0.7025  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3263  Corr: -0.0281 
2021-01-28 19:01:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4249  Corr: 0.1237  Loss: 2.7716 
2021-01-28 19:01:32:INFO:TRAIN-(misa) (4/6/1)>> loss: 2.3072  Has0_acc_2: 0.5615  Has0_F1_score: 0.7012  Non0_acc_2: 0.5426  Non0_F1_score: 0.6849  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3198  Corr: 0.0078 
2021-01-28 19:01:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4194  Corr: 0.1018  Loss: 2.7474 
2021-01-28 19:01:50:INFO:TRAIN-(misa) (5/7/1)>> loss: 2.3073  Has0_acc_2: 0.5646  Has0_F1_score: 0.7137  Non0_acc_2: 0.5459  Non0_F1_score: 0.6980  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3205  Corr: -0.0202 
2021-01-28 19:01:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4189  Corr: 0.1000  Loss: 2.7180 
2021-01-28 19:02:08:INFO:TRAIN-(misa) (6/8/1)>> loss: 2.3057  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3222  Corr: -0.0096 
2021-01-28 19:02:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4225  Corr: 0.1054  Loss: 2.6987 
2021-01-28 19:02:25:INFO:TRAIN-(misa) (7/9/1)>> loss: 2.2999  Has0_acc_2: 0.5405  Has0_F1_score: 0.6049  Non0_acc_2: 0.5313  Non0_F1_score: 0.5989  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3205  Corr: 0.0213 
2021-01-28 19:02:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4152  Corr: 0.0114  Loss: 2.7629 
2021-01-28 19:02:43:INFO:TRAIN-(misa) (8/10/1)>> loss: 2.3518  Has0_acc_2: 0.5607  Has0_F1_score: 0.6855  Non0_acc_2: 0.5435  Non0_F1_score: 0.6710  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3236  Corr: -0.0145 
2021-01-28 19:02:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4153  Corr: 0.0581  Loss: 2.6892 
2021-01-28 19:02:46:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4721  Corr: 0.1602  Loss: 2.8633 
2021-01-28 19:02:46:INFO:Start saving results...
2021-01-28 19:02:46:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:02:46:INFO:########################################misa-(27/50)########################################
2021-01-28 19:02:46:INFO:batch_size:32
2021-01-28 19:02:46:INFO:learning_rate:0.0001
2021-01-28 19:02:46:INFO:hidden_size:64
2021-01-28 19:02:46:INFO:dropout:0.2
2021-01-28 19:02:46:INFO:reverse_grad_weight:0.8
2021-01-28 19:02:46:INFO:diff_weight:0.5
2021-01-28 19:02:46:INFO:sim_weight:1.0
2021-01-28 19:02:46:INFO:sp_weight:0.0
2021-01-28 19:02:46:INFO:recon_weight:0.8
2021-01-28 19:02:46:INFO:grad_clip:0.8
2021-01-28 19:02:46:INFO:weight_decay:5e-05
2021-01-28 19:02:46:INFO:##########################################################################################
2021-01-28 19:02:46:INFO:Start running misa...
2021-01-28 19:02:46:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 19:02:46:INFO:Let's use 1 GPUs!
2021-01-28 19:02:46:INFO:train samples: (1284,)
2021-01-28 19:02:47:INFO:valid samples: (229,)
2021-01-28 19:02:48:INFO:test samples: (686,)
2021-01-28 19:02:48:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:02:48:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:02:48:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:02:48:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:02:48:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:02:48:INFO:loading file None
2021-01-28 19:02:48:INFO:loading file None
2021-01-28 19:02:48:INFO:loading file None
2021-01-28 19:02:48:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:02:48:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:02:48:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:02:51:INFO:The model has 109943985 trainable parameters
2021-01-28 19:03:03:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.0038  Has0_acc_2: 0.6667  Has0_F1_score: 0.6932  Non0_acc_2: 0.6645  Non0_F1_score: 0.6923  Mult_acc_5: 0.2134  Mult_acc_7: 0.2134  MAE: 1.2013  Corr: 0.4578 
2021-01-28 19:03:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8193  Non0_acc_2: 0.8519  Non0_F1_score: 0.8511  Mult_acc_5: 0.2664  Mult_acc_7: 0.2664  MAE: 1.0571  Corr: 0.7414  Loss: 1.5613 
2021-01-28 19:03:17:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5232  Has0_acc_2: 0.8442  Has0_F1_score: 0.8437  Non0_acc_2: 0.8627  Non0_F1_score: 0.8626  Mult_acc_5: 0.3840  Mult_acc_7: 0.3668  MAE: 0.7480  Corr: 0.8075 
2021-01-28 19:03:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7813  Non0_acc_2: 0.8009  Non0_F1_score: 0.8017  Mult_acc_5: 0.4410  Mult_acc_7: 0.3581  MAE: 0.8876  Corr: 0.7279  Loss: 1.2683 
2021-01-28 19:03:31:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.7672  Has0_acc_2: 0.8886  Has0_F1_score: 0.8883  Non0_acc_2: 0.9115  Non0_F1_score: 0.9115  Mult_acc_5: 0.5514  Mult_acc_7: 0.5117  MAE: 0.5464  Corr: 0.8895 
2021-01-28 19:03:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8112  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.4454  Mult_acc_7: 0.3668  MAE: 0.8333  Corr: 0.7584  Loss: 1.1499 
2021-01-28 19:03:46:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.4319  Has0_acc_2: 0.8863  Has0_F1_score: 0.8861  Non0_acc_2: 0.9058  Non0_F1_score: 0.9059  Mult_acc_5: 0.5833  Mult_acc_7: 0.5296  MAE: 0.5107  Corr: 0.9048 
2021-01-28 19:03:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8404  Non0_acc_2: 0.8426  Non0_F1_score: 0.8449  Mult_acc_5: 0.5022  Mult_acc_7: 0.3930  MAE: 0.7943  Corr: 0.7769  Loss: 1.1117 
2021-01-28 19:04:01:INFO:TRAIN-(misa) (1/5/1)>> loss: 1.1212  Has0_acc_2: 0.9097  Has0_F1_score: 0.9095  Non0_acc_2: 0.9253  Non0_F1_score: 0.9253  Mult_acc_5: 0.6449  Mult_acc_7: 0.5935  MAE: 0.4321  Corr: 0.9356 
2021-01-28 19:04:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8341  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.4847  Mult_acc_7: 0.3799  MAE: 0.7671  Corr: 0.7836  Loss: 1.0107 
2021-01-28 19:04:16:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.9132  Has0_acc_2: 0.9174  Has0_F1_score: 0.9174  Non0_acc_2: 0.9334  Non0_F1_score: 0.9335  Mult_acc_5: 0.6659  Mult_acc_7: 0.6121  MAE: 0.3936  Corr: 0.9460 
2021-01-28 19:04:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.4847  Mult_acc_7: 0.3668  MAE: 0.7393  Corr: 0.7921  Loss: 1.0071 
2021-01-28 19:04:30:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.7844  Has0_acc_2: 0.9260  Has0_F1_score: 0.9260  Non0_acc_2: 0.9407  Non0_F1_score: 0.9408  Mult_acc_5: 0.6877  Mult_acc_7: 0.6176  MAE: 0.3907  Corr: 0.9453 
2021-01-28 19:04:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8380  Non0_F1_score: 0.8372  Mult_acc_5: 0.4672  Mult_acc_7: 0.3581  MAE: 0.8062  Corr: 0.7726  Loss: 1.1723 
2021-01-28 19:04:44:INFO:TRAIN-(misa) (2/8/1)>> loss: 0.6745  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9439  Non0_F1_score: 0.9440  Mult_acc_5: 0.6729  Mult_acc_7: 0.6129  MAE: 0.3759  Corr: 0.9499 
2021-01-28 19:04:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8380  Non0_F1_score: 0.8375  Mult_acc_5: 0.5153  Mult_acc_7: 0.4061  MAE: 0.7506  Corr: 0.7805  Loss: 1.0275 
2021-01-28 19:04:57:INFO:TRAIN-(misa) (3/9/1)>> loss: 0.5973  Has0_acc_2: 0.9034  Has0_F1_score: 0.9033  Non0_acc_2: 0.9188  Non0_F1_score: 0.9189  Mult_acc_5: 0.6752  Mult_acc_7: 0.6246  MAE: 0.3866  Corr: 0.9486 
2021-01-28 19:04:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8236  Non0_acc_2: 0.8565  Non0_F1_score: 0.8557  Mult_acc_5: 0.4803  Mult_acc_7: 0.3974  MAE: 0.7941  Corr: 0.7782  Loss: 1.1004 
2021-01-28 19:05:10:INFO:TRAIN-(misa) (4/10/1)>> loss: 0.5528  Has0_acc_2: 0.9128  Has0_F1_score: 0.9126  Non0_acc_2: 0.9285  Non0_F1_score: 0.9285  Mult_acc_5: 0.6636  Mult_acc_7: 0.6098  MAE: 0.3919  Corr: 0.9456 
2021-01-28 19:05:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4891  Mult_acc_7: 0.3712  MAE: 0.8011  Corr: 0.7916  Loss: 1.1551 
2021-01-28 19:05:23:INFO:TRAIN-(misa) (5/11/1)>> loss: 0.4856  Has0_acc_2: 0.9315  Has0_F1_score: 0.9314  Non0_acc_2: 0.9456  Non0_F1_score: 0.9456  Mult_acc_5: 0.6908  Mult_acc_7: 0.6386  MAE: 0.3605  Corr: 0.9543 
2021-01-28 19:05:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7324  Corr: 0.7994  Loss: 1.4841 
2021-01-28 19:05:36:INFO:TRAIN-(misa) (6/12/1)>> loss: 0.4627  Has0_acc_2: 0.9182  Has0_F1_score: 0.9181  Non0_acc_2: 0.9342  Non0_F1_score: 0.9343  Mult_acc_5: 0.6916  Mult_acc_7: 0.6379  MAE: 0.3678  Corr: 0.9523 
2021-01-28 19:05:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8515  Has0_F1_score: 0.8528  Non0_acc_2: 0.8565  Non0_F1_score: 0.8580  Mult_acc_5: 0.4934  Mult_acc_7: 0.3930  MAE: 0.7791  Corr: 0.8066  Loss: 1.1505 
2021-01-28 19:05:49:INFO:TRAIN-(misa) (7/13/1)>> loss: 0.4616  Has0_acc_2: 0.9120  Has0_F1_score: 0.9118  Non0_acc_2: 0.9301  Non0_F1_score: 0.9302  Mult_acc_5: 0.6713  Mult_acc_7: 0.6129  MAE: 0.3873  Corr: 0.9472 
2021-01-28 19:05:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8341  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.5502  Mult_acc_7: 0.4498  MAE: 0.7593  Corr: 0.8046  Loss: 1.2600 
2021-01-28 19:06:02:INFO:TRAIN-(misa) (8/14/1)>> loss: 0.3892  Has0_acc_2: 0.9299  Has0_F1_score: 0.9299  Non0_acc_2: 0.9415  Non0_F1_score: 0.9416  Mult_acc_5: 0.7212  Mult_acc_7: 0.6690  MAE: 0.3369  Corr: 0.9593 
2021-01-28 19:06:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5415  Mult_acc_7: 0.4279  MAE: 0.7523  Corr: 0.7946  Loss: 0.9984 
2021-01-28 19:06:16:INFO:TRAIN-(misa) (1/15/1)>> loss: 0.3936  Has0_acc_2: 0.9237  Has0_F1_score: 0.9236  Non0_acc_2: 0.9415  Non0_F1_score: 0.9416  Mult_acc_5: 0.7142  Mult_acc_7: 0.6604  MAE: 0.3479  Corr: 0.9571 
2021-01-28 19:06:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8462  Non0_acc_2: 0.8704  Non0_F1_score: 0.8702  Mult_acc_5: 0.5153  Mult_acc_7: 0.4410  MAE: 0.7333  Corr: 0.7925  Loss: 1.4561 
2021-01-28 19:06:29:INFO:TRAIN-(misa) (2/16/1)>> loss: 0.3742  Has0_acc_2: 0.9245  Has0_F1_score: 0.9244  Non0_acc_2: 0.9399  Non0_F1_score: 0.9400  Mult_acc_5: 0.7095  Mult_acc_7: 0.6597  MAE: 0.3534  Corr: 0.9566 
2021-01-28 19:06:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8222  Non0_acc_2: 0.8194  Non0_F1_score: 0.8254  Mult_acc_5: 0.4629  Mult_acc_7: 0.3581  MAE: 0.8186  Corr: 0.7917  Loss: 1.3164 
2021-01-28 19:06:42:INFO:TRAIN-(misa) (3/17/1)>> loss: 0.3571  Has0_acc_2: 0.9276  Has0_F1_score: 0.9275  Non0_acc_2: 0.9431  Non0_F1_score: 0.9432  Mult_acc_5: 0.7181  Mult_acc_7: 0.6706  MAE: 0.3330  Corr: 0.9603 
2021-01-28 19:06:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8309  Non0_acc_2: 0.8380  Non0_F1_score: 0.8397  Mult_acc_5: 0.4978  Mult_acc_7: 0.4105  MAE: 0.7409  Corr: 0.7978  Loss: 1.2350 
2021-01-28 19:06:54:INFO:TRAIN-(misa) (4/18/1)>> loss: 0.3552  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9464  Non0_F1_score: 0.9464  Mult_acc_5: 0.7095  Mult_acc_7: 0.6651  MAE: 0.3545  Corr: 0.9563 
2021-01-28 19:06:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5066  Mult_acc_7: 0.3974  MAE: 0.7315  Corr: 0.7991  Loss: 1.2297 
2021-01-28 19:07:07:INFO:TRAIN-(misa) (5/19/1)>> loss: 0.2993  Has0_acc_2: 0.9221  Has0_F1_score: 0.9220  Non0_acc_2: 0.9407  Non0_F1_score: 0.9407  Mult_acc_5: 0.7438  Mult_acc_7: 0.6994  MAE: 0.3072  Corr: 0.9671 
2021-01-28 19:07:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8318  Non0_acc_2: 0.8333  Non0_F1_score: 0.8357  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.8035  Corr: 0.7941  Loss: 1.1064 
2021-01-28 19:07:20:INFO:TRAIN-(misa) (6/20/1)>> loss: 0.2950  Has0_acc_2: 0.9245  Has0_F1_score: 0.9243  Non0_acc_2: 0.9448  Non0_F1_score: 0.9448  Mult_acc_5: 0.7352  Mult_acc_7: 0.6908  MAE: 0.3097  Corr: 0.9668 
2021-01-28 19:07:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8054  Non0_acc_2: 0.8148  Non0_F1_score: 0.8175  Mult_acc_5: 0.4716  Mult_acc_7: 0.3668  MAE: 0.7954  Corr: 0.7977  Loss: 1.0915 
2021-01-28 19:07:33:INFO:TRAIN-(misa) (7/21/1)>> loss: 0.3153  Has0_acc_2: 0.9393  Has0_F1_score: 0.9392  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7142  Mult_acc_7: 0.6612  MAE: 0.3397  Corr: 0.9597 
2021-01-28 19:07:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8283  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5502  Mult_acc_7: 0.4541  MAE: 0.7238  Corr: 0.8006  Loss: 1.0413 
2021-01-28 19:07:45:INFO:TRAIN-(misa) (8/22/1)>> loss: 0.3029  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7266  Mult_acc_7: 0.6783  MAE: 0.3211  Corr: 0.9629 
2021-01-28 19:07:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7288  Corr: 0.7962  Loss: 0.9162 
2021-01-28 19:07:59:INFO:TRAIN-(misa) (1/23/1)>> loss: 0.3117  Has0_acc_2: 0.9221  Has0_F1_score: 0.9219  Non0_acc_2: 0.9431  Non0_F1_score: 0.9432  Mult_acc_5: 0.7150  Mult_acc_7: 0.6682  MAE: 0.3344  Corr: 0.9609 
2021-01-28 19:08:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8307  Non0_acc_2: 0.8287  Non0_F1_score: 0.8343  Mult_acc_5: 0.4672  Mult_acc_7: 0.3581  MAE: 0.8622  Corr: 0.8055  Loss: 1.3128 
2021-01-28 19:08:12:INFO:TRAIN-(misa) (2/24/1)>> loss: 0.3426  Has0_acc_2: 0.9221  Has0_F1_score: 0.9220  Non0_acc_2: 0.9350  Non0_F1_score: 0.9350  Mult_acc_5: 0.6768  Mult_acc_7: 0.6269  MAE: 0.3729  Corr: 0.9526 
2021-01-28 19:08:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8392  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.4978  Mult_acc_7: 0.3974  MAE: 0.7294  Corr: 0.8163  Loss: 1.0268 
2021-01-28 19:08:24:INFO:TRAIN-(misa) (3/25/1)>> loss: 0.2600  Has0_acc_2: 0.9377  Has0_F1_score: 0.9376  Non0_acc_2: 0.9529  Non0_F1_score: 0.9529  Mult_acc_5: 0.7648  Mult_acc_7: 0.7313  MAE: 0.2899  Corr: 0.9693 
2021-01-28 19:08:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8383  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5153  Mult_acc_7: 0.4017  MAE: 0.7291  Corr: 0.8079  Loss: 0.9447 
2021-01-28 19:08:38:INFO:TRAIN-(misa) (4/26/1)>> loss: 0.2414  Has0_acc_2: 0.9377  Has0_F1_score: 0.9376  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7656  Mult_acc_7: 0.7290  MAE: 0.2863  Corr: 0.9719 
2021-01-28 19:08:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8193  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7337  Corr: 0.8051  Loss: 0.9795 
2021-01-28 19:08:50:INFO:TRAIN-(misa) (5/27/1)>> loss: 0.2590  Has0_acc_2: 0.9221  Has0_F1_score: 0.9219  Non0_acc_2: 0.9407  Non0_F1_score: 0.9407  Mult_acc_5: 0.7251  Mult_acc_7: 0.6799  MAE: 0.3084  Corr: 0.9676 
2021-01-28 19:08:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8415  Non0_acc_2: 0.8657  Non0_F1_score: 0.8652  Mult_acc_5: 0.4978  Mult_acc_7: 0.4017  MAE: 0.7272  Corr: 0.8027  Loss: 1.0471 
2021-01-28 19:09:02:INFO:TRAIN-(misa) (6/28/1)>> loss: 0.2475  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9569  Non0_F1_score: 0.9569  Mult_acc_5: 0.7391  Mult_acc_7: 0.6908  MAE: 0.2931  Corr: 0.9692 
2021-01-28 19:09:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8386  Non0_acc_2: 0.8565  Non0_F1_score: 0.8573  Mult_acc_5: 0.5109  Mult_acc_7: 0.3930  MAE: 0.7394  Corr: 0.8099  Loss: 0.9780 
2021-01-28 19:09:15:INFO:TRAIN-(misa) (7/29/1)>> loss: 0.2318  Has0_acc_2: 0.9354  Has0_F1_score: 0.9352  Non0_acc_2: 0.9513  Non0_F1_score: 0.9512  Mult_acc_5: 0.7687  Mult_acc_7: 0.7134  MAE: 0.2832  Corr: 0.9719 
2021-01-28 19:09:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5109  Mult_acc_7: 0.4017  MAE: 0.7439  Corr: 0.8056  Loss: 0.9634 
2021-01-28 19:09:27:INFO:TRAIN-(misa) (8/30/1)>> loss: 0.2303  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7422  Mult_acc_7: 0.6916  MAE: 0.2828  Corr: 0.9715 
2021-01-28 19:09:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5328  Mult_acc_7: 0.4279  MAE: 0.7159  Corr: 0.8100  Loss: 0.9725 
2021-01-28 19:09:31:INFO:TEST-(misa) >>  Has0_acc_2: 0.8149  Has0_F1_score: 0.8157  Non0_acc_2: 0.8354  Non0_F1_score: 0.8355  Mult_acc_5: 0.4883  Mult_acc_7: 0.4271  MAE: 0.7713  Corr: 0.7680  Loss: 1.0861 
2021-01-28 19:09:31:INFO:Start saving results...
2021-01-28 19:09:31:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:09:31:INFO:########################################misa-(28/50)########################################
2021-01-28 19:09:31:INFO:batch_size:16
2021-01-28 19:09:31:INFO:learning_rate:0.0005
2021-01-28 19:09:31:INFO:hidden_size:64
2021-01-28 19:09:31:INFO:dropout:0.5
2021-01-28 19:09:31:INFO:reverse_grad_weight:1.0
2021-01-28 19:09:31:INFO:diff_weight:0.1
2021-01-28 19:09:31:INFO:sim_weight:0.8
2021-01-28 19:09:31:INFO:sp_weight:0.0
2021-01-28 19:09:31:INFO:recon_weight:0.5
2021-01-28 19:09:31:INFO:grad_clip:-1.0
2021-01-28 19:09:31:INFO:weight_decay:0.0
2021-01-28 19:09:31:INFO:##########################################################################################
2021-01-28 19:09:31:INFO:Start running misa...
2021-01-28 19:09:31:INFO:Find gpu: 1, with memory: 1665990656 left!
2021-01-28 19:09:31:INFO:Let's use 1 GPUs!
2021-01-28 19:09:36:INFO:train samples: (1284,)
2021-01-28 19:09:37:INFO:valid samples: (229,)
2021-01-28 19:09:37:INFO:test samples: (686,)
2021-01-28 19:09:37:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:09:37:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:09:37:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:09:37:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:09:37:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:09:37:INFO:loading file None
2021-01-28 19:09:37:INFO:loading file None
2021-01-28 19:09:37:INFO:loading file None
2021-01-28 19:09:37:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:09:37:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:09:37:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:09:40:INFO:The model has 109943985 trainable parameters
2021-01-28 19:09:56:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.1118  Has0_acc_2: 0.5592  Has0_F1_score: 0.5916  Non0_acc_2: 0.5548  Non0_F1_score: 0.5895  Mult_acc_5: 0.1970  Mult_acc_7: 0.1970  MAE: 1.3158  Corr: 0.0621 
2021-01-28 19:09:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4123  Corr: 0.1071  Loss: 2.7206 
2021-01-28 19:10:14:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4497  Has0_acc_2: 0.5646  Has0_F1_score: 0.6147  Non0_acc_2: 0.5524  Non0_F1_score: 0.6038  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3045  Corr: 0.1161 
2021-01-28 19:10:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4089  Corr: 0.1501  Loss: 2.6793 
2021-01-28 19:10:32:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.3625  Has0_acc_2: 0.5911  Has0_F1_score: 0.6197  Non0_acc_2: 0.5816  Non0_F1_score: 0.6110  Mult_acc_5: 0.1822  Mult_acc_7: 0.1822  MAE: 1.3043  Corr: 0.1436 
2021-01-28 19:10:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.4016  Corr: 0.1694  Loss: 2.7079 
2021-01-28 19:10:49:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.2414  Has0_acc_2: 0.6044  Has0_F1_score: 0.6403  Non0_acc_2: 0.5930  Non0_F1_score: 0.6295  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.2755  Corr: 0.2337 
2021-01-28 19:10:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7409  Non0_acc_2: 0.5741  Non0_F1_score: 0.7213  Mult_acc_5: 0.1659  Mult_acc_7: 0.1659  MAE: 1.4066  Corr: 0.1579  Loss: 2.6533 
2021-01-28 19:11:09:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.2162  Has0_acc_2: 0.6176  Has0_F1_score: 0.6475  Non0_acc_2: 0.6084  Non0_F1_score: 0.6389  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.2569  Corr: 0.2574 
2021-01-28 19:11:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7409  Non0_acc_2: 0.5741  Non0_F1_score: 0.7213  Mult_acc_5: 0.1921  Mult_acc_7: 0.1921  MAE: 1.3983  Corr: 0.1761  Loss: 2.6992 
2021-01-28 19:11:28:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.1716  Has0_acc_2: 0.6051  Has0_F1_score: 0.6305  Non0_acc_2: 0.5971  Non0_F1_score: 0.6232  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2509  Corr: 0.2853 
2021-01-28 19:11:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4081  Corr: 0.1968  Loss: 2.7912 
2021-01-28 19:11:47:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.1091  Has0_acc_2: 0.6246  Has0_F1_score: 0.6412  Non0_acc_2: 0.6174  Non0_F1_score: 0.6344  Mult_acc_5: 0.1986  Mult_acc_7: 0.1978  MAE: 1.2291  Corr: 0.3313 
2021-01-28 19:11:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7265  Non0_acc_2: 0.6019  Non0_F1_score: 0.7064  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.3871  Corr: 0.1867  Loss: 2.6737 
2021-01-28 19:12:06:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.0916  Has0_acc_2: 0.6285  Has0_F1_score: 0.6399  Non0_acc_2: 0.6223  Non0_F1_score: 0.6340  Mult_acc_5: 0.2103  Mult_acc_7: 0.2095  MAE: 1.2165  Corr: 0.3409 
2021-01-28 19:12:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7265  Non0_acc_2: 0.6019  Non0_F1_score: 0.7064  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.3846  Corr: 0.1754  Loss: 2.6468 
2021-01-28 19:12:26:INFO:TRAIN-(misa) (1/9/1)>> loss: 1.9488  Has0_acc_2: 0.6690  Has0_F1_score: 0.6753  Non0_acc_2: 0.6694  Non0_F1_score: 0.6764  Mult_acc_5: 0.2243  Mult_acc_7: 0.2212  MAE: 1.1640  Corr: 0.4159 
2021-01-28 19:12:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7447  Non0_acc_2: 0.5972  Non0_F1_score: 0.7255  Mult_acc_5: 0.1878  Mult_acc_7: 0.1747  MAE: 1.4191  Corr: 0.1659  Loss: 2.9644 
2021-01-28 19:12:45:INFO:TRAIN-(misa) (2/10/1)>> loss: 2.0433  Has0_acc_2: 0.6612  Has0_F1_score: 0.6758  Non0_acc_2: 0.6539  Non0_F1_score: 0.6687  Mult_acc_5: 0.2165  Mult_acc_7: 0.2142  MAE: 1.1835  Corr: 0.3869 
2021-01-28 19:12:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.6419  Has0_F1_score: 0.7113  Non0_acc_2: 0.6250  Non0_F1_score: 0.6967  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3648  Corr: 0.2096  Loss: 2.5940 
2021-01-28 19:13:06:INFO:TRAIN-(misa) (1/11/1)>> loss: 1.9277  Has0_acc_2: 0.6636  Has0_F1_score: 0.6696  Non0_acc_2: 0.6637  Non0_F1_score: 0.6704  Mult_acc_5: 0.2165  Mult_acc_7: 0.2150  MAE: 1.1529  Corr: 0.4369 
2021-01-28 19:13:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.1834  Mult_acc_7: 0.1659  MAE: 1.4337  Corr: 0.1689  Loss: 3.2916 
2021-01-28 19:13:25:INFO:TRAIN-(misa) (2/12/1)>> loss: 1.9242  Has0_acc_2: 0.6651  Has0_F1_score: 0.6734  Non0_acc_2: 0.6621  Non0_F1_score: 0.6708  Mult_acc_5: 0.2235  Mult_acc_7: 0.2220  MAE: 1.1478  Corr: 0.4318 
2021-01-28 19:13:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5677  Has0_F1_score: 0.5698  Non0_acc_2: 0.5648  Non0_F1_score: 0.5689  Mult_acc_5: 0.2489  Mult_acc_7: 0.2489  MAE: 1.3838  Corr: 0.1767  Loss: 2.6517 
2021-01-28 19:13:44:INFO:TRAIN-(misa) (3/13/1)>> loss: 1.9445  Has0_acc_2: 0.6597  Has0_F1_score: 0.6665  Non0_acc_2: 0.6588  Non0_F1_score: 0.6663  Mult_acc_5: 0.2204  Mult_acc_7: 0.2173  MAE: 1.1569  Corr: 0.4295 
2021-01-28 19:13:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6742  Non0_acc_2: 0.6019  Non0_F1_score: 0.6632  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3675  Corr: 0.1939  Loss: 2.6362 
2021-01-28 19:14:03:INFO:TRAIN-(misa) (4/14/1)>> loss: 1.9603  Has0_acc_2: 0.6519  Has0_F1_score: 0.6598  Non0_acc_2: 0.6474  Non0_F1_score: 0.6558  Mult_acc_5: 0.2266  Mult_acc_7: 0.2235  MAE: 1.1636  Corr: 0.4242 
2021-01-28 19:14:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7444  Non0_acc_2: 0.6019  Non0_F1_score: 0.7253  Mult_acc_5: 0.1878  Mult_acc_7: 0.1747  MAE: 1.3945  Corr: 0.2461  Loss: 2.8473 
2021-01-28 19:14:21:INFO:TRAIN-(misa) (5/15/1)>> loss: 1.8403  Has0_acc_2: 0.6947  Has0_F1_score: 0.7032  Non0_acc_2: 0.6946  Non0_F1_score: 0.7036  Mult_acc_5: 0.2336  Mult_acc_7: 0.2298  MAE: 1.1242  Corr: 0.4717 
2021-01-28 19:14:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7141  Non0_acc_2: 0.6157  Non0_F1_score: 0.6937  Mult_acc_5: 0.2009  Mult_acc_7: 0.1878  MAE: 1.3609  Corr: 0.2469  Loss: 2.7183 
2021-01-28 19:14:40:INFO:TRAIN-(misa) (6/16/1)>> loss: 1.7899  Has0_acc_2: 0.6854  Has0_F1_score: 0.6935  Non0_acc_2: 0.6824  Non0_F1_score: 0.6909  Mult_acc_5: 0.2445  Mult_acc_7: 0.2399  MAE: 1.1042  Corr: 0.4962 
2021-01-28 19:14:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.6693  Non0_acc_2: 0.6065  Non0_F1_score: 0.6580  Mult_acc_5: 0.2314  Mult_acc_7: 0.2052  MAE: 1.3548  Corr: 0.2402  Loss: 2.6859 
2021-01-28 19:14:59:INFO:TRAIN-(misa) (7/17/1)>> loss: 1.7729  Has0_acc_2: 0.6955  Has0_F1_score: 0.7016  Non0_acc_2: 0.6929  Non0_F1_score: 0.6994  Mult_acc_5: 0.2570  Mult_acc_7: 0.2523  MAE: 1.0986  Corr: 0.4984 
2021-01-28 19:15:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7210  Non0_acc_2: 0.6250  Non0_F1_score: 0.7011  Mult_acc_5: 0.1878  Mult_acc_7: 0.1790  MAE: 1.3603  Corr: 0.2663  Loss: 2.7686 
2021-01-28 19:15:18:INFO:TRAIN-(misa) (8/18/1)>> loss: 1.7905  Has0_acc_2: 0.7002  Has0_F1_score: 0.7065  Non0_acc_2: 0.6978  Non0_F1_score: 0.7044  Mult_acc_5: 0.2430  Mult_acc_7: 0.2383  MAE: 1.1033  Corr: 0.4958 
2021-01-28 19:15:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.6507  Has0_F1_score: 0.7356  Non0_acc_2: 0.6296  Non0_F1_score: 0.7165  Mult_acc_5: 0.2227  Mult_acc_7: 0.1921  MAE: 1.4133  Corr: 0.2520  Loss: 3.0656 
2021-01-28 19:15:23:INFO:TEST-(misa) >>  Has0_acc_2: 0.5073  Has0_F1_score: 0.5770  Non0_acc_2: 0.4878  Non0_F1_score: 0.5558  Mult_acc_5: 0.1706  Mult_acc_7: 0.1706  MAE: 1.4478  Corr: 0.2255  Loss: 2.8915 
2021-01-28 19:15:23:INFO:Start saving results...
2021-01-28 19:15:23:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:15:23:INFO:########################################misa-(29/50)########################################
2021-01-28 19:15:23:INFO:batch_size:64
2021-01-28 19:15:23:INFO:learning_rate:0.0001
2021-01-28 19:15:23:INFO:hidden_size:256
2021-01-28 19:15:23:INFO:dropout:0.5
2021-01-28 19:15:23:INFO:reverse_grad_weight:1.0
2021-01-28 19:15:23:INFO:diff_weight:0.1
2021-01-28 19:15:23:INFO:sim_weight:0.5
2021-01-28 19:15:23:INFO:sp_weight:1.0
2021-01-28 19:15:23:INFO:recon_weight:1.0
2021-01-28 19:15:23:INFO:grad_clip:-1.0
2021-01-28 19:15:23:INFO:weight_decay:5e-05
2021-01-28 19:15:23:INFO:##########################################################################################
2021-01-28 19:15:23:INFO:Start running misa...
2021-01-28 19:15:23:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:15:23:INFO:Let's use 1 GPUs!
2021-01-28 19:15:23:INFO:train samples: (1284,)
2021-01-28 19:15:24:INFO:valid samples: (229,)
2021-01-28 19:15:24:INFO:test samples: (686,)
2021-01-28 19:15:24:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:15:24:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:15:24:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:15:24:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:15:24:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:15:24:INFO:loading file None
2021-01-28 19:15:24:INFO:loading file None
2021-01-28 19:15:24:INFO:loading file None
2021-01-28 19:15:24:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:15:24:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:15:24:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:15:28:INFO:The model has 112685553 trainable parameters
2021-01-28 19:15:38:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.3729  Has0_acc_2: 0.5771  Has0_F1_score: 0.5953  Non0_acc_2: 0.5727  Non0_F1_score: 0.5922  Mult_acc_5: 0.2103  Mult_acc_7: 0.2103  MAE: 1.2752  Corr: 0.1886 
2021-01-28 19:15:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.7467  Has0_F1_score: 0.7469  Non0_acc_2: 0.7685  Non0_F1_score: 0.7697  Mult_acc_5: 0.2314  Mult_acc_7: 0.2314  MAE: 1.2742  Corr: 0.5813  Loss: 2.1966 
2021-01-28 19:15:51:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.0735  Has0_acc_2: 0.7399  Has0_F1_score: 0.7386  Non0_acc_2: 0.7571  Non0_F1_score: 0.7565  Mult_acc_5: 0.3006  Mult_acc_7: 0.2944  MAE: 0.9895  Corr: 0.5997 
2021-01-28 19:15:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7758  Non0_acc_2: 0.8102  Non0_F1_score: 0.8095  Mult_acc_5: 0.3886  Mult_acc_7: 0.3275  MAE: 0.9424  Corr: 0.7109  Loss: 1.4431 
2021-01-28 19:16:04:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.0232  Has0_acc_2: 0.8528  Has0_F1_score: 0.8521  Non0_acc_2: 0.8741  Non0_F1_score: 0.8738  Mult_acc_5: 0.4229  Mult_acc_7: 0.3925  MAE: 0.7082  Corr: 0.8071 
2021-01-28 19:16:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4279  Mult_acc_7: 0.3406  MAE: 0.8334  Corr: 0.7552  Loss: 1.2202 
2021-01-28 19:16:17:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.4675  Has0_acc_2: 0.8879  Has0_F1_score: 0.8874  Non0_acc_2: 0.9074  Non0_F1_score: 0.9073  Mult_acc_5: 0.5436  Mult_acc_7: 0.4992  MAE: 0.5793  Corr: 0.8717 
2021-01-28 19:16:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8364  Non0_acc_2: 0.8426  Non0_F1_score: 0.8453  Mult_acc_5: 0.4716  Mult_acc_7: 0.3799  MAE: 0.8450  Corr: 0.7768  Loss: 1.3109 
2021-01-28 19:16:29:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.1534  Has0_acc_2: 0.8980  Has0_F1_score: 0.8977  Non0_acc_2: 0.9180  Non0_F1_score: 0.9180  Mult_acc_5: 0.5569  Mult_acc_7: 0.5055  MAE: 0.5318  Corr: 0.8931 
2021-01-28 19:16:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8392  Non0_acc_2: 0.8519  Non0_F1_score: 0.8532  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.8102  Corr: 0.7697  Loss: 1.2597 
2021-01-28 19:16:40:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.7897  Has0_acc_2: 0.9276  Has0_F1_score: 0.9273  Non0_acc_2: 0.9464  Non0_F1_score: 0.9464  Mult_acc_5: 0.6682  Mult_acc_7: 0.6168  MAE: 0.4135  Corr: 0.9368 
2021-01-28 19:16:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.4760  Mult_acc_7: 0.3755  MAE: 0.7583  Corr: 0.7814  Loss: 1.0734 
2021-01-28 19:16:53:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.6034  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7040  Mult_acc_7: 0.6503  MAE: 0.3511  Corr: 0.9553 
2021-01-28 19:16:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.7522  Corr: 0.7845  Loss: 1.0497 
2021-01-28 19:17:06:INFO:TRAIN-(misa) (1/8/1)>> loss: 0.4799  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9626  Non0_F1_score: 0.9627  Mult_acc_5: 0.7531  Mult_acc_7: 0.6970  MAE: 0.2950  Corr: 0.9687 
2021-01-28 19:17:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8611  Non0_F1_score: 0.8611  Mult_acc_5: 0.4760  Mult_acc_7: 0.3799  MAE: 0.7377  Corr: 0.7893  Loss: 1.0653 
2021-01-28 19:17:18:INFO:TRAIN-(misa) (2/9/1)>> loss: 0.4013  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7812  Mult_acc_7: 0.7305  MAE: 0.2731  Corr: 0.9730 
2021-01-28 19:17:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8376  Non0_acc_2: 0.8611  Non0_F1_score: 0.8611  Mult_acc_5: 0.4934  Mult_acc_7: 0.4017  MAE: 0.7328  Corr: 0.7903  Loss: 1.0339 
2021-01-28 19:17:31:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.3603  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7858  Mult_acc_7: 0.7290  MAE: 0.2655  Corr: 0.9752 
2021-01-28 19:17:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8515  Has0_F1_score: 0.8515  Non0_acc_2: 0.8657  Non0_F1_score: 0.8663  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.7477  Corr: 0.7886  Loss: 1.0784 
2021-01-28 19:17:42:INFO:TRAIN-(misa) (2/11/1)>> loss: 0.3261  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8006  Mult_acc_7: 0.7516  MAE: 0.2534  Corr: 0.9771 
2021-01-28 19:17:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8559  Has0_F1_score: 0.8563  Non0_acc_2: 0.8657  Non0_F1_score: 0.8666  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7371  Corr: 0.7970  Loss: 1.0777 
2021-01-28 19:17:54:INFO:TRAIN-(misa) (3/12/1)>> loss: 0.2873  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.7983  Mult_acc_7: 0.7516  MAE: 0.2337  Corr: 0.9811 
2021-01-28 19:17:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8421  Non0_acc_2: 0.8657  Non0_F1_score: 0.8658  Mult_acc_5: 0.5197  Mult_acc_7: 0.4236  MAE: 0.7245  Corr: 0.7988  Loss: 1.0522 
2021-01-28 19:18:05:INFO:TRAIN-(misa) (4/13/1)>> loss: 0.2671  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8162  Mult_acc_7: 0.7765  MAE: 0.2241  Corr: 0.9824 
2021-01-28 19:18:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8328  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.5022  Mult_acc_7: 0.4061  MAE: 0.7303  Corr: 0.7999  Loss: 0.9857 
2021-01-28 19:18:19:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2637  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8022  Mult_acc_7: 0.7570  MAE: 0.2419  Corr: 0.9802 
2021-01-28 19:18:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8194  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.4891  Mult_acc_7: 0.4061  MAE: 0.7369  Corr: 0.7980  Loss: 1.0228 
2021-01-28 19:18:30:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2741  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8014  Mult_acc_7: 0.7570  MAE: 0.2554  Corr: 0.9779 
2021-01-28 19:18:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8472  Non0_F1_score: 0.8466  Mult_acc_5: 0.4760  Mult_acc_7: 0.3886  MAE: 0.7382  Corr: 0.7992  Loss: 1.0786 
2021-01-28 19:18:42:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2606  Has0_acc_2: 0.9650  Has0_F1_score: 0.9649  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.7897  Mult_acc_7: 0.7391  MAE: 0.2520  Corr: 0.9783 
2021-01-28 19:18:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8105  Non0_acc_2: 0.8426  Non0_F1_score: 0.8419  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7513  Corr: 0.8006  Loss: 1.0142 
2021-01-28 19:18:53:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.2372  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8131  Mult_acc_7: 0.7741  MAE: 0.2289  Corr: 0.9814 
2021-01-28 19:18:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8462  Non0_acc_2: 0.8704  Non0_F1_score: 0.8702  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7132  Corr: 0.8011  Loss: 0.9744 
2021-01-28 19:19:07:INFO:TRAIN-(misa) (1/18/1)>> loss: 0.2097  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8435  Mult_acc_7: 0.8030  MAE: 0.1975  Corr: 0.9862 
2021-01-28 19:19:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8462  Non0_acc_2: 0.8750  Non0_F1_score: 0.8749  Mult_acc_5: 0.4934  Mult_acc_7: 0.4105  MAE: 0.7171  Corr: 0.8011  Loss: 0.9991 
2021-01-28 19:19:18:INFO:TRAIN-(misa) (2/19/1)>> loss: 0.1910  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8731  Mult_acc_7: 0.8333  MAE: 0.1865  Corr: 0.9878 
2021-01-28 19:19:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8559  Has0_F1_score: 0.8551  Non0_acc_2: 0.8796  Non0_F1_score: 0.8796  Mult_acc_5: 0.5109  Mult_acc_7: 0.4236  MAE: 0.7055  Corr: 0.8048  Loss: 0.9562 
2021-01-28 19:19:32:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.1818  Has0_acc_2: 0.9665  Has0_F1_score: 0.9664  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8559  Mult_acc_7: 0.8030  MAE: 0.1903  Corr: 0.9874 
2021-01-28 19:19:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7062  Corr: 0.8037  Loss: 0.9609 
2021-01-28 19:19:43:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.1886  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8364  Mult_acc_7: 0.7991  MAE: 0.2004  Corr: 0.9857 
2021-01-28 19:19:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5415  Mult_acc_7: 0.4454  MAE: 0.7164  Corr: 0.8030  Loss: 1.0105 
2021-01-28 19:19:55:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.1711  Has0_acc_2: 0.9735  Has0_F1_score: 0.9735  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8411  Mult_acc_7: 0.8014  MAE: 0.1905  Corr: 0.9872 
2021-01-28 19:19:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8462  Non0_acc_2: 0.8750  Non0_F1_score: 0.8749  Mult_acc_5: 0.5197  Mult_acc_7: 0.4367  MAE: 0.7063  Corr: 0.8054  Loss: 1.0214 
2021-01-28 19:20:06:INFO:TRAIN-(misa) (4/23/1)>> loss: 0.1534  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8637  Mult_acc_7: 0.8240  MAE: 0.1746  Corr: 0.9894 
2021-01-28 19:20:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5240  Mult_acc_7: 0.4410  MAE: 0.6941  Corr: 0.8073  Loss: 0.9737 
2021-01-28 19:20:18:INFO:TRAIN-(misa) (5/24/1)>> loss: 0.1548  Has0_acc_2: 0.9696  Has0_F1_score: 0.9695  Non0_acc_2: 0.9919  Non0_F1_score: 0.9919  Mult_acc_5: 0.8575  Mult_acc_7: 0.8271  MAE: 0.1697  Corr: 0.9896 
2021-01-28 19:20:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8423  Non0_acc_2: 0.8657  Non0_F1_score: 0.8661  Mult_acc_5: 0.5197  Mult_acc_7: 0.4279  MAE: 0.7020  Corr: 0.8054  Loss: 0.9711 
2021-01-28 19:20:29:INFO:TRAIN-(misa) (6/25/1)>> loss: 0.1514  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8637  Mult_acc_7: 0.8287  MAE: 0.1763  Corr: 0.9893 
2021-01-28 19:20:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7001  Corr: 0.8047  Loss: 0.9609 
2021-01-28 19:20:41:INFO:TRAIN-(misa) (7/26/1)>> loss: 0.1638  Has0_acc_2: 0.9720  Has0_F1_score: 0.9719  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8544  Mult_acc_7: 0.8146  MAE: 0.1864  Corr: 0.9875 
2021-01-28 19:20:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7179  Corr: 0.8039  Loss: 1.0120 
2021-01-28 19:20:52:INFO:TRAIN-(misa) (8/27/1)>> loss: 0.1520  Has0_acc_2: 0.9657  Has0_F1_score: 0.9656  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8684  Mult_acc_7: 0.8255  MAE: 0.1868  Corr: 0.9881 
2021-01-28 19:20:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7085  Corr: 0.8042  Loss: 0.9091 
2021-01-28 19:21:05:INFO:TRAIN-(misa) (1/28/1)>> loss: 0.1474  Has0_acc_2: 0.9673  Has0_F1_score: 0.9672  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8474  Mult_acc_7: 0.8131  MAE: 0.1813  Corr: 0.9886 
2021-01-28 19:21:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8419  Non0_acc_2: 0.8704  Non0_F1_score: 0.8704  Mult_acc_5: 0.5371  Mult_acc_7: 0.4498  MAE: 0.7069  Corr: 0.8040  Loss: 1.0216 
2021-01-28 19:21:16:INFO:TRAIN-(misa) (2/29/1)>> loss: 0.1432  Has0_acc_2: 0.9657  Has0_F1_score: 0.9656  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8668  Mult_acc_7: 0.8248  MAE: 0.1728  Corr: 0.9896 
2021-01-28 19:21:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.6963  Corr: 0.8075  Loss: 0.9593 
2021-01-28 19:21:28:INFO:TRAIN-(misa) (3/30/1)>> loss: 0.1331  Has0_acc_2: 0.9688  Has0_F1_score: 0.9688  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8590  Mult_acc_7: 0.8271  MAE: 0.1692  Corr: 0.9901 
2021-01-28 19:21:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8611  Non0_F1_score: 0.8616  Mult_acc_5: 0.5284  Mult_acc_7: 0.4279  MAE: 0.7047  Corr: 0.8076  Loss: 1.0696 
2021-01-28 19:21:40:INFO:TRAIN-(misa) (4/31/1)>> loss: 0.1330  Has0_acc_2: 0.9681  Has0_F1_score: 0.9680  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8746  Mult_acc_7: 0.8435  MAE: 0.1726  Corr: 0.9895 
2021-01-28 19:21:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8515  Has0_F1_score: 0.8508  Non0_acc_2: 0.8750  Non0_F1_score: 0.8751  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7013  Corr: 0.8075  Loss: 0.9249 
2021-01-28 19:21:51:INFO:TRAIN-(misa) (5/32/1)>> loss: 0.1262  Has0_acc_2: 0.9720  Has0_F1_score: 0.9719  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.8684  Mult_acc_7: 0.8380  MAE: 0.1602  Corr: 0.9910 
2021-01-28 19:21:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5240  Mult_acc_7: 0.4410  MAE: 0.7027  Corr: 0.8084  Loss: 0.9326 
2021-01-28 19:22:03:INFO:TRAIN-(misa) (6/33/1)>> loss: 0.1197  Has0_acc_2: 0.9657  Has0_F1_score: 0.9656  Non0_acc_2: 0.9927  Non0_F1_score: 0.9927  Mult_acc_5: 0.8692  Mult_acc_7: 0.8318  MAE: 0.1585  Corr: 0.9910 
2021-01-28 19:22:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8462  Non0_acc_2: 0.8750  Non0_F1_score: 0.8749  Mult_acc_5: 0.5109  Mult_acc_7: 0.4279  MAE: 0.7155  Corr: 0.8074  Loss: 0.9173 
2021-01-28 19:22:14:INFO:TRAIN-(misa) (7/34/1)>> loss: 0.1307  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8653  Mult_acc_7: 0.8271  MAE: 0.1761  Corr: 0.9895 
2021-01-28 19:22:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5153  Mult_acc_7: 0.4192  MAE: 0.7046  Corr: 0.8066  Loss: 0.9725 
2021-01-28 19:22:26:INFO:TRAIN-(misa) (8/35/1)>> loss: 0.1370  Has0_acc_2: 0.9579  Has0_F1_score: 0.9578  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8271  Mult_acc_7: 0.7913  MAE: 0.2028  Corr: 0.9859 
2021-01-28 19:22:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8372  Non0_acc_2: 0.8657  Non0_F1_score: 0.8655  Mult_acc_5: 0.4847  Mult_acc_7: 0.3930  MAE: 0.7293  Corr: 0.8026  Loss: 1.0619 
2021-01-28 19:22:29:INFO:TEST-(misa) >>  Has0_acc_2: 0.8149  Has0_F1_score: 0.8146  Non0_acc_2: 0.8293  Non0_F1_score: 0.8285  Mult_acc_5: 0.4767  Mult_acc_7: 0.4300  MAE: 0.7749  Corr: 0.7780  Loss: 1.0895 
2021-01-28 19:22:29:INFO:Start saving results...
2021-01-28 19:22:29:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:22:29:INFO:########################################misa-(30/50)########################################
2021-01-28 19:22:29:INFO:batch_size:16
2021-01-28 19:22:29:INFO:learning_rate:0.001
2021-01-28 19:22:29:INFO:hidden_size:256
2021-01-28 19:22:29:INFO:dropout:0.0
2021-01-28 19:22:29:INFO:reverse_grad_weight:0.8
2021-01-28 19:22:29:INFO:diff_weight:0.3
2021-01-28 19:22:29:INFO:sim_weight:0.8
2021-01-28 19:22:29:INFO:sp_weight:1.0
2021-01-28 19:22:29:INFO:recon_weight:0.5
2021-01-28 19:22:29:INFO:grad_clip:1.0
2021-01-28 19:22:29:INFO:weight_decay:5e-05
2021-01-28 19:22:29:INFO:##########################################################################################
2021-01-28 19:22:29:INFO:Start running misa...
2021-01-28 19:22:29:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:22:29:INFO:Let's use 1 GPUs!
2021-01-28 19:22:34:INFO:train samples: (1284,)
2021-01-28 19:22:35:INFO:valid samples: (229,)
2021-01-28 19:22:35:INFO:test samples: (686,)
2021-01-28 19:22:35:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:22:35:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:22:35:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:22:35:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:22:35:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:22:35:INFO:loading file None
2021-01-28 19:22:35:INFO:loading file None
2021-01-28 19:22:35:INFO:loading file None
2021-01-28 19:22:35:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:22:35:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:22:35:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:22:39:INFO:The model has 112685553 trainable parameters
2021-01-28 19:22:58:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.7069  Has0_acc_2: 0.5086  Has0_F1_score: 0.5170  Non0_acc_2: 0.5061  Non0_F1_score: 0.5162  Mult_acc_5: 0.1978  Mult_acc_7: 0.1900  MAE: 1.5367  Corr: -0.0379 
2021-01-28 19:22:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4994  Corr: 0.1180  Loss: 3.1213 
2021-01-28 19:23:19:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5355  Has0_acc_2: 0.5273  Has0_F1_score: 0.5491  Non0_acc_2: 0.5175  Non0_F1_score: 0.5403  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3381  Corr: 0.0192 
2021-01-28 19:23:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4967  Corr: 0.1530  Loss: 3.0536 
2021-01-28 19:23:40:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4381  Has0_acc_2: 0.5389  Has0_F1_score: 0.5687  Non0_acc_2: 0.5248  Non0_F1_score: 0.5549  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3280  Corr: 0.0119 
2021-01-28 19:23:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4141  Corr: 0.1645  Loss: 2.7528 
2021-01-28 19:24:01:INFO:TRAIN-(misa) (1/4/1)>> loss: 2.4067  Has0_acc_2: 0.5366  Has0_F1_score: 0.6019  Non0_acc_2: 0.5248  Non0_F1_score: 0.5925  Mult_acc_5: 0.1963  Mult_acc_7: 0.1963  MAE: 1.3263  Corr: -0.0284 
2021-01-28 19:24:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4133  Corr: 0.1875  Loss: 2.7036 
2021-01-28 19:24:22:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.4059  Has0_acc_2: 0.5421  Has0_F1_score: 0.6055  Non0_acc_2: 0.5272  Non0_F1_score: 0.5921  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3337  Corr: -0.0341 
2021-01-28 19:24:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4150  Corr: 0.1742  Loss: 2.7255 
2021-01-28 19:24:42:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3507  Has0_acc_2: 0.5576  Has0_F1_score: 0.6787  Non0_acc_2: 0.5418  Non0_F1_score: 0.6662  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3215  Corr: -0.0268 
2021-01-28 19:24:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4173  Corr: 0.1890  Loss: 2.8225 
2021-01-28 19:25:01:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3419  Has0_acc_2: 0.5693  Has0_F1_score: 0.7250  Non0_acc_2: 0.5508  Non0_F1_score: 0.7097  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3253  Corr: -0.0434 
2021-01-28 19:25:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4183  Corr: 0.2107  Loss: 2.7696 
2021-01-28 19:25:20:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.3189  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3215  Corr: -0.0778 
2021-01-28 19:25:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4245  Corr: 0.2160  Loss: 2.8067 
2021-01-28 19:25:40:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.3226  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3212  Corr: -0.0194 
2021-01-28 19:25:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4232  Corr: 0.0287  Loss: 2.7095 
2021-01-28 19:26:00:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.3192  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3188  Corr: -0.0223 
2021-01-28 19:26:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4198  Corr: 0.1070  Loss: 2.7090 
2021-01-28 19:26:19:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.3521  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3213  Corr: -0.0093 
2021-01-28 19:26:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4246  Corr: 0.1818  Loss: 2.7381 
2021-01-28 19:26:39:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.3144  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3197  Corr: -0.0265 
2021-01-28 19:26:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4170  Corr: 0.1670  Loss: 2.7354 
2021-01-28 19:26:44:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.5139  Corr: 0.0928  Loss: 3.0720 
2021-01-28 19:26:44:INFO:Start saving results...
2021-01-28 19:26:44:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:26:44:INFO:########################################misa-(31/50)########################################
2021-01-28 19:26:44:INFO:batch_size:32
2021-01-28 19:26:44:INFO:learning_rate:0.001
2021-01-28 19:26:44:INFO:hidden_size:256
2021-01-28 19:26:44:INFO:dropout:0.2
2021-01-28 19:26:44:INFO:reverse_grad_weight:0.8
2021-01-28 19:26:44:INFO:diff_weight:0.1
2021-01-28 19:26:44:INFO:sim_weight:0.5
2021-01-28 19:26:44:INFO:sp_weight:0.0
2021-01-28 19:26:44:INFO:recon_weight:0.5
2021-01-28 19:26:44:INFO:grad_clip:-1.0
2021-01-28 19:26:44:INFO:weight_decay:5e-05
2021-01-28 19:26:44:INFO:##########################################################################################
2021-01-28 19:26:44:INFO:Start running misa...
2021-01-28 19:26:44:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:26:44:INFO:Let's use 1 GPUs!
2021-01-28 19:26:49:INFO:train samples: (1284,)
2021-01-28 19:26:50:INFO:valid samples: (229,)
2021-01-28 19:26:50:INFO:test samples: (686,)
2021-01-28 19:26:50:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:26:50:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:26:50:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:26:50:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:26:50:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:26:50:INFO:loading file None
2021-01-28 19:26:50:INFO:loading file None
2021-01-28 19:26:50:INFO:loading file None
2021-01-28 19:26:50:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:26:50:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:26:50:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:26:54:INFO:The model has 112685553 trainable parameters
2021-01-28 19:27:08:INFO:TRAIN-(misa) (1/1/1)>> loss: 5.3895  Has0_acc_2: 0.5234  Has0_F1_score: 0.5232  Non0_acc_2: 0.5232  Non0_F1_score: 0.5241  Mult_acc_5: 0.1900  Mult_acc_7: 0.1760  MAE: 1.6515  Corr: -0.0293 
2021-01-28 19:27:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4160  Corr: 0.1034  Loss: 2.6848 
2021-01-28 19:27:23:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5911  Has0_acc_2: 0.5202  Has0_F1_score: 0.5622  Non0_acc_2: 0.5142  Non0_F1_score: 0.5592  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3410  Corr: -0.0254 
2021-01-28 19:27:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4216  Corr: 0.1126  Loss: 2.7213 
2021-01-28 19:27:37:INFO:TRAIN-(misa) (2/3/1)>> loss: 2.4562  Has0_acc_2: 0.5421  Has0_F1_score: 0.6062  Non0_acc_2: 0.5280  Non0_F1_score: 0.5939  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3318  Corr: -0.0256 
2021-01-28 19:27:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4219  Corr: 0.0433  Loss: 2.8411 
2021-01-28 19:27:51:INFO:TRAIN-(misa) (3/4/1)>> loss: 2.3604  Has0_acc_2: 0.5615  Has0_F1_score: 0.6734  Non0_acc_2: 0.5443  Non0_F1_score: 0.6584  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3163  Corr: 0.0516 
2021-01-28 19:27:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4137  Corr: 0.0721  Loss: 2.6689 
2021-01-28 19:28:05:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3640  Has0_acc_2: 0.5717  Has0_F1_score: 0.7244  Non0_acc_2: 0.5532  Non0_F1_score: 0.7092  Mult_acc_5: 0.1963  Mult_acc_7: 0.1963  MAE: 1.3242  Corr: -0.0355 
2021-01-28 19:28:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4146  Corr: 0.0533  Loss: 2.7333 
2021-01-28 19:28:19:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3351  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3213  Corr: -0.0113 
2021-01-28 19:28:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4153  Corr: 0.1002  Loss: 2.9661 
2021-01-28 19:28:33:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3083  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3181  Corr: -0.0125 
2021-01-28 19:28:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4188  Corr: 0.0727  Loss: 2.8293 
2021-01-28 19:28:48:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.2892  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3172  Corr: -0.0031 
2021-01-28 19:28:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4179  Corr: 0.0586  Loss: 2.8670 
2021-01-28 19:29:02:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.3161  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3208  Corr: -0.0334 
2021-01-28 19:29:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4267  Corr: 0.0428  Loss: 2.6750 
2021-01-28 19:29:16:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.3325  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3187  Corr: 0.0149 
2021-01-28 19:29:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4148  Corr: 0.0865  Loss: 2.6767 
2021-01-28 19:29:31:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.3788  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3169  Corr: 0.0104 
2021-01-28 19:29:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4244  Corr: 0.0857  Loss: 2.7280 
2021-01-28 19:29:45:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.3238  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3199  Corr: -0.0262 
2021-01-28 19:29:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4172  Corr: 0.1026  Loss: 2.7534 
2021-01-28 19:29:48:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.5166  Corr: 0.1520  Loss: 3.0847 
2021-01-28 19:29:48:INFO:Start saving results...
2021-01-28 19:29:48:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:29:48:INFO:########################################misa-(32/50)########################################
2021-01-28 19:29:48:INFO:batch_size:64
2021-01-28 19:29:48:INFO:learning_rate:0.0005
2021-01-28 19:29:48:INFO:hidden_size:256
2021-01-28 19:29:48:INFO:dropout:0.0
2021-01-28 19:29:48:INFO:reverse_grad_weight:0.8
2021-01-28 19:29:48:INFO:diff_weight:0.1
2021-01-28 19:29:48:INFO:sim_weight:1.0
2021-01-28 19:29:48:INFO:sp_weight:1.0
2021-01-28 19:29:48:INFO:recon_weight:0.8
2021-01-28 19:29:48:INFO:grad_clip:1.0
2021-01-28 19:29:48:INFO:weight_decay:0.0
2021-01-28 19:29:48:INFO:##########################################################################################
2021-01-28 19:29:48:INFO:Start running misa...
2021-01-28 19:29:48:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:29:48:INFO:Let's use 1 GPUs!
2021-01-28 19:29:48:INFO:train samples: (1284,)
2021-01-28 19:29:48:INFO:valid samples: (229,)
2021-01-28 19:29:48:INFO:test samples: (686,)
2021-01-28 19:29:48:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:29:48:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:29:48:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:29:48:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:29:48:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:29:48:INFO:loading file None
2021-01-28 19:29:48:INFO:loading file None
2021-01-28 19:29:48:INFO:loading file None
2021-01-28 19:29:49:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:29:49:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:29:49:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:29:52:INFO:The model has 112685553 trainable parameters
2021-01-28 19:30:03:INFO:TRAIN-(misa) (1/1/1)>> loss: 7.3932  Has0_acc_2: 0.5280  Has0_F1_score: 0.5590  Non0_acc_2: 0.5167  Non0_F1_score: 0.5486  Mult_acc_5: 0.1838  Mult_acc_7: 0.1651  MAE: 1.8102  Corr: -0.0260 
2021-01-28 19:30:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4219  Corr: 0.0836  Loss: 2.6980 
2021-01-28 19:30:17:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.3896  Has0_acc_2: 0.4953  Has0_F1_score: 0.4973  Non0_acc_2: 0.4874  Non0_F1_score: 0.4902  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3517  Corr: -0.0464 
2021-01-28 19:30:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4171  Corr: 0.0962  Loss: 2.6898 
2021-01-28 19:30:30:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.7933  Has0_acc_2: 0.5709  Has0_F1_score: 0.7126  Non0_acc_2: 0.5532  Non0_F1_score: 0.6981  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3212  Corr: 0.0187 
2021-01-28 19:30:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4172  Corr: 0.1062  Loss: 2.7442 
2021-01-28 19:30:41:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.6234  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3157  Corr: 0.0494 
2021-01-28 19:30:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4149  Corr: 0.1125  Loss: 2.6673 
2021-01-28 19:30:54:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.5286  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3155  Corr: 0.0613 
2021-01-28 19:30:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4179  Corr: 0.1147  Loss: 2.7342 
2021-01-28 19:31:06:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.4756  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3195  Corr: 0.0135 
2021-01-28 19:31:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4151  Corr: 0.1128  Loss: 2.6917 
2021-01-28 19:31:18:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.4125  Has0_acc_2: 0.5693  Has0_F1_score: 0.7250  Non0_acc_2: 0.5508  Non0_F1_score: 0.7097  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3159  Corr: 0.0415 
2021-01-28 19:31:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4149  Corr: 0.1117  Loss: 2.6901 
2021-01-28 19:31:30:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.3767  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3180  Corr: 0.0218 
2021-01-28 19:31:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4149  Corr: 0.1127  Loss: 2.6784 
2021-01-28 19:31:41:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.3896  Has0_acc_2: 0.5709  Has0_F1_score: 0.7260  Non0_acc_2: 0.5524  Non0_F1_score: 0.7108  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3150  Corr: 0.0705 
2021-01-28 19:31:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4252  Corr: 0.1144  Loss: 2.7623 
2021-01-28 19:31:53:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.4067  Has0_acc_2: 0.5709  Has0_F1_score: 0.7260  Non0_acc_2: 0.5524  Non0_F1_score: 0.7108  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3130  Corr: 0.0705 
2021-01-28 19:31:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4162  Corr: 0.1149  Loss: 2.6906 
2021-01-28 19:32:05:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.5520  Has0_acc_2: 0.5693  Has0_F1_score: 0.7222  Non0_acc_2: 0.5508  Non0_F1_score: 0.7069  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3165  Corr: 0.0271 
2021-01-28 19:32:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4281  Corr: 0.1172  Loss: 2.8088 
2021-01-28 19:32:17:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.4028  Has0_acc_2: 0.5724  Has0_F1_score: 0.7025  Non0_acc_2: 0.5548  Non0_F1_score: 0.6876  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3160  Corr: 0.0476 
2021-01-28 19:32:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4174  Corr: 0.1184  Loss: 2.6689 
2021-01-28 19:32:22:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4780  Corr: 0.1036  Loss: 2.8908 
2021-01-28 19:32:22:INFO:Start saving results...
2021-01-28 19:32:22:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:32:22:INFO:########################################misa-(33/50)########################################
2021-01-28 19:32:22:INFO:batch_size:32
2021-01-28 19:32:22:INFO:learning_rate:0.0001
2021-01-28 19:32:22:INFO:hidden_size:64
2021-01-28 19:32:22:INFO:dropout:0.0
2021-01-28 19:32:22:INFO:reverse_grad_weight:1.0
2021-01-28 19:32:22:INFO:diff_weight:0.5
2021-01-28 19:32:22:INFO:sim_weight:0.8
2021-01-28 19:32:22:INFO:sp_weight:0.0
2021-01-28 19:32:22:INFO:recon_weight:0.8
2021-01-28 19:32:22:INFO:grad_clip:1.0
2021-01-28 19:32:22:INFO:weight_decay:0.0
2021-01-28 19:32:22:INFO:##########################################################################################
2021-01-28 19:32:22:INFO:Start running misa...
2021-01-28 19:32:22:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:32:22:INFO:Let's use 1 GPUs!
2021-01-28 19:32:27:INFO:train samples: (1284,)
2021-01-28 19:32:28:INFO:valid samples: (229,)
2021-01-28 19:32:28:INFO:test samples: (686,)
2021-01-28 19:32:28:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:32:28:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:32:28:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:32:28:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:32:28:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:32:28:INFO:loading file None
2021-01-28 19:32:28:INFO:loading file None
2021-01-28 19:32:28:INFO:loading file None
2021-01-28 19:32:28:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:32:28:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:32:28:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:32:32:INFO:The model has 109943985 trainable parameters
2021-01-28 19:32:45:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.8490  Has0_acc_2: 0.6589  Has0_F1_score: 0.7077  Non0_acc_2: 0.6523  Non0_F1_score: 0.7027  Mult_acc_5: 0.2033  Mult_acc_7: 0.2033  MAE: 1.2205  Corr: 0.4504 
2021-01-28 19:32:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8287  Non0_F1_score: 0.8284  Mult_acc_5: 0.2926  Mult_acc_7: 0.2926  MAE: 1.0356  Corr: 0.7224  Loss: 1.5254 
2021-01-28 19:33:01:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4761  Has0_acc_2: 0.8333  Has0_F1_score: 0.8330  Non0_acc_2: 0.8448  Non0_F1_score: 0.8449  Mult_acc_5: 0.3715  Mult_acc_7: 0.3598  MAE: 0.7885  Corr: 0.7817 
2021-01-28 19:33:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.7511  Has0_F1_score: 0.7503  Non0_acc_2: 0.7870  Non0_F1_score: 0.7868  Mult_acc_5: 0.3493  Mult_acc_7: 0.3144  MAE: 0.9715  Corr: 0.7556  Loss: 1.4402 
2021-01-28 19:33:17:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.7457  Has0_acc_2: 0.8840  Has0_F1_score: 0.8837  Non0_acc_2: 0.9033  Non0_F1_score: 0.9034  Mult_acc_5: 0.5327  Mult_acc_7: 0.5000  MAE: 0.5669  Corr: 0.8744 
2021-01-28 19:33:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5328  Mult_acc_7: 0.4367  MAE: 0.7974  Corr: 0.7661  Loss: 1.0904 
2021-01-28 19:33:32:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.5226  Has0_acc_2: 0.8684  Has0_F1_score: 0.8682  Non0_acc_2: 0.8895  Non0_F1_score: 0.8897  Mult_acc_5: 0.5444  Mult_acc_7: 0.4953  MAE: 0.5682  Corr: 0.8807 
2021-01-28 19:33:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8019  Non0_acc_2: 0.8426  Non0_F1_score: 0.8418  Mult_acc_5: 0.4498  Mult_acc_7: 0.3581  MAE: 0.8767  Corr: 0.7746  Loss: 1.3480 
2021-01-28 19:33:47:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.1427  Has0_acc_2: 0.8980  Has0_F1_score: 0.8980  Non0_acc_2: 0.9074  Non0_F1_score: 0.9075  Mult_acc_5: 0.6316  Mult_acc_7: 0.5810  MAE: 0.4551  Corr: 0.9251 
2021-01-28 19:33:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8205  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7651  Corr: 0.7756  Loss: 0.9957 
2021-01-28 19:34:03:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.9033  Has0_acc_2: 0.9143  Has0_F1_score: 0.9142  Non0_acc_2: 0.9318  Non0_F1_score: 0.9319  Mult_acc_5: 0.6752  Mult_acc_7: 0.6207  MAE: 0.3798  Corr: 0.9503 
2021-01-28 19:34:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8264  Non0_acc_2: 0.8333  Non0_F1_score: 0.8349  Mult_acc_5: 0.5240  Mult_acc_7: 0.4061  MAE: 0.7647  Corr: 0.7883  Loss: 1.0611 
2021-01-28 19:34:17:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.7628  Has0_acc_2: 0.9034  Has0_F1_score: 0.9034  Non0_acc_2: 0.9139  Non0_F1_score: 0.9140  Mult_acc_5: 0.6885  Mult_acc_7: 0.6433  MAE: 0.3544  Corr: 0.9554 
2021-01-28 19:34:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7973  Non0_acc_2: 0.8380  Non0_F1_score: 0.8371  Mult_acc_5: 0.4629  Mult_acc_7: 0.3755  MAE: 0.8529  Corr: 0.7657  Loss: 1.4024 
2021-01-28 19:34:31:INFO:TRAIN-(misa) (3/8/1)>> loss: 0.6531  Has0_acc_2: 0.9167  Has0_F1_score: 0.9165  Non0_acc_2: 0.9310  Non0_F1_score: 0.9310  Mult_acc_5: 0.6955  Mult_acc_7: 0.6456  MAE: 0.3508  Corr: 0.9560 
2021-01-28 19:34:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7935  Corr: 0.7949  Loss: 1.1538 
2021-01-28 19:34:46:INFO:TRAIN-(misa) (4/9/1)>> loss: 0.5597  Has0_acc_2: 0.9206  Has0_F1_score: 0.9204  Non0_acc_2: 0.9374  Non0_F1_score: 0.9375  Mult_acc_5: 0.7196  Mult_acc_7: 0.6674  MAE: 0.3415  Corr: 0.9588 
2021-01-28 19:34:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8353  Non0_acc_2: 0.8333  Non0_F1_score: 0.8391  Mult_acc_5: 0.4585  Mult_acc_7: 0.3100  MAE: 0.9866  Corr: 0.7943  Loss: 1.6276 
2021-01-28 19:35:01:INFO:TRAIN-(misa) (5/10/1)>> loss: 0.5855  Has0_acc_2: 0.9026  Has0_F1_score: 0.9027  Non0_acc_2: 0.9147  Non0_F1_score: 0.9149  Mult_acc_5: 0.6526  Mult_acc_7: 0.6036  MAE: 0.4177  Corr: 0.9382 
2021-01-28 19:35:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7755  Corr: 0.7761  Loss: 1.1181 
2021-01-28 19:35:16:INFO:TRAIN-(misa) (6/11/1)>> loss: 0.4583  Has0_acc_2: 0.9283  Has0_F1_score: 0.9282  Non0_acc_2: 0.9431  Non0_F1_score: 0.9431  Mult_acc_5: 0.7002  Mult_acc_7: 0.6526  MAE: 0.3420  Corr: 0.9590 
2021-01-28 19:35:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8404  Non0_acc_2: 0.8426  Non0_F1_score: 0.8449  Mult_acc_5: 0.4672  Mult_acc_7: 0.3668  MAE: 0.7972  Corr: 0.7830  Loss: 1.6884 
2021-01-28 19:35:30:INFO:TRAIN-(misa) (7/12/1)>> loss: 0.4674  Has0_acc_2: 0.9276  Has0_F1_score: 0.9274  Non0_acc_2: 0.9448  Non0_F1_score: 0.9448  Mult_acc_5: 0.6620  Mult_acc_7: 0.6137  MAE: 0.3745  Corr: 0.9500 
2021-01-28 19:35:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8149  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.4760  Mult_acc_7: 0.3843  MAE: 0.7992  Corr: 0.7796  Loss: 1.2162 
2021-01-28 19:35:45:INFO:TRAIN-(misa) (8/13/1)>> loss: 0.4259  Has0_acc_2: 0.9245  Has0_F1_score: 0.9243  Non0_acc_2: 0.9415  Non0_F1_score: 0.9416  Mult_acc_5: 0.6861  Mult_acc_7: 0.6324  MAE: 0.3665  Corr: 0.9535 
2021-01-28 19:35:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8192  Non0_acc_2: 0.8565  Non0_F1_score: 0.8557  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7768  Corr: 0.7926  Loss: 1.3195 
2021-01-28 19:35:48:INFO:TEST-(misa) >>  Has0_acc_2: 0.7959  Has0_F1_score: 0.7955  Non0_acc_2: 0.8110  Non0_F1_score: 0.8099  Mult_acc_5: 0.4636  Mult_acc_7: 0.4125  MAE: 0.8246  Corr: 0.7468  Loss: 1.2166 
2021-01-28 19:35:48:INFO:Start saving results...
2021-01-28 19:35:48:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:35:48:INFO:########################################misa-(34/50)########################################
2021-01-28 19:35:48:INFO:batch_size:32
2021-01-28 19:35:48:INFO:learning_rate:0.0005
2021-01-28 19:35:48:INFO:hidden_size:256
2021-01-28 19:35:48:INFO:dropout:0.2
2021-01-28 19:35:48:INFO:reverse_grad_weight:1.0
2021-01-28 19:35:48:INFO:diff_weight:0.1
2021-01-28 19:35:48:INFO:sim_weight:0.5
2021-01-28 19:35:48:INFO:sp_weight:1.0
2021-01-28 19:35:48:INFO:recon_weight:0.5
2021-01-28 19:35:48:INFO:grad_clip:0.8
2021-01-28 19:35:48:INFO:weight_decay:0.002
2021-01-28 19:35:48:INFO:##########################################################################################
2021-01-28 19:35:48:INFO:Start running misa...
2021-01-28 19:35:48:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:35:48:INFO:Let's use 1 GPUs!
2021-01-28 19:35:48:INFO:train samples: (1284,)
2021-01-28 19:35:48:INFO:valid samples: (229,)
2021-01-28 19:35:49:INFO:test samples: (686,)
2021-01-28 19:35:49:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:35:49:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:35:49:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:35:49:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:35:49:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:35:49:INFO:loading file None
2021-01-28 19:35:49:INFO:loading file None
2021-01-28 19:35:49:INFO:loading file None
2021-01-28 19:35:49:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:35:49:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:35:49:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:35:52:INFO:The model has 112685553 trainable parameters
2021-01-28 19:36:05:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.2832  Has0_acc_2: 0.5148  Has0_F1_score: 0.5171  Non0_acc_2: 0.5134  Non0_F1_score: 0.5170  Mult_acc_5: 0.1963  Mult_acc_7: 0.1900  MAE: 1.4692  Corr: -0.0305 
2021-01-28 19:36:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7041  Non0_acc_2: 0.5972  Non0_F1_score: 0.6890  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4305  Corr: 0.1318  Loss: 2.8078 
2021-01-28 19:36:20:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.6012  Has0_acc_2: 0.5421  Has0_F1_score: 0.5667  Non0_acc_2: 0.5353  Non0_F1_score: 0.5616  Mult_acc_5: 0.1877  Mult_acc_7: 0.1877  MAE: 1.3234  Corr: 0.0523 
2021-01-28 19:36:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4235  Corr: 0.1240  Loss: 2.7320 
2021-01-28 19:36:36:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4504  Has0_acc_2: 0.5732  Has0_F1_score: 0.5973  Non0_acc_2: 0.5646  Non0_F1_score: 0.5896  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.3130  Corr: 0.0571 
2021-01-28 19:36:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4507  Corr: 0.1270  Loss: 3.0249 
2021-01-28 19:36:50:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3788  Has0_acc_2: 0.5717  Has0_F1_score: 0.6451  Non0_acc_2: 0.5597  Non0_F1_score: 0.6355  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.3060  Corr: 0.0816 
2021-01-28 19:36:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1659  Mult_acc_7: 0.1659  MAE: 1.4165  Corr: 0.1251  Loss: 2.7075 
2021-01-28 19:37:05:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3717  Has0_acc_2: 0.5748  Has0_F1_score: 0.6447  Non0_acc_2: 0.5630  Non0_F1_score: 0.6351  Mult_acc_5: 0.1861  Mult_acc_7: 0.1861  MAE: 1.3136  Corr: 0.0709 
2021-01-28 19:37:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7205  Non0_acc_2: 0.5972  Non0_F1_score: 0.7001  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4171  Corr: 0.1244  Loss: 2.7301 
2021-01-28 19:37:19:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.2919  Has0_acc_2: 0.5927  Has0_F1_score: 0.6464  Non0_acc_2: 0.5808  Non0_F1_score: 0.6358  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.2924  Corr: 0.1764 
2021-01-28 19:37:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6924  Non0_acc_2: 0.5833  Non0_F1_score: 0.6704  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3978  Corr: 0.1300  Loss: 2.9823 
2021-01-28 19:37:33:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.2348  Has0_acc_2: 0.6129  Has0_F1_score: 0.6392  Non0_acc_2: 0.6028  Non0_F1_score: 0.6294  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.2713  Corr: 0.2279 
2021-01-28 19:37:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7262  Non0_acc_2: 0.5787  Non0_F1_score: 0.7058  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4030  Corr: 0.1439  Loss: 2.8753 
2021-01-28 19:37:47:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.2045  Has0_acc_2: 0.6246  Has0_F1_score: 0.6478  Non0_acc_2: 0.6141  Non0_F1_score: 0.6375  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.2623  Corr: 0.2416 
2021-01-28 19:37:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6578  Non0_acc_2: 0.6019  Non0_F1_score: 0.6458  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3973  Corr: 0.1418  Loss: 2.8309 
2021-01-28 19:38:01:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.1486  Has0_acc_2: 0.6254  Has0_F1_score: 0.6546  Non0_acc_2: 0.6158  Non0_F1_score: 0.6455  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.2446  Corr: 0.2877 
2021-01-28 19:38:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.6930  Non0_acc_2: 0.6019  Non0_F1_score: 0.6714  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.3847  Corr: 0.1515  Loss: 2.6151 
2021-01-28 19:38:17:INFO:TRAIN-(misa) (1/10/1)>> loss: 2.1507  Has0_acc_2: 0.6168  Has0_F1_score: 0.6265  Non0_acc_2: 0.6133  Non0_F1_score: 0.6238  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.2383  Corr: 0.2915 
2021-01-28 19:38:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7108  Non0_acc_2: 0.6019  Non0_F1_score: 0.6900  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3842  Corr: 0.1611  Loss: 2.6378 
2021-01-28 19:38:31:INFO:TRAIN-(misa) (2/11/1)>> loss: 2.2054  Has0_acc_2: 0.6215  Has0_F1_score: 0.6439  Non0_acc_2: 0.6125  Non0_F1_score: 0.6353  Mult_acc_5: 0.2009  Mult_acc_7: 0.1994  MAE: 1.2386  Corr: 0.2910 
2021-01-28 19:38:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7086  Non0_acc_2: 0.5880  Non0_F1_score: 0.6874  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3921  Corr: 0.1543  Loss: 2.7517 
2021-01-28 19:38:45:INFO:TRAIN-(misa) (3/12/1)>> loss: 2.2006  Has0_acc_2: 0.6129  Has0_F1_score: 0.6229  Non0_acc_2: 0.6068  Non0_F1_score: 0.6172  Mult_acc_5: 0.1970  Mult_acc_7: 0.1970  MAE: 1.2504  Corr: 0.2626 
2021-01-28 19:38:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7325  Non0_acc_2: 0.5833  Non0_F1_score: 0.7125  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4125  Corr: 0.1616  Loss: 2.9438 
2021-01-28 19:38:59:INFO:TRAIN-(misa) (4/13/1)>> loss: 2.0367  Has0_acc_2: 0.6355  Has0_F1_score: 0.6461  Non0_acc_2: 0.6312  Non0_F1_score: 0.6423  Mult_acc_5: 0.2126  Mult_acc_7: 0.2087  MAE: 1.2020  Corr: 0.3618 
2021-01-28 19:39:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7259  Non0_acc_2: 0.5880  Non0_F1_score: 0.7056  Mult_acc_5: 0.2140  Mult_acc_7: 0.2009  MAE: 1.3839  Corr: 0.1886  Loss: 2.5163 
2021-01-28 19:39:14:INFO:TRAIN-(misa) (1/14/1)>> loss: 2.0035  Has0_acc_2: 0.6371  Has0_F1_score: 0.6469  Non0_acc_2: 0.6336  Non0_F1_score: 0.6441  Mult_acc_5: 0.2298  Mult_acc_7: 0.2259  MAE: 1.1905  Corr: 0.3840 
2021-01-28 19:39:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.6890  Non0_acc_2: 0.6204  Non0_F1_score: 0.6789  Mult_acc_5: 0.2140  Mult_acc_7: 0.2009  MAE: 1.3747  Corr: 0.1872  Loss: 2.6300 
2021-01-28 19:39:29:INFO:TRAIN-(misa) (2/15/1)>> loss: 2.0476  Has0_acc_2: 0.6176  Has0_F1_score: 0.6286  Non0_acc_2: 0.6141  Non0_F1_score: 0.6259  Mult_acc_5: 0.2150  Mult_acc_7: 0.2134  MAE: 1.2067  Corr: 0.3509 
2021-01-28 19:39:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7451  Non0_acc_2: 0.5926  Non0_F1_score: 0.7260  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.4020  Corr: 0.1698  Loss: 2.5857 
2021-01-28 19:39:43:INFO:TRAIN-(misa) (3/16/1)>> loss: 1.9487  Has0_acc_2: 0.6332  Has0_F1_score: 0.6376  Non0_acc_2: 0.6328  Non0_F1_score: 0.6380  Mult_acc_5: 0.2266  Mult_acc_7: 0.2235  MAE: 1.1697  Corr: 0.4137 
2021-01-28 19:39:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7322  Non0_acc_2: 0.6019  Non0_F1_score: 0.7124  Mult_acc_5: 0.2052  Mult_acc_7: 0.1878  MAE: 1.4057  Corr: 0.1973  Loss: 2.9197 
2021-01-28 19:39:57:INFO:TRAIN-(misa) (4/17/1)>> loss: 1.8836  Has0_acc_2: 0.6667  Has0_F1_score: 0.6744  Non0_acc_2: 0.6645  Non0_F1_score: 0.6727  Mult_acc_5: 0.2227  Mult_acc_7: 0.2188  MAE: 1.1384  Corr: 0.4544 
2021-01-28 19:39:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.6329  Non0_acc_2: 0.6111  Non0_F1_score: 0.6359  Mult_acc_5: 0.2445  Mult_acc_7: 0.2314  MAE: 1.3687  Corr: 0.1914  Loss: 2.8181 
2021-01-28 19:40:12:INFO:TRAIN-(misa) (5/18/1)>> loss: 2.0887  Has0_acc_2: 0.6168  Has0_F1_score: 0.6217  Non0_acc_2: 0.6182  Non0_F1_score: 0.6241  Mult_acc_5: 0.2290  Mult_acc_7: 0.2251  MAE: 1.1927  Corr: 0.3586 
2021-01-28 19:40:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.5284  Has0_F1_score: 0.5328  Non0_acc_2: 0.5509  Non0_F1_score: 0.5555  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4264  Corr: 0.1843  Loss: 2.9574 
2021-01-28 19:40:26:INFO:TRAIN-(misa) (6/19/1)>> loss: 2.0012  Has0_acc_2: 0.6542  Has0_F1_score: 0.6687  Non0_acc_2: 0.6491  Non0_F1_score: 0.6640  Mult_acc_5: 0.2157  Mult_acc_7: 0.2142  MAE: 1.1938  Corr: 0.3766 
2021-01-28 19:40:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5939  Has0_F1_score: 0.5906  Non0_acc_2: 0.5972  Non0_F1_score: 0.5957  Mult_acc_5: 0.2402  Mult_acc_7: 0.2402  MAE: 1.3829  Corr: 0.1869  Loss: 2.7465 
2021-01-28 19:40:40:INFO:TRAIN-(misa) (7/20/1)>> loss: 1.9839  Has0_acc_2: 0.6386  Has0_F1_score: 0.6444  Non0_acc_2: 0.6401  Non0_F1_score: 0.6468  Mult_acc_5: 0.2188  Mult_acc_7: 0.2157  MAE: 1.1709  Corr: 0.4109 
2021-01-28 19:40:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.7028  Non0_acc_2: 0.6111  Non0_F1_score: 0.6877  Mult_acc_5: 0.2183  Mult_acc_7: 0.2183  MAE: 1.3551  Corr: 0.2295  Loss: 2.5982 
2021-01-28 19:40:54:INFO:TRAIN-(misa) (8/21/1)>> loss: 2.0121  Has0_acc_2: 0.6472  Has0_F1_score: 0.6632  Non0_acc_2: 0.6393  Non0_F1_score: 0.6555  Mult_acc_5: 0.2282  Mult_acc_7: 0.2251  MAE: 1.1792  Corr: 0.3872 
2021-01-28 19:40:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.6325  Non0_acc_2: 0.6250  Non0_F1_score: 0.6405  Mult_acc_5: 0.2533  Mult_acc_7: 0.2489  MAE: 1.3560  Corr: 0.2150  Loss: 2.6843 
2021-01-28 19:40:57:INFO:TEST-(misa) >>  Has0_acc_2: 0.4854  Has0_F1_score: 0.5861  Non0_acc_2: 0.4649  Non0_F1_score: 0.5651  Mult_acc_5: 0.1691  Mult_acc_7: 0.1691  MAE: 1.4784  Corr: 0.1740  Loss: 3.0292 
2021-01-28 19:40:57:INFO:Start saving results...
2021-01-28 19:40:57:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:40:57:INFO:########################################misa-(35/50)########################################
2021-01-28 19:40:57:INFO:batch_size:32
2021-01-28 19:40:57:INFO:learning_rate:0.0005
2021-01-28 19:40:57:INFO:hidden_size:256
2021-01-28 19:40:57:INFO:dropout:0.2
2021-01-28 19:40:57:INFO:reverse_grad_weight:0.5
2021-01-28 19:40:57:INFO:diff_weight:0.5
2021-01-28 19:40:57:INFO:sim_weight:0.8
2021-01-28 19:40:57:INFO:sp_weight:1.0
2021-01-28 19:40:57:INFO:recon_weight:0.8
2021-01-28 19:40:57:INFO:grad_clip:-1.0
2021-01-28 19:40:57:INFO:weight_decay:5e-05
2021-01-28 19:40:57:INFO:##########################################################################################
2021-01-28 19:40:57:INFO:Start running misa...
2021-01-28 19:40:57:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:40:57:INFO:Let's use 1 GPUs!
2021-01-28 19:40:57:INFO:train samples: (1284,)
2021-01-28 19:40:58:INFO:valid samples: (229,)
2021-01-28 19:40:58:INFO:test samples: (686,)
2021-01-28 19:40:58:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:40:58:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:40:58:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:40:58:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:40:58:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:40:58:INFO:loading file None
2021-01-28 19:40:58:INFO:loading file None
2021-01-28 19:40:58:INFO:loading file None
2021-01-28 19:40:58:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:40:58:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:40:58:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:41:01:INFO:The model has 112685553 trainable parameters
2021-01-28 19:41:14:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.8158  Has0_acc_2: 0.5101  Has0_F1_score: 0.5126  Non0_acc_2: 0.5085  Non0_F1_score: 0.5123  Mult_acc_5: 0.1854  Mult_acc_7: 0.1791  MAE: 1.4950  Corr: -0.0405 
2021-01-28 19:41:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.5295  Corr: 0.1382  Loss: 3.3431 
2021-01-28 19:41:29:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.8126  Has0_acc_2: 0.5047  Has0_F1_score: 0.5042  Non0_acc_2: 0.5037  Non0_F1_score: 0.5044  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3462  Corr: 0.0303 
2021-01-28 19:41:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4114  Corr: 0.1270  Loss: 2.6575 
2021-01-28 19:41:45:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.5306  Has0_acc_2: 0.5498  Has0_F1_score: 0.6451  Non0_acc_2: 0.5345  Non0_F1_score: 0.6323  Mult_acc_5: 0.1830  Mult_acc_7: 0.1830  MAE: 1.3299  Corr: -0.0173 
2021-01-28 19:41:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4150  Corr: 0.1194  Loss: 2.7986 
2021-01-28 19:41:59:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.4200  Has0_acc_2: 0.5709  Has0_F1_score: 0.6979  Non0_acc_2: 0.5524  Non0_F1_score: 0.6816  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3115  Corr: 0.0697 
2021-01-28 19:41:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4133  Corr: 0.1306  Loss: 2.6674 
2021-01-28 19:42:13:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.4136  Has0_acc_2: 0.5701  Has0_F1_score: 0.7127  Non0_acc_2: 0.5524  Non0_F1_score: 0.6982  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3191  Corr: 0.0028 
2021-01-28 19:42:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4158  Corr: 0.1382  Loss: 2.7272 
2021-01-28 19:42:27:INFO:TRAIN-(misa) (4/6/1)>> loss: 2.4048  Has0_acc_2: 0.5561  Has0_F1_score: 0.6537  Non0_acc_2: 0.5418  Non0_F1_score: 0.6424  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3246  Corr: 0.0066 
2021-01-28 19:42:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4255  Corr: 0.1405  Loss: 2.9441 
2021-01-28 19:42:40:INFO:TRAIN-(misa) (5/7/1)>> loss: 2.3661  Has0_acc_2: 0.5631  Has0_F1_score: 0.6674  Non0_acc_2: 0.5483  Non0_F1_score: 0.6556  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3222  Corr: 0.0147 
2021-01-28 19:42:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4244  Corr: 0.1498  Loss: 2.8385 
2021-01-28 19:42:54:INFO:TRAIN-(misa) (6/8/1)>> loss: 2.3209  Has0_acc_2: 0.5740  Has0_F1_score: 0.7212  Non0_acc_2: 0.5556  Non0_F1_score: 0.7058  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3127  Corr: 0.0602 
2021-01-28 19:42:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4228  Corr: 0.1483  Loss: 2.8807 
2021-01-28 19:43:08:INFO:TRAIN-(misa) (7/9/1)>> loss: 2.3628  Has0_acc_2: 0.5670  Has0_F1_score: 0.6595  Non0_acc_2: 0.5500  Non0_F1_score: 0.6440  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3179  Corr: 0.0153 
2021-01-28 19:43:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4282  Corr: 0.1499  Loss: 2.6738 
2021-01-28 19:43:22:INFO:TRAIN-(misa) (8/10/1)>> loss: 2.3502  Has0_acc_2: 0.5670  Has0_F1_score: 0.7146  Non0_acc_2: 0.5491  Non0_F1_score: 0.7001  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3151  Corr: 0.0575 
2021-01-28 19:43:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4161  Corr: 0.1448  Loss: 2.6711 
2021-01-28 19:43:25:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.5042  Corr: 0.1318  Loss: 3.0211 
2021-01-28 19:43:25:INFO:Start saving results...
2021-01-28 19:43:25:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:43:25:INFO:########################################misa-(36/50)########################################
2021-01-28 19:43:25:INFO:batch_size:64
2021-01-28 19:43:25:INFO:learning_rate:0.0001
2021-01-28 19:43:25:INFO:hidden_size:256
2021-01-28 19:43:25:INFO:dropout:0.5
2021-01-28 19:43:25:INFO:reverse_grad_weight:1.0
2021-01-28 19:43:25:INFO:diff_weight:0.5
2021-01-28 19:43:25:INFO:sim_weight:0.8
2021-01-28 19:43:25:INFO:sp_weight:1.0
2021-01-28 19:43:25:INFO:recon_weight:0.5
2021-01-28 19:43:25:INFO:grad_clip:1.0
2021-01-28 19:43:25:INFO:weight_decay:0.0
2021-01-28 19:43:25:INFO:##########################################################################################
2021-01-28 19:43:25:INFO:Start running misa...
2021-01-28 19:43:25:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:43:25:INFO:Let's use 1 GPUs!
2021-01-28 19:43:25:INFO:train samples: (1284,)
2021-01-28 19:43:25:INFO:valid samples: (229,)
2021-01-28 19:43:25:INFO:test samples: (686,)
2021-01-28 19:43:25:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:43:25:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:43:25:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:43:25:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:43:25:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:43:25:INFO:loading file None
2021-01-28 19:43:25:INFO:loading file None
2021-01-28 19:43:25:INFO:loading file None
2021-01-28 19:43:25:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:43:25:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:43:25:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:43:29:INFO:The model has 112685553 trainable parameters
2021-01-28 19:43:39:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.4063  Has0_acc_2: 0.5872  Has0_F1_score: 0.6027  Non0_acc_2: 0.5841  Non0_F1_score: 0.6009  Mult_acc_5: 0.2103  Mult_acc_7: 0.2103  MAE: 1.2691  Corr: 0.2047 
2021-01-28 19:43:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.7424  Has0_F1_score: 0.7428  Non0_acc_2: 0.7685  Non0_F1_score: 0.7697  Mult_acc_5: 0.2314  Mult_acc_7: 0.2314  MAE: 1.2557  Corr: 0.5923  Loss: 2.1428 
2021-01-28 19:43:52:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.9991  Has0_acc_2: 0.7562  Has0_F1_score: 0.7551  Non0_acc_2: 0.7725  Non0_F1_score: 0.7720  Mult_acc_5: 0.3092  Mult_acc_7: 0.2998  MAE: 0.9575  Corr: 0.6284 
2021-01-28 19:43:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8281  Non0_acc_2: 0.8611  Non0_F1_score: 0.8605  Mult_acc_5: 0.4236  Mult_acc_7: 0.3493  MAE: 0.8574  Corr: 0.7520  Loss: 1.2011 
2021-01-28 19:44:05:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.9110  Has0_acc_2: 0.8598  Has0_F1_score: 0.8593  Non0_acc_2: 0.8781  Non0_F1_score: 0.8780  Mult_acc_5: 0.4385  Mult_acc_7: 0.4073  MAE: 0.6871  Corr: 0.8177 
2021-01-28 19:44:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.4541  Mult_acc_7: 0.3624  MAE: 0.7810  Corr: 0.7851  Loss: 1.1274 
2021-01-28 19:44:18:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.3047  Has0_acc_2: 0.9019  Has0_F1_score: 0.9015  Non0_acc_2: 0.9204  Non0_F1_score: 0.9203  Mult_acc_5: 0.5670  Mult_acc_7: 0.5195  MAE: 0.5436  Corr: 0.8869 
2021-01-28 19:44:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8450  Non0_acc_2: 0.8519  Non0_F1_score: 0.8544  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7911  Corr: 0.7901  Loss: 1.1867 
2021-01-28 19:44:29:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.9260  Has0_acc_2: 0.9229  Has0_F1_score: 0.9227  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6090  Mult_acc_7: 0.5561  MAE: 0.4742  Corr: 0.9158 
2021-01-28 19:44:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8333  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.4672  Mult_acc_7: 0.3712  MAE: 0.7600  Corr: 0.7782  Loss: 1.1243 
2021-01-28 19:44:42:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.6540  Has0_acc_2: 0.9268  Has0_F1_score: 0.9265  Non0_acc_2: 0.9504  Non0_F1_score: 0.9504  Mult_acc_5: 0.7111  Mult_acc_7: 0.6589  MAE: 0.3650  Corr: 0.9522 
2021-01-28 19:44:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8333  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7456  Corr: 0.7829  Loss: 1.0458 
2021-01-28 19:44:55:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.5583  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.7126  Mult_acc_7: 0.6526  MAE: 0.3301  Corr: 0.9605 
2021-01-28 19:44:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8331  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.5022  Mult_acc_7: 0.3930  MAE: 0.7334  Corr: 0.7881  Loss: 1.0724 
2021-01-28 19:45:06:INFO:TRAIN-(misa) (2/8/1)>> loss: 0.4695  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.7819  Mult_acc_7: 0.7227  MAE: 0.2821  Corr: 0.9714 
2021-01-28 19:45:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7299  Corr: 0.7932  Loss: 1.0408 
2021-01-28 19:45:19:INFO:TRAIN-(misa) (1/9/1)>> loss: 0.4123  Has0_acc_2: 0.9486  Has0_F1_score: 0.9484  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7960  Mult_acc_7: 0.7321  MAE: 0.2680  Corr: 0.9746 
2021-01-28 19:45:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8515  Has0_F1_score: 0.8513  Non0_acc_2: 0.8657  Non0_F1_score: 0.8661  Mult_acc_5: 0.5022  Mult_acc_7: 0.3974  MAE: 0.7433  Corr: 0.7916  Loss: 1.0190 
2021-01-28 19:45:32:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.3933  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7780  Mult_acc_7: 0.7220  MAE: 0.2658  Corr: 0.9749 
2021-01-28 19:45:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8425  Non0_acc_2: 0.8611  Non0_F1_score: 0.8616  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7370  Corr: 0.7921  Loss: 1.0623 
2021-01-28 19:45:43:INFO:TRAIN-(misa) (2/11/1)>> loss: 0.3503  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.7960  Mult_acc_7: 0.7523  MAE: 0.2426  Corr: 0.9787 
2021-01-28 19:45:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8515  Has0_F1_score: 0.8513  Non0_acc_2: 0.8657  Non0_F1_score: 0.8661  Mult_acc_5: 0.5328  Mult_acc_7: 0.4323  MAE: 0.7150  Corr: 0.8006  Loss: 1.0231 
2021-01-28 19:45:55:INFO:TRAIN-(misa) (3/12/1)>> loss: 0.3126  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8178  Mult_acc_7: 0.7679  MAE: 0.2231  Corr: 0.9826 
2021-01-28 19:45:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8559  Has0_F1_score: 0.8560  Non0_acc_2: 0.8704  Non0_F1_score: 0.8710  Mult_acc_5: 0.5153  Mult_acc_7: 0.4148  MAE: 0.7267  Corr: 0.7995  Loss: 1.0772 
2021-01-28 19:46:06:INFO:TRAIN-(misa) (4/13/1)>> loss: 0.3045  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8310  Mult_acc_7: 0.7874  MAE: 0.2225  Corr: 0.9826 
2021-01-28 19:46:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8466  Non0_acc_2: 0.8657  Non0_F1_score: 0.8658  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7276  Corr: 0.7971  Loss: 0.9820 
2021-01-28 19:46:18:INFO:TRAIN-(misa) (1/14/1)>> loss: 0.2828  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8139  Mult_acc_7: 0.7710  MAE: 0.2230  Corr: 0.9827 
2021-01-28 19:46:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7402  Corr: 0.7944  Loss: 1.0107 
2021-01-28 19:46:29:INFO:TRAIN-(misa) (2/15/1)>> loss: 0.2817  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8146  Mult_acc_7: 0.7726  MAE: 0.2314  Corr: 0.9813 
2021-01-28 19:46:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8464  Non0_acc_2: 0.8657  Non0_F1_score: 0.8656  Mult_acc_5: 0.5240  Mult_acc_7: 0.4192  MAE: 0.7316  Corr: 0.7963  Loss: 1.1033 
2021-01-28 19:46:41:INFO:TRAIN-(misa) (3/16/1)>> loss: 0.2848  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7991  Mult_acc_7: 0.7539  MAE: 0.2455  Corr: 0.9802 
2021-01-28 19:46:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.8603  Has0_F1_score: 0.8600  Non0_acc_2: 0.8796  Non0_F1_score: 0.8800  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7203  Corr: 0.7994  Loss: 1.0136 
2021-01-28 19:46:53:INFO:TRAIN-(misa) (4/17/1)>> loss: 0.2735  Has0_acc_2: 0.9447  Has0_F1_score: 0.9445  Non0_acc_2: 0.9634  Non0_F1_score: 0.9634  Mult_acc_5: 0.8014  Mult_acc_7: 0.7609  MAE: 0.2437  Corr: 0.9798 
2021-01-28 19:46:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8515  Has0_F1_score: 0.8507  Non0_acc_2: 0.8704  Non0_F1_score: 0.8702  Mult_acc_5: 0.5502  Mult_acc_7: 0.4454  MAE: 0.7242  Corr: 0.7983  Loss: 1.0079 
2021-01-28 19:47:04:INFO:TRAIN-(misa) (5/18/1)>> loss: 0.2619  Has0_acc_2: 0.9618  Has0_F1_score: 0.9618  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8310  Mult_acc_7: 0.7804  MAE: 0.2232  Corr: 0.9823 
2021-01-28 19:47:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7332  Corr: 0.7945  Loss: 1.0137 
2021-01-28 19:47:16:INFO:TRAIN-(misa) (6/19/1)>> loss: 0.2303  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8528  Mult_acc_7: 0.8162  MAE: 0.2009  Corr: 0.9860 
2021-01-28 19:47:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8464  Non0_acc_2: 0.8657  Non0_F1_score: 0.8656  Mult_acc_5: 0.5459  Mult_acc_7: 0.4410  MAE: 0.7080  Corr: 0.8013  Loss: 0.9667 
2021-01-28 19:47:28:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.2169  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8497  Mult_acc_7: 0.7983  MAE: 0.1961  Corr: 0.9867 
2021-01-28 19:47:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8559  Has0_F1_score: 0.8555  Non0_acc_2: 0.8704  Non0_F1_score: 0.8706  Mult_acc_5: 0.5022  Mult_acc_7: 0.4105  MAE: 0.7171  Corr: 0.7986  Loss: 0.9900 
2021-01-28 19:47:40:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.2172  Has0_acc_2: 0.9642  Has0_F1_score: 0.9641  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8497  Mult_acc_7: 0.8178  MAE: 0.2032  Corr: 0.9856 
2021-01-28 19:47:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8423  Non0_acc_2: 0.8611  Non0_F1_score: 0.8613  Mult_acc_5: 0.5415  Mult_acc_7: 0.4279  MAE: 0.7236  Corr: 0.7988  Loss: 1.0764 
2021-01-28 19:47:51:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.2037  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8310  Mult_acc_7: 0.7928  MAE: 0.2029  Corr: 0.9859 
2021-01-28 19:47:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.5415  Mult_acc_7: 0.4367  MAE: 0.7118  Corr: 0.8004  Loss: 1.0471 
2021-01-28 19:48:03:INFO:TRAIN-(misa) (4/23/1)>> loss: 0.1804  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8575  Mult_acc_7: 0.8209  MAE: 0.1781  Corr: 0.9890 
2021-01-28 19:48:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8657  Non0_F1_score: 0.8656  Mult_acc_5: 0.5633  Mult_acc_7: 0.4585  MAE: 0.6943  Corr: 0.8034  Loss: 0.9900 
2021-01-28 19:48:14:INFO:TRAIN-(misa) (5/24/1)>> loss: 0.1885  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8645  Mult_acc_7: 0.8302  MAE: 0.1825  Corr: 0.9882 
2021-01-28 19:48:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7141  Corr: 0.8006  Loss: 0.9761 
2021-01-28 19:48:26:INFO:TRAIN-(misa) (6/25/1)>> loss: 0.1828  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8637  Mult_acc_7: 0.8326  MAE: 0.1865  Corr: 0.9880 
2021-01-28 19:48:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5721  Mult_acc_7: 0.4803  MAE: 0.7015  Corr: 0.8018  Loss: 0.9762 
2021-01-28 19:48:38:INFO:TRAIN-(misa) (7/26/1)>> loss: 0.1878  Has0_acc_2: 0.9735  Has0_F1_score: 0.9735  Non0_acc_2: 0.9878  Non0_F1_score: 0.9878  Mult_acc_5: 0.8520  Mult_acc_7: 0.8146  MAE: 0.1862  Corr: 0.9875 
2021-01-28 19:48:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8195  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7275  Corr: 0.7990  Loss: 1.0217 
2021-01-28 19:48:49:INFO:TRAIN-(misa) (8/27/1)>> loss: 0.1928  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8302  Mult_acc_7: 0.7905  MAE: 0.2149  Corr: 0.9844 
2021-01-28 19:48:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5284  Mult_acc_7: 0.4279  MAE: 0.7161  Corr: 0.7988  Loss: 0.9253 
2021-01-28 19:49:02:INFO:TRAIN-(misa) (1/28/1)>> loss: 0.1922  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8310  Mult_acc_7: 0.7913  MAE: 0.2066  Corr: 0.9852 
2021-01-28 19:49:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8195  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.5371  Mult_acc_7: 0.4323  MAE: 0.7263  Corr: 0.7961  Loss: 1.0725 
2021-01-28 19:49:13:INFO:TRAIN-(misa) (2/29/1)>> loss: 0.1886  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8474  Mult_acc_7: 0.8146  MAE: 0.2046  Corr: 0.9855 
2021-01-28 19:49:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8473  Non0_acc_2: 0.8657  Non0_F1_score: 0.8666  Mult_acc_5: 0.5459  Mult_acc_7: 0.4541  MAE: 0.6995  Corr: 0.8027  Loss: 0.9911 
2021-01-28 19:49:25:INFO:TRAIN-(misa) (3/30/1)>> loss: 0.1650  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9829  Non0_F1_score: 0.9829  Mult_acc_5: 0.8575  Mult_acc_7: 0.8170  MAE: 0.1839  Corr: 0.9884 
2021-01-28 19:49:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8473  Non0_acc_2: 0.8657  Non0_F1_score: 0.8666  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7111  Corr: 0.8013  Loss: 1.0947 
2021-01-28 19:49:37:INFO:TRAIN-(misa) (4/31/1)>> loss: 0.1625  Has0_acc_2: 0.9688  Has0_F1_score: 0.9688  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8544  Mult_acc_7: 0.8248  MAE: 0.1806  Corr: 0.9887 
2021-01-28 19:49:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8603  Has0_F1_score: 0.8598  Non0_acc_2: 0.8796  Non0_F1_score: 0.8798  Mult_acc_5: 0.5240  Mult_acc_7: 0.4236  MAE: 0.7052  Corr: 0.8007  Loss: 0.9697 
2021-01-28 19:49:48:INFO:TRAIN-(misa) (5/32/1)>> loss: 0.1574  Has0_acc_2: 0.9673  Has0_F1_score: 0.9672  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.8567  Mult_acc_7: 0.8201  MAE: 0.1718  Corr: 0.9895 
2021-01-28 19:49:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8472  Has0_F1_score: 0.8470  Non0_acc_2: 0.8657  Non0_F1_score: 0.8663  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7054  Corr: 0.8015  Loss: 0.9616 
2021-01-28 19:50:00:INFO:TRAIN-(misa) (6/33/1)>> loss: 0.1433  Has0_acc_2: 0.9696  Has0_F1_score: 0.9695  Non0_acc_2: 0.9927  Non0_F1_score: 0.9927  Mult_acc_5: 0.8692  Mult_acc_7: 0.8326  MAE: 0.1628  Corr: 0.9905 
2021-01-28 19:50:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5546  Mult_acc_7: 0.4585  MAE: 0.7010  Corr: 0.8006  Loss: 0.9643 
2021-01-28 19:50:11:INFO:TRAIN-(misa) (7/34/1)>> loss: 0.1503  Has0_acc_2: 0.9681  Has0_F1_score: 0.9680  Non0_acc_2: 0.9903  Non0_F1_score: 0.9903  Mult_acc_5: 0.8660  Mult_acc_7: 0.8294  MAE: 0.1680  Corr: 0.9903 
2021-01-28 19:50:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8428  Non0_acc_2: 0.8611  Non0_F1_score: 0.8618  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7099  Corr: 0.8003  Loss: 1.0249 
2021-01-28 19:50:22:INFO:TRAIN-(misa) (8/35/1)>> loss: 0.1383  Has0_acc_2: 0.9704  Has0_F1_score: 0.9703  Non0_acc_2: 0.9894  Non0_F1_score: 0.9894  Mult_acc_5: 0.8769  Mult_acc_7: 0.8505  MAE: 0.1666  Corr: 0.9902 
2021-01-28 19:50:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5459  Mult_acc_7: 0.4498  MAE: 0.7159  Corr: 0.7989  Loss: 1.0620 
2021-01-28 19:50:25:INFO:TEST-(misa) >>  Has0_acc_2: 0.8105  Has0_F1_score: 0.8109  Non0_acc_2: 0.8293  Non0_F1_score: 0.8290  Mult_acc_5: 0.4854  Mult_acc_7: 0.4329  MAE: 0.7528  Corr: 0.7845  Loss: 1.0235 
2021-01-28 19:50:25:INFO:Start saving results...
2021-01-28 19:50:25:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:50:25:INFO:########################################misa-(37/50)########################################
2021-01-28 19:50:25:INFO:batch_size:16
2021-01-28 19:50:25:INFO:learning_rate:0.0005
2021-01-28 19:50:25:INFO:hidden_size:64
2021-01-28 19:50:25:INFO:dropout:0.5
2021-01-28 19:50:25:INFO:reverse_grad_weight:1.0
2021-01-28 19:50:25:INFO:diff_weight:0.1
2021-01-28 19:50:25:INFO:sim_weight:0.5
2021-01-28 19:50:25:INFO:sp_weight:1.0
2021-01-28 19:50:25:INFO:recon_weight:1.0
2021-01-28 19:50:25:INFO:grad_clip:0.8
2021-01-28 19:50:25:INFO:weight_decay:5e-05
2021-01-28 19:50:25:INFO:##########################################################################################
2021-01-28 19:50:25:INFO:Start running misa...
2021-01-28 19:50:25:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:50:25:INFO:Let's use 1 GPUs!
2021-01-28 19:50:25:INFO:train samples: (1284,)
2021-01-28 19:50:26:INFO:valid samples: (229,)
2021-01-28 19:50:26:INFO:test samples: (686,)
2021-01-28 19:50:26:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:50:26:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:50:26:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:50:26:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:50:26:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:50:26:INFO:loading file None
2021-01-28 19:50:26:INFO:loading file None
2021-01-28 19:50:26:INFO:loading file None
2021-01-28 19:50:26:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:50:26:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:50:26:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:50:29:INFO:The model has 109943985 trainable parameters
2021-01-28 19:50:48:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.2167  Has0_acc_2: 0.5530  Has0_F1_score: 0.5915  Non0_acc_2: 0.5532  Non0_F1_score: 0.5956  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3211  Corr: 0.0425 
2021-01-28 19:50:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.4100  Corr: 0.1443  Loss: 2.7153 
2021-01-28 19:51:08:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.4350  Has0_acc_2: 0.5646  Has0_F1_score: 0.6189  Non0_acc_2: 0.5548  Non0_F1_score: 0.6112  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3122  Corr: 0.0655 
2021-01-28 19:51:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4097  Corr: 0.1671  Loss: 2.6818 
2021-01-28 19:51:28:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.3644  Has0_acc_2: 0.5553  Has0_F1_score: 0.5985  Non0_acc_2: 0.5418  Non0_F1_score: 0.5859  Mult_acc_5: 0.1861  Mult_acc_7: 0.1861  MAE: 1.3205  Corr: 0.0735 
2021-01-28 19:51:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7336  Non0_acc_2: 0.5741  Non0_F1_score: 0.7135  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4078  Corr: 0.1642  Loss: 2.7234 
2021-01-28 19:51:48:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.2301  Has0_acc_2: 0.5896  Has0_F1_score: 0.6175  Non0_acc_2: 0.5784  Non0_F1_score: 0.6067  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.2775  Corr: 0.2215 
2021-01-28 19:51:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7409  Non0_acc_2: 0.5741  Non0_F1_score: 0.7213  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4078  Corr: 0.1612  Loss: 2.6518 
2021-01-28 19:52:08:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.2353  Has0_acc_2: 0.6044  Has0_F1_score: 0.6322  Non0_acc_2: 0.5955  Non0_F1_score: 0.6240  Mult_acc_5: 0.1690  Mult_acc_7: 0.1690  MAE: 1.2702  Corr: 0.2341 
2021-01-28 19:52:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3997  Corr: 0.1608  Loss: 2.7000 
2021-01-28 19:52:27:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.1576  Has0_acc_2: 0.6114  Has0_F1_score: 0.6359  Non0_acc_2: 0.6044  Non0_F1_score: 0.6298  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.2538  Corr: 0.2779 
2021-01-28 19:52:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3993  Corr: 0.1971  Loss: 2.7427 
2021-01-28 19:52:46:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.1190  Has0_acc_2: 0.6262  Has0_F1_score: 0.6397  Non0_acc_2: 0.6206  Non0_F1_score: 0.6347  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.2348  Corr: 0.3126 
2021-01-28 19:52:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7329  Non0_acc_2: 0.5787  Non0_F1_score: 0.7129  Mult_acc_5: 0.1659  Mult_acc_7: 0.1659  MAE: 1.4028  Corr: 0.1679  Loss: 2.7269 
2021-01-28 19:53:06:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.0995  Has0_acc_2: 0.6231  Has0_F1_score: 0.6357  Non0_acc_2: 0.6158  Non0_F1_score: 0.6287  Mult_acc_5: 0.2095  Mult_acc_7: 0.2087  MAE: 1.2221  Corr: 0.3239 
2021-01-28 19:53:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6993  Non0_acc_2: 0.5926  Non0_F1_score: 0.6777  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3791  Corr: 0.1695  Loss: 2.6201 
2021-01-28 19:53:26:INFO:TRAIN-(misa) (1/9/1)>> loss: 1.9688  Has0_acc_2: 0.6449  Has0_F1_score: 0.6554  Non0_acc_2: 0.6450  Non0_F1_score: 0.6565  Mult_acc_5: 0.2243  Mult_acc_7: 0.2227  MAE: 1.1729  Corr: 0.3979 
2021-01-28 19:53:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7137  Non0_acc_2: 0.5833  Non0_F1_score: 0.6928  Mult_acc_5: 0.1747  Mult_acc_7: 0.1703  MAE: 1.3902  Corr: 0.1802  Loss: 2.7868 
2021-01-28 19:53:46:INFO:TRAIN-(misa) (2/10/1)>> loss: 2.0348  Has0_acc_2: 0.6620  Has0_F1_score: 0.6767  Non0_acc_2: 0.6572  Non0_F1_score: 0.6723  Mult_acc_5: 0.2118  Mult_acc_7: 0.2087  MAE: 1.1928  Corr: 0.3813 
2021-01-28 19:53:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6802  Non0_acc_2: 0.6111  Non0_F1_score: 0.6638  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.3592  Corr: 0.2206  Loss: 2.5528 
2021-01-28 19:54:08:INFO:TRAIN-(misa) (1/11/1)>> loss: 1.9444  Has0_acc_2: 0.6573  Has0_F1_score: 0.6677  Non0_acc_2: 0.6531  Non0_F1_score: 0.6639  Mult_acc_5: 0.2173  Mult_acc_7: 0.2165  MAE: 1.1631  Corr: 0.4236 
2021-01-28 19:54:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7447  Non0_acc_2: 0.5972  Non0_F1_score: 0.7255  Mult_acc_5: 0.1921  Mult_acc_7: 0.1878  MAE: 1.4053  Corr: 0.1720  Loss: 3.0298 
2021-01-28 19:54:27:INFO:TRAIN-(misa) (2/12/1)>> loss: 1.8911  Has0_acc_2: 0.6768  Has0_F1_score: 0.6909  Non0_acc_2: 0.6742  Non0_F1_score: 0.6890  Mult_acc_5: 0.2243  Mult_acc_7: 0.2212  MAE: 1.1508  Corr: 0.4353 
2021-01-28 19:54:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.6313  Non0_acc_2: 0.5926  Non0_F1_score: 0.6233  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3854  Corr: 0.1519  Loss: 2.6375 
2021-01-28 19:54:47:INFO:TRAIN-(misa) (3/13/1)>> loss: 1.9018  Has0_acc_2: 0.6752  Has0_F1_score: 0.6873  Non0_acc_2: 0.6734  Non0_F1_score: 0.6861  Mult_acc_5: 0.2251  Mult_acc_7: 0.2212  MAE: 1.1505  Corr: 0.4391 
2021-01-28 19:54:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.6685  Non0_acc_2: 0.6157  Non0_F1_score: 0.6628  Mult_acc_5: 0.2183  Mult_acc_7: 0.2140  MAE: 1.3648  Corr: 0.1920  Loss: 2.7156 
2021-01-28 19:55:07:INFO:TRAIN-(misa) (4/14/1)>> loss: 1.9469  Has0_acc_2: 0.6612  Has0_F1_score: 0.6745  Non0_acc_2: 0.6572  Non0_F1_score: 0.6710  Mult_acc_5: 0.2266  Mult_acc_7: 0.2212  MAE: 1.1557  Corr: 0.4294 
2021-01-28 19:55:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.1790  Mult_acc_7: 0.1703  MAE: 1.4351  Corr: 0.2127  Loss: 3.0236 
2021-01-28 19:55:27:INFO:TRAIN-(misa) (5/15/1)>> loss: 1.8841  Has0_acc_2: 0.6690  Has0_F1_score: 0.6802  Non0_acc_2: 0.6661  Non0_F1_score: 0.6778  Mult_acc_5: 0.2313  Mult_acc_7: 0.2266  MAE: 1.1431  Corr: 0.4462 
2021-01-28 19:55:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7387  Non0_acc_2: 0.6157  Non0_F1_score: 0.7195  Mult_acc_5: 0.2009  Mult_acc_7: 0.1834  MAE: 1.3928  Corr: 0.2160  Loss: 2.8815 
2021-01-28 19:55:47:INFO:TRAIN-(misa) (6/16/1)>> loss: 1.8128  Has0_acc_2: 0.6791  Has0_F1_score: 0.6910  Non0_acc_2: 0.6742  Non0_F1_score: 0.6863  Mult_acc_5: 0.2500  Mult_acc_7: 0.2438  MAE: 1.1191  Corr: 0.4811 
2021-01-28 19:55:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7057  Non0_acc_2: 0.6204  Non0_F1_score: 0.6908  Mult_acc_5: 0.1965  Mult_acc_7: 0.1878  MAE: 1.3519  Corr: 0.2426  Loss: 2.5758 
2021-01-28 19:56:06:INFO:TRAIN-(misa) (7/17/1)>> loss: 1.7758  Has0_acc_2: 0.6854  Has0_F1_score: 0.6949  Non0_acc_2: 0.6816  Non0_F1_score: 0.6914  Mult_acc_5: 0.2516  Mult_acc_7: 0.2453  MAE: 1.1061  Corr: 0.4904 
2021-01-28 19:56:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.6797  Non0_acc_2: 0.6111  Non0_F1_score: 0.6749  Mult_acc_5: 0.2140  Mult_acc_7: 0.2096  MAE: 1.3520  Corr: 0.2298  Loss: 2.6490 
2021-01-28 19:56:26:INFO:TRAIN-(misa) (8/18/1)>> loss: 1.8158  Has0_acc_2: 0.6815  Has0_F1_score: 0.6904  Non0_acc_2: 0.6791  Non0_F1_score: 0.6885  Mult_acc_5: 0.2352  Mult_acc_7: 0.2282  MAE: 1.1170  Corr: 0.4793 
2021-01-28 19:56:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.7442  Non0_acc_2: 0.6111  Non0_F1_score: 0.7252  Mult_acc_5: 0.2533  Mult_acc_7: 0.2227  MAE: 1.4315  Corr: 0.2365  Loss: 3.1379 
2021-01-28 19:56:31:INFO:TEST-(misa) >>  Has0_acc_2: 0.5248  Has0_F1_score: 0.5568  Non0_acc_2: 0.5122  Non0_F1_score: 0.5426  Mult_acc_5: 0.1603  Mult_acc_7: 0.1603  MAE: 1.4113  Corr: 0.1734  Loss: 2.7437 
2021-01-28 19:56:31:INFO:Start saving results...
2021-01-28 19:56:31:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 19:56:31:INFO:########################################misa-(38/50)########################################
2021-01-28 19:56:31:INFO:batch_size:64
2021-01-28 19:56:31:INFO:learning_rate:0.0001
2021-01-28 19:56:31:INFO:hidden_size:64
2021-01-28 19:56:31:INFO:dropout:0.5
2021-01-28 19:56:31:INFO:reverse_grad_weight:0.8
2021-01-28 19:56:31:INFO:diff_weight:0.1
2021-01-28 19:56:31:INFO:sim_weight:1.0
2021-01-28 19:56:31:INFO:sp_weight:1.0
2021-01-28 19:56:31:INFO:recon_weight:0.8
2021-01-28 19:56:31:INFO:grad_clip:-1.0
2021-01-28 19:56:31:INFO:weight_decay:0.002
2021-01-28 19:56:31:INFO:##########################################################################################
2021-01-28 19:56:31:INFO:Start running misa...
2021-01-28 19:56:31:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 19:56:31:INFO:Let's use 1 GPUs!
2021-01-28 19:56:31:INFO:train samples: (1284,)
2021-01-28 19:56:31:INFO:valid samples: (229,)
2021-01-28 19:56:32:INFO:test samples: (686,)
2021-01-28 19:56:32:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 19:56:32:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 19:56:32:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 19:56:32:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 19:56:32:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 19:56:32:INFO:loading file None
2021-01-28 19:56:32:INFO:loading file None
2021-01-28 19:56:32:INFO:loading file None
2021-01-28 19:56:32:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 19:56:32:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 19:56:32:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 19:56:36:INFO:The model has 109943985 trainable parameters
2021-01-28 19:56:47:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.3404  Has0_acc_2: 0.6098  Has0_F1_score: 0.6399  Non0_acc_2: 0.6044  Non0_F1_score: 0.6358  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.2756  Corr: 0.2041 
2021-01-28 19:56:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.6987  Has0_F1_score: 0.7377  Non0_acc_2: 0.6852  Non0_F1_score: 0.7251  Mult_acc_5: 0.2489  Mult_acc_7: 0.2489  MAE: 1.2442  Corr: 0.6783  Loss: 2.1681 
2021-01-28 19:57:00:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.3612  Has0_acc_2: 0.7882  Has0_F1_score: 0.7909  Non0_acc_2: 0.7969  Non0_F1_score: 0.8002  Mult_acc_5: 0.2617  Mult_acc_7: 0.2609  MAE: 0.9987  Corr: 0.6763 
2021-01-28 19:57:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8025  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.2882  Mult_acc_7: 0.2882  MAE: 0.9554  Corr: 0.7362  Loss: 1.4102 
2021-01-28 19:57:13:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4348  Has0_acc_2: 0.8684  Has0_F1_score: 0.8678  Non0_acc_2: 0.8846  Non0_F1_score: 0.8844  Mult_acc_5: 0.4042  Mult_acc_7: 0.3886  MAE: 0.7045  Corr: 0.8346 
2021-01-28 19:57:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7842  Non0_acc_2: 0.8148  Non0_F1_score: 0.8142  Mult_acc_5: 0.4148  Mult_acc_7: 0.3493  MAE: 0.8528  Corr: 0.7416  Loss: 1.2619 
2021-01-28 19:57:26:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.9294  Has0_acc_2: 0.8972  Has0_F1_score: 0.8968  Non0_acc_2: 0.9163  Non0_F1_score: 0.9162  Mult_acc_5: 0.5249  Mult_acc_7: 0.4875  MAE: 0.5523  Corr: 0.8919 
2021-01-28 19:57:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8086  Non0_acc_2: 0.8241  Non0_F1_score: 0.8257  Mult_acc_5: 0.4629  Mult_acc_7: 0.3712  MAE: 0.8141  Corr: 0.7567  Loss: 1.1914 
2021-01-28 19:57:39:INFO:TRAIN-(misa) (1/5/1)>> loss: 1.6569  Has0_acc_2: 0.9174  Has0_F1_score: 0.9173  Non0_acc_2: 0.9358  Non0_F1_score: 0.9358  Mult_acc_5: 0.5919  Mult_acc_7: 0.5405  MAE: 0.4856  Corr: 0.9149 
2021-01-28 19:57:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8146  Non0_acc_2: 0.8241  Non0_F1_score: 0.8271  Mult_acc_5: 0.4585  Mult_acc_7: 0.3668  MAE: 0.8056  Corr: 0.7676  Loss: 1.1808 
2021-01-28 19:57:52:INFO:TRAIN-(misa) (1/6/1)>> loss: 1.4351  Has0_acc_2: 0.9089  Has0_F1_score: 0.9088  Non0_acc_2: 0.9277  Non0_F1_score: 0.9279  Mult_acc_5: 0.6160  Mult_acc_7: 0.5662  MAE: 0.4461  Corr: 0.9275 
2021-01-28 19:57:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7633  Corr: 0.7846  Loss: 1.1237 
2021-01-28 19:58:05:INFO:TRAIN-(misa) (1/7/1)>> loss: 1.2619  Has0_acc_2: 0.9104  Has0_F1_score: 0.9102  Non0_acc_2: 0.9253  Non0_F1_score: 0.9252  Mult_acc_5: 0.6542  Mult_acc_7: 0.6067  MAE: 0.4072  Corr: 0.9401 
2021-01-28 19:58:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8182  Non0_acc_2: 0.8241  Non0_F1_score: 0.8262  Mult_acc_5: 0.5415  Mult_acc_7: 0.4323  MAE: 0.7465  Corr: 0.7851  Loss: 1.0857 
2021-01-28 19:58:18:INFO:TRAIN-(misa) (1/8/1)>> loss: 1.1318  Has0_acc_2: 0.9112  Has0_F1_score: 0.9112  Non0_acc_2: 0.9293  Non0_F1_score: 0.9295  Mult_acc_5: 0.6597  Mult_acc_7: 0.6005  MAE: 0.3996  Corr: 0.9431 
2021-01-28 19:58:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8106  Non0_acc_2: 0.8426  Non0_F1_score: 0.8421  Mult_acc_5: 0.5284  Mult_acc_7: 0.4192  MAE: 0.7551  Corr: 0.7806  Loss: 1.1067 
2021-01-28 19:58:30:INFO:TRAIN-(misa) (2/9/1)>> loss: 1.0432  Has0_acc_2: 0.9128  Has0_F1_score: 0.9126  Non0_acc_2: 0.9310  Non0_F1_score: 0.9310  Mult_acc_5: 0.6737  Mult_acc_7: 0.6153  MAE: 0.4089  Corr: 0.9413 
2021-01-28 19:58:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7894  Corr: 0.7769  Loss: 1.1662 
2021-01-28 19:58:42:INFO:TRAIN-(misa) (3/10/1)>> loss: 0.9292  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9456  Non0_F1_score: 0.9456  Mult_acc_5: 0.6854  Mult_acc_7: 0.6137  MAE: 0.3812  Corr: 0.9499 
2021-01-28 19:58:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8017  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5066  Mult_acc_7: 0.4148  MAE: 0.7574  Corr: 0.7825  Loss: 1.0594 
2021-01-28 19:58:56:INFO:TRAIN-(misa) (1/11/1)>> loss: 0.8544  Has0_acc_2: 0.9206  Has0_F1_score: 0.9203  Non0_acc_2: 0.9415  Non0_F1_score: 0.9415  Mult_acc_5: 0.6752  Mult_acc_7: 0.6067  MAE: 0.3881  Corr: 0.9478 
2021-01-28 19:58:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8611  Non0_F1_score: 0.8613  Mult_acc_5: 0.5066  Mult_acc_7: 0.4017  MAE: 0.7526  Corr: 0.7765  Loss: 1.1843 
2021-01-28 19:59:07:INFO:TRAIN-(misa) (2/12/1)>> loss: 0.7981  Has0_acc_2: 0.9174  Has0_F1_score: 0.9173  Non0_acc_2: 0.9334  Non0_F1_score: 0.9334  Mult_acc_5: 0.6706  Mult_acc_7: 0.6067  MAE: 0.3992  Corr: 0.9460 
2021-01-28 19:59:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.5328  Mult_acc_7: 0.4323  MAE: 0.7362  Corr: 0.7868  Loss: 1.0425 
2021-01-28 19:59:20:INFO:TRAIN-(misa) (1/13/1)>> loss: 0.7036  Has0_acc_2: 0.9338  Has0_F1_score: 0.9338  Non0_acc_2: 0.9513  Non0_F1_score: 0.9513  Mult_acc_5: 0.7017  Mult_acc_7: 0.6503  MAE: 0.3644  Corr: 0.9535 
2021-01-28 19:59:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5022  Mult_acc_7: 0.3930  MAE: 0.7292  Corr: 0.7903  Loss: 1.0908 
2021-01-28 19:59:32:INFO:TRAIN-(misa) (2/14/1)>> loss: 0.6581  Has0_acc_2: 0.9213  Has0_F1_score: 0.9212  Non0_acc_2: 0.9366  Non0_F1_score: 0.9366  Mult_acc_5: 0.7126  Mult_acc_7: 0.6550  MAE: 0.3697  Corr: 0.9519 
2021-01-28 19:59:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5371  Mult_acc_7: 0.4192  MAE: 0.7447  Corr: 0.7892  Loss: 1.1119 
2021-01-28 19:59:43:INFO:TRAIN-(misa) (3/15/1)>> loss: 0.5984  Has0_acc_2: 0.9354  Has0_F1_score: 0.9352  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7072  Mult_acc_7: 0.6433  MAE: 0.3570  Corr: 0.9562 
2021-01-28 19:59:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8200  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7343  Corr: 0.7919  Loss: 1.1437 
2021-01-28 19:59:55:INFO:TRAIN-(misa) (4/16/1)>> loss: 0.5195  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9626  Non0_F1_score: 0.9627  Mult_acc_5: 0.7305  Mult_acc_7: 0.6861  MAE: 0.3174  Corr: 0.9652 
2021-01-28 19:59:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8333  Non0_F1_score: 0.8345  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7504  Corr: 0.7834  Loss: 1.0800 
2021-01-28 20:00:07:INFO:TRAIN-(misa) (5/17/1)>> loss: 0.4904  Has0_acc_2: 0.9346  Has0_F1_score: 0.9345  Non0_acc_2: 0.9561  Non0_F1_score: 0.9562  Mult_acc_5: 0.7383  Mult_acc_7: 0.6799  MAE: 0.3235  Corr: 0.9627 
2021-01-28 20:00:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8519  Non0_F1_score: 0.8517  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7411  Corr: 0.7878  Loss: 1.1573 
2021-01-28 20:00:18:INFO:TRAIN-(misa) (6/18/1)>> loss: 0.4685  Has0_acc_2: 0.9252  Has0_F1_score: 0.9251  Non0_acc_2: 0.9399  Non0_F1_score: 0.9399  Mult_acc_5: 0.7383  Mult_acc_7: 0.6877  MAE: 0.3323  Corr: 0.9614 
2021-01-28 20:00:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8264  Non0_acc_2: 0.8333  Non0_F1_score: 0.8349  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7517  Corr: 0.7915  Loss: 1.1260 
2021-01-28 20:00:30:INFO:TRAIN-(misa) (7/19/1)>> loss: 0.4657  Has0_acc_2: 0.9268  Has0_F1_score: 0.9266  Non0_acc_2: 0.9472  Non0_F1_score: 0.9472  Mult_acc_5: 0.7391  Mult_acc_7: 0.6721  MAE: 0.3429  Corr: 0.9589 
2021-01-28 20:00:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8160  Non0_acc_2: 0.8426  Non0_F1_score: 0.8431  Mult_acc_5: 0.5109  Mult_acc_7: 0.4236  MAE: 0.7446  Corr: 0.7856  Loss: 1.0339 
2021-01-28 20:00:43:INFO:TRAIN-(misa) (1/20/1)>> loss: 0.4545  Has0_acc_2: 0.9400  Has0_F1_score: 0.9401  Non0_acc_2: 0.9504  Non0_F1_score: 0.9505  Mult_acc_5: 0.7009  Mult_acc_7: 0.6495  MAE: 0.3457  Corr: 0.9583 
2021-01-28 20:00:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.7714  Corr: 0.7886  Loss: 1.0961 
2021-01-28 20:00:55:INFO:TRAIN-(misa) (2/21/1)>> loss: 0.4274  Has0_acc_2: 0.9361  Has0_F1_score: 0.9359  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7181  Mult_acc_7: 0.6643  MAE: 0.3337  Corr: 0.9608 
2021-01-28 20:00:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8351  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5109  Mult_acc_7: 0.3974  MAE: 0.7375  Corr: 0.8008  Loss: 1.0643 
2021-01-28 20:01:06:INFO:TRAIN-(misa) (3/22/1)>> loss: 0.3778  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9626  Non0_F1_score: 0.9627  Mult_acc_5: 0.7274  Mult_acc_7: 0.6713  MAE: 0.3093  Corr: 0.9665 
2021-01-28 20:01:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8075  Non0_acc_2: 0.8333  Non0_F1_score: 0.8342  Mult_acc_5: 0.5328  Mult_acc_7: 0.4323  MAE: 0.7141  Corr: 0.8005  Loss: 0.9669 
2021-01-28 20:01:20:INFO:TRAIN-(misa) (1/23/1)>> loss: 0.3681  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7461  Mult_acc_7: 0.6994  MAE: 0.3137  Corr: 0.9661 
2021-01-28 20:01:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5459  Mult_acc_7: 0.4410  MAE: 0.7040  Corr: 0.8020  Loss: 0.9807 
2021-01-28 20:01:31:INFO:TRAIN-(misa) (2/24/1)>> loss: 0.3487  Has0_acc_2: 0.9354  Has0_F1_score: 0.9353  Non0_acc_2: 0.9513  Non0_F1_score: 0.9513  Mult_acc_5: 0.7399  Mult_acc_7: 0.6822  MAE: 0.3152  Corr: 0.9653 
2021-01-28 20:01:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5459  Mult_acc_7: 0.4410  MAE: 0.7226  Corr: 0.8007  Loss: 1.0130 
2021-01-28 20:01:43:INFO:TRAIN-(misa) (3/25/1)>> loss: 0.3736  Has0_acc_2: 0.9291  Has0_F1_score: 0.9290  Non0_acc_2: 0.9480  Non0_F1_score: 0.9480  Mult_acc_5: 0.7056  Mult_acc_7: 0.6511  MAE: 0.3453  Corr: 0.9591 
2021-01-28 20:01:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8203  Non0_acc_2: 0.8148  Non0_F1_score: 0.8186  Mult_acc_5: 0.4498  Mult_acc_7: 0.3537  MAE: 0.8004  Corr: 0.7935  Loss: 1.1522 
2021-01-28 20:01:55:INFO:TRAIN-(misa) (4/26/1)>> loss: 0.3740  Has0_acc_2: 0.9206  Has0_F1_score: 0.9204  Non0_acc_2: 0.9423  Non0_F1_score: 0.9423  Mult_acc_5: 0.6994  Mult_acc_7: 0.6503  MAE: 0.3535  Corr: 0.9575 
2021-01-28 20:01:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.5153  Mult_acc_7: 0.4148  MAE: 0.7605  Corr: 0.7912  Loss: 1.0671 
2021-01-28 20:02:06:INFO:TRAIN-(misa) (5/27/1)>> loss: 0.3541  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9586  Non0_F1_score: 0.9586  Mult_acc_5: 0.7196  Mult_acc_7: 0.6597  MAE: 0.3320  Corr: 0.9621 
2021-01-28 20:02:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8219  Non0_acc_2: 0.8380  Non0_F1_score: 0.8397  Mult_acc_5: 0.5284  Mult_acc_7: 0.4105  MAE: 0.7465  Corr: 0.8002  Loss: 1.0556 
2021-01-28 20:02:18:INFO:TRAIN-(misa) (6/28/1)>> loss: 0.3192  Has0_acc_2: 0.9354  Has0_F1_score: 0.9353  Non0_acc_2: 0.9529  Non0_F1_score: 0.9529  Mult_acc_5: 0.7368  Mult_acc_7: 0.6869  MAE: 0.3158  Corr: 0.9658 
2021-01-28 20:02:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5109  Mult_acc_7: 0.4192  MAE: 0.7150  Corr: 0.7995  Loss: 1.0606 
2021-01-28 20:02:29:INFO:TRAIN-(misa) (7/29/1)>> loss: 0.3078  Has0_acc_2: 0.9322  Has0_F1_score: 0.9320  Non0_acc_2: 0.9537  Non0_F1_score: 0.9537  Mult_acc_5: 0.7469  Mult_acc_7: 0.6939  MAE: 0.3097  Corr: 0.9664 
2021-01-28 20:02:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8341  Non0_acc_2: 0.8565  Non0_F1_score: 0.8573  Mult_acc_5: 0.5459  Mult_acc_7: 0.4585  MAE: 0.7215  Corr: 0.7969  Loss: 1.0964 
2021-01-28 20:02:41:INFO:TRAIN-(misa) (8/30/1)>> loss: 0.2832  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.7757  Mult_acc_7: 0.7336  MAE: 0.2866  Corr: 0.9715 
2021-01-28 20:02:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8374  Non0_acc_2: 0.8657  Non0_F1_score: 0.8656  Mult_acc_5: 0.5459  Mult_acc_7: 0.4585  MAE: 0.7204  Corr: 0.7977  Loss: 1.0434 
2021-01-28 20:02:44:INFO:TEST-(misa) >>  Has0_acc_2: 0.8105  Has0_F1_score: 0.8103  Non0_acc_2: 0.8308  Non0_F1_score: 0.8300  Mult_acc_5: 0.4738  Mult_acc_7: 0.4213  MAE: 0.7860  Corr: 0.7780  Loss: 1.1134 
2021-01-28 20:02:44:INFO:Start saving results...
2021-01-28 20:02:44:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:02:44:INFO:########################################misa-(39/50)########################################
2021-01-28 20:02:44:INFO:batch_size:64
2021-01-28 20:02:44:INFO:learning_rate:0.001
2021-01-28 20:02:44:INFO:hidden_size:256
2021-01-28 20:02:44:INFO:dropout:0.5
2021-01-28 20:02:44:INFO:reverse_grad_weight:1.0
2021-01-28 20:02:44:INFO:diff_weight:0.5
2021-01-28 20:02:44:INFO:sim_weight:1.0
2021-01-28 20:02:44:INFO:sp_weight:1.0
2021-01-28 20:02:44:INFO:recon_weight:0.8
2021-01-28 20:02:44:INFO:grad_clip:1.0
2021-01-28 20:02:44:INFO:weight_decay:0.002
2021-01-28 20:02:44:INFO:##########################################################################################
2021-01-28 20:02:44:INFO:Start running misa...
2021-01-28 20:02:44:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:02:44:INFO:Let's use 1 GPUs!
2021-01-28 20:02:45:INFO:train samples: (1284,)
2021-01-28 20:02:45:INFO:valid samples: (229,)
2021-01-28 20:02:46:INFO:test samples: (686,)
2021-01-28 20:02:46:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:02:46:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:02:46:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:02:46:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:02:46:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:02:46:INFO:loading file None
2021-01-28 20:02:46:INFO:loading file None
2021-01-28 20:02:46:INFO:loading file None
2021-01-28 20:02:46:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:02:46:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:02:46:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:02:49:INFO:The model has 112685553 trainable parameters
2021-01-28 20:03:00:INFO:TRAIN-(misa) (1/1/1)>> loss: 7.4623  Has0_acc_2: 0.5086  Has0_F1_score: 0.5126  Non0_acc_2: 0.5004  Non0_F1_score: 0.5052  Mult_acc_5: 0.2173  Mult_acc_7: 0.1908  MAE: 1.8271  Corr: -0.0454 
2021-01-28 20:03:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.1397  Mult_acc_7: 0.1397  MAE: 1.7319  Corr: 0.0953  Loss: 4.1632 
2021-01-28 20:03:13:INFO:TRAIN-(misa) (1/2/1)>> loss: 4.3540  Has0_acc_2: 0.4922  Has0_F1_score: 0.4897  Non0_acc_2: 0.4955  Non0_F1_score: 0.4942  Mult_acc_5: 0.1939  Mult_acc_7: 0.1924  MAE: 1.4282  Corr: -0.0028 
2021-01-28 20:03:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.5380  Corr: 0.0837  Loss: 3.1859 
2021-01-28 20:03:26:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.9388  Has0_acc_2: 0.5226  Has0_F1_score: 0.5614  Non0_acc_2: 0.5118  Non0_F1_score: 0.5522  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3528  Corr: -0.0198 
2021-01-28 20:03:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4356  Corr: 0.0751  Loss: 2.8388 
2021-01-28 20:03:40:INFO:TRAIN-(misa) (1/4/1)>> loss: 2.6342  Has0_acc_2: 0.5273  Has0_F1_score: 0.5411  Non0_acc_2: 0.5183  Non0_F1_score: 0.5329  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3234  Corr: 0.0265 
2021-01-28 20:03:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4168  Corr: 0.0855  Loss: 2.7144 
2021-01-28 20:03:53:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.4898  Has0_acc_2: 0.5646  Has0_F1_score: 0.6923  Non0_acc_2: 0.5483  Non0_F1_score: 0.6793  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3211  Corr: 0.0205 
2021-01-28 20:03:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4246  Corr: 0.1132  Loss: 2.7530 
2021-01-28 20:04:04:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.4344  Has0_acc_2: 0.5639  Has0_F1_score: 0.6996  Non0_acc_2: 0.5467  Non0_F1_score: 0.6858  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3260  Corr: -0.0284 
2021-01-28 20:04:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4155  Corr: 0.0769  Loss: 2.6974 
2021-01-28 20:04:18:INFO:TRAIN-(misa) (1/7/1)>> loss: 2.3557  Has0_acc_2: 0.5685  Has0_F1_score: 0.7170  Non0_acc_2: 0.5500  Non0_F1_score: 0.7014  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3228  Corr: -0.0135 
2021-01-28 20:04:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4196  Corr: 0.1130  Loss: 2.7014 
2021-01-28 20:04:29:INFO:TRAIN-(misa) (2/8/1)>> loss: 2.3039  Has0_acc_2: 0.5717  Has0_F1_score: 0.7244  Non0_acc_2: 0.5532  Non0_F1_score: 0.7092  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3171  Corr: 0.0319 
2021-01-28 20:04:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4162  Corr: 0.1319  Loss: 2.6853 
2021-01-28 20:04:42:INFO:TRAIN-(misa) (1/9/1)>> loss: 2.3520  Has0_acc_2: 0.5717  Has0_F1_score: 0.7258  Non0_acc_2: 0.5532  Non0_F1_score: 0.7106  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3206  Corr: -0.0176 
2021-01-28 20:04:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4219  Corr: 0.0831  Loss: 2.7531 
2021-01-28 20:04:54:INFO:TRAIN-(misa) (2/10/1)>> loss: 2.3700  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3166  Corr: 0.0375 
2021-01-28 20:04:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4192  Corr: 0.0524  Loss: 2.7005 
2021-01-28 20:05:06:INFO:TRAIN-(misa) (3/11/1)>> loss: 2.5082  Has0_acc_2: 0.5693  Has0_F1_score: 0.7250  Non0_acc_2: 0.5508  Non0_F1_score: 0.7097  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3237  Corr: -0.0343 
2021-01-28 20:05:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4217  Corr: 0.0685  Loss: 2.7799 
2021-01-28 20:05:17:INFO:TRAIN-(misa) (4/12/1)>> loss: 2.3817  Has0_acc_2: 0.5662  Has0_F1_score: 0.7082  Non0_acc_2: 0.5483  Non0_F1_score: 0.6935  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3236  Corr: -0.0402 
2021-01-28 20:05:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4197  Corr: -0.0245  Loss: 2.6774 
2021-01-28 20:05:30:INFO:TRAIN-(misa) (1/13/1)>> loss: 2.2895  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3213  Corr: 0.0010 
2021-01-28 20:05:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4182  Corr: -0.0044  Loss: 2.7243 
2021-01-28 20:05:42:INFO:TRAIN-(misa) (2/14/1)>> loss: 2.3055  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3207  Corr: 0.0185 
2021-01-28 20:05:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4212  Corr: 0.0229  Loss: 2.6608 
2021-01-28 20:05:55:INFO:TRAIN-(misa) (1/15/1)>> loss: 2.2654  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3216  Corr: -0.0014 
2021-01-28 20:05:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4203  Corr: 0.0537  Loss: 2.8081 
2021-01-28 20:06:07:INFO:TRAIN-(misa) (2/16/1)>> loss: 2.2759  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3163  Corr: 0.0427 
2021-01-28 20:06:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4168  Corr: 0.0776  Loss: 2.6762 
2021-01-28 20:06:19:INFO:TRAIN-(misa) (3/17/1)>> loss: 2.3405  Has0_acc_2: 0.5662  Has0_F1_score: 0.7188  Non0_acc_2: 0.5475  Non0_F1_score: 0.7033  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3207  Corr: -0.0058 
2021-01-28 20:06:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4219  Corr: 0.0839  Loss: 2.7201 
2021-01-28 20:06:30:INFO:TRAIN-(misa) (4/18/1)>> loss: 2.3875  Has0_acc_2: 0.5662  Has0_F1_score: 0.7175  Non0_acc_2: 0.5475  Non0_F1_score: 0.7019  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3211  Corr: 0.0054 
2021-01-28 20:06:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4210  Corr: 0.0720  Loss: 2.7627 
2021-01-28 20:06:42:INFO:TRAIN-(misa) (5/19/1)>> loss: 2.3261  Has0_acc_2: 0.5693  Has0_F1_score: 0.7250  Non0_acc_2: 0.5508  Non0_F1_score: 0.7097  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3186  Corr: 0.0284 
2021-01-28 20:06:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4188  Corr: 0.0685  Loss: 2.7635 
2021-01-28 20:06:54:INFO:TRAIN-(misa) (6/20/1)>> loss: 2.4321  Has0_acc_2: 0.5717  Has0_F1_score: 0.7244  Non0_acc_2: 0.5532  Non0_F1_score: 0.7092  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3219  Corr: -0.0171 
2021-01-28 20:06:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4217  Corr: 0.0634  Loss: 2.6706 
2021-01-28 20:07:05:INFO:TRAIN-(misa) (7/21/1)>> loss: 2.3928  Has0_acc_2: 0.5654  Has0_F1_score: 0.7190  Non0_acc_2: 0.5475  Non0_F1_score: 0.7047  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3183  Corr: -0.0063 
2021-01-28 20:07:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4213  Corr: 0.0695  Loss: 2.7479 
2021-01-28 20:07:17:INFO:TRAIN-(misa) (8/22/1)>> loss: 2.3528  Has0_acc_2: 0.5701  Has0_F1_score: 0.7248  Non0_acc_2: 0.5516  Non0_F1_score: 0.7095  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3197  Corr: 0.0159 
2021-01-28 20:07:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4187  Corr: 0.0750  Loss: 2.7199 
2021-01-28 20:07:20:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4541  Corr: -0.0430  Loss: 2.7886 
2021-01-28 20:07:20:INFO:Start saving results...
2021-01-28 20:07:20:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:07:20:INFO:########################################misa-(40/50)########################################
2021-01-28 20:07:20:INFO:batch_size:32
2021-01-28 20:07:20:INFO:learning_rate:0.0001
2021-01-28 20:07:20:INFO:hidden_size:64
2021-01-28 20:07:20:INFO:dropout:0.5
2021-01-28 20:07:20:INFO:reverse_grad_weight:0.8
2021-01-28 20:07:20:INFO:diff_weight:0.1
2021-01-28 20:07:20:INFO:sim_weight:1.0
2021-01-28 20:07:20:INFO:sp_weight:1.0
2021-01-28 20:07:20:INFO:recon_weight:0.5
2021-01-28 20:07:20:INFO:grad_clip:1.0
2021-01-28 20:07:20:INFO:weight_decay:5e-05
2021-01-28 20:07:20:INFO:##########################################################################################
2021-01-28 20:07:20:INFO:Start running misa...
2021-01-28 20:07:20:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:07:20:INFO:Let's use 1 GPUs!
2021-01-28 20:07:21:INFO:train samples: (1284,)
2021-01-28 20:07:21:INFO:valid samples: (229,)
2021-01-28 20:07:21:INFO:test samples: (686,)
2021-01-28 20:07:21:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:07:21:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:07:21:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:07:21:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:07:21:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:07:21:INFO:loading file None
2021-01-28 20:07:21:INFO:loading file None
2021-01-28 20:07:21:INFO:loading file None
2021-01-28 20:07:21:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:07:21:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:07:21:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:07:24:INFO:The model has 109943985 trainable parameters
2021-01-28 20:07:38:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.6121  Has0_acc_2: 0.6441  Has0_F1_score: 0.6566  Non0_acc_2: 0.6426  Non0_F1_score: 0.6560  Mult_acc_5: 0.2196  Mult_acc_7: 0.2196  MAE: 1.2062  Corr: 0.3896 
2021-01-28 20:07:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.7598  Has0_F1_score: 0.7576  Non0_acc_2: 0.7917  Non0_F1_score: 0.7905  Mult_acc_5: 0.2926  Mult_acc_7: 0.2926  MAE: 1.0947  Corr: 0.6247  Loss: 1.7478 
2021-01-28 20:07:54:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.2827  Has0_acc_2: 0.8372  Has0_F1_score: 0.8365  Non0_acc_2: 0.8546  Non0_F1_score: 0.8543  Mult_acc_5: 0.3349  Mult_acc_7: 0.3232  MAE: 0.8145  Corr: 0.7471 
2021-01-28 20:07:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8333  Non0_F1_score: 0.8324  Mult_acc_5: 0.3843  Mult_acc_7: 0.3188  MAE: 0.8758  Corr: 0.7519  Loss: 1.2236 
2021-01-28 20:08:10:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.5812  Has0_acc_2: 0.8762  Has0_F1_score: 0.8757  Non0_acc_2: 0.9009  Non0_F1_score: 0.9008  Mult_acc_5: 0.4868  Mult_acc_7: 0.4540  MAE: 0.6204  Corr: 0.8536 
2021-01-28 20:08:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8426  Non0_F1_score: 0.8419  Mult_acc_5: 0.4716  Mult_acc_7: 0.3886  MAE: 0.7966  Corr: 0.7591  Loss: 1.0740 
2021-01-28 20:08:25:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.1498  Has0_acc_2: 0.9081  Has0_F1_score: 0.9077  Non0_acc_2: 0.9277  Non0_F1_score: 0.9276  Mult_acc_5: 0.5623  Mult_acc_7: 0.5101  MAE: 0.5101  Corr: 0.9060 
2021-01-28 20:08:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8072  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.4716  Mult_acc_7: 0.3799  MAE: 0.7941  Corr: 0.7616  Loss: 1.0909 
2021-01-28 20:08:39:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.8961  Has0_acc_2: 0.9213  Has0_F1_score: 0.9212  Non0_acc_2: 0.9350  Non0_F1_score: 0.9350  Mult_acc_5: 0.6488  Mult_acc_7: 0.5958  MAE: 0.4344  Corr: 0.9316 
2021-01-28 20:08:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8333  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7418  Corr: 0.7900  Loss: 0.9577 
2021-01-28 20:08:55:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.7317  Has0_acc_2: 0.9245  Has0_F1_score: 0.9243  Non0_acc_2: 0.9423  Non0_F1_score: 0.9424  Mult_acc_5: 0.6737  Mult_acc_7: 0.6114  MAE: 0.3944  Corr: 0.9445 
2021-01-28 20:08:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8158  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.4760  Mult_acc_7: 0.3712  MAE: 0.7636  Corr: 0.7874  Loss: 1.0315 
2021-01-28 20:09:09:INFO:TRAIN-(misa) (2/7/1)>> loss: 0.6066  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9602  Non0_F1_score: 0.9602  Mult_acc_5: 0.7079  Mult_acc_7: 0.6371  MAE: 0.3597  Corr: 0.9527 
2021-01-28 20:09:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8288  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7473  Corr: 0.7925  Loss: 1.0000 
2021-01-28 20:09:24:INFO:TRAIN-(misa) (3/8/1)>> loss: 0.5186  Has0_acc_2: 0.9408  Has0_F1_score: 0.9407  Non0_acc_2: 0.9594  Non0_F1_score: 0.9594  Mult_acc_5: 0.7344  Mult_acc_7: 0.6643  MAE: 0.3413  Corr: 0.9589 
2021-01-28 20:09:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7972  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4236  Mult_acc_7: 0.3275  MAE: 0.7916  Corr: 0.7802  Loss: 1.0100 
2021-01-28 20:09:38:INFO:TRAIN-(misa) (4/9/1)>> loss: 0.4742  Has0_acc_2: 0.9424  Has0_F1_score: 0.9423  Non0_acc_2: 0.9529  Non0_F1_score: 0.9529  Mult_acc_5: 0.7282  Mult_acc_7: 0.6643  MAE: 0.3428  Corr: 0.9590 
2021-01-28 20:09:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.4672  Mult_acc_7: 0.3755  MAE: 0.7590  Corr: 0.7889  Loss: 1.0359 
2021-01-28 20:09:53:INFO:TRAIN-(misa) (5/10/1)>> loss: 0.4016  Has0_acc_2: 0.9369  Has0_F1_score: 0.9367  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7531  Mult_acc_7: 0.6978  MAE: 0.3028  Corr: 0.9673 
2021-01-28 20:09:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8072  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7531  Corr: 0.7878  Loss: 1.0455 
2021-01-28 20:10:07:INFO:TRAIN-(misa) (6/11/1)>> loss: 0.3806  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9691  Non0_F1_score: 0.9692  Mult_acc_5: 0.7562  Mult_acc_7: 0.6963  MAE: 0.3123  Corr: 0.9658 
2021-01-28 20:10:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8239  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7370  Corr: 0.7969  Loss: 1.5315 
2021-01-28 20:10:22:INFO:TRAIN-(misa) (7/12/1)>> loss: 0.3549  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7695  Mult_acc_7: 0.7157  MAE: 0.3110  Corr: 0.9661 
2021-01-28 20:10:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8565  Non0_F1_score: 0.8562  Mult_acc_5: 0.4891  Mult_acc_7: 0.4061  MAE: 0.7373  Corr: 0.7913  Loss: 1.0552 
2021-01-28 20:10:36:INFO:TRAIN-(misa) (8/13/1)>> loss: 0.3132  Has0_acc_2: 0.9447  Has0_F1_score: 0.9445  Non0_acc_2: 0.9643  Non0_F1_score: 0.9642  Mult_acc_5: 0.7749  Mult_acc_7: 0.7126  MAE: 0.2877  Corr: 0.9711 
2021-01-28 20:10:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.4978  Mult_acc_7: 0.4105  MAE: 0.7471  Corr: 0.7941  Loss: 1.1309 
2021-01-28 20:10:40:INFO:TEST-(misa) >>  Has0_acc_2: 0.8134  Has0_F1_score: 0.8138  Non0_acc_2: 0.8354  Non0_F1_score: 0.8351  Mult_acc_5: 0.4854  Mult_acc_7: 0.4213  MAE: 0.7810  Corr: 0.7660  Loss: 1.1218 
2021-01-28 20:10:40:INFO:Start saving results...
2021-01-28 20:10:40:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:10:40:INFO:########################################misa-(41/50)########################################
2021-01-28 20:10:40:INFO:batch_size:64
2021-01-28 20:10:40:INFO:learning_rate:0.0001
2021-01-28 20:10:40:INFO:hidden_size:64
2021-01-28 20:10:40:INFO:dropout:0.0
2021-01-28 20:10:40:INFO:reverse_grad_weight:0.8
2021-01-28 20:10:40:INFO:diff_weight:0.3
2021-01-28 20:10:40:INFO:sim_weight:0.5
2021-01-28 20:10:40:INFO:sp_weight:1.0
2021-01-28 20:10:40:INFO:recon_weight:1.0
2021-01-28 20:10:40:INFO:grad_clip:-1.0
2021-01-28 20:10:40:INFO:weight_decay:5e-05
2021-01-28 20:10:40:INFO:##########################################################################################
2021-01-28 20:10:40:INFO:Start running misa...
2021-01-28 20:10:40:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:10:40:INFO:Let's use 1 GPUs!
2021-01-28 20:10:40:INFO:train samples: (1284,)
2021-01-28 20:10:40:INFO:valid samples: (229,)
2021-01-28 20:10:41:INFO:test samples: (686,)
2021-01-28 20:10:41:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:10:41:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:10:41:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:10:41:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:10:41:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:10:41:INFO:loading file None
2021-01-28 20:10:41:INFO:loading file None
2021-01-28 20:10:41:INFO:loading file None
2021-01-28 20:10:41:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:10:41:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:10:41:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:10:44:INFO:The model has 109943985 trainable parameters
2021-01-28 20:10:55:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.2063  Has0_acc_2: 0.5740  Has0_F1_score: 0.6858  Non0_acc_2: 0.5573  Non0_F1_score: 0.6714  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.3066  Corr: 0.1070 
2021-01-28 20:10:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4081  Corr: 0.2201  Loss: 2.6680 
2021-01-28 20:11:08:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.9898  Has0_acc_2: 0.5701  Has0_F1_score: 0.7140  Non0_acc_2: 0.5516  Non0_F1_score: 0.6984  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3152  Corr: 0.0642 
2021-01-28 20:11:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4132  Corr: 0.1298  Loss: 2.7345 
2021-01-28 20:11:19:INFO:TRAIN-(misa) (2/3/1)>> loss: 3.8071  Has0_acc_2: 0.5802  Has0_F1_score: 0.7139  Non0_acc_2: 0.5621  Non0_F1_score: 0.6983  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.3108  Corr: 0.0904 
2021-01-28 20:11:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.7269  Non0_acc_2: 0.6065  Non0_F1_score: 0.7070  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4207  Corr: 0.1383  Loss: 2.7104 
2021-01-28 20:11:31:INFO:TRAIN-(misa) (3/4/1)>> loss: 3.5491  Has0_acc_2: 0.5841  Has0_F1_score: 0.6887  Non0_acc_2: 0.5678  Non0_F1_score: 0.6745  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.3045  Corr: 0.1616 
2021-01-28 20:11:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.4055  Corr: 0.1542  Loss: 2.6648 
2021-01-28 20:11:44:INFO:TRAIN-(misa) (1/5/1)>> loss: 3.4344  Has0_acc_2: 0.5841  Has0_F1_score: 0.7148  Non0_acc_2: 0.5662  Non0_F1_score: 0.6993  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3014  Corr: 0.1612 
2021-01-28 20:11:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4062  Corr: 0.1532  Loss: 2.6887 
2021-01-28 20:11:55:INFO:TRAIN-(misa) (2/6/1)>> loss: 3.2745  Has0_acc_2: 0.5989  Has0_F1_score: 0.6974  Non0_acc_2: 0.5825  Non0_F1_score: 0.6826  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.2940  Corr: 0.2288 
2021-01-28 20:11:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7388  Non0_acc_2: 0.5880  Non0_F1_score: 0.7192  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4054  Corr: 0.1563  Loss: 2.6517 
2021-01-28 20:12:08:INFO:TRAIN-(misa) (1/7/1)>> loss: 3.1427  Has0_acc_2: 0.5872  Has0_F1_score: 0.6950  Non0_acc_2: 0.5703  Non0_F1_score: 0.6800  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.2952  Corr: 0.2092 
2021-01-28 20:12:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.7269  Non0_acc_2: 0.6065  Non0_F1_score: 0.7070  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.4034  Corr: 0.1494  Loss: 2.7679 
2021-01-28 20:12:19:INFO:TRAIN-(misa) (2/8/1)>> loss: 3.0582  Has0_acc_2: 0.6083  Has0_F1_score: 0.6744  Non0_acc_2: 0.5930  Non0_F1_score: 0.6598  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.2853  Corr: 0.2380 
2021-01-28 20:12:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7141  Non0_acc_2: 0.6204  Non0_F1_score: 0.6997  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.4006  Corr: 0.1524  Loss: 2.6212 
2021-01-28 20:12:32:INFO:TRAIN-(misa) (1/9/1)>> loss: 2.8788  Has0_acc_2: 0.6083  Has0_F1_score: 0.6427  Non0_acc_2: 0.6019  Non0_F1_score: 0.6378  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.2780  Corr: 0.2480 
2021-01-28 20:12:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4052  Corr: 0.1525  Loss: 2.8064 
2021-01-28 20:12:44:INFO:TRAIN-(misa) (2/10/1)>> loss: 3.0601  Has0_acc_2: 0.6020  Has0_F1_score: 0.6315  Non0_acc_2: 0.5946  Non0_F1_score: 0.6251  Mult_acc_5: 0.2048  Mult_acc_7: 0.2048  MAE: 1.2805  Corr: 0.1957 
2021-01-28 20:12:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7282  Non0_acc_2: 0.6157  Non0_F1_score: 0.7085  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3907  Corr: 0.1553  Loss: 2.6634 
2021-01-28 20:12:55:INFO:TRAIN-(misa) (3/11/1)>> loss: 2.8658  Has0_acc_2: 0.6067  Has0_F1_score: 0.6520  Non0_acc_2: 0.5946  Non0_F1_score: 0.6406  Mult_acc_5: 0.1963  Mult_acc_7: 0.1963  MAE: 1.2724  Corr: 0.2376 
2021-01-28 20:12:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.6984  Non0_acc_2: 0.6296  Non0_F1_score: 0.6832  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3928  Corr: 0.1595  Loss: 2.6544 
2021-01-28 20:13:07:INFO:TRAIN-(misa) (4/12/1)>> loss: 2.6234  Has0_acc_2: 0.6254  Has0_F1_score: 0.6665  Non0_acc_2: 0.6149  Non0_F1_score: 0.6568  Mult_acc_5: 0.2072  Mult_acc_7: 0.2072  MAE: 1.2538  Corr: 0.3077 
2021-01-28 20:13:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7384  Non0_acc_2: 0.5926  Non0_F1_score: 0.7189  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3913  Corr: 0.1649  Loss: 2.6303 
2021-01-28 20:13:18:INFO:TRAIN-(misa) (5/13/1)>> loss: 2.6284  Has0_acc_2: 0.6153  Has0_F1_score: 0.6412  Non0_acc_2: 0.6076  Non0_F1_score: 0.6344  Mult_acc_5: 0.2017  Mult_acc_7: 0.2017  MAE: 1.2542  Corr: 0.2883 
2021-01-28 20:13:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7210  Non0_acc_2: 0.6019  Non0_F1_score: 0.7007  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.3854  Corr: 0.1692  Loss: 2.6892 
2021-01-28 20:13:30:INFO:TRAIN-(misa) (6/14/1)>> loss: 2.6394  Has0_acc_2: 0.6238  Has0_F1_score: 0.6509  Non0_acc_2: 0.6158  Non0_F1_score: 0.6435  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.2487  Corr: 0.3006 
2021-01-28 20:13:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7382  Non0_acc_2: 0.5972  Non0_F1_score: 0.7187  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.3991  Corr: 0.1660  Loss: 2.7764 
2021-01-28 20:13:41:INFO:TRAIN-(misa) (7/15/1)>> loss: 2.5802  Has0_acc_2: 0.6223  Has0_F1_score: 0.6385  Non0_acc_2: 0.6182  Non0_F1_score: 0.6353  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.2405  Corr: 0.2928 
2021-01-28 20:13:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7254  Non0_acc_2: 0.6250  Non0_F1_score: 0.7057  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3837  Corr: 0.1646  Loss: 2.6643 
2021-01-28 20:13:53:INFO:TRAIN-(misa) (8/16/1)>> loss: 2.5258  Has0_acc_2: 0.6215  Has0_F1_score: 0.6425  Non0_acc_2: 0.6125  Non0_F1_score: 0.6339  Mult_acc_5: 0.1838  Mult_acc_7: 0.1838  MAE: 1.2521  Corr: 0.2752 
2021-01-28 20:13:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.6616  Non0_acc_2: 0.6204  Non0_F1_score: 0.6446  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3894  Corr: 0.1684  Loss: 2.6130 
2021-01-28 20:14:06:INFO:TRAIN-(misa) (1/17/1)>> loss: 2.3824  Has0_acc_2: 0.6394  Has0_F1_score: 0.6691  Non0_acc_2: 0.6271  Non0_F1_score: 0.6568  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.2417  Corr: 0.3065 
2021-01-28 20:14:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6738  Non0_acc_2: 0.6111  Non0_F1_score: 0.6571  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.3817  Corr: 0.1728  Loss: 2.6379 
2021-01-28 20:14:17:INFO:TRAIN-(misa) (2/18/1)>> loss: 2.3641  Has0_acc_2: 0.6425  Has0_F1_score: 0.6579  Non0_acc_2: 0.6369  Non0_F1_score: 0.6528  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.2294  Corr: 0.3298 
2021-01-28 20:14:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7300  Non0_acc_2: 0.6250  Non0_F1_score: 0.7105  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3838  Corr: 0.1712  Loss: 2.7636 
2021-01-28 20:14:29:INFO:TRAIN-(misa) (3/19/1)>> loss: 2.2387  Has0_acc_2: 0.6379  Has0_F1_score: 0.6526  Non0_acc_2: 0.6336  Non0_F1_score: 0.6491  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2192  Corr: 0.3403 
2021-01-28 20:14:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7018  Non0_acc_2: 0.6296  Non0_F1_score: 0.6867  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3783  Corr: 0.1713  Loss: 2.6564 
2021-01-28 20:14:40:INFO:TRAIN-(misa) (4/20/1)>> loss: 2.2490  Has0_acc_2: 0.6379  Has0_F1_score: 0.6643  Non0_acc_2: 0.6288  Non0_F1_score: 0.6555  Mult_acc_5: 0.2072  Mult_acc_7: 0.2072  MAE: 1.2142  Corr: 0.3552 
2021-01-28 20:14:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.6419  Has0_F1_score: 0.6759  Non0_acc_2: 0.6250  Non0_F1_score: 0.6595  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3830  Corr: 0.1706  Loss: 2.6662 
2021-01-28 20:14:51:INFO:TRAIN-(misa) (5/21/1)>> loss: 2.2020  Has0_acc_2: 0.6519  Has0_F1_score: 0.6723  Non0_acc_2: 0.6434  Non0_F1_score: 0.6640  Mult_acc_5: 0.2040  Mult_acc_7: 0.2033  MAE: 1.2113  Corr: 0.3667 
2021-01-28 20:14:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7018  Non0_acc_2: 0.6296  Non0_F1_score: 0.6867  Mult_acc_5: 0.1921  Mult_acc_7: 0.1921  MAE: 1.3786  Corr: 0.1720  Loss: 2.7053 
2021-01-28 20:15:03:INFO:TRAIN-(misa) (6/22/1)>> loss: 2.1400  Has0_acc_2: 0.6425  Has0_F1_score: 0.6616  Non0_acc_2: 0.6361  Non0_F1_score: 0.6557  Mult_acc_5: 0.2056  Mult_acc_7: 0.2048  MAE: 1.2088  Corr: 0.3658 
2021-01-28 20:15:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.6921  Non0_acc_2: 0.6296  Non0_F1_score: 0.6765  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3793  Corr: 0.1704  Loss: 2.6733 
2021-01-28 20:15:14:INFO:TRAIN-(misa) (7/23/1)>> loss: 2.1191  Has0_acc_2: 0.6456  Has0_F1_score: 0.6581  Non0_acc_2: 0.6442  Non0_F1_score: 0.6575  Mult_acc_5: 0.2079  Mult_acc_7: 0.2079  MAE: 1.2062  Corr: 0.3706 
2021-01-28 20:15:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.7275  Non0_acc_2: 0.6111  Non0_F1_score: 0.7077  Mult_acc_5: 0.2009  Mult_acc_7: 0.1878  MAE: 1.3878  Corr: 0.1782  Loss: 2.6793 
2021-01-28 20:15:25:INFO:TRAIN-(misa) (8/24/1)>> loss: 2.1282  Has0_acc_2: 0.6340  Has0_F1_score: 0.6467  Non0_acc_2: 0.6263  Non0_F1_score: 0.6393  Mult_acc_5: 0.2103  Mult_acc_7: 0.2087  MAE: 1.2041  Corr: 0.3605 
2021-01-28 20:15:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7282  Non0_acc_2: 0.6157  Non0_F1_score: 0.7085  Mult_acc_5: 0.2140  Mult_acc_7: 0.2052  MAE: 1.3811  Corr: 0.1829  Loss: 2.7557 
2021-01-28 20:15:28:INFO:TEST-(misa) >>  Has0_acc_2: 0.5248  Has0_F1_score: 0.5431  Non0_acc_2: 0.5152  Non0_F1_score: 0.5319  Mult_acc_5: 0.1472  Mult_acc_7: 0.1472  MAE: 1.4178  Corr: 0.1511  Loss: 2.6810 
2021-01-28 20:15:28:INFO:Start saving results...
2021-01-28 20:15:28:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:15:28:INFO:########################################misa-(42/50)########################################
2021-01-28 20:15:28:INFO:batch_size:64
2021-01-28 20:15:28:INFO:learning_rate:0.0005
2021-01-28 20:15:28:INFO:hidden_size:128
2021-01-28 20:15:28:INFO:dropout:0.2
2021-01-28 20:15:28:INFO:reverse_grad_weight:1.0
2021-01-28 20:15:28:INFO:diff_weight:0.3
2021-01-28 20:15:28:INFO:sim_weight:0.5
2021-01-28 20:15:28:INFO:sp_weight:0.0
2021-01-28 20:15:28:INFO:recon_weight:0.8
2021-01-28 20:15:28:INFO:grad_clip:-1.0
2021-01-28 20:15:28:INFO:weight_decay:5e-05
2021-01-28 20:15:28:INFO:##########################################################################################
2021-01-28 20:15:28:INFO:Start running misa...
2021-01-28 20:15:28:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:15:28:INFO:Let's use 1 GPUs!
2021-01-28 20:15:29:INFO:train samples: (1284,)
2021-01-28 20:15:29:INFO:valid samples: (229,)
2021-01-28 20:15:29:INFO:test samples: (686,)
2021-01-28 20:15:29:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:15:29:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:15:29:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:15:29:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:15:29:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:15:29:INFO:loading file None
2021-01-28 20:15:29:INFO:loading file None
2021-01-28 20:15:29:INFO:loading file None
2021-01-28 20:15:29:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:15:29:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:15:29:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:15:32:INFO:The model has 110620273 trainable parameters
2021-01-28 20:15:43:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.1150  Has0_acc_2: 0.5483  Has0_F1_score: 0.5838  Non0_acc_2: 0.5386  Non0_F1_score: 0.5755  Mult_acc_5: 0.1885  Mult_acc_7: 0.1861  MAE: 1.3863  Corr: 0.0407 
2021-01-28 20:15:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4104  Corr: 0.1062  Loss: 2.7130 
2021-01-28 20:15:56:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.9605  Has0_acc_2: 0.5693  Has0_F1_score: 0.6243  Non0_acc_2: 0.5573  Non0_F1_score: 0.6137  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.3073  Corr: 0.0820 
2021-01-28 20:15:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.4144  Corr: 0.1219  Loss: 2.7431 
2021-01-28 20:16:07:INFO:TRAIN-(misa) (2/3/1)>> loss: 2.5980  Has0_acc_2: 0.5514  Has0_F1_score: 0.5783  Non0_acc_2: 0.5418  Non0_F1_score: 0.5698  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3198  Corr: 0.0540 
2021-01-28 20:16:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4123  Corr: 0.1280  Loss: 2.7183 
2021-01-28 20:16:18:INFO:TRAIN-(misa) (3/4/1)>> loss: 2.4477  Has0_acc_2: 0.5607  Has0_F1_score: 0.6744  Non0_acc_2: 0.5435  Non0_F1_score: 0.6594  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3213  Corr: 0.0076 
2021-01-28 20:16:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4235  Corr: 0.1325  Loss: 2.7917 
2021-01-28 20:16:30:INFO:TRAIN-(misa) (4/5/1)>> loss: 2.3577  Has0_acc_2: 0.5732  Has0_F1_score: 0.7123  Non0_acc_2: 0.5548  Non0_F1_score: 0.6966  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3125  Corr: 0.0759 
2021-01-28 20:16:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4141  Corr: 0.1436  Loss: 2.6598 
2021-01-28 20:16:43:INFO:TRAIN-(misa) (1/6/1)>> loss: 2.3403  Has0_acc_2: 0.5732  Has0_F1_score: 0.6967  Non0_acc_2: 0.5565  Non0_F1_score: 0.6827  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3159  Corr: 0.0589 
2021-01-28 20:16:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4117  Corr: 0.1587  Loss: 2.7128 
2021-01-28 20:16:54:INFO:TRAIN-(misa) (2/7/1)>> loss: 2.3844  Has0_acc_2: 0.5724  Has0_F1_score: 0.7025  Non0_acc_2: 0.5548  Non0_F1_score: 0.6876  Mult_acc_5: 0.1916  Mult_acc_7: 0.1916  MAE: 1.3123  Corr: 0.0763 
2021-01-28 20:16:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4152  Corr: 0.1639  Loss: 2.8098 
2021-01-28 20:17:06:INFO:TRAIN-(misa) (3/8/1)>> loss: 2.2512  Has0_acc_2: 0.5732  Has0_F1_score: 0.6600  Non0_acc_2: 0.5573  Non0_F1_score: 0.6457  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3138  Corr: 0.0642 
2021-01-28 20:17:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.5284  Has0_F1_score: 0.5246  Non0_acc_2: 0.5139  Non0_F1_score: 0.5130  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4328  Corr: 0.1658  Loss: 2.7546 
2021-01-28 20:17:18:INFO:TRAIN-(misa) (4/9/1)>> loss: 2.3839  Has0_acc_2: 0.5927  Has0_F1_score: 0.6552  Non0_acc_2: 0.5808  Non0_F1_score: 0.6450  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3066  Corr: 0.1145 
2021-01-28 20:17:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.4072  Corr: 0.1692  Loss: 2.7028 
2021-01-28 20:17:29:INFO:TRAIN-(misa) (5/10/1)>> loss: 2.2991  Has0_acc_2: 0.5966  Has0_F1_score: 0.6906  Non0_acc_2: 0.5800  Non0_F1_score: 0.6755  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.2877  Corr: 0.2384 
2021-01-28 20:17:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7475  Non0_acc_2: 0.5787  Non0_F1_score: 0.7283  Mult_acc_5: 0.1616  Mult_acc_7: 0.1616  MAE: 1.4019  Corr: 0.1703  Loss: 2.7301 
2021-01-28 20:17:41:INFO:TRAIN-(misa) (6/11/1)>> loss: 2.2765  Has0_acc_2: 0.6083  Has0_F1_score: 0.6418  Non0_acc_2: 0.5987  Non0_F1_score: 0.6330  Mult_acc_5: 0.2033  Mult_acc_7: 0.2033  MAE: 1.2648  Corr: 0.2321 
2021-01-28 20:17:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3990  Corr: 0.1758  Loss: 2.7217 
2021-01-28 20:17:52:INFO:TRAIN-(misa) (7/12/1)>> loss: 2.1866  Has0_acc_2: 0.6090  Has0_F1_score: 0.6432  Non0_acc_2: 0.5987  Non0_F1_score: 0.6335  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.2418  Corr: 0.3065 
2021-01-28 20:17:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.6523  Non0_acc_2: 0.6065  Non0_F1_score: 0.6400  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3902  Corr: 0.1791  Loss: 2.6162 
2021-01-28 20:18:05:INFO:TRAIN-(misa) (1/13/1)>> loss: 2.1043  Has0_acc_2: 0.6199  Has0_F1_score: 0.6398  Non0_acc_2: 0.6109  Non0_F1_score: 0.6310  Mult_acc_5: 0.2033  Mult_acc_7: 0.2033  MAE: 1.2382  Corr: 0.3059 
2021-01-28 20:18:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7259  Non0_acc_2: 0.5833  Non0_F1_score: 0.7056  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.3803  Corr: 0.1948  Loss: 2.6113 
2021-01-28 20:18:18:INFO:TRAIN-(misa) (1/14/1)>> loss: 2.1091  Has0_acc_2: 0.6238  Has0_F1_score: 0.6427  Non0_acc_2: 0.6117  Non0_F1_score: 0.6303  Mult_acc_5: 0.2056  Mult_acc_7: 0.2048  MAE: 1.2278  Corr: 0.3276 
2021-01-28 20:18:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.6890  Non0_acc_2: 0.6065  Non0_F1_score: 0.6731  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.3765  Corr: 0.2080  Loss: 2.5661 
2021-01-28 20:18:31:INFO:TRAIN-(misa) (1/15/1)>> loss: 2.0352  Has0_acc_2: 0.6153  Has0_F1_score: 0.6259  Non0_acc_2: 0.6149  Non0_F1_score: 0.6268  Mult_acc_5: 0.2087  Mult_acc_7: 0.2072  MAE: 1.2173  Corr: 0.3385 
2021-01-28 20:18:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1878  Mult_acc_7: 0.1747  MAE: 1.4394  Corr: 0.2174  Loss: 2.9981 
2021-01-28 20:18:43:INFO:TRAIN-(misa) (2/16/1)>> loss: 2.1154  Has0_acc_2: 0.6231  Has0_F1_score: 0.6496  Non0_acc_2: 0.6109  Non0_F1_score: 0.6374  Mult_acc_5: 0.2040  Mult_acc_7: 0.2025  MAE: 1.2366  Corr: 0.3028 
2021-01-28 20:18:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6627  Non0_acc_2: 0.6204  Non0_F1_score: 0.6566  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3716  Corr: 0.2094  Loss: 2.5966 
2021-01-28 20:18:55:INFO:TRAIN-(misa) (3/17/1)>> loss: 2.0489  Has0_acc_2: 0.6441  Has0_F1_score: 0.6563  Non0_acc_2: 0.6353  Non0_F1_score: 0.6475  Mult_acc_5: 0.2204  Mult_acc_7: 0.2165  MAE: 1.1928  Corr: 0.3839 
2021-01-28 20:18:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.6707  Non0_acc_2: 0.6250  Non0_F1_score: 0.6595  Mult_acc_5: 0.2140  Mult_acc_7: 0.2009  MAE: 1.3638  Corr: 0.2109  Loss: 2.5919 
2021-01-28 20:19:06:INFO:TRAIN-(misa) (4/18/1)>> loss: 1.9148  Has0_acc_2: 0.6581  Has0_F1_score: 0.6639  Non0_acc_2: 0.6539  Non0_F1_score: 0.6601  Mult_acc_5: 0.2266  Mult_acc_7: 0.2235  MAE: 1.1669  Corr: 0.4184 
2021-01-28 20:19:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2009  Mult_acc_7: 0.1703  MAE: 1.4800  Corr: 0.2046  Loss: 3.3289 
2021-01-28 20:19:18:INFO:TRAIN-(misa) (5/19/1)>> loss: 2.0763  Has0_acc_2: 0.6231  Has0_F1_score: 0.6421  Non0_acc_2: 0.6149  Non0_F1_score: 0.6344  Mult_acc_5: 0.2079  Mult_acc_7: 0.2048  MAE: 1.2205  Corr: 0.3163 
2021-01-28 20:19:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.6371  Non0_acc_2: 0.6019  Non0_F1_score: 0.6295  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.3651  Corr: 0.2166  Loss: 2.7012 
2021-01-28 20:19:29:INFO:TRAIN-(misa) (6/20/1)>> loss: 2.0243  Has0_acc_2: 0.6394  Has0_F1_score: 0.6444  Non0_acc_2: 0.6344  Non0_F1_score: 0.6398  Mult_acc_5: 0.2251  Mult_acc_7: 0.2243  MAE: 1.1882  Corr: 0.3809 
2021-01-28 20:19:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7261  Non0_acc_2: 0.6019  Non0_F1_score: 0.7124  Mult_acc_5: 0.1878  Mult_acc_7: 0.1703  MAE: 1.4064  Corr: 0.2180  Loss: 2.9158 
2021-01-28 20:19:41:INFO:TRAIN-(misa) (7/21/1)>> loss: 2.0616  Has0_acc_2: 0.6308  Has0_F1_score: 0.6450  Non0_acc_2: 0.6247  Non0_F1_score: 0.6393  Mult_acc_5: 0.2111  Mult_acc_7: 0.2111  MAE: 1.1899  Corr: 0.3873 
2021-01-28 20:19:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6946  Non0_acc_2: 0.6019  Non0_F1_score: 0.6850  Mult_acc_5: 0.2140  Mult_acc_7: 0.2009  MAE: 1.3667  Corr: 0.2225  Loss: 2.6532 
2021-01-28 20:19:52:INFO:TRAIN-(misa) (8/22/1)>> loss: 1.8945  Has0_acc_2: 0.6830  Has0_F1_score: 0.6899  Non0_acc_2: 0.6791  Non0_F1_score: 0.6863  Mult_acc_5: 0.2477  Mult_acc_7: 0.2445  MAE: 1.1299  Corr: 0.4629 
2021-01-28 20:19:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5808  Has0_F1_score: 0.5816  Non0_acc_2: 0.5880  Non0_F1_score: 0.5913  Mult_acc_5: 0.2620  Mult_acc_7: 0.2489  MAE: 1.3608  Corr: 0.2120  Loss: 2.6395 
2021-01-28 20:19:55:INFO:TEST-(misa) >>  Has0_acc_2: 0.5015  Has0_F1_score: 0.5520  Non0_acc_2: 0.4832  Non0_F1_score: 0.5317  Mult_acc_5: 0.1516  Mult_acc_7: 0.1516  MAE: 1.4317  Corr: 0.1523  Loss: 2.7629 
2021-01-28 20:19:55:INFO:Start saving results...
2021-01-28 20:19:55:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:19:55:INFO:########################################misa-(43/50)########################################
2021-01-28 20:19:55:INFO:batch_size:32
2021-01-28 20:19:55:INFO:learning_rate:0.0005
2021-01-28 20:19:55:INFO:hidden_size:128
2021-01-28 20:19:55:INFO:dropout:0.2
2021-01-28 20:19:55:INFO:reverse_grad_weight:0.8
2021-01-28 20:19:55:INFO:diff_weight:0.1
2021-01-28 20:19:55:INFO:sim_weight:1.0
2021-01-28 20:19:55:INFO:sp_weight:1.0
2021-01-28 20:19:55:INFO:recon_weight:1.0
2021-01-28 20:19:55:INFO:grad_clip:0.8
2021-01-28 20:19:55:INFO:weight_decay:5e-05
2021-01-28 20:19:55:INFO:##########################################################################################
2021-01-28 20:19:55:INFO:Start running misa...
2021-01-28 20:19:55:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:19:55:INFO:Let's use 1 GPUs!
2021-01-28 20:19:55:INFO:train samples: (1284,)
2021-01-28 20:19:55:INFO:valid samples: (229,)
2021-01-28 20:19:56:INFO:test samples: (686,)
2021-01-28 20:19:56:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:19:56:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:19:56:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:19:56:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:19:56:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:19:56:INFO:loading file None
2021-01-28 20:19:56:INFO:loading file None
2021-01-28 20:19:56:INFO:loading file None
2021-01-28 20:19:56:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:19:56:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:19:56:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:19:59:INFO:The model has 110620273 trainable parameters
2021-01-28 20:20:13:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.0364  Has0_acc_2: 0.5561  Has0_F1_score: 0.5949  Non0_acc_2: 0.5443  Non0_F1_score: 0.5840  Mult_acc_5: 0.1815  Mult_acc_7: 0.1815  MAE: 1.3396  Corr: 0.0086 
2021-01-28 20:20:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.4100  Corr: 0.1094  Loss: 2.7045 
2021-01-28 20:20:29:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.6534  Has0_acc_2: 0.5639  Has0_F1_score: 0.6284  Non0_acc_2: 0.5532  Non0_F1_score: 0.6201  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.3087  Corr: 0.0808 
2021-01-28 20:20:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.4033  Corr: 0.1449  Loss: 2.5520 
2021-01-28 20:20:45:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4211  Has0_acc_2: 0.6059  Has0_F1_score: 0.6382  Non0_acc_2: 0.5963  Non0_F1_score: 0.6292  Mult_acc_5: 0.1791  Mult_acc_7: 0.1791  MAE: 1.2860  Corr: 0.1832 
2021-01-28 20:20:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6365  Non0_acc_2: 0.5926  Non0_F1_score: 0.6233  Mult_acc_5: 0.2183  Mult_acc_7: 0.2183  MAE: 1.4025  Corr: 0.1514  Loss: 2.6944 
2021-01-28 20:20:59:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3608  Has0_acc_2: 0.5997  Has0_F1_score: 0.6219  Non0_acc_2: 0.5890  Non0_F1_score: 0.6114  Mult_acc_5: 0.1908  Mult_acc_7: 0.1900  MAE: 1.2750  Corr: 0.2181 
2021-01-28 20:21:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3940  Corr: 0.1830  Loss: 2.7719 
2021-01-28 20:21:13:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.2860  Has0_acc_2: 0.6106  Has0_F1_score: 0.6373  Non0_acc_2: 0.6019  Non0_F1_score: 0.6293  Mult_acc_5: 0.2002  Mult_acc_7: 0.1994  MAE: 1.2594  Corr: 0.2496 
2021-01-28 20:21:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7197  Non0_acc_2: 0.5787  Non0_F1_score: 0.6990  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3831  Corr: 0.1905  Loss: 2.4578 
2021-01-28 20:21:30:INFO:TRAIN-(misa) (1/6/1)>> loss: 2.1974  Has0_acc_2: 0.6168  Has0_F1_score: 0.6375  Non0_acc_2: 0.6076  Non0_F1_score: 0.6286  Mult_acc_5: 0.2017  Mult_acc_7: 0.2017  MAE: 1.2442  Corr: 0.2858 
2021-01-28 20:21:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7465  Non0_acc_2: 0.5833  Non0_F1_score: 0.7273  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.4000  Corr: 0.2219  Loss: 2.8298 
2021-01-28 20:21:44:INFO:TRAIN-(misa) (2/7/1)>> loss: 2.2035  Has0_acc_2: 0.6114  Has0_F1_score: 0.6342  Non0_acc_2: 0.6060  Non0_F1_score: 0.6299  Mult_acc_5: 0.2002  Mult_acc_7: 0.1994  MAE: 1.2460  Corr: 0.2853 
2021-01-28 20:21:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7003  Non0_acc_2: 0.6019  Non0_F1_score: 0.6850  Mult_acc_5: 0.1921  Mult_acc_7: 0.1790  MAE: 1.3751  Corr: 0.2181  Loss: 2.7711 
2021-01-28 20:21:58:INFO:TRAIN-(misa) (3/8/1)>> loss: 2.1862  Has0_acc_2: 0.6168  Has0_F1_score: 0.6263  Non0_acc_2: 0.6093  Non0_F1_score: 0.6190  Mult_acc_5: 0.2079  Mult_acc_7: 0.2079  MAE: 1.2379  Corr: 0.2861 
2021-01-28 20:21:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7465  Non0_acc_2: 0.5833  Non0_F1_score: 0.7273  Mult_acc_5: 0.1878  Mult_acc_7: 0.1834  MAE: 1.4048  Corr: 0.2324  Loss: 2.6708 
2021-01-28 20:22:13:INFO:TRAIN-(misa) (4/9/1)>> loss: 2.1834  Has0_acc_2: 0.6262  Has0_F1_score: 0.6469  Non0_acc_2: 0.6182  Non0_F1_score: 0.6394  Mult_acc_5: 0.2017  Mult_acc_7: 0.2002  MAE: 1.2258  Corr: 0.3214 
2021-01-28 20:22:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7393  Non0_acc_2: 0.5833  Non0_F1_score: 0.7197  Mult_acc_5: 0.1878  Mult_acc_7: 0.1747  MAE: 1.4088  Corr: 0.2261  Loss: 2.8292 
2021-01-28 20:22:27:INFO:TRAIN-(misa) (5/10/1)>> loss: 2.1584  Has0_acc_2: 0.6254  Has0_F1_score: 0.6442  Non0_acc_2: 0.6182  Non0_F1_score: 0.6375  Mult_acc_5: 0.1970  Mult_acc_7: 0.1963  MAE: 1.2175  Corr: 0.3377 
2021-01-28 20:22:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.6527  Non0_acc_2: 0.6157  Non0_F1_score: 0.6459  Mult_acc_5: 0.2358  Mult_acc_7: 0.2227  MAE: 1.3518  Corr: 0.2329  Loss: 2.6099 
2021-01-28 20:22:42:INFO:TRAIN-(misa) (6/11/1)>> loss: 2.0386  Has0_acc_2: 0.6417  Has0_F1_score: 0.6526  Non0_acc_2: 0.6361  Non0_F1_score: 0.6473  Mult_acc_5: 0.2157  Mult_acc_7: 0.2134  MAE: 1.1781  Corr: 0.3997 
2021-01-28 20:22:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.5590  Has0_F1_score: 0.5590  Non0_acc_2: 0.5787  Non0_F1_score: 0.5797  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3940  Corr: 0.2302  Loss: 2.7273 
2021-01-28 20:22:56:INFO:TRAIN-(misa) (7/12/1)>> loss: 2.1216  Has0_acc_2: 0.6301  Has0_F1_score: 0.6375  Non0_acc_2: 0.6247  Non0_F1_score: 0.6325  Mult_acc_5: 0.2165  Mult_acc_7: 0.2142  MAE: 1.2054  Corr: 0.3573 
2021-01-28 20:22:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7003  Non0_acc_2: 0.6019  Non0_F1_score: 0.6850  Mult_acc_5: 0.2140  Mult_acc_7: 0.2009  MAE: 1.3602  Corr: 0.2318  Loss: 2.5995 
2021-01-28 20:23:10:INFO:TRAIN-(misa) (8/13/1)>> loss: 1.9354  Has0_acc_2: 0.6604  Has0_F1_score: 0.6670  Non0_acc_2: 0.6588  Non0_F1_score: 0.6659  Mult_acc_5: 0.2360  Mult_acc_7: 0.2344  MAE: 1.1498  Corr: 0.4352 
2021-01-28 20:23:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.6483  Non0_acc_2: 0.6157  Non0_F1_score: 0.6413  Mult_acc_5: 0.2707  Mult_acc_7: 0.2533  MAE: 1.3407  Corr: 0.2460  Loss: 2.7569 
2021-01-28 20:23:14:INFO:TEST-(misa) >>  Has0_acc_2: 0.4781  Has0_F1_score: 0.5777  Non0_acc_2: 0.4573  Non0_F1_score: 0.5562  Mult_acc_5: 0.1560  Mult_acc_7: 0.1560  MAE: 1.4719  Corr: 0.1626  Loss: 2.9226 
2021-01-28 20:23:14:INFO:Start saving results...
2021-01-28 20:23:14:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:23:14:INFO:########################################misa-(44/50)########################################
2021-01-28 20:23:14:INFO:batch_size:16
2021-01-28 20:23:14:INFO:learning_rate:0.0005
2021-01-28 20:23:14:INFO:hidden_size:64
2021-01-28 20:23:14:INFO:dropout:0.2
2021-01-28 20:23:14:INFO:reverse_grad_weight:0.5
2021-01-28 20:23:14:INFO:diff_weight:0.3
2021-01-28 20:23:14:INFO:sim_weight:0.5
2021-01-28 20:23:14:INFO:sp_weight:0.0
2021-01-28 20:23:14:INFO:recon_weight:0.8
2021-01-28 20:23:14:INFO:grad_clip:-1.0
2021-01-28 20:23:14:INFO:weight_decay:5e-05
2021-01-28 20:23:14:INFO:##########################################################################################
2021-01-28 20:23:14:INFO:Start running misa...
2021-01-28 20:23:14:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:23:14:INFO:Let's use 1 GPUs!
2021-01-28 20:23:14:INFO:train samples: (1284,)
2021-01-28 20:23:14:INFO:valid samples: (229,)
2021-01-28 20:23:14:INFO:test samples: (686,)
2021-01-28 20:23:14:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:23:14:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:23:14:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:23:14:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:23:14:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:23:14:INFO:loading file None
2021-01-28 20:23:14:INFO:loading file None
2021-01-28 20:23:14:INFO:loading file None
2021-01-28 20:23:14:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:23:14:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:23:14:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:23:17:INFO:The model has 109943985 trainable parameters
2021-01-28 20:23:35:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.0473  Has0_acc_2: 0.5576  Has0_F1_score: 0.6190  Non0_acc_2: 0.5459  Non0_F1_score: 0.6092  Mult_acc_5: 0.1947  Mult_acc_7: 0.1947  MAE: 1.3135  Corr: 0.0748 
2021-01-28 20:23:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.4070  Corr: 0.1560  Loss: 2.6990 
2021-01-28 20:23:56:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.3604  Has0_acc_2: 0.6051  Has0_F1_score: 0.6590  Non0_acc_2: 0.5930  Non0_F1_score: 0.6479  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2942  Corr: 0.1532 
2021-01-28 20:23:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7322  Non0_acc_2: 0.5880  Non0_F1_score: 0.7123  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3953  Corr: 0.1726  Loss: 2.6298 
2021-01-28 20:24:16:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.2673  Has0_acc_2: 0.6114  Has0_F1_score: 0.6405  Non0_acc_2: 0.6044  Non0_F1_score: 0.6346  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.2758  Corr: 0.2178 
2021-01-28 20:24:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6986  Non0_acc_2: 0.6065  Non0_F1_score: 0.6773  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.3966  Corr: 0.1759  Loss: 2.6979 
2021-01-28 20:24:34:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.2053  Has0_acc_2: 0.5958  Has0_F1_score: 0.6129  Non0_acc_2: 0.5849  Non0_F1_score: 0.6021  Mult_acc_5: 0.1970  Mult_acc_7: 0.1955  MAE: 1.2583  Corr: 0.2542 
2021-01-28 20:24:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7336  Non0_acc_2: 0.5741  Non0_F1_score: 0.7135  Mult_acc_5: 0.1659  Mult_acc_7: 0.1659  MAE: 1.3868  Corr: 0.1968  Loss: 2.5920 
2021-01-28 20:24:55:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.1420  Has0_acc_2: 0.6363  Has0_F1_score: 0.6639  Non0_acc_2: 0.6279  Non0_F1_score: 0.6561  Mult_acc_5: 0.1931  Mult_acc_7: 0.1924  MAE: 1.2396  Corr: 0.3052 
2021-01-28 20:24:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7400  Non0_acc_2: 0.5787  Non0_F1_score: 0.7204  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.3865  Corr: 0.2083  Loss: 2.6667 
2021-01-28 20:25:14:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.0908  Has0_acc_2: 0.6262  Has0_F1_score: 0.6476  Non0_acc_2: 0.6214  Non0_F1_score: 0.6438  Mult_acc_5: 0.2079  Mult_acc_7: 0.2079  MAE: 1.2217  Corr: 0.3314 
2021-01-28 20:25:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.4188  Corr: 0.2171  Loss: 2.9059 
2021-01-28 20:25:33:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.0736  Has0_acc_2: 0.6363  Has0_F1_score: 0.6483  Non0_acc_2: 0.6320  Non0_F1_score: 0.6447  Mult_acc_5: 0.1908  Mult_acc_7: 0.1900  MAE: 1.2182  Corr: 0.3480 
2021-01-28 20:25:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7205  Non0_acc_2: 0.5972  Non0_F1_score: 0.7001  Mult_acc_5: 0.1834  Mult_acc_7: 0.1790  MAE: 1.3809  Corr: 0.1931  Loss: 2.6962 
2021-01-28 20:25:52:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.0294  Has0_acc_2: 0.6433  Has0_F1_score: 0.6513  Non0_acc_2: 0.6393  Non0_F1_score: 0.6478  Mult_acc_5: 0.2072  Mult_acc_7: 0.2056  MAE: 1.1998  Corr: 0.3727 
2021-01-28 20:25:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.6216  Non0_acc_2: 0.5926  Non0_F1_score: 0.6185  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3888  Corr: 0.1728  Loss: 2.6261 
2021-01-28 20:26:11:INFO:TRAIN-(misa) (5/9/1)>> loss: 1.9496  Has0_acc_2: 0.6604  Has0_F1_score: 0.6683  Non0_acc_2: 0.6572  Non0_F1_score: 0.6655  Mult_acc_5: 0.2204  Mult_acc_7: 0.2181  MAE: 1.1649  Corr: 0.4128 
2021-01-28 20:26:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.7186  Non0_acc_2: 0.6157  Non0_F1_score: 0.6984  Mult_acc_5: 0.1921  Mult_acc_7: 0.1747  MAE: 1.3847  Corr: 0.1947  Loss: 2.8201 
2021-01-28 20:26:29:INFO:TRAIN-(misa) (6/10/1)>> loss: 1.9537  Has0_acc_2: 0.6636  Has0_F1_score: 0.6750  Non0_acc_2: 0.6588  Non0_F1_score: 0.6707  Mult_acc_5: 0.2259  Mult_acc_7: 0.2227  MAE: 1.1578  Corr: 0.4282 
2021-01-28 20:26:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.6811  Non0_acc_2: 0.6343  Non0_F1_score: 0.6705  Mult_acc_5: 0.2227  Mult_acc_7: 0.2183  MAE: 1.3447  Corr: 0.2303  Loss: 2.5594 
2021-01-28 20:26:50:INFO:TRAIN-(misa) (1/11/1)>> loss: 1.9038  Has0_acc_2: 0.6643  Has0_F1_score: 0.6691  Non0_acc_2: 0.6621  Non0_F1_score: 0.6673  Mult_acc_5: 0.2227  Mult_acc_7: 0.2204  MAE: 1.1444  Corr: 0.4441 
2021-01-28 20:26:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7384  Non0_acc_2: 0.5926  Non0_F1_score: 0.7189  Mult_acc_5: 0.1921  Mult_acc_7: 0.1790  MAE: 1.4170  Corr: 0.2011  Loss: 3.1913 
2021-01-28 20:27:08:INFO:TRAIN-(misa) (2/12/1)>> loss: 1.8847  Has0_acc_2: 0.6737  Has0_F1_score: 0.6832  Non0_acc_2: 0.6710  Non0_F1_score: 0.6810  Mult_acc_5: 0.2188  Mult_acc_7: 0.2157  MAE: 1.1420  Corr: 0.4462 
2021-01-28 20:27:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5895  Has0_F1_score: 0.6021  Non0_acc_2: 0.5880  Non0_F1_score: 0.6032  Mult_acc_5: 0.2183  Mult_acc_7: 0.2183  MAE: 1.3792  Corr: 0.1864  Loss: 2.5857 
2021-01-28 20:27:26:INFO:TRAIN-(misa) (3/13/1)>> loss: 1.8443  Has0_acc_2: 0.6745  Has0_F1_score: 0.6790  Non0_acc_2: 0.6710  Non0_F1_score: 0.6759  Mult_acc_5: 0.2329  Mult_acc_7: 0.2266  MAE: 1.1232  Corr: 0.4749 
2021-01-28 20:27:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.6837  Non0_acc_2: 0.6435  Non0_F1_score: 0.6842  Mult_acc_5: 0.2052  Mult_acc_7: 0.2009  MAE: 1.3529  Corr: 0.2209  Loss: 2.7098 
2021-01-28 20:27:45:INFO:TRAIN-(misa) (4/14/1)>> loss: 1.9108  Has0_acc_2: 0.6589  Has0_F1_score: 0.6657  Non0_acc_2: 0.6531  Non0_F1_score: 0.6601  Mult_acc_5: 0.2173  Mult_acc_7: 0.2134  MAE: 1.1470  Corr: 0.4457 
2021-01-28 20:27:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7447  Non0_acc_2: 0.5972  Non0_F1_score: 0.7255  Mult_acc_5: 0.2140  Mult_acc_7: 0.1921  MAE: 1.4201  Corr: 0.2517  Loss: 2.9908 
2021-01-28 20:28:03:INFO:TRAIN-(misa) (5/15/1)>> loss: 1.7800  Has0_acc_2: 0.6854  Has0_F1_score: 0.6957  Non0_acc_2: 0.6824  Non0_F1_score: 0.6931  Mult_acc_5: 0.2547  Mult_acc_7: 0.2484  MAE: 1.0950  Corr: 0.4957 
2021-01-28 20:28:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.6910  Non0_acc_2: 0.6296  Non0_F1_score: 0.6867  Mult_acc_5: 0.2358  Mult_acc_7: 0.2140  MAE: 1.3688  Corr: 0.2378  Loss: 2.8431 
2021-01-28 20:28:22:INFO:TRAIN-(misa) (6/16/1)>> loss: 1.7168  Has0_acc_2: 0.6893  Has0_F1_score: 0.6970  Non0_acc_2: 0.6881  Non0_F1_score: 0.6963  Mult_acc_5: 0.2726  Mult_acc_7: 0.2640  MAE: 1.0696  Corr: 0.5259 
2021-01-28 20:28:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6627  Non0_acc_2: 0.6250  Non0_F1_score: 0.6621  Mult_acc_5: 0.2271  Mult_acc_7: 0.2096  MAE: 1.3480  Corr: 0.2532  Loss: 2.6407 
2021-01-28 20:28:41:INFO:TRAIN-(misa) (7/17/1)>> loss: 1.7081  Has0_acc_2: 0.6916  Has0_F1_score: 0.6963  Non0_acc_2: 0.6889  Non0_F1_score: 0.6939  Mult_acc_5: 0.2593  Mult_acc_7: 0.2484  MAE: 1.0727  Corr: 0.5230 
2021-01-28 20:28:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.6419  Has0_F1_score: 0.7113  Non0_acc_2: 0.6204  Non0_F1_score: 0.6908  Mult_acc_5: 0.2052  Mult_acc_7: 0.2009  MAE: 1.3439  Corr: 0.2592  Loss: 2.6160 
2021-01-28 20:28:59:INFO:TRAIN-(misa) (8/18/1)>> loss: 1.7454  Has0_acc_2: 0.6900  Has0_F1_score: 0.7006  Non0_acc_2: 0.6905  Non0_F1_score: 0.7018  Mult_acc_5: 0.2492  Mult_acc_7: 0.2414  MAE: 1.0870  Corr: 0.5122 
2021-01-28 20:29:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7210  Non0_acc_2: 0.6019  Non0_F1_score: 0.7007  Mult_acc_5: 0.2489  Mult_acc_7: 0.2140  MAE: 1.4207  Corr: 0.2492  Loss: 3.0728 
2021-01-28 20:29:03:INFO:TEST-(misa) >>  Has0_acc_2: 0.5510  Has0_F1_score: 0.5743  Non0_acc_2: 0.5366  Non0_F1_score: 0.5575  Mult_acc_5: 0.1676  Mult_acc_7: 0.1676  MAE: 1.4054  Corr: 0.2180  Loss: 2.7639 
2021-01-28 20:29:03:INFO:Start saving results...
2021-01-28 20:29:03:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:29:03:INFO:########################################misa-(45/50)########################################
2021-01-28 20:29:03:INFO:batch_size:32
2021-01-28 20:29:03:INFO:learning_rate:0.001
2021-01-28 20:29:03:INFO:hidden_size:256
2021-01-28 20:29:03:INFO:dropout:0.0
2021-01-28 20:29:03:INFO:reverse_grad_weight:0.8
2021-01-28 20:29:03:INFO:diff_weight:0.3
2021-01-28 20:29:03:INFO:sim_weight:0.5
2021-01-28 20:29:03:INFO:sp_weight:0.0
2021-01-28 20:29:03:INFO:recon_weight:1.0
2021-01-28 20:29:03:INFO:grad_clip:-1.0
2021-01-28 20:29:03:INFO:weight_decay:5e-05
2021-01-28 20:29:03:INFO:##########################################################################################
2021-01-28 20:29:03:INFO:Start running misa...
2021-01-28 20:29:03:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:29:03:INFO:Let's use 1 GPUs!
2021-01-28 20:29:04:INFO:train samples: (1284,)
2021-01-28 20:29:04:INFO:valid samples: (229,)
2021-01-28 20:29:04:INFO:test samples: (686,)
2021-01-28 20:29:04:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:29:04:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:29:04:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:29:04:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:29:04:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:29:04:INFO:loading file None
2021-01-28 20:29:04:INFO:loading file None
2021-01-28 20:29:04:INFO:loading file None
2021-01-28 20:29:04:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:29:04:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:29:04:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:29:07:INFO:The model has 112685553 trainable parameters
2021-01-28 20:29:21:INFO:TRAIN-(misa) (1/1/1)>> loss: 5.8088  Has0_acc_2: 0.5319  Has0_F1_score: 0.5554  Non0_acc_2: 0.5264  Non0_F1_score: 0.5517  Mult_acc_5: 0.1908  Mult_acc_7: 0.1807  MAE: 1.6414  Corr: -0.0414 
2021-01-28 20:29:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4472  Corr: 0.1151  Loss: 2.9057 
2021-01-28 20:29:36:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5827  Has0_acc_2: 0.5514  Has0_F1_score: 0.5596  Non0_acc_2: 0.5459  Non0_F1_score: 0.5550  Mult_acc_5: 0.1838  Mult_acc_7: 0.1838  MAE: 1.3261  Corr: 0.0557 
2021-01-28 20:29:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4144  Corr: 0.1336  Loss: 2.6634 
2021-01-28 20:29:52:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4225  Has0_acc_2: 0.5296  Has0_F1_score: 0.5534  Non0_acc_2: 0.5223  Non0_F1_score: 0.5477  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3242  Corr: 0.0102 
2021-01-28 20:29:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4329  Corr: 0.1359  Loss: 2.9191 
2021-01-28 20:30:06:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3704  Has0_acc_2: 0.5701  Has0_F1_score: 0.7248  Non0_acc_2: 0.5516  Non0_F1_score: 0.7095  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3165  Corr: 0.0236 
2021-01-28 20:30:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4130  Corr: 0.1523  Loss: 2.6632 
2021-01-28 20:30:22:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3776  Has0_acc_2: 0.5374  Has0_F1_score: 0.6073  Non0_acc_2: 0.5248  Non0_F1_score: 0.5971  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3267  Corr: -0.0173 
2021-01-28 20:30:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4191  Corr: 0.1545  Loss: 2.7349 
2021-01-28 20:30:36:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3414  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3205  Corr: -0.0142 
2021-01-28 20:30:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4174  Corr: 0.1631  Loss: 2.9530 
2021-01-28 20:30:50:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3274  Has0_acc_2: 0.5717  Has0_F1_score: 0.7258  Non0_acc_2: 0.5532  Non0_F1_score: 0.7106  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3235  Corr: -0.0361 
2021-01-28 20:30:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4129  Corr: 0.1726  Loss: 2.8437 
2021-01-28 20:31:04:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.3155  Has0_acc_2: 0.5678  Has0_F1_score: 0.6981  Non0_acc_2: 0.5500  Non0_F1_score: 0.6830  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3232  Corr: -0.0160 
2021-01-28 20:31:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4438  Corr: 0.1792  Loss: 2.9778 
2021-01-28 20:31:17:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.3441  Has0_acc_2: 0.5327  Has0_F1_score: 0.5490  Non0_acc_2: 0.5207  Non0_F1_score: 0.5373  Mult_acc_5: 0.1861  Mult_acc_7: 0.1861  MAE: 1.3262  Corr: 0.0162 
2021-01-28 20:31:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4163  Corr: 0.1597  Loss: 2.6736 
2021-01-28 20:31:31:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.3372  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3216  Corr: -0.0418 
2021-01-28 20:31:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4166  Corr: 0.1484  Loss: 2.6756 
2021-01-28 20:31:46:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.4019  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3210  Corr: -0.0309 
2021-01-28 20:31:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4283  Corr: 0.1925  Loss: 2.7460 
2021-01-28 20:32:00:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.3285  Has0_acc_2: 0.5701  Has0_F1_score: 0.7262  Non0_acc_2: 0.5516  Non0_F1_score: 0.7110  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3222  Corr: -0.0199 
2021-01-28 20:32:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4218  Corr: 0.2110  Loss: 2.7486 
2021-01-28 20:32:03:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.5122  Corr: 0.1525  Loss: 3.0630 
2021-01-28 20:32:03:INFO:Start saving results...
2021-01-28 20:32:03:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:32:03:INFO:########################################misa-(46/50)########################################
2021-01-28 20:32:03:INFO:batch_size:64
2021-01-28 20:32:03:INFO:learning_rate:0.0005
2021-01-28 20:32:03:INFO:hidden_size:64
2021-01-28 20:32:03:INFO:dropout:0.0
2021-01-28 20:32:03:INFO:reverse_grad_weight:0.8
2021-01-28 20:32:03:INFO:diff_weight:0.1
2021-01-28 20:32:03:INFO:sim_weight:1.0
2021-01-28 20:32:03:INFO:sp_weight:0.0
2021-01-28 20:32:03:INFO:recon_weight:1.0
2021-01-28 20:32:03:INFO:grad_clip:-1.0
2021-01-28 20:32:03:INFO:weight_decay:0.002
2021-01-28 20:32:03:INFO:##########################################################################################
2021-01-28 20:32:03:INFO:Start running misa...
2021-01-28 20:32:03:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:32:03:INFO:Let's use 1 GPUs!
2021-01-28 20:32:04:INFO:train samples: (1284,)
2021-01-28 20:32:04:INFO:valid samples: (229,)
2021-01-28 20:32:04:INFO:test samples: (686,)
2021-01-28 20:32:04:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:32:04:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:32:04:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:32:04:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:32:04:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:32:04:INFO:loading file None
2021-01-28 20:32:04:INFO:loading file None
2021-01-28 20:32:04:INFO:loading file None
2021-01-28 20:32:04:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:32:04:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:32:04:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:32:07:INFO:The model has 109943985 trainable parameters
2021-01-28 20:32:18:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.5103  Has0_acc_2: 0.5421  Has0_F1_score: 0.5863  Non0_acc_2: 0.5288  Non0_F1_score: 0.5741  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.3347  Corr: 0.0086 
2021-01-28 20:32:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4101  Corr: 0.1192  Loss: 2.6881 
2021-01-28 20:32:30:INFO:TRAIN-(misa) (1/2/1)>> loss: 3.5777  Has0_acc_2: 0.5810  Has0_F1_score: 0.7091  Non0_acc_2: 0.5630  Non0_F1_score: 0.6933  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3091  Corr: 0.1117 
2021-01-28 20:32:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4090  Corr: 0.1514  Loss: 2.7436 
2021-01-28 20:32:41:INFO:TRAIN-(misa) (2/3/1)>> loss: 3.0868  Has0_acc_2: 0.5748  Has0_F1_score: 0.6134  Non0_acc_2: 0.5646  Non0_F1_score: 0.6043  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.3072  Corr: 0.1050 
2021-01-28 20:32:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.4039  Corr: 0.1605  Loss: 2.6680 
2021-01-28 20:32:54:INFO:TRAIN-(misa) (1/4/1)>> loss: 2.6530  Has0_acc_2: 0.5794  Has0_F1_score: 0.6390  Non0_acc_2: 0.5670  Non0_F1_score: 0.6281  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.2987  Corr: 0.1408 
2021-01-28 20:32:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1616  Mult_acc_7: 0.1616  MAE: 1.4051  Corr: 0.1566  Loss: 2.6905 
2021-01-28 20:33:05:INFO:TRAIN-(misa) (2/5/1)>> loss: 2.4512  Has0_acc_2: 0.6215  Has0_F1_score: 0.6891  Non0_acc_2: 0.6084  Non0_F1_score: 0.6773  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.2815  Corr: 0.2216 
2021-01-28 20:33:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.7201  Non0_acc_2: 0.5926  Non0_F1_score: 0.6996  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.3955  Corr: 0.1563  Loss: 2.6901 
2021-01-28 20:33:17:INFO:TRAIN-(misa) (3/6/1)>> loss: 2.2627  Has0_acc_2: 0.6262  Has0_F1_score: 0.6532  Non0_acc_2: 0.6158  Non0_F1_score: 0.6431  Mult_acc_5: 0.1955  Mult_acc_7: 0.1955  MAE: 1.2532  Corr: 0.2934 
2021-01-28 20:33:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7393  Non0_acc_2: 0.5833  Non0_F1_score: 0.7197  Mult_acc_5: 0.1703  Mult_acc_7: 0.1703  MAE: 1.4087  Corr: 0.1715  Loss: 2.8182 
2021-01-28 20:33:28:INFO:TRAIN-(misa) (4/7/1)>> loss: 2.2718  Has0_acc_2: 0.6160  Has0_F1_score: 0.6460  Non0_acc_2: 0.6060  Non0_F1_score: 0.6365  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.2585  Corr: 0.2611 
2021-01-28 20:33:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6653  Non0_acc_2: 0.6157  Non0_F1_score: 0.6538  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3940  Corr: 0.1792  Loss: 2.7623 
2021-01-28 20:33:40:INFO:TRAIN-(misa) (5/8/1)>> loss: 2.2901  Has0_acc_2: 0.6246  Has0_F1_score: 0.6379  Non0_acc_2: 0.6206  Non0_F1_score: 0.6347  Mult_acc_5: 0.1861  Mult_acc_7: 0.1861  MAE: 1.2623  Corr: 0.2566 
2021-01-28 20:33:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.6762  Non0_acc_2: 0.6157  Non0_F1_score: 0.6596  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3889  Corr: 0.1694  Loss: 2.5968 
2021-01-28 20:33:53:INFO:TRAIN-(misa) (1/9/1)>> loss: 2.1338  Has0_acc_2: 0.6098  Has0_F1_score: 0.6383  Non0_acc_2: 0.6052  Non0_F1_score: 0.6351  Mult_acc_5: 0.1947  Mult_acc_7: 0.1939  MAE: 1.2382  Corr: 0.2987 
2021-01-28 20:33:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7409  Non0_acc_2: 0.5741  Non0_F1_score: 0.7213  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.4186  Corr: 0.1719  Loss: 2.9302 
2021-01-28 20:34:04:INFO:TRAIN-(misa) (2/10/1)>> loss: 2.3549  Has0_acc_2: 0.6059  Has0_F1_score: 0.6303  Non0_acc_2: 0.5963  Non0_F1_score: 0.6211  Mult_acc_5: 0.2142  Mult_acc_7: 0.2118  MAE: 1.2346  Corr: 0.2888 
2021-01-28 20:34:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7393  Non0_acc_2: 0.5833  Non0_F1_score: 0.7197  Mult_acc_5: 0.1790  Mult_acc_7: 0.1790  MAE: 1.3979  Corr: 0.1739  Loss: 2.7570 
2021-01-28 20:34:16:INFO:TRAIN-(misa) (3/11/1)>> loss: 2.1842  Has0_acc_2: 0.6238  Has0_F1_score: 0.6439  Non0_acc_2: 0.6174  Non0_F1_score: 0.6382  Mult_acc_5: 0.1931  Mult_acc_7: 0.1924  MAE: 1.2169  Corr: 0.3513 
2021-01-28 20:34:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.7328  Non0_acc_2: 0.6111  Non0_F1_score: 0.7133  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3890  Corr: 0.1737  Loss: 2.7825 
2021-01-28 20:34:28:INFO:TRAIN-(misa) (4/12/1)>> loss: 2.1126  Has0_acc_2: 0.6176  Has0_F1_score: 0.6397  Non0_acc_2: 0.6093  Non0_F1_score: 0.6318  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.2262  Corr: 0.3261 
2021-01-28 20:34:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.6507  Has0_F1_score: 0.6974  Non0_acc_2: 0.6343  Non0_F1_score: 0.6822  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3769  Corr: 0.1833  Loss: 2.6059 
2021-01-28 20:34:39:INFO:TRAIN-(misa) (5/13/1)>> loss: 2.1066  Has0_acc_2: 0.6254  Has0_F1_score: 0.6470  Non0_acc_2: 0.6158  Non0_F1_score: 0.6376  Mult_acc_5: 0.2142  Mult_acc_7: 0.2118  MAE: 1.2129  Corr: 0.3709 
2021-01-28 20:34:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6446  Non0_acc_2: 0.6065  Non0_F1_score: 0.6374  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.3750  Corr: 0.1738  Loss: 2.6561 
2021-01-28 20:34:51:INFO:TRAIN-(misa) (6/14/1)>> loss: 2.1167  Has0_acc_2: 0.6347  Has0_F1_score: 0.6410  Non0_acc_2: 0.6328  Non0_F1_score: 0.6397  Mult_acc_5: 0.2259  Mult_acc_7: 0.2251  MAE: 1.1848  Corr: 0.3654 
2021-01-28 20:34:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.6247  Non0_acc_2: 0.5926  Non0_F1_score: 0.6163  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3862  Corr: 0.1582  Loss: 2.6806 
2021-01-28 20:35:02:INFO:TRAIN-(misa) (7/15/1)>> loss: 2.2132  Has0_acc_2: 0.6277  Has0_F1_score: 0.6372  Non0_acc_2: 0.6239  Non0_F1_score: 0.6340  Mult_acc_5: 0.2165  Mult_acc_7: 0.2157  MAE: 1.2147  Corr: 0.3224 
2021-01-28 20:35:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7393  Non0_acc_2: 0.5833  Non0_F1_score: 0.7197  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4016  Corr: 0.1770  Loss: 2.8070 
2021-01-28 20:35:14:INFO:TRAIN-(misa) (8/16/1)>> loss: 2.2175  Has0_acc_2: 0.6207  Has0_F1_score: 0.6328  Non0_acc_2: 0.6117  Non0_F1_score: 0.6239  Mult_acc_5: 0.2079  Mult_acc_7: 0.2064  MAE: 1.2216  Corr: 0.3229 
2021-01-28 20:35:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7388  Non0_acc_2: 0.5880  Non0_F1_score: 0.7192  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.3870  Corr: 0.1874  Loss: 2.6890 
2021-01-28 20:35:16:INFO:TEST-(misa) >>  Has0_acc_2: 0.5262  Has0_F1_score: 0.5610  Non0_acc_2: 0.5091  Non0_F1_score: 0.5414  Mult_acc_5: 0.1574  Mult_acc_7: 0.1574  MAE: 1.4227  Corr: 0.1538  Loss: 2.6834 
2021-01-28 20:35:16:INFO:Start saving results...
2021-01-28 20:35:17:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:35:17:INFO:########################################misa-(47/50)########################################
2021-01-28 20:35:17:INFO:batch_size:16
2021-01-28 20:35:17:INFO:learning_rate:0.0005
2021-01-28 20:35:17:INFO:hidden_size:256
2021-01-28 20:35:17:INFO:dropout:0.0
2021-01-28 20:35:17:INFO:reverse_grad_weight:1.0
2021-01-28 20:35:17:INFO:diff_weight:0.5
2021-01-28 20:35:17:INFO:sim_weight:1.0
2021-01-28 20:35:17:INFO:sp_weight:1.0
2021-01-28 20:35:17:INFO:recon_weight:0.5
2021-01-28 20:35:17:INFO:grad_clip:1.0
2021-01-28 20:35:17:INFO:weight_decay:0.002
2021-01-28 20:35:17:INFO:##########################################################################################
2021-01-28 20:35:17:INFO:Start running misa...
2021-01-28 20:35:17:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:35:17:INFO:Let's use 1 GPUs!
2021-01-28 20:35:17:INFO:train samples: (1284,)
2021-01-28 20:35:17:INFO:valid samples: (229,)
2021-01-28 20:35:17:INFO:test samples: (686,)
2021-01-28 20:35:17:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:35:17:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:35:17:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:35:17:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:35:17:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:35:17:INFO:loading file None
2021-01-28 20:35:17:INFO:loading file None
2021-01-28 20:35:17:INFO:loading file None
2021-01-28 20:35:17:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:35:17:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:35:17:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:35:21:INFO:The model has 112685553 trainable parameters
2021-01-28 20:35:39:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.7983  Has0_acc_2: 0.5428  Has0_F1_score: 0.5543  Non0_acc_2: 0.5386  Non0_F1_score: 0.5514  Mult_acc_5: 0.1970  Mult_acc_7: 0.1900  MAE: 1.4100  Corr: -0.0114 
2021-01-28 20:35:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.4017  Has0_F1_score: 0.5732  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4736  Corr: 0.1173  Loss: 3.0071 
2021-01-28 20:35:59:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5415  Has0_acc_2: 0.5678  Has0_F1_score: 0.6114  Non0_acc_2: 0.5548  Non0_F1_score: 0.5993  Mult_acc_5: 0.1970  Mult_acc_7: 0.1970  MAE: 1.3192  Corr: 0.0635 
2021-01-28 20:36:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.4061  Has0_F1_score: 0.5726  Non0_acc_2: 0.4306  Non0_F1_score: 0.5966  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4439  Corr: 0.1166  Loss: 2.8213 
2021-01-28 20:36:20:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4487  Has0_acc_2: 0.5436  Has0_F1_score: 0.5758  Non0_acc_2: 0.5329  Non0_F1_score: 0.5661  Mult_acc_5: 0.1986  Mult_acc_7: 0.1986  MAE: 1.3129  Corr: 0.0661 
2021-01-28 20:36:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4092  Corr: 0.1312  Loss: 2.7351 
2021-01-28 20:36:41:INFO:TRAIN-(misa) (1/4/1)>> loss: 2.4046  Has0_acc_2: 0.5810  Has0_F1_score: 0.6105  Non0_acc_2: 0.5751  Non0_F1_score: 0.6062  Mult_acc_5: 0.2095  Mult_acc_7: 0.2095  MAE: 1.2926  Corr: 0.1303 
2021-01-28 20:36:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7108  Non0_acc_2: 0.6019  Non0_F1_score: 0.6900  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3822  Corr: 0.2199  Loss: 2.5771 
2021-01-28 20:37:02:INFO:TRAIN-(misa) (1/5/1)>> loss: 2.3447  Has0_acc_2: 0.6199  Has0_F1_score: 0.6475  Non0_acc_2: 0.6101  Non0_F1_score: 0.6380  Mult_acc_5: 0.1799  Mult_acc_7: 0.1799  MAE: 1.2623  Corr: 0.2388 
2021-01-28 20:37:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7051  Non0_acc_2: 0.5972  Non0_F1_score: 0.6839  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4035  Corr: 0.1246  Loss: 2.6891 
2021-01-28 20:37:22:INFO:TRAIN-(misa) (2/6/1)>> loss: 2.3681  Has0_acc_2: 0.5974  Has0_F1_score: 0.6121  Non0_acc_2: 0.5906  Non0_F1_score: 0.6059  Mult_acc_5: 0.1970  Mult_acc_7: 0.1963  MAE: 1.2787  Corr: 0.1931 
2021-01-28 20:37:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.7003  Non0_acc_2: 0.5972  Non0_F1_score: 0.6789  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.3990  Corr: 0.1330  Loss: 2.7910 
2021-01-28 20:37:41:INFO:TRAIN-(misa) (3/7/1)>> loss: 2.3927  Has0_acc_2: 0.5631  Has0_F1_score: 0.5790  Non0_acc_2: 0.5548  Non0_F1_score: 0.5715  Mult_acc_5: 0.1807  Mult_acc_7: 0.1807  MAE: 1.3015  Corr: 0.1490 
2021-01-28 20:37:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.7141  Non0_acc_2: 0.5880  Non0_F1_score: 0.6932  Mult_acc_5: 0.2096  Mult_acc_7: 0.2096  MAE: 1.4023  Corr: 0.1192  Loss: 2.7362 
2021-01-28 20:38:00:INFO:TRAIN-(misa) (4/8/1)>> loss: 2.1785  Has0_acc_2: 0.6176  Has0_F1_score: 0.6467  Non0_acc_2: 0.6084  Non0_F1_score: 0.6381  Mult_acc_5: 0.2079  Mult_acc_7: 0.2072  MAE: 1.2367  Corr: 0.2933 
2021-01-28 20:38:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.6026  Has0_F1_score: 0.7076  Non0_acc_2: 0.5787  Non0_F1_score: 0.6863  Mult_acc_5: 0.1921  Mult_acc_7: 0.1921  MAE: 1.3954  Corr: 0.1212  Loss: 2.7535 
2021-01-28 20:38:19:INFO:TRAIN-(misa) (5/9/1)>> loss: 2.1387  Has0_acc_2: 0.6184  Has0_F1_score: 0.6413  Non0_acc_2: 0.6101  Non0_F1_score: 0.6335  Mult_acc_5: 0.1986  Mult_acc_7: 0.1970  MAE: 1.2290  Corr: 0.3172 
2021-01-28 20:38:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.6122  Non0_acc_2: 0.5880  Non0_F1_score: 0.6032  Mult_acc_5: 0.2271  Mult_acc_7: 0.2271  MAE: 1.3913  Corr: 0.1431  Loss: 2.6839 
2021-01-28 20:38:38:INFO:TRAIN-(misa) (6/10/1)>> loss: 2.1308  Has0_acc_2: 0.6160  Has0_F1_score: 0.6295  Non0_acc_2: 0.6093  Non0_F1_score: 0.6232  Mult_acc_5: 0.2111  Mult_acc_7: 0.2095  MAE: 1.2171  Corr: 0.3252 
2021-01-28 20:38:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.6201  Has0_F1_score: 0.6915  Non0_acc_2: 0.6019  Non0_F1_score: 0.6757  Mult_acc_5: 0.2052  Mult_acc_7: 0.2052  MAE: 1.3888  Corr: 0.1334  Loss: 2.6569 
2021-01-28 20:38:57:INFO:TRAIN-(misa) (7/11/1)>> loss: 2.1153  Has0_acc_2: 0.6207  Has0_F1_score: 0.6407  Non0_acc_2: 0.6174  Non0_F1_score: 0.6385  Mult_acc_5: 0.2188  Mult_acc_7: 0.2173  MAE: 1.2126  Corr: 0.3417 
2021-01-28 20:38:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.7197  Non0_acc_2: 0.5833  Non0_F1_score: 0.6990  Mult_acc_5: 0.1747  Mult_acc_7: 0.1747  MAE: 1.4121  Corr: 0.1096  Loss: 2.8670 
2021-01-28 20:39:16:INFO:TRAIN-(misa) (8/12/1)>> loss: 2.0771  Has0_acc_2: 0.6293  Has0_F1_score: 0.6445  Non0_acc_2: 0.6231  Non0_F1_score: 0.6388  Mult_acc_5: 0.2087  Mult_acc_7: 0.2072  MAE: 1.2106  Corr: 0.3488 
2021-01-28 20:39:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6495  Non0_acc_2: 0.6065  Non0_F1_score: 0.6426  Mult_acc_5: 0.2009  Mult_acc_7: 0.1878  MAE: 1.4019  Corr: 0.1426  Loss: 2.8832 
2021-01-28 20:39:20:INFO:TEST-(misa) >>  Has0_acc_2: 0.4985  Has0_F1_score: 0.5631  Non0_acc_2: 0.4802  Non0_F1_score: 0.5432  Mult_acc_5: 0.1589  Mult_acc_7: 0.1589  MAE: 1.4352  Corr: 0.1627  Loss: 2.7624 
2021-01-28 20:39:20:INFO:Start saving results...
2021-01-28 20:39:20:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:39:20:INFO:########################################misa-(48/50)########################################
2021-01-28 20:39:20:INFO:batch_size:32
2021-01-28 20:39:20:INFO:learning_rate:0.001
2021-01-28 20:39:20:INFO:hidden_size:128
2021-01-28 20:39:20:INFO:dropout:0.5
2021-01-28 20:39:20:INFO:reverse_grad_weight:0.8
2021-01-28 20:39:20:INFO:diff_weight:0.5
2021-01-28 20:39:20:INFO:sim_weight:1.0
2021-01-28 20:39:20:INFO:sp_weight:0.0
2021-01-28 20:39:20:INFO:recon_weight:1.0
2021-01-28 20:39:20:INFO:grad_clip:1.0
2021-01-28 20:39:20:INFO:weight_decay:5e-05
2021-01-28 20:39:20:INFO:##########################################################################################
2021-01-28 20:39:20:INFO:Start running misa...
2021-01-28 20:39:20:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:39:20:INFO:Let's use 1 GPUs!
2021-01-28 20:39:21:INFO:train samples: (1284,)
2021-01-28 20:39:21:INFO:valid samples: (229,)
2021-01-28 20:39:21:INFO:test samples: (686,)
2021-01-28 20:39:21:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:39:21:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:39:21:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:39:21:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:39:21:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:39:21:INFO:loading file None
2021-01-28 20:39:21:INFO:loading file None
2021-01-28 20:39:21:INFO:loading file None
2021-01-28 20:39:21:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:39:21:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:39:21:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:39:24:INFO:The model has 110620273 trainable parameters
2021-01-28 20:39:37:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.8744  Has0_acc_2: 0.5343  Has0_F1_score: 0.5606  Non0_acc_2: 0.5264  Non0_F1_score: 0.5542  Mult_acc_5: 0.1885  Mult_acc_7: 0.1885  MAE: 1.3817  Corr: -0.0223 
2021-01-28 20:39:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4130  Corr: 0.1168  Loss: 2.6810 
2021-01-28 20:39:53:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.5918  Has0_acc_2: 0.5428  Has0_F1_score: 0.5879  Non0_acc_2: 0.5305  Non0_F1_score: 0.5767  Mult_acc_5: 0.2002  Mult_acc_7: 0.2002  MAE: 1.3307  Corr: 0.0053 
2021-01-28 20:39:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4167  Corr: 0.1678  Loss: 2.6061 
2021-01-28 20:40:08:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.4389  Has0_acc_2: 0.5584  Has0_F1_score: 0.6141  Non0_acc_2: 0.5467  Non0_F1_score: 0.6041  Mult_acc_5: 0.1869  Mult_acc_7: 0.1869  MAE: 1.3307  Corr: 0.0139 
2021-01-28 20:40:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4128  Corr: 0.1877  Loss: 2.7264 
2021-01-28 20:40:23:INFO:TRAIN-(misa) (2/4/1)>> loss: 2.3853  Has0_acc_2: 0.5631  Has0_F1_score: 0.6415  Non0_acc_2: 0.5491  Non0_F1_score: 0.6296  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3151  Corr: 0.0369 
2021-01-28 20:40:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4182  Corr: 0.1213  Loss: 2.7382 
2021-01-28 20:40:37:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.3659  Has0_acc_2: 0.5561  Has0_F1_score: 0.6446  Non0_acc_2: 0.5418  Non0_F1_score: 0.6329  Mult_acc_5: 0.2009  Mult_acc_7: 0.2009  MAE: 1.3225  Corr: 0.0058 
2021-01-28 20:40:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4160  Corr: 0.0604  Loss: 2.5354 
2021-01-28 20:40:53:INFO:TRAIN-(misa) (1/6/1)>> loss: 2.3708  Has0_acc_2: 0.5319  Has0_F1_score: 0.6054  Non0_acc_2: 0.5240  Non0_F1_score: 0.6017  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.3256  Corr: -0.0191 
2021-01-28 20:40:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4177  Corr: 0.0423  Loss: 2.8103 
2021-01-28 20:41:07:INFO:TRAIN-(misa) (2/7/1)>> loss: 2.3836  Has0_acc_2: 0.5654  Has0_F1_score: 0.6821  Non0_acc_2: 0.5500  Non0_F1_score: 0.6699  Mult_acc_5: 0.1924  Mult_acc_7: 0.1924  MAE: 1.3226  Corr: -0.0172 
2021-01-28 20:41:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4231  Corr: 0.0335  Loss: 2.7566 
2021-01-28 20:41:21:INFO:TRAIN-(misa) (3/8/1)>> loss: 2.2901  Has0_acc_2: 0.5724  Has0_F1_score: 0.7149  Non0_acc_2: 0.5548  Non0_F1_score: 0.7005  Mult_acc_5: 0.1877  Mult_acc_7: 0.1877  MAE: 1.3184  Corr: 0.0361 
2021-01-28 20:41:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4221  Corr: 0.0270  Loss: 2.5427 
2021-01-28 20:41:35:INFO:TRAIN-(misa) (4/9/1)>> loss: 2.3686  Has0_acc_2: 0.5553  Has0_F1_score: 0.6351  Non0_acc_2: 0.5402  Non0_F1_score: 0.6219  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3210  Corr: 0.0238 
2021-01-28 20:41:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4190  Corr: -0.0852  Loss: 2.8013 
2021-01-28 20:41:49:INFO:TRAIN-(misa) (5/10/1)>> loss: 2.3347  Has0_acc_2: 0.5615  Has0_F1_score: 0.6913  Non0_acc_2: 0.5426  Non0_F1_score: 0.6747  Mult_acc_5: 0.1908  Mult_acc_7: 0.1908  MAE: 1.3159  Corr: 0.0291 
2021-01-28 20:41:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4189  Corr: -0.1336  Loss: 2.8482 
2021-01-28 20:42:04:INFO:TRAIN-(misa) (6/11/1)>> loss: 2.3322  Has0_acc_2: 0.5631  Has0_F1_score: 0.6936  Non0_acc_2: 0.5451  Non0_F1_score: 0.6783  Mult_acc_5: 0.1893  Mult_acc_7: 0.1893  MAE: 1.3207  Corr: 0.0244 
2021-01-28 20:42:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4201  Corr: -0.0821  Loss: 2.7165 
2021-01-28 20:42:18:INFO:TRAIN-(misa) (7/12/1)>> loss: 2.3290  Has0_acc_2: 0.5561  Has0_F1_score: 0.6918  Non0_acc_2: 0.5378  Non0_F1_score: 0.6763  Mult_acc_5: 0.1931  Mult_acc_7: 0.1931  MAE: 1.3215  Corr: 0.0059 
2021-01-28 20:42:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4190  Corr: -0.0901  Loss: 2.6807 
2021-01-28 20:42:32:INFO:TRAIN-(misa) (8/13/1)>> loss: 2.3406  Has0_acc_2: 0.5654  Has0_F1_score: 0.6800  Non0_acc_2: 0.5491  Non0_F1_score: 0.6665  Mult_acc_5: 0.1900  Mult_acc_7: 0.1900  MAE: 1.3228  Corr: -0.0146 
2021-01-28 20:42:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.2140  Mult_acc_7: 0.2140  MAE: 1.4144  Corr: 0.1259  Loss: 2.9262 
2021-01-28 20:42:36:INFO:TEST-(misa) >>  Has0_acc_2: 0.4475  Has0_F1_score: 0.6183  Non0_acc_2: 0.4223  Non0_F1_score: 0.5938  Mult_acc_5: 0.1545  Mult_acc_7: 0.1545  MAE: 1.4812  Corr: 0.1386  Loss: 2.8992 
2021-01-28 20:42:36:INFO:Start saving results...
2021-01-28 20:42:36:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:42:36:INFO:########################################misa-(49/50)########################################
2021-01-28 20:42:36:INFO:batch_size:16
2021-01-28 20:42:36:INFO:learning_rate:0.0005
2021-01-28 20:42:36:INFO:hidden_size:64
2021-01-28 20:42:36:INFO:dropout:0.0
2021-01-28 20:42:36:INFO:reverse_grad_weight:1.0
2021-01-28 20:42:36:INFO:diff_weight:0.1
2021-01-28 20:42:36:INFO:sim_weight:0.8
2021-01-28 20:42:36:INFO:sp_weight:0.0
2021-01-28 20:42:36:INFO:recon_weight:0.5
2021-01-28 20:42:36:INFO:grad_clip:1.0
2021-01-28 20:42:36:INFO:weight_decay:0.0
2021-01-28 20:42:36:INFO:##########################################################################################
2021-01-28 20:42:36:INFO:Start running misa...
2021-01-28 20:42:36:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:42:36:INFO:Let's use 1 GPUs!
2021-01-28 20:42:36:INFO:train samples: (1284,)
2021-01-28 20:42:36:INFO:valid samples: (229,)
2021-01-28 20:42:36:INFO:test samples: (686,)
2021-01-28 20:42:36:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:42:36:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:42:36:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:42:36:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:42:36:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:42:36:INFO:loading file None
2021-01-28 20:42:36:INFO:loading file None
2021-01-28 20:42:36:INFO:loading file None
2021-01-28 20:42:36:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:42:36:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:42:36:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:42:39:INFO:The model has 109943985 trainable parameters
2021-01-28 20:42:57:INFO:TRAIN-(misa) (1/1/1)>> loss: 2.9927  Has0_acc_2: 0.5880  Has0_F1_score: 0.6097  Non0_acc_2: 0.5865  Non0_F1_score: 0.6101  Mult_acc_5: 0.2111  Mult_acc_7: 0.2111  MAE: 1.2649  Corr: 0.2201 
2021-01-28 20:42:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.6376  Has0_F1_score: 0.6980  Non0_acc_2: 0.6157  Non0_F1_score: 0.6769  Mult_acc_5: 0.1878  Mult_acc_7: 0.1878  MAE: 1.3576  Corr: 0.3039  Loss: 2.4987 
2021-01-28 20:43:18:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.3267  Has0_acc_2: 0.6121  Has0_F1_score: 0.6290  Non0_acc_2: 0.6076  Non0_F1_score: 0.6254  Mult_acc_5: 0.2111  Mult_acc_7: 0.2072  MAE: 1.2169  Corr: 0.3280 
2021-01-28 20:43:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.6792  Non0_acc_2: 0.6157  Non0_F1_score: 0.6628  Mult_acc_5: 0.2969  Mult_acc_7: 0.2576  MAE: 1.2339  Corr: 0.4298  Loss: 2.2213 
2021-01-28 20:43:40:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.0082  Has0_acc_2: 0.6503  Has0_F1_score: 0.6551  Non0_acc_2: 0.6499  Non0_F1_score: 0.6554  Mult_acc_5: 0.2640  Mult_acc_7: 0.2516  MAE: 1.1258  Corr: 0.4398 
2021-01-28 20:43:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.6157  Has0_F1_score: 0.6127  Non0_acc_2: 0.6296  Non0_F1_score: 0.6281  Mult_acc_5: 0.2402  Mult_acc_7: 0.2402  MAE: 1.3015  Corr: 0.3273  Loss: 2.4625 
2021-01-28 20:43:59:INFO:TRAIN-(misa) (2/4/1)>> loss: 1.9292  Has0_acc_2: 0.6628  Has0_F1_score: 0.6641  Non0_acc_2: 0.6613  Non0_F1_score: 0.6631  Mult_acc_5: 0.2664  Mult_acc_7: 0.2562  MAE: 1.1160  Corr: 0.4624 
2021-01-28 20:44:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.6288  Has0_F1_score: 0.6871  Non0_acc_2: 0.6111  Non0_F1_score: 0.6710  Mult_acc_5: 0.2882  Mult_acc_7: 0.2576  MAE: 1.2665  Corr: 0.3802  Loss: 2.2973 
2021-01-28 20:44:18:INFO:TRAIN-(misa) (3/5/1)>> loss: 2.0265  Has0_acc_2: 0.6495  Has0_F1_score: 0.6588  Non0_acc_2: 0.6450  Non0_F1_score: 0.6547  Mult_acc_5: 0.2383  Mult_acc_7: 0.2336  MAE: 1.1594  Corr: 0.3998 
2021-01-28 20:44:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.7486  Non0_acc_2: 0.5741  Non0_F1_score: 0.7294  Mult_acc_5: 0.1921  Mult_acc_7: 0.1921  MAE: 1.3855  Corr: 0.2653  Loss: 2.7543 
2021-01-28 20:44:38:INFO:TRAIN-(misa) (4/6/1)>> loss: 2.1019  Has0_acc_2: 0.6277  Has0_F1_score: 0.6491  Non0_acc_2: 0.6198  Non0_F1_score: 0.6416  Mult_acc_5: 0.2150  Mult_acc_7: 0.2134  MAE: 1.2137  Corr: 0.3436 
2021-01-28 20:44:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.7322  Non0_acc_2: 0.6019  Non0_F1_score: 0.7124  Mult_acc_5: 0.2183  Mult_acc_7: 0.2183  MAE: 1.3558  Corr: 0.2717  Loss: 2.5870 
2021-01-28 20:44:57:INFO:TRAIN-(misa) (5/7/1)>> loss: 2.0853  Has0_acc_2: 0.6324  Has0_F1_score: 0.6473  Non0_acc_2: 0.6271  Non0_F1_score: 0.6426  Mult_acc_5: 0.2173  Mult_acc_7: 0.2150  MAE: 1.2068  Corr: 0.3529 
2021-01-28 20:44:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.7300  Non0_acc_2: 0.6250  Non0_F1_score: 0.7105  Mult_acc_5: 0.1834  Mult_acc_7: 0.1834  MAE: 1.3446  Corr: 0.2632  Loss: 2.5744 
2021-01-28 20:45:17:INFO:TRAIN-(misa) (6/8/1)>> loss: 2.0538  Has0_acc_2: 0.6410  Has0_F1_score: 0.6515  Non0_acc_2: 0.6336  Non0_F1_score: 0.6443  Mult_acc_5: 0.2040  Mult_acc_7: 0.2009  MAE: 1.1987  Corr: 0.3735 
2021-01-28 20:45:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.6419  Has0_F1_score: 0.7290  Non0_acc_2: 0.6204  Non0_F1_score: 0.7094  Mult_acc_5: 0.1965  Mult_acc_7: 0.1965  MAE: 1.3563  Corr: 0.2574  Loss: 2.5407 
2021-01-28 20:45:36:INFO:TRAIN-(misa) (7/9/1)>> loss: 1.9927  Has0_acc_2: 0.6480  Has0_F1_score: 0.6633  Non0_acc_2: 0.6434  Non0_F1_score: 0.6592  Mult_acc_5: 0.2274  Mult_acc_7: 0.2243  MAE: 1.1742  Corr: 0.4077 
2021-01-28 20:45:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.6507  Has0_F1_score: 0.7266  Non0_acc_2: 0.6296  Non0_F1_score: 0.7070  Mult_acc_5: 0.2314  Mult_acc_7: 0.2140  MAE: 1.3581  Corr: 0.2428  Loss: 2.6999 
2021-01-28 20:45:55:INFO:TRAIN-(misa) (8/10/1)>> loss: 1.9690  Has0_acc_2: 0.6526  Has0_F1_score: 0.6650  Non0_acc_2: 0.6466  Non0_F1_score: 0.6593  Mult_acc_5: 0.2344  Mult_acc_7: 0.2274  MAE: 1.1524  Corr: 0.4326 
2021-01-28 20:45:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.6507  Has0_F1_score: 0.6814  Non0_acc_2: 0.6343  Non0_F1_score: 0.6654  Mult_acc_5: 0.2314  Mult_acc_7: 0.2227  MAE: 1.3216  Corr: 0.2780  Loss: 2.4714 
2021-01-28 20:45:59:INFO:TEST-(misa) >>  Has0_acc_2: 0.5335  Has0_F1_score: 0.5716  Non0_acc_2: 0.5183  Non0_F1_score: 0.5543  Mult_acc_5: 0.1968  Mult_acc_7: 0.1910  MAE: 1.3808  Corr: 0.2835  Loss: 2.6851 
2021-01-28 20:45:59:INFO:Start saving results...
2021-01-28 20:45:59:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-28 20:45:59:INFO:########################################misa-(50/50)########################################
2021-01-28 20:45:59:INFO:batch_size:32
2021-01-28 20:45:59:INFO:learning_rate:0.0001
2021-01-28 20:45:59:INFO:hidden_size:64
2021-01-28 20:45:59:INFO:dropout:0.5
2021-01-28 20:45:59:INFO:reverse_grad_weight:1.0
2021-01-28 20:45:59:INFO:diff_weight:0.1
2021-01-28 20:45:59:INFO:sim_weight:0.8
2021-01-28 20:45:59:INFO:sp_weight:1.0
2021-01-28 20:45:59:INFO:recon_weight:1.0
2021-01-28 20:45:59:INFO:grad_clip:-1.0
2021-01-28 20:45:59:INFO:weight_decay:0.0
2021-01-28 20:45:59:INFO:##########################################################################################
2021-01-28 20:45:59:INFO:Start running misa...
2021-01-28 20:45:59:INFO:Find gpu: 1, with memory: 2256338944 left!
2021-01-28 20:45:59:INFO:Let's use 1 GPUs!
2021-01-28 20:45:59:INFO:train samples: (1284,)
2021-01-28 20:45:59:INFO:valid samples: (229,)
2021-01-28 20:46:00:INFO:test samples: (686,)
2021-01-28 20:46:00:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-28 20:46:00:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-28 20:46:00:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-28 20:46:00:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-28 20:46:00:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-28 20:46:00:INFO:loading file None
2021-01-28 20:46:00:INFO:loading file None
2021-01-28 20:46:00:INFO:loading file None
2021-01-28 20:46:00:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-28 20:46:00:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-28 20:46:00:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-28 20:46:03:INFO:The model has 109943985 trainable parameters
2021-01-28 20:46:17:INFO:TRAIN-(misa) (1/1/1)>> loss: 3.9792  Has0_acc_2: 0.6433  Has0_F1_score: 0.6577  Non0_acc_2: 0.6434  Non0_F1_score: 0.6590  Mult_acc_5: 0.2220  Mult_acc_7: 0.2220  MAE: 1.1978  Corr: 0.4061 
2021-01-28 20:46:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7711  Non0_acc_2: 0.8148  Non0_F1_score: 0.8139  Mult_acc_5: 0.3013  Mult_acc_7: 0.3013  MAE: 1.0842  Corr: 0.6835  Loss: 1.6525 
2021-01-28 20:46:32:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.6549  Has0_acc_2: 0.8318  Has0_F1_score: 0.8310  Non0_acc_2: 0.8513  Non0_F1_score: 0.8510  Mult_acc_5: 0.3512  Mult_acc_7: 0.3411  MAE: 0.8115  Corr: 0.7495 
2021-01-28 20:46:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7985  Non0_acc_2: 0.8009  Non0_F1_score: 0.8053  Mult_acc_5: 0.4061  Mult_acc_7: 0.3362  MAE: 0.8850  Corr: 0.7628  Loss: 1.1861 
2021-01-28 20:46:48:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.9000  Has0_acc_2: 0.8840  Has0_F1_score: 0.8835  Non0_acc_2: 0.9033  Non0_F1_score: 0.9032  Mult_acc_5: 0.4727  Mult_acc_7: 0.4361  MAE: 0.6166  Corr: 0.8512 
2021-01-28 20:46:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8386  Non0_acc_2: 0.8565  Non0_F1_score: 0.8573  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7587  Corr: 0.7900  Loss: 0.9520 
2021-01-28 20:47:04:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.3816  Has0_acc_2: 0.9097  Has0_F1_score: 0.9093  Non0_acc_2: 0.9310  Non0_F1_score: 0.9309  Mult_acc_5: 0.5911  Mult_acc_7: 0.5397  MAE: 0.4981  Corr: 0.9099 
2021-01-28 20:47:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8288  Non0_acc_2: 0.8287  Non0_F1_score: 0.8325  Mult_acc_5: 0.4934  Mult_acc_7: 0.3974  MAE: 0.8296  Corr: 0.7837  Loss: 1.1527 
2021-01-28 20:47:18:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.0951  Has0_acc_2: 0.9190  Has0_F1_score: 0.9190  Non0_acc_2: 0.9334  Non0_F1_score: 0.9335  Mult_acc_5: 0.6332  Mult_acc_7: 0.5763  MAE: 0.4380  Corr: 0.9304 
2021-01-28 20:47:19:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8472  Non0_F1_score: 0.8478  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7398  Corr: 0.7836  Loss: 0.9897 
2021-01-28 20:47:33:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.8807  Has0_acc_2: 0.9206  Has0_F1_score: 0.9205  Non0_acc_2: 0.9399  Non0_F1_score: 0.9400  Mult_acc_5: 0.6807  Mult_acc_7: 0.6199  MAE: 0.3977  Corr: 0.9432 
2021-01-28 20:47:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.4716  Mult_acc_7: 0.3755  MAE: 0.7527  Corr: 0.7874  Loss: 1.0225 
2021-01-28 20:47:46:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.7012  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.6986  Mult_acc_7: 0.6316  MAE: 0.3598  Corr: 0.9536 
2021-01-28 20:47:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8611  Non0_F1_score: 0.8616  Mult_acc_5: 0.5066  Mult_acc_7: 0.3930  MAE: 0.7243  Corr: 0.7998  Loss: 0.9900 
2021-01-28 20:48:00:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.5835  Has0_acc_2: 0.9354  Has0_F1_score: 0.9352  Non0_acc_2: 0.9513  Non0_F1_score: 0.9513  Mult_acc_5: 0.7235  Mult_acc_7: 0.6581  MAE: 0.3495  Corr: 0.9569 
2021-01-28 20:48:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8428  Has0_F1_score: 0.8423  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5153  Mult_acc_7: 0.4061  MAE: 0.7320  Corr: 0.7883  Loss: 1.0308 
2021-01-28 20:48:14:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.5179  Has0_acc_2: 0.9268  Has0_F1_score: 0.9267  Non0_acc_2: 0.9448  Non0_F1_score: 0.9448  Mult_acc_5: 0.7344  Mult_acc_7: 0.6659  MAE: 0.3460  Corr: 0.9581 
2021-01-28 20:48:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.4672  Mult_acc_7: 0.3712  MAE: 0.7495  Corr: 0.7910  Loss: 0.9732 
2021-01-28 20:48:29:INFO:TRAIN-(misa) (7/10/1)>> loss: 0.4549  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7204  Mult_acc_7: 0.6682  MAE: 0.3296  Corr: 0.9608 
2021-01-28 20:48:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8400  Non0_acc_2: 0.8472  Non0_F1_score: 0.8492  Mult_acc_5: 0.5109  Mult_acc_7: 0.3974  MAE: 0.7412  Corr: 0.7977  Loss: 1.0671 
2021-01-28 20:48:43:INFO:TRAIN-(misa) (8/11/1)>> loss: 0.4036  Has0_acc_2: 0.9408  Has0_F1_score: 0.9406  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7414  Mult_acc_7: 0.6854  MAE: 0.3256  Corr: 0.9631 
2021-01-28 20:48:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8386  Non0_acc_2: 0.8611  Non0_F1_score: 0.8621  Mult_acc_5: 0.5328  Mult_acc_7: 0.4454  MAE: 0.7001  Corr: 0.8136  Loss: 1.5222 
2021-01-28 20:48:47:INFO:TEST-(misa) >>  Has0_acc_2: 0.8178  Has0_F1_score: 0.8174  Non0_acc_2: 0.8308  Non0_F1_score: 0.8299  Mult_acc_5: 0.4431  Mult_acc_7: 0.3936  MAE: 0.8382  Corr: 0.7494  Loss: 1.2288 
2021-01-28 20:48:47:INFO:Start saving results...
2021-01-28 20:48:47:INFO:Results are saved to results/results/mosi-misa-regression-tune.csv...
2021-01-29 14:08:02:INFO:########################################misa-(1/50)########################################
2021-01-29 14:08:02:INFO:batch_size:64
2021-01-29 14:08:02:INFO:learning_rate:0.0001
2021-01-29 14:08:02:INFO:hidden_size:256
2021-01-29 14:08:02:INFO:dropout:0.2
2021-01-29 14:08:02:INFO:reverse_grad_weight:0.8
2021-01-29 14:08:02:INFO:diff_weight:0.3
2021-01-29 14:08:02:INFO:sim_weight:0.5
2021-01-29 14:08:02:INFO:sp_weight:1.0
2021-01-29 14:08:02:INFO:recon_weight:0.8
2021-01-29 14:08:02:INFO:grad_clip:0.8
2021-01-29 14:08:02:INFO:weight_decay:0.0
2021-01-29 14:08:02:INFO:##########################################################################################
2021-01-29 14:08:02:INFO:Start running misa...
2021-01-29 14:08:02:INFO:Find gpu: 3, with memory: 3459055616 left!
2021-01-29 14:08:02:INFO:Let's use 1 GPUs!
2021-01-29 14:08:02:INFO:train samples: (1284,)
2021-01-29 14:08:03:INFO:valid samples: (229,)
2021-01-29 14:08:03:INFO:test samples: (686,)
2021-01-29 14:08:03:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-01-29 14:08:03:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-01-29 14:08:03:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-01-29 14:08:03:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-01-29 14:08:03:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-01-29 14:08:03:INFO:loading file None
2021-01-29 14:08:03:INFO:loading file None
2021-01-29 14:08:03:INFO:loading file None
2021-01-29 14:08:03:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-01-29 14:08:03:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-01-29 14:08:03:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-01-29 14:08:06:INFO:The model has 112687091 trainable parameters
2021-01-29 14:08:07:ERROR:CUDA out of memory. Tried to allocate 38.00 MiB (GPU 3; 7.77 GiB total capacity; 4.44 GiB already allocated; 29.50 MiB free; 210.78 MiB cached)
2021-02-02 07:57:44:INFO:########################################misa-(1/50)########################################
2021-02-02 07:57:44:INFO:batch_size:16
2021-02-02 07:57:44:INFO:learning_rate:0.0005
2021-02-02 07:57:44:INFO:hidden_size:128
2021-02-02 07:57:44:INFO:dropout:0.2
2021-02-02 07:57:44:INFO:reverse_grad_weight:0.5
2021-02-02 07:57:44:INFO:diff_weight:0.5
2021-02-02 07:57:44:INFO:sim_weight:0.8
2021-02-02 07:57:44:INFO:sp_weight:0.0
2021-02-02 07:57:44:INFO:recon_weight:0.8
2021-02-02 07:57:44:INFO:grad_clip:1.0
2021-02-02 07:57:44:INFO:weight_decay:0.002
2021-02-02 07:57:44:INFO:##########################################################################################
2021-02-02 07:57:44:INFO:Start running misa...
2021-02-02 07:57:45:INFO:Find gpu: 2, with memory: 3464298496 left!
2021-02-02 07:57:45:INFO:Let's use 1 GPUs!
2021-02-02 07:57:45:INFO:train samples: (1284,)
2021-02-02 07:57:45:INFO:valid samples: (229,)
2021-02-02 07:57:46:INFO:test samples: (686,)
2021-02-02 07:57:46:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 07:57:46:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 07:57:46:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 07:57:46:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 07:57:46:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 07:57:46:INFO:loading file None
2021-02-02 07:57:46:INFO:loading file None
2021-02-02 07:57:46:INFO:loading file None
2021-02-02 07:57:46:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 07:57:46:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 07:57:46:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 07:57:48:INFO:The model has 110621043 trainable parameters
2021-02-02 07:58:04:INFO:TRAIN-(misa) (1/1/1)>> loss: 1.5602  Has0_acc_2: 0.4969  Has0_F1_score: 0.5056  Non0_acc_2: 0.1592  Non0_F1_score: 0.1434  Acc_3: 0.4813  F1_score_3: 0.4987 
2021-02-02 07:58:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8744 
2021-02-02 07:58:22:INFO:TRAIN-(misa) (1/2/1)>> loss: 0.9614  Has0_acc_2: 0.5335  Has0_F1_score: 0.5645  Non0_acc_2: 0.1219  Non0_F1_score: 0.0873  Acc_3: 0.5226  F1_score_3: 0.5618 
2021-02-02 07:58:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8878 
2021-02-02 07:58:39:INFO:TRAIN-(misa) (2/3/1)>> loss: 0.9267  Has0_acc_2: 0.5226  Has0_F1_score: 0.5456  Non0_acc_2: 0.1332  Non0_F1_score: 0.1036  Acc_3: 0.5109  F1_score_3: 0.5424 
2021-02-02 07:58:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8947 
2021-02-02 07:58:56:INFO:TRAIN-(misa) (3/4/1)>> loss: 0.9036  Has0_acc_2: 0.5055  Has0_F1_score: 0.5401  Non0_acc_2: 0.1080  Non0_F1_score: 0.0769  Acc_3: 0.4984  F1_score_3: 0.5397 
2021-02-02 07:58:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8964 
2021-02-02 07:59:14:INFO:TRAIN-(misa) (4/5/1)>> loss: 0.8945  Has0_acc_2: 0.5210  Has0_F1_score: 0.5951  Non0_acc_2: 0.0601  Non0_F1_score: 0.0279  Acc_3: 0.5140  F1_score_3: 0.5938 
2021-02-02 07:59:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8713 
2021-02-02 07:59:33:INFO:TRAIN-(misa) (1/6/1)>> loss: 0.8795  Has0_acc_2: 0.5171  Has0_F1_score: 0.6184  Non0_acc_2: 0.0357  Non0_F1_score: 0.0117  Acc_3: 0.5132  F1_score_3: 0.6180 
2021-02-02 07:59:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8710 
2021-02-02 07:59:52:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.8793  Has0_acc_2: 0.5218  Has0_F1_score: 0.6239  Non0_acc_2: 0.0374  Non0_F1_score: 0.0119  Acc_3: 0.5187  F1_score_3: 0.6239 
2021-02-02 07:59:53:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8725 
2021-02-02 08:00:10:INFO:TRAIN-(misa) (2/8/1)>> loss: 0.8769  Has0_acc_2: 0.4969  Has0_F1_score: 0.5682  Non0_acc_2: 0.0577  Non0_F1_score: 0.0293  Acc_3: 0.4930  F1_score_3: 0.5682 
2021-02-02 08:00:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8981 
2021-02-02 08:00:28:INFO:TRAIN-(misa) (3/9/1)>> loss: 0.8680  Has0_acc_2: 0.5241  Has0_F1_score: 0.6180  Non0_acc_2: 0.0455  Non0_F1_score: 0.0165  Acc_3: 0.5210  F1_score_3: 0.6181 
2021-02-02 08:00:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.5459  Has0_F1_score: 0.7016  Non0_acc_2: 0.0046  Non0_F1_score: 0.0001  Acc_3: 0.5459  F1_score_3: 0.7016  Loss: 0.8684 
2021-02-02 08:00:47:INFO:TRAIN-(misa) (1/10/1)>> loss: 0.8708  Has0_acc_2: 0.5210  Has0_F1_score: 0.5907  Non0_acc_2: 0.0690  Non0_F1_score: 0.0345  Acc_3: 0.5179  F1_score_3: 0.5915 
2021-02-02 08:00:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8566 
2021-02-02 08:01:07:INFO:TRAIN-(misa) (1/11/1)>> loss: 0.8644  Has0_acc_2: 0.5164  Has0_F1_score: 0.5919  Non0_acc_2: 0.0569  Non0_F1_score: 0.0262  Acc_3: 0.5093  F1_score_3: 0.5905 
2021-02-02 08:01:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8549 
2021-02-02 08:01:26:INFO:TRAIN-(misa) (1/12/1)>> loss: 0.8634  Has0_acc_2: 0.5319  Has0_F1_score: 0.6080  Non0_acc_2: 0.0642  Non0_F1_score: 0.0288  Acc_3: 0.5273  F1_score_3: 0.6080 
2021-02-02 08:01:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.9166 
2021-02-02 08:01:44:INFO:TRAIN-(misa) (2/13/1)>> loss: 0.8609  Has0_acc_2: 0.5241  Has0_F1_score: 0.6244  Non0_acc_2: 0.0406  Non0_F1_score: 0.0134  Acc_3: 0.5218  F1_score_3: 0.6246 
2021-02-02 08:01:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8617 
2021-02-02 08:02:02:INFO:TRAIN-(misa) (3/14/1)>> loss: 0.8652  Has0_acc_2: 0.5327  Has0_F1_score: 0.6482  Non0_acc_2: 0.0325  Non0_F1_score: 0.0079  Acc_3: 0.5319  F1_score_3: 0.6486 
2021-02-02 08:02:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8675 
2021-02-02 08:02:20:INFO:TRAIN-(misa) (4/15/1)>> loss: 0.8613  Has0_acc_2: 0.5171  Has0_F1_score: 0.5421  Non0_acc_2: 0.1251  Non0_F1_score: 0.0954  Acc_3: 0.5039  F1_score_3: 0.5375 
2021-02-02 08:02:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8917 
2021-02-02 08:02:37:INFO:TRAIN-(misa) (5/16/1)>> loss: 0.8570  Has0_acc_2: 0.5288  Has0_F1_score: 0.6555  Non0_acc_2: 0.0195  Non0_F1_score: 0.0034  Acc_3: 0.5249  F1_score_3: 0.6551 
2021-02-02 08:02:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8601 
2021-02-02 08:02:55:INFO:TRAIN-(misa) (6/17/1)>> loss: 0.8555  Has0_acc_2: 0.5273  Has0_F1_score: 0.6405  Non0_acc_2: 0.0301  Non0_F1_score: 0.0076  Acc_3: 0.5241  F1_score_3: 0.6403 
2021-02-02 08:02:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8626 
2021-02-02 08:03:13:INFO:TRAIN-(misa) (7/18/1)>> loss: 0.8511  Has0_acc_2: 0.5257  Has0_F1_score: 0.6842  Non0_acc_2: 0.0016  Non0_F1_score: 0.0000  Acc_3: 0.5257  F1_score_3: 0.6842 
2021-02-02 08:03:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8572 
2021-02-02 08:03:29:INFO:TRAIN-(misa) (8/19/1)>> loss: 0.8540  Has0_acc_2: 0.5273  Has0_F1_score: 0.6880  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5265  F1_score_3: 0.6880 
2021-02-02 08:03:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8618 
2021-02-02 08:03:33:INFO:TEST-(misa) >>  Has0_acc_2: 0.4038  Has0_F1_score: 0.5753  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.4038  F1_score_3: 0.5753  Loss: 0.8662 
2021-02-02 08:03:33:INFO:Start saving results...
2021-02-02 08:03:33:INFO:Results are saved to results/results/mosi-misa-classification-tune.csv...
2021-02-02 08:03:33:INFO:########################################misa-(2/50)########################################
2021-02-02 08:03:33:INFO:batch_size:16
2021-02-02 08:03:33:INFO:learning_rate:0.001
2021-02-02 08:03:33:INFO:hidden_size:256
2021-02-02 08:03:33:INFO:dropout:0.2
2021-02-02 08:03:33:INFO:reverse_grad_weight:1.0
2021-02-02 08:03:33:INFO:diff_weight:0.3
2021-02-02 08:03:33:INFO:sim_weight:1.0
2021-02-02 08:03:33:INFO:sp_weight:0.0
2021-02-02 08:03:33:INFO:recon_weight:1.0
2021-02-02 08:03:33:INFO:grad_clip:1.0
2021-02-02 08:03:33:INFO:weight_decay:0.0
2021-02-02 08:03:33:INFO:##########################################################################################
2021-02-02 08:03:33:INFO:Start running misa...
2021-02-02 08:03:33:INFO:Find gpu: 2, with memory: 3428646912 left!
2021-02-02 08:03:33:INFO:Let's use 1 GPUs!
2021-02-02 08:03:34:INFO:train samples: (1284,)
2021-02-02 08:03:34:INFO:valid samples: (229,)
2021-02-02 08:03:34:INFO:test samples: (686,)
2021-02-02 08:03:34:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 08:03:34:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 08:03:34:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 08:03:34:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 08:03:34:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 08:03:34:INFO:loading file None
2021-02-02 08:03:34:INFO:loading file None
2021-02-02 08:03:34:INFO:loading file None
2021-02-02 08:03:35:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 08:03:35:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 08:03:35:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 08:03:36:INFO:The model has 112687091 trainable parameters
2021-02-02 08:03:53:INFO:TRAIN-(misa) (1/1/1)>> loss: 1.7470  Has0_acc_2: 0.4860  Has0_F1_score: 0.4886  Non0_acc_2: 0.1795  Non0_F1_score: 0.1742  Acc_3: 0.4681  F1_score_3: 0.4796 
2021-02-02 08:03:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.9047 
2021-02-02 08:04:12:INFO:TRAIN-(misa) (1/2/1)>> loss: 0.9674  Has0_acc_2: 0.5101  Has0_F1_score: 0.5502  Non0_acc_2: 0.0942  Non0_F1_score: 0.0624  Acc_3: 0.4969  F1_score_3: 0.5453 
2021-02-02 08:04:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8894 
2021-02-02 08:04:31:INFO:TRAIN-(misa) (1/3/1)>> loss: 0.9446  Has0_acc_2: 0.4922  Has0_F1_score: 0.4982  Non0_acc_2: 0.1690  Non0_F1_score: 0.1574  Acc_3: 0.4782  F1_score_3: 0.4929 
2021-02-02 08:04:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8986 
2021-02-02 08:04:49:INFO:TRAIN-(misa) (2/4/1)>> loss: 0.9059  Has0_acc_2: 0.5296  Has0_F1_score: 0.5970  Non0_acc_2: 0.0723  Non0_F1_score: 0.0361  Acc_3: 0.5241  F1_score_3: 0.5967 
2021-02-02 08:04:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8674 
2021-02-02 08:05:08:INFO:TRAIN-(misa) (1/5/1)>> loss: 0.8974  Has0_acc_2: 0.4945  Has0_F1_score: 0.5123  Non0_acc_2: 0.1340  Non0_F1_score: 0.1108  Acc_3: 0.4829  F1_score_3: 0.5087 
2021-02-02 08:05:09:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8748 
2021-02-02 08:05:25:INFO:TRAIN-(misa) (2/6/1)>> loss: 0.8719  Has0_acc_2: 0.5312  Has0_F1_score: 0.6502  Non0_acc_2: 0.0244  Non0_F1_score: 0.0051  Acc_3: 0.5257  F1_score_3: 0.6494 
2021-02-02 08:05:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8613 
2021-02-02 08:05:44:INFO:TRAIN-(misa) (1/7/1)>> loss: 0.8715  Has0_acc_2: 0.5249  Has0_F1_score: 0.6712  Non0_acc_2: 0.0081  Non0_F1_score: 0.0007  Acc_3: 0.5241  F1_score_3: 0.6712 
2021-02-02 08:05:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8942 
2021-02-02 08:06:02:INFO:TRAIN-(misa) (2/8/1)>> loss: 0.8707  Has0_acc_2: 0.5273  Has0_F1_score: 0.6467  Non0_acc_2: 0.0260  Non0_F1_score: 0.0058  Acc_3: 0.5249  F1_score_3: 0.6467 
2021-02-02 08:06:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8640 
2021-02-02 08:06:20:INFO:TRAIN-(misa) (3/9/1)>> loss: 0.8606  Has0_acc_2: 0.5280  Has0_F1_score: 0.6252  Non0_acc_2: 0.0414  Non0_F1_score: 0.0138  Acc_3: 0.5226  F1_score_3: 0.6244 
2021-02-02 08:06:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8991 
2021-02-02 08:06:37:INFO:TRAIN-(misa) (4/10/1)>> loss: 0.8654  Has0_acc_2: 0.5202  Has0_F1_score: 0.5835  Non0_acc_2: 0.0715  Non0_F1_score: 0.0376  Acc_3: 0.5125  F1_score_3: 0.5819 
2021-02-02 08:06:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.9062 
2021-02-02 08:06:54:INFO:TRAIN-(misa) (5/11/1)>> loss: 0.8515  Has0_acc_2: 0.5358  Has0_F1_score: 0.6109  Non0_acc_2: 0.0658  Non0_F1_score: 0.0296  Acc_3: 0.5304  F1_score_3: 0.6106 
2021-02-02 08:06:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.4585  Has0_F1_score: 0.6287  Non0_acc_2: 0.4259  Non0_F1_score: 0.5974  Acc_3: 0.4017  F1_score_3: 0.5732  Loss: 0.8980 
2021-02-02 08:07:12:INFO:TRAIN-(misa) (6/12/1)>> loss: 0.8565  Has0_acc_2: 0.5109  Has0_F1_score: 0.5781  Non0_acc_2: 0.0650  Non0_F1_score: 0.0334  Acc_3: 0.5047  F1_score_3: 0.5772 
2021-02-02 08:07:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.9117 
2021-02-02 08:07:29:INFO:TRAIN-(misa) (7/13/1)>> loss: 0.8520  Has0_acc_2: 0.5249  Has0_F1_score: 0.6173  Non0_acc_2: 0.0463  Non0_F1_score: 0.0170  Acc_3: 0.5210  F1_score_3: 0.6172 
2021-02-02 08:07:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8648 
2021-02-02 08:07:47:INFO:TRAIN-(misa) (8/14/1)>> loss: 0.8510  Has0_acc_2: 0.5312  Has0_F1_score: 0.6794  Non0_acc_2: 0.0097  Non0_F1_score: 0.0007  Acc_3: 0.5312  F1_score_3: 0.6794 
2021-02-02 08:07:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.5415  Has0_F1_score: 0.7025  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.5415  F1_score_3: 0.7025  Loss: 0.8792 
2021-02-02 08:07:51:INFO:TEST-(misa) >>  Has0_acc_2: 0.4038  Has0_F1_score: 0.5753  Non0_acc_2: 0.0000  Non0_F1_score: 0.0000  Acc_3: 0.4038  F1_score_3: 0.5753  Loss: 0.8789 
2021-02-02 08:07:51:INFO:Start saving results...
2021-02-02 08:07:51:INFO:Results are saved to results/results/mosi-misa-classification-tune.csv...
2021-02-02 08:07:51:INFO:########################################misa-(3/50)########################################
2021-02-02 08:07:51:INFO:batch_size:64
2021-02-02 08:07:51:INFO:learning_rate:0.0005
2021-02-02 08:07:51:INFO:hidden_size:64
2021-02-02 08:07:51:INFO:dropout:0.0
2021-02-02 08:07:51:INFO:reverse_grad_weight:0.8
2021-02-02 08:07:51:INFO:diff_weight:0.3
2021-02-02 08:07:51:INFO:sim_weight:1.0
2021-02-02 08:07:51:INFO:sp_weight:1.0
2021-02-02 08:07:51:INFO:recon_weight:0.8
2021-02-02 08:07:51:INFO:grad_clip:0.8
2021-02-02 08:07:51:INFO:weight_decay:0.002
2021-02-02 08:07:51:INFO:##########################################################################################
2021-02-02 08:07:51:INFO:Start running misa...
2021-02-02 08:07:51:INFO:Find gpu: 2, with memory: 3428646912 left!
2021-02-02 08:07:51:INFO:Let's use 1 GPUs!
2021-02-02 08:07:51:INFO:train samples: (1284,)
2021-02-02 08:07:52:INFO:valid samples: (229,)
2021-02-02 08:07:52:INFO:test samples: (686,)
2021-02-02 08:07:52:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 08:07:52:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 08:07:52:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 08:07:52:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 08:07:52:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 08:07:52:INFO:loading file None
2021-02-02 08:07:52:INFO:loading file None
2021-02-02 08:07:52:INFO:loading file None
2021-02-02 08:07:52:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 08:07:52:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 08:07:52:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 08:07:54:INFO:The model has 109944371 trainable parameters
2021-02-02 08:07:55:ERROR:CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 7.77 GiB total capacity; 4.42 GiB already allocated; 10.50 MiB free; 144.04 MiB cached)
2021-02-02 19:54:50:INFO:Start running misa...
2021-02-02 19:54:50:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1111}>
2021-02-02 19:54:50:INFO:Find gpu: 2, with memory: 2224881664 left!
2021-02-02 19:54:50:INFO:Let's use 1 GPUs!
2021-02-02 19:54:56:INFO:train samples: (1284,)
2021-02-02 19:54:56:INFO:valid samples: (229,)
2021-02-02 19:54:57:INFO:test samples: (686,)
2021-02-02 19:54:57:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 19:54:57:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 19:54:57:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 19:54:57:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 19:54:57:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 19:54:57:INFO:loading file None
2021-02-02 19:54:57:INFO:loading file None
2021-02-02 19:54:57:INFO:loading file None
2021-02-02 19:54:57:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 19:54:57:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 19:54:57:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 19:55:01:INFO:The model has 110620273 trainable parameters
2021-02-02 19:55:10:INFO:TRAIN-(misa) (1/1/1)>> loss: 4.1939  Has0_acc_2: 0.6051  Has0_F1_score: 0.6243  Non0_acc_2: 0.6003  Non0_F1_score: 0.6205  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2626  Corr: 0.2678 
2021-02-02 19:55:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.7336  Has0_F1_score: 0.7498  Non0_acc_2: 0.7269  Non0_F1_score: 0.7435  Mult_acc_5: 0.2620  Mult_acc_7: 0.2620  MAE: 1.1304  Corr: 0.6556  Loss: 1.9080 
2021-02-02 19:55:22:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.8274  Has0_acc_2: 0.8154  Has0_F1_score: 0.8152  Non0_acc_2: 0.8278  Non0_F1_score: 0.8280  Mult_acc_5: 0.3287  Mult_acc_7: 0.3240  MAE: 0.8471  Corr: 0.7331 
2021-02-02 19:55:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7885  Non0_acc_2: 0.8287  Non0_F1_score: 0.8278  Mult_acc_5: 0.4148  Mult_acc_7: 0.3450  MAE: 0.8742  Corr: 0.7382  Loss: 1.2753 
2021-02-02 19:55:33:INFO:TRAIN-(misa) (1/3/1)>> loss: 2.0085  Has0_acc_2: 0.8692  Has0_F1_score: 0.8685  Non0_acc_2: 0.8879  Non0_F1_score: 0.8876  Mult_acc_5: 0.4938  Mult_acc_7: 0.4595  MAE: 0.6070  Corr: 0.8529 
2021-02-02 19:55:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7760  Corr: 0.7781  Loss: 1.0592 
2021-02-02 19:55:44:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.5276  Has0_acc_2: 0.8980  Has0_F1_score: 0.8978  Non0_acc_2: 0.9171  Non0_F1_score: 0.9172  Mult_acc_5: 0.5833  Mult_acc_7: 0.5296  MAE: 0.4968  Corr: 0.9047 
2021-02-02 19:55:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7958  Non0_acc_2: 0.8148  Non0_F1_score: 0.8170  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7957  Corr: 0.7617  Loss: 1.2106 
2021-02-02 19:55:54:INFO:TRAIN-(misa) (2/5/1)>> loss: 1.1650  Has0_acc_2: 0.9237  Has0_F1_score: 0.9235  Non0_acc_2: 0.9399  Non0_F1_score: 0.9399  Mult_acc_5: 0.6410  Mult_acc_7: 0.5927  MAE: 0.4183  Corr: 0.9362 
2021-02-02 19:55:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8061  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.4541  Mult_acc_7: 0.3581  MAE: 0.7928  Corr: 0.7780  Loss: 1.1996 
2021-02-02 19:56:04:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.9062  Has0_acc_2: 0.9322  Has0_F1_score: 0.9321  Non0_acc_2: 0.9529  Non0_F1_score: 0.9529  Mult_acc_5: 0.7033  Mult_acc_7: 0.6410  MAE: 0.3488  Corr: 0.9553 
2021-02-02 19:56:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7929  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.4629  Mult_acc_7: 0.3624  MAE: 0.7954  Corr: 0.7783  Loss: 1.1341 
2021-02-02 19:56:14:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.7170  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7352  Mult_acc_7: 0.6760  MAE: 0.3161  Corr: 0.9647 
2021-02-02 19:56:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7929  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.4716  Mult_acc_7: 0.3712  MAE: 0.7804  Corr: 0.7782  Loss: 1.1674 
2021-02-02 19:56:24:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.5828  Has0_acc_2: 0.9439  Has0_F1_score: 0.9438  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7827  Mult_acc_7: 0.7329  MAE: 0.2848  Corr: 0.9712 
2021-02-02 19:56:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7839  Non0_acc_2: 0.8194  Non0_F1_score: 0.8185  Mult_acc_5: 0.4498  Mult_acc_7: 0.3624  MAE: 0.8029  Corr: 0.7739  Loss: 1.1117 
2021-02-02 19:56:34:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4899  Has0_acc_2: 0.9486  Has0_F1_score: 0.9484  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7944  Mult_acc_7: 0.7461  MAE: 0.2772  Corr: 0.9732 
2021-02-02 19:56:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8203  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5328  Mult_acc_7: 0.4105  MAE: 0.7529  Corr: 0.7839  Loss: 1.1072 
2021-02-02 19:56:44:INFO:TRAIN-(misa) (7/10/1)>> loss: 0.4272  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7819  Mult_acc_7: 0.7383  MAE: 0.2624  Corr: 0.9755 
2021-02-02 19:56:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.4934  Mult_acc_7: 0.3799  MAE: 0.7716  Corr: 0.7830  Loss: 1.0969 
2021-02-02 19:56:54:INFO:TRAIN-(misa) (8/11/1)>> loss: 0.3941  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.7718  Mult_acc_7: 0.7274  MAE: 0.2688  Corr: 0.9752 
2021-02-02 19:56:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7884  Non0_acc_2: 0.8241  Non0_F1_score: 0.8231  Mult_acc_5: 0.4847  Mult_acc_7: 0.3755  MAE: 0.7853  Corr: 0.7766  Loss: 1.1766 
2021-02-02 19:56:57:INFO:TEST-(misa) >>  Has0_acc_2: 0.8236  Has0_F1_score: 0.8239  Non0_acc_2: 0.8445  Non0_F1_score: 0.8442  Mult_acc_5: 0.4708  Mult_acc_7: 0.4155  MAE: 0.7739  Corr: 0.7746  Loss: 1.0386 
2021-02-02 19:57:02:INFO:Start running misa...
2021-02-02 19:57:02:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [2], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1112}>
2021-02-02 19:57:02:INFO:Let's use 1 GPUs!
2021-02-02 19:57:02:INFO:train samples: (1284,)
2021-02-02 19:57:03:INFO:valid samples: (229,)
2021-02-02 19:57:04:INFO:test samples: (686,)
2021-02-02 19:57:04:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 19:57:04:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 19:57:04:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 19:57:04:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 19:57:04:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 19:57:04:INFO:loading file None
2021-02-02 19:57:04:INFO:loading file None
2021-02-02 19:57:04:INFO:loading file None
2021-02-02 19:57:04:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 19:57:04:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 19:57:04:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 19:57:07:INFO:The model has 110620273 trainable parameters
2021-02-02 19:57:16:INFO:TRAIN-(misa) (1/1/2)>> loss: 4.2547  Has0_acc_2: 0.5989  Has0_F1_score: 0.6282  Non0_acc_2: 0.5890  Non0_F1_score: 0.6188  Mult_acc_5: 0.1939  Mult_acc_7: 0.1939  MAE: 1.2870  Corr: 0.1872 
2021-02-02 19:57:17:INFO:VAL-(misa) >>  Has0_acc_2: 0.7642  Has0_F1_score: 0.7714  Non0_acc_2: 0.7731  Non0_F1_score: 0.7815  Mult_acc_5: 0.2707  Mult_acc_7: 0.2707  MAE: 1.1870  Corr: 0.6275  Loss: 1.9982 
2021-02-02 19:57:28:INFO:TRAIN-(misa) (1/2/2)>> loss: 2.9174  Has0_acc_2: 0.7967  Has0_F1_score: 0.7964  Non0_acc_2: 0.8091  Non0_F1_score: 0.8093  Mult_acc_5: 0.3022  Mult_acc_7: 0.2975  MAE: 0.9147  Corr: 0.6999 
2021-02-02 19:57:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.7686  Has0_F1_score: 0.7673  Non0_acc_2: 0.8056  Non0_F1_score: 0.8049  Mult_acc_5: 0.3362  Mult_acc_7: 0.3057  MAE: 0.9646  Corr: 0.7468  Loss: 1.3940 
2021-02-02 19:57:39:INFO:TRAIN-(misa) (1/3/2)>> loss: 2.0547  Has0_acc_2: 0.8614  Has0_F1_score: 0.8608  Non0_acc_2: 0.8790  Non0_F1_score: 0.8787  Mult_acc_5: 0.4735  Mult_acc_7: 0.4400  MAE: 0.6626  Corr: 0.8308 
2021-02-02 19:57:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7931  Non0_acc_2: 0.8287  Non0_F1_score: 0.8284  Mult_acc_5: 0.4716  Mult_acc_7: 0.3843  MAE: 0.8120  Corr: 0.7663  Loss: 1.1958 
2021-02-02 19:57:51:INFO:TRAIN-(misa) (1/4/2)>> loss: 1.6039  Has0_acc_2: 0.8855  Has0_F1_score: 0.8851  Non0_acc_2: 0.9074  Non0_F1_score: 0.9073  Mult_acc_5: 0.5678  Mult_acc_7: 0.5241  MAE: 0.5262  Corr: 0.8937 
2021-02-02 19:57:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8130  Non0_acc_2: 0.8148  Non0_F1_score: 0.8205  Mult_acc_5: 0.4541  Mult_acc_7: 0.3668  MAE: 0.8395  Corr: 0.7611  Loss: 1.2546 
2021-02-02 19:58:01:INFO:TRAIN-(misa) (2/5/2)>> loss: 1.2582  Has0_acc_2: 0.9268  Has0_F1_score: 0.9267  Non0_acc_2: 0.9399  Non0_F1_score: 0.9400  Mult_acc_5: 0.6145  Mult_acc_7: 0.5623  MAE: 0.4564  Corr: 0.9260 
2021-02-02 19:58:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7928  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4760  Mult_acc_7: 0.3930  MAE: 0.8252  Corr: 0.7777  Loss: 1.2284 
2021-02-02 19:58:11:INFO:TRAIN-(misa) (3/6/2)>> loss: 0.9997  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.6589  Mult_acc_7: 0.6020  MAE: 0.3808  Corr: 0.9480 
2021-02-02 19:58:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8260  Non0_acc_2: 0.8472  Non0_F1_score: 0.8488  Mult_acc_5: 0.5153  Mult_acc_7: 0.4236  MAE: 0.7546  Corr: 0.7890  Loss: 1.0748 
2021-02-02 19:58:23:INFO:TRAIN-(misa) (1/7/2)>> loss: 0.7653  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.7282  Mult_acc_7: 0.6776  MAE: 0.3063  Corr: 0.9660 
2021-02-02 19:58:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8109  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7353  Corr: 0.7915  Loss: 1.0780 
2021-02-02 19:58:33:INFO:TRAIN-(misa) (2/8/2)>> loss: 0.5985  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7843  Mult_acc_7: 0.7344  MAE: 0.2666  Corr: 0.9752 
2021-02-02 19:58:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8152  Non0_acc_2: 0.8519  Non0_F1_score: 0.8517  Mult_acc_5: 0.5153  Mult_acc_7: 0.4323  MAE: 0.7423  Corr: 0.7903  Loss: 1.0285 
2021-02-02 19:58:44:INFO:TRAIN-(misa) (1/9/2)>> loss: 0.4993  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.8006  Mult_acc_7: 0.7516  MAE: 0.2593  Corr: 0.9762 
2021-02-02 19:58:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8173  Non0_acc_2: 0.8426  Non0_F1_score: 0.8445  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7431  Corr: 0.7930  Loss: 1.0688 
2021-02-02 19:58:55:INFO:TRAIN-(misa) (2/10/2)>> loss: 0.4265  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9708  Non0_F1_score: 0.9708  Mult_acc_5: 0.8030  Mult_acc_7: 0.7593  MAE: 0.2454  Corr: 0.9791 
2021-02-02 19:58:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8067  Non0_acc_2: 0.8380  Non0_F1_score: 0.8381  Mult_acc_5: 0.5197  Mult_acc_7: 0.4279  MAE: 0.7419  Corr: 0.7903  Loss: 1.0209 
2021-02-02 19:59:06:INFO:TRAIN-(misa) (1/11/2)>> loss: 0.3914  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.7928  Mult_acc_7: 0.7547  MAE: 0.2362  Corr: 0.9799 
2021-02-02 19:59:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8208  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5415  Mult_acc_7: 0.4498  MAE: 0.7281  Corr: 0.7967  Loss: 1.0017 
2021-02-02 19:59:18:INFO:TRAIN-(misa) (1/12/2)>> loss: 0.3636  Has0_acc_2: 0.9416  Has0_F1_score: 0.9415  Non0_acc_2: 0.9602  Non0_F1_score: 0.9602  Mult_acc_5: 0.8076  Mult_acc_7: 0.7710  MAE: 0.2457  Corr: 0.9792 
2021-02-02 19:59:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8062  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5284  Mult_acc_7: 0.4454  MAE: 0.7412  Corr: 0.7965  Loss: 1.1152 
2021-02-02 19:59:28:INFO:TRAIN-(misa) (2/13/2)>> loss: 0.3343  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.7983  Mult_acc_7: 0.7578  MAE: 0.2335  Corr: 0.9809 
2021-02-02 19:59:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8107  Non0_acc_2: 0.8472  Non0_F1_score: 0.8469  Mult_acc_5: 0.5415  Mult_acc_7: 0.4585  MAE: 0.7252  Corr: 0.7977  Loss: 1.0088 
2021-02-02 19:59:38:INFO:TRAIN-(misa) (3/14/2)>> loss: 0.3396  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.7741  Mult_acc_7: 0.7399  MAE: 0.2584  Corr: 0.9760 
2021-02-02 19:59:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5328  Mult_acc_7: 0.4279  MAE: 0.7387  Corr: 0.7939  Loss: 0.9958 
2021-02-02 19:59:50:INFO:TRAIN-(misa) (1/15/2)>> loss: 0.2878  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.8107  Mult_acc_7: 0.7702  MAE: 0.2201  Corr: 0.9832 
2021-02-02 19:59:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8611  Non0_F1_score: 0.8609  Mult_acc_5: 0.5459  Mult_acc_7: 0.4454  MAE: 0.7211  Corr: 0.8007  Loss: 0.9990 
2021-02-02 20:00:00:INFO:TRAIN-(misa) (2/16/2)>> loss: 0.2880  Has0_acc_2: 0.9486  Has0_F1_score: 0.9485  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.8123  Mult_acc_7: 0.7734  MAE: 0.2362  Corr: 0.9808 
2021-02-02 20:00:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8153  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5284  Mult_acc_7: 0.4279  MAE: 0.7194  Corr: 0.7984  Loss: 0.9909 
2021-02-02 20:00:12:INFO:TRAIN-(misa) (1/17/2)>> loss: 0.2716  Has0_acc_2: 0.9525  Has0_F1_score: 0.9524  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8076  Mult_acc_7: 0.7718  MAE: 0.2310  Corr: 0.9815 
2021-02-02 20:00:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8237  Non0_acc_2: 0.8657  Non0_F1_score: 0.8652  Mult_acc_5: 0.5240  Mult_acc_7: 0.4236  MAE: 0.7503  Corr: 0.7993  Loss: 1.0734 
2021-02-02 20:00:22:INFO:TRAIN-(misa) (2/18/2)>> loss: 0.2721  Has0_acc_2: 0.9455  Has0_F1_score: 0.9454  Non0_acc_2: 0.9610  Non0_F1_score: 0.9610  Mult_acc_5: 0.7998  Mult_acc_7: 0.7625  MAE: 0.2427  Corr: 0.9789 
2021-02-02 20:00:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8472  Non0_F1_score: 0.8473  Mult_acc_5: 0.5677  Mult_acc_7: 0.4760  MAE: 0.7080  Corr: 0.8051  Loss: 0.9490 
2021-02-02 20:00:34:INFO:TRAIN-(misa) (1/19/2)>> loss: 0.2478  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.8333  Mult_acc_7: 0.7944  MAE: 0.2186  Corr: 0.9834 
2021-02-02 20:00:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8197  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.5546  Mult_acc_7: 0.4541  MAE: 0.7190  Corr: 0.8040  Loss: 1.0026 
2021-02-02 20:00:44:INFO:TRAIN-(misa) (2/20/2)>> loss: 0.2244  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8349  Mult_acc_7: 0.8022  MAE: 0.2027  Corr: 0.9855 
2021-02-02 20:00:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5459  Mult_acc_7: 0.4585  MAE: 0.6962  Corr: 0.8090  Loss: 0.9215 
2021-02-02 20:00:55:INFO:TRAIN-(misa) (1/21/2)>> loss: 0.2287  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8170  Mult_acc_7: 0.7780  MAE: 0.2142  Corr: 0.9839 
2021-02-02 20:00:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8241  Non0_acc_2: 0.8611  Non0_F1_score: 0.8611  Mult_acc_5: 0.5459  Mult_acc_7: 0.4410  MAE: 0.7071  Corr: 0.8088  Loss: 1.0356 
2021-02-02 20:01:05:INFO:TRAIN-(misa) (2/22/2)>> loss: 0.2197  Has0_acc_2: 0.9533  Has0_F1_score: 0.9531  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8326  Mult_acc_7: 0.8053  MAE: 0.2164  Corr: 0.9841 
2021-02-02 20:01:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8611  Non0_F1_score: 0.8613  Mult_acc_5: 0.5371  Mult_acc_7: 0.4585  MAE: 0.7010  Corr: 0.8049  Loss: 0.9347 
2021-02-02 20:01:15:INFO:TRAIN-(misa) (3/23/2)>> loss: 0.2034  Has0_acc_2: 0.9579  Has0_F1_score: 0.9579  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8294  Mult_acc_7: 0.8014  MAE: 0.1942  Corr: 0.9868 
2021-02-02 20:01:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8253  Non0_acc_2: 0.8519  Non0_F1_score: 0.8529  Mult_acc_5: 0.5546  Mult_acc_7: 0.4672  MAE: 0.7079  Corr: 0.8032  Loss: 1.0652 
2021-02-02 20:01:26:INFO:TRAIN-(misa) (4/24/2)>> loss: 0.1962  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8310  Mult_acc_7: 0.7991  MAE: 0.1940  Corr: 0.9865 
2021-02-02 20:01:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8565  Non0_F1_score: 0.8571  Mult_acc_5: 0.5590  Mult_acc_7: 0.4498  MAE: 0.7271  Corr: 0.8001  Loss: 0.9976 
2021-02-02 20:01:36:INFO:TRAIN-(misa) (5/25/2)>> loss: 0.2020  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8248  Mult_acc_7: 0.7960  MAE: 0.2117  Corr: 0.9843 
2021-02-02 20:01:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5284  Mult_acc_7: 0.4454  MAE: 0.7160  Corr: 0.8006  Loss: 1.0452 
2021-02-02 20:01:46:INFO:TRAIN-(misa) (6/26/2)>> loss: 0.1891  Has0_acc_2: 0.9587  Has0_F1_score: 0.9586  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8403  Mult_acc_7: 0.8092  MAE: 0.2028  Corr: 0.9859 
2021-02-02 20:01:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8333  Non0_acc_2: 0.8657  Non0_F1_score: 0.8661  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7026  Corr: 0.8039  Loss: 0.9552 
2021-02-02 20:01:56:INFO:TRAIN-(misa) (7/27/2)>> loss: 0.1783  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8474  Mult_acc_7: 0.8146  MAE: 0.1968  Corr: 0.9865 
2021-02-02 20:01:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8519  Non0_F1_score: 0.8512  Mult_acc_5: 0.4803  Mult_acc_7: 0.3886  MAE: 0.7392  Corr: 0.8006  Loss: 1.1077 
2021-02-02 20:02:06:INFO:TRAIN-(misa) (8/28/2)>> loss: 0.1760  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8287  Mult_acc_7: 0.8053  MAE: 0.1850  Corr: 0.9876 
2021-02-02 20:02:07:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5328  Mult_acc_7: 0.4367  MAE: 0.7059  Corr: 0.8050  Loss: 0.9909 
2021-02-02 20:02:09:INFO:TEST-(misa) >>  Has0_acc_2: 0.8192  Has0_F1_score: 0.8197  Non0_acc_2: 0.8415  Non0_F1_score: 0.8412  Mult_acc_5: 0.4913  Mult_acc_7: 0.4431  MAE: 0.7442  Corr: 0.7898  Loss: 1.0052 
2021-02-02 20:02:14:INFO:Start running misa...
2021-02-02 20:02:14:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [2], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1113}>
2021-02-02 20:02:14:INFO:Let's use 1 GPUs!
2021-02-02 20:02:15:INFO:train samples: (1284,)
2021-02-02 20:02:15:INFO:valid samples: (229,)
2021-02-02 20:02:16:INFO:test samples: (686,)
2021-02-02 20:02:16:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 20:02:16:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 20:02:16:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 20:02:16:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 20:02:16:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 20:02:16:INFO:loading file None
2021-02-02 20:02:16:INFO:loading file None
2021-02-02 20:02:16:INFO:loading file None
2021-02-02 20:02:16:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 20:02:16:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 20:02:16:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 20:02:19:INFO:The model has 110620273 trainable parameters
2021-02-02 20:02:28:INFO:TRAIN-(misa) (1/1/3)>> loss: 4.2596  Has0_acc_2: 0.6402  Has0_F1_score: 0.6596  Non0_acc_2: 0.6312  Non0_F1_score: 0.6507  Mult_acc_5: 0.1978  Mult_acc_7: 0.1978  MAE: 1.2532  Corr: 0.2904 
2021-02-02 20:02:29:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7796  Non0_acc_2: 0.8056  Non0_F1_score: 0.8045  Mult_acc_5: 0.2795  Mult_acc_7: 0.2795  MAE: 1.1578  Corr: 0.6667  Loss: 1.9389 
2021-02-02 20:02:39:INFO:TRAIN-(misa) (1/2/3)>> loss: 2.9126  Has0_acc_2: 0.8263  Has0_F1_score: 0.8256  Non0_acc_2: 0.8416  Non0_F1_score: 0.8413  Mult_acc_5: 0.3287  Mult_acc_7: 0.3193  MAE: 0.8471  Corr: 0.7405 
2021-02-02 20:02:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.3930  Mult_acc_7: 0.3188  MAE: 0.8831  Corr: 0.7253  Loss: 1.3872 
2021-02-02 20:02:51:INFO:TRAIN-(misa) (1/3/3)>> loss: 2.0403  Has0_acc_2: 0.8684  Has0_F1_score: 0.8678  Non0_acc_2: 0.8903  Non0_F1_score: 0.8901  Mult_acc_5: 0.5078  Mult_acc_7: 0.4688  MAE: 0.6020  Corr: 0.8609 
2021-02-02 20:02:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8022  Non0_acc_2: 0.8333  Non0_F1_score: 0.8333  Mult_acc_5: 0.4803  Mult_acc_7: 0.3843  MAE: 0.8313  Corr: 0.7402  Loss: 1.2596 
2021-02-02 20:03:02:INFO:TRAIN-(misa) (1/4/3)>> loss: 1.5936  Has0_acc_2: 0.9089  Has0_F1_score: 0.9086  Non0_acc_2: 0.9269  Non0_F1_score: 0.9268  Mult_acc_5: 0.5818  Mult_acc_7: 0.5343  MAE: 0.4939  Corr: 0.9072 
2021-02-02 20:03:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.4410  Mult_acc_7: 0.3406  MAE: 0.8332  Corr: 0.7493  Loss: 1.2442 
2021-02-02 20:03:14:INFO:TRAIN-(misa) (1/5/3)>> loss: 1.2302  Has0_acc_2: 0.9221  Has0_F1_score: 0.9218  Non0_acc_2: 0.9423  Non0_F1_score: 0.9423  Mult_acc_5: 0.6573  Mult_acc_7: 0.6044  MAE: 0.4072  Corr: 0.9404 
2021-02-02 20:03:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8268  Non0_acc_2: 0.8333  Non0_F1_score: 0.8353  Mult_acc_5: 0.4454  Mult_acc_7: 0.3362  MAE: 0.8207  Corr: 0.7688  Loss: 1.2547 
2021-02-02 20:03:24:INFO:TRAIN-(misa) (2/6/3)>> loss: 1.0095  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9504  Non0_F1_score: 0.9504  Mult_acc_5: 0.6869  Mult_acc_7: 0.6246  MAE: 0.3723  Corr: 0.9513 
2021-02-02 20:03:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8481  Mult_acc_5: 0.4803  Mult_acc_7: 0.3755  MAE: 0.7791  Corr: 0.7787  Loss: 1.0877 
2021-02-02 20:03:35:INFO:TRAIN-(misa) (1/7/3)>> loss: 0.7784  Has0_acc_2: 0.9377  Has0_F1_score: 0.9376  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7259  Mult_acc_7: 0.6682  MAE: 0.3080  Corr: 0.9667 
2021-02-02 20:03:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8245  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.5022  Mult_acc_7: 0.3886  MAE: 0.7608  Corr: 0.7787  Loss: 1.0606 
2021-02-02 20:03:47:INFO:TRAIN-(misa) (1/8/3)>> loss: 0.6673  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9586  Non0_F1_score: 0.9586  Mult_acc_5: 0.7555  Mult_acc_7: 0.7009  MAE: 0.2947  Corr: 0.9695 
2021-02-02 20:03:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8194  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5284  Mult_acc_7: 0.4061  MAE: 0.7718  Corr: 0.7797  Loss: 1.1138 
2021-02-02 20:03:57:INFO:TRAIN-(misa) (2/9/3)>> loss: 0.5377  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9651  Non0_F1_score: 0.9650  Mult_acc_5: 0.8014  Mult_acc_7: 0.7516  MAE: 0.2498  Corr: 0.9784 
2021-02-02 20:03:58:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8293  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.4847  Mult_acc_7: 0.3755  MAE: 0.7704  Corr: 0.7776  Loss: 1.2413 
2021-02-02 20:04:07:INFO:TRAIN-(misa) (3/10/3)>> loss: 0.4954  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7967  Mult_acc_7: 0.7539  MAE: 0.2518  Corr: 0.9770 
2021-02-02 20:04:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8150  Non0_acc_2: 0.8472  Non0_F1_score: 0.8468  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.7822  Corr: 0.7768  Loss: 1.1479 
2021-02-02 20:04:18:INFO:TRAIN-(misa) (4/11/3)>> loss: 0.4624  Has0_acc_2: 0.9369  Has0_F1_score: 0.9367  Non0_acc_2: 0.9618  Non0_F1_score: 0.9618  Mult_acc_5: 0.7656  Mult_acc_7: 0.7235  MAE: 0.2680  Corr: 0.9748 
2021-02-02 20:04:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8166  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.4978  Mult_acc_7: 0.3930  MAE: 0.7684  Corr: 0.7824  Loss: 1.1253 
2021-02-02 20:04:28:INFO:TRAIN-(misa) (5/12/3)>> loss: 0.4293  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7889  Mult_acc_7: 0.7407  MAE: 0.2697  Corr: 0.9748 
2021-02-02 20:04:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8519  Non0_F1_score: 0.8519  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7711  Corr: 0.7772  Loss: 1.1681 
2021-02-02 20:04:38:INFO:TRAIN-(misa) (6/13/3)>> loss: 0.4364  Has0_acc_2: 0.9385  Has0_F1_score: 0.9383  Non0_acc_2: 0.9553  Non0_F1_score: 0.9553  Mult_acc_5: 0.7531  Mult_acc_7: 0.7002  MAE: 0.3010  Corr: 0.9679 
2021-02-02 20:04:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8153  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7767  Corr: 0.7756  Loss: 1.2321 
2021-02-02 20:04:48:INFO:TRAIN-(misa) (7/14/3)>> loss: 0.4027  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7438  Mult_acc_7: 0.7002  MAE: 0.2825  Corr: 0.9717 
2021-02-02 20:04:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8240  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.4978  Mult_acc_7: 0.3974  MAE: 0.7723  Corr: 0.7810  Loss: 1.1260 
2021-02-02 20:04:58:INFO:TRAIN-(misa) (8/15/3)>> loss: 0.3526  Has0_acc_2: 0.9416  Has0_F1_score: 0.9414  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7936  Mult_acc_7: 0.7562  MAE: 0.2469  Corr: 0.9783 
2021-02-02 20:04:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8519  Non0_F1_score: 0.8523  Mult_acc_5: 0.5022  Mult_acc_7: 0.4061  MAE: 0.7453  Corr: 0.7856  Loss: 1.0934 
2021-02-02 20:05:00:INFO:TEST-(misa) >>  Has0_acc_2: 0.8207  Has0_F1_score: 0.8208  Non0_acc_2: 0.8384  Non0_F1_score: 0.8380  Mult_acc_5: 0.4475  Mult_acc_7: 0.3848  MAE: 0.7919  Corr: 0.7708  Loss: 1.1107 
2021-02-02 20:05:06:INFO:Start running misa...
2021-02-02 20:05:06:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [2], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1114}>
2021-02-02 20:05:06:INFO:Let's use 1 GPUs!
2021-02-02 20:05:06:INFO:train samples: (1284,)
2021-02-02 20:05:06:INFO:valid samples: (229,)
2021-02-02 20:05:07:INFO:test samples: (686,)
2021-02-02 20:05:07:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 20:05:07:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 20:05:07:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 20:05:07:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 20:05:07:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 20:05:07:INFO:loading file None
2021-02-02 20:05:07:INFO:loading file None
2021-02-02 20:05:07:INFO:loading file None
2021-02-02 20:05:07:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 20:05:07:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 20:05:07:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 20:05:10:INFO:The model has 110620273 trainable parameters
2021-02-02 20:05:19:INFO:TRAIN-(misa) (1/1/4)>> loss: 4.4554  Has0_acc_2: 0.6106  Has0_F1_score: 0.6492  Non0_acc_2: 0.6068  Non0_F1_score: 0.6475  Mult_acc_5: 0.2025  Mult_acc_7: 0.2025  MAE: 1.2687  Corr: 0.2390 
2021-02-02 20:05:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7821  Non0_acc_2: 0.7917  Non0_F1_score: 0.7977  Mult_acc_5: 0.2795  Mult_acc_7: 0.2795  MAE: 1.1778  Corr: 0.6244  Loss: 1.9269 
2021-02-02 20:05:31:INFO:TRAIN-(misa) (1/2/4)>> loss: 3.3203  Has0_acc_2: 0.7866  Has0_F1_score: 0.7856  Non0_acc_2: 0.8026  Non0_F1_score: 0.8021  Mult_acc_5: 0.2897  Mult_acc_7: 0.2866  MAE: 0.9356  Corr: 0.6769 
2021-02-02 20:05:32:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8116  Non0_acc_2: 0.8009  Non0_F1_score: 0.8091  Mult_acc_5: 0.3974  Mult_acc_7: 0.3144  MAE: 1.0071  Corr: 0.7441  Loss: 1.6410 
2021-02-02 20:05:43:INFO:TRAIN-(misa) (1/3/4)>> loss: 2.5220  Has0_acc_2: 0.8255  Has0_F1_score: 0.8255  Non0_acc_2: 0.8408  Non0_F1_score: 0.8412  Mult_acc_5: 0.4034  Mult_acc_7: 0.3769  MAE: 0.7427  Corr: 0.7877 
2021-02-02 20:05:43:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8472  Non0_F1_score: 0.8485  Mult_acc_5: 0.4891  Mult_acc_7: 0.3974  MAE: 0.8021  Corr: 0.7696  Loss: 1.1500 
2021-02-02 20:05:54:INFO:TRAIN-(misa) (1/4/4)>> loss: 1.8036  Has0_acc_2: 0.8925  Has0_F1_score: 0.8922  Non0_acc_2: 0.9106  Non0_F1_score: 0.9106  Mult_acc_5: 0.5600  Mult_acc_7: 0.5195  MAE: 0.5472  Corr: 0.8890 
2021-02-02 20:05:55:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7974  Non0_acc_2: 0.8287  Non0_F1_score: 0.8282  Mult_acc_5: 0.5109  Mult_acc_7: 0.4061  MAE: 0.7887  Corr: 0.7668  Loss: 1.1682 
2021-02-02 20:06:04:INFO:TRAIN-(misa) (2/5/4)>> loss: 1.4080  Has0_acc_2: 0.9050  Has0_F1_score: 0.9046  Non0_acc_2: 0.9253  Non0_F1_score: 0.9251  Mult_acc_5: 0.6488  Mult_acc_7: 0.6005  MAE: 0.4447  Corr: 0.9255 
2021-02-02 20:06:05:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8025  Non0_acc_2: 0.8194  Non0_F1_score: 0.8193  Mult_acc_5: 0.4847  Mult_acc_7: 0.3799  MAE: 0.7831  Corr: 0.7613  Loss: 1.1410 
2021-02-02 20:06:16:INFO:TRAIN-(misa) (1/6/4)>> loss: 1.0852  Has0_acc_2: 0.9354  Has0_F1_score: 0.9353  Non0_acc_2: 0.9504  Non0_F1_score: 0.9505  Mult_acc_5: 0.7072  Mult_acc_7: 0.6503  MAE: 0.3627  Corr: 0.9523 
2021-02-02 20:06:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7847  Non0_acc_2: 0.8056  Non0_F1_score: 0.8053  Mult_acc_5: 0.5022  Mult_acc_7: 0.4017  MAE: 0.7705  Corr: 0.7712  Loss: 1.1822 
2021-02-02 20:06:26:INFO:TRAIN-(misa) (2/7/4)>> loss: 0.8456  Has0_acc_2: 0.9369  Has0_F1_score: 0.9368  Non0_acc_2: 0.9545  Non0_F1_score: 0.9545  Mult_acc_5: 0.7329  Mult_acc_7: 0.6783  MAE: 0.3214  Corr: 0.9633 
2021-02-02 20:06:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8062  Non0_acc_2: 0.8287  Non0_F1_score: 0.8281  Mult_acc_5: 0.5328  Mult_acc_7: 0.4148  MAE: 0.7602  Corr: 0.7777  Loss: 1.1223 
2021-02-02 20:06:37:INFO:TRAIN-(misa) (1/8/4)>> loss: 0.6864  Has0_acc_2: 0.9463  Has0_F1_score: 0.9462  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.7430  Mult_acc_7: 0.6963  MAE: 0.2951  Corr: 0.9692 
2021-02-02 20:06:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7973  Non0_acc_2: 0.8241  Non0_F1_score: 0.8233  Mult_acc_5: 0.5109  Mult_acc_7: 0.3886  MAE: 0.7584  Corr: 0.7740  Loss: 1.1894 
2021-02-02 20:06:48:INFO:TRAIN-(misa) (2/9/4)>> loss: 0.5611  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.7998  Mult_acc_7: 0.7368  MAE: 0.2734  Corr: 0.9738 
2021-02-02 20:06:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8072  Non0_acc_2: 0.8287  Non0_F1_score: 0.8291  Mult_acc_5: 0.5284  Mult_acc_7: 0.4148  MAE: 0.7502  Corr: 0.7774  Loss: 1.1207 
2021-02-02 20:06:59:INFO:TRAIN-(misa) (1/10/4)>> loss: 0.5051  Has0_acc_2: 0.9322  Has0_F1_score: 0.9322  Non0_acc_2: 0.9488  Non0_F1_score: 0.9489  Mult_acc_5: 0.7671  Mult_acc_7: 0.7150  MAE: 0.2898  Corr: 0.9705 
2021-02-02 20:07:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.5109  Mult_acc_7: 0.4017  MAE: 0.7625  Corr: 0.7780  Loss: 1.1804 
2021-02-02 20:07:10:INFO:TRAIN-(misa) (2/11/4)>> loss: 0.4303  Has0_acc_2: 0.9517  Has0_F1_score: 0.9516  Non0_acc_2: 0.9683  Non0_F1_score: 0.9683  Mult_acc_5: 0.7889  Mult_acc_7: 0.7438  MAE: 0.2457  Corr: 0.9785 
2021-02-02 20:07:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8065  Non0_acc_2: 0.8287  Non0_F1_score: 0.8284  Mult_acc_5: 0.5197  Mult_acc_7: 0.4105  MAE: 0.7470  Corr: 0.7794  Loss: 1.1604 
2021-02-02 20:07:20:INFO:TRAIN-(misa) (3/12/4)>> loss: 0.4049  Has0_acc_2: 0.9478  Has0_F1_score: 0.9477  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7913  Mult_acc_7: 0.7469  MAE: 0.2584  Corr: 0.9766 
2021-02-02 20:07:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8173  Non0_acc_2: 0.8287  Non0_F1_score: 0.8301  Mult_acc_5: 0.4934  Mult_acc_7: 0.3755  MAE: 0.7943  Corr: 0.7805  Loss: 1.2079 
2021-02-02 20:07:30:INFO:TRAIN-(misa) (4/13/4)>> loss: 0.3798  Has0_acc_2: 0.9502  Has0_F1_score: 0.9500  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7889  Mult_acc_7: 0.7500  MAE: 0.2609  Corr: 0.9765 
2021-02-02 20:07:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8106  Non0_acc_2: 0.8333  Non0_F1_score: 0.8326  Mult_acc_5: 0.5415  Mult_acc_7: 0.4367  MAE: 0.7466  Corr: 0.7825  Loss: 1.1055 
2021-02-02 20:07:42:INFO:TRAIN-(misa) (1/14/4)>> loss: 0.3660  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.8178  Mult_acc_7: 0.7734  MAE: 0.2525  Corr: 0.9780 
2021-02-02 20:07:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.5197  Mult_acc_7: 0.4061  MAE: 0.7647  Corr: 0.7788  Loss: 1.1742 
2021-02-02 20:07:52:INFO:TRAIN-(misa) (2/15/4)>> loss: 0.3338  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.8217  Mult_acc_7: 0.7858  MAE: 0.2303  Corr: 0.9814 
2021-02-02 20:07:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8264  Non0_acc_2: 0.8333  Non0_F1_score: 0.8349  Mult_acc_5: 0.5022  Mult_acc_7: 0.3799  MAE: 0.8159  Corr: 0.7809  Loss: 1.2412 
2021-02-02 20:08:02:INFO:TRAIN-(misa) (3/16/4)>> loss: 0.3230  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9626  Non0_F1_score: 0.9627  Mult_acc_5: 0.7788  Mult_acc_7: 0.7344  MAE: 0.2535  Corr: 0.9773 
2021-02-02 20:08:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7574  Corr: 0.7835  Loss: 1.1244 
2021-02-02 20:08:12:INFO:TRAIN-(misa) (4/17/4)>> loss: 0.2881  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.8255  Mult_acc_7: 0.7882  MAE: 0.2271  Corr: 0.9818 
2021-02-02 20:08:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8115  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5371  Mult_acc_7: 0.4279  MAE: 0.7380  Corr: 0.7852  Loss: 1.0937 
2021-02-02 20:08:23:INFO:TRAIN-(misa) (1/18/4)>> loss: 0.2781  Has0_acc_2: 0.9626  Has0_F1_score: 0.9625  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8037  Mult_acc_7: 0.7718  MAE: 0.2201  Corr: 0.9828 
2021-02-02 20:08:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8124  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.5109  Mult_acc_7: 0.4061  MAE: 0.7429  Corr: 0.7883  Loss: 1.1186 
2021-02-02 20:08:33:INFO:TRAIN-(misa) (2/19/4)>> loss: 0.2874  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7850  Mult_acc_7: 0.7562  MAE: 0.2541  Corr: 0.9771 
2021-02-02 20:08:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8248  Non0_acc_2: 0.8426  Non0_F1_score: 0.8428  Mult_acc_5: 0.5459  Mult_acc_7: 0.4454  MAE: 0.7322  Corr: 0.7867  Loss: 1.1649 
2021-02-02 20:08:43:INFO:TRAIN-(misa) (3/20/4)>> loss: 0.3102  Has0_acc_2: 0.9400  Has0_F1_score: 0.9399  Non0_acc_2: 0.9602  Non0_F1_score: 0.9602  Mult_acc_5: 0.7500  Mult_acc_7: 0.7056  MAE: 0.2911  Corr: 0.9716 
2021-02-02 20:08:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7465  Corr: 0.7787  Loss: 1.0531 
2021-02-02 20:08:55:INFO:TRAIN-(misa) (1/21/4)>> loss: 0.2747  Has0_acc_2: 0.9463  Has0_F1_score: 0.9463  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.7718  Mult_acc_7: 0.7251  MAE: 0.2539  Corr: 0.9775 
2021-02-02 20:08:56:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8380  Non0_F1_score: 0.8379  Mult_acc_5: 0.5284  Mult_acc_7: 0.4279  MAE: 0.7297  Corr: 0.7843  Loss: 1.0575 
2021-02-02 20:09:05:INFO:TRAIN-(misa) (2/22/4)>> loss: 0.2635  Has0_acc_2: 0.9463  Has0_F1_score: 0.9461  Non0_acc_2: 0.9691  Non0_F1_score: 0.9691  Mult_acc_5: 0.7874  Mult_acc_7: 0.7555  MAE: 0.2401  Corr: 0.9798 
2021-02-02 20:09:06:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8355  Non0_acc_2: 0.8426  Non0_F1_score: 0.8445  Mult_acc_5: 0.5240  Mult_acc_7: 0.4148  MAE: 0.7825  Corr: 0.7895  Loss: 1.1994 
2021-02-02 20:09:15:INFO:TRAIN-(misa) (3/23/4)>> loss: 0.2945  Has0_acc_2: 0.9431  Has0_F1_score: 0.9430  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7648  Mult_acc_7: 0.7173  MAE: 0.2883  Corr: 0.9722 
2021-02-02 20:09:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8104  Non0_acc_2: 0.8472  Non0_F1_score: 0.8465  Mult_acc_5: 0.5284  Mult_acc_7: 0.4410  MAE: 0.7525  Corr: 0.7908  Loss: 1.0339 
2021-02-02 20:09:27:INFO:TRAIN-(misa) (1/24/4)>> loss: 0.2596  Has0_acc_2: 0.9408  Has0_F1_score: 0.9406  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7913  Mult_acc_7: 0.7555  MAE: 0.2487  Corr: 0.9783 
2021-02-02 20:09:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8287  Non0_F1_score: 0.8297  Mult_acc_5: 0.5371  Mult_acc_7: 0.4323  MAE: 0.7318  Corr: 0.7939  Loss: 1.0549 
2021-02-02 20:09:37:INFO:TRAIN-(misa) (2/25/4)>> loss: 0.2250  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.8380  Mult_acc_7: 0.8084  MAE: 0.2154  Corr: 0.9837 
2021-02-02 20:09:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8243  Non0_acc_2: 0.8472  Non0_F1_score: 0.8471  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7177  Corr: 0.7906  Loss: 1.0244 
2021-02-02 20:09:48:INFO:TRAIN-(misa) (1/26/4)>> loss: 0.2196  Has0_acc_2: 0.9463  Has0_F1_score: 0.9462  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.8146  Mult_acc_7: 0.7773  MAE: 0.2228  Corr: 0.9829 
2021-02-02 20:09:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8198  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5590  Mult_acc_7: 0.4541  MAE: 0.7175  Corr: 0.7944  Loss: 1.0305 
2021-02-02 20:09:58:INFO:TRAIN-(misa) (2/27/4)>> loss: 0.2283  Has0_acc_2: 0.9540  Has0_F1_score: 0.9539  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8162  Mult_acc_7: 0.7921  MAE: 0.2209  Corr: 0.9833 
2021-02-02 20:09:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8290  Non0_acc_2: 0.8519  Non0_F1_score: 0.8521  Mult_acc_5: 0.5546  Mult_acc_7: 0.4454  MAE: 0.7043  Corr: 0.7980  Loss: 0.9951 
2021-02-02 20:10:09:INFO:TRAIN-(misa) (1/28/4)>> loss: 0.2096  Has0_acc_2: 0.9556  Has0_F1_score: 0.9556  Non0_acc_2: 0.9699  Non0_F1_score: 0.9700  Mult_acc_5: 0.8310  Mult_acc_7: 0.7921  MAE: 0.2152  Corr: 0.9838 
2021-02-02 20:10:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8380  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5371  Mult_acc_7: 0.4367  MAE: 0.7261  Corr: 0.7954  Loss: 1.0146 
2021-02-02 20:10:19:INFO:TRAIN-(misa) (2/29/4)>> loss: 0.2432  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9643  Non0_F1_score: 0.9643  Mult_acc_5: 0.7998  Mult_acc_7: 0.7601  MAE: 0.2570  Corr: 0.9774 
2021-02-02 20:10:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8238  Non0_acc_2: 0.8565  Non0_F1_score: 0.8559  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7413  Corr: 0.7968  Loss: 1.0961 
2021-02-02 20:10:29:INFO:TRAIN-(misa) (3/30/4)>> loss: 0.2268  Has0_acc_2: 0.9424  Has0_F1_score: 0.9422  Non0_acc_2: 0.9651  Non0_F1_score: 0.9651  Mult_acc_5: 0.8069  Mult_acc_7: 0.7757  MAE: 0.2507  Corr: 0.9788 
2021-02-02 20:10:30:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8305  Non0_acc_2: 0.8426  Non0_F1_score: 0.8441  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7159  Corr: 0.8000  Loss: 1.0798 
2021-02-02 20:10:39:INFO:TRAIN-(misa) (4/31/4)>> loss: 0.2113  Has0_acc_2: 0.9626  Has0_F1_score: 0.9626  Non0_acc_2: 0.9773  Non0_F1_score: 0.9773  Mult_acc_5: 0.8092  Mult_acc_7: 0.7640  MAE: 0.2209  Corr: 0.9833 
2021-02-02 20:10:40:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8237  Non0_acc_2: 0.8565  Non0_F1_score: 0.8558  Mult_acc_5: 0.5284  Mult_acc_7: 0.4454  MAE: 0.7329  Corr: 0.7948  Loss: 1.0552 
2021-02-02 20:10:50:INFO:TRAIN-(misa) (5/32/4)>> loss: 0.2050  Has0_acc_2: 0.9470  Has0_F1_score: 0.9469  Non0_acc_2: 0.9659  Non0_F1_score: 0.9659  Mult_acc_5: 0.8030  Mult_acc_7: 0.7640  MAE: 0.2278  Corr: 0.9821 
2021-02-02 20:10:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7271  Corr: 0.7949  Loss: 1.0484 
2021-02-02 20:11:00:INFO:TRAIN-(misa) (6/33/4)>> loss: 0.2037  Has0_acc_2: 0.9595  Has0_F1_score: 0.9594  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.7983  Mult_acc_7: 0.7547  MAE: 0.2293  Corr: 0.9820 
2021-02-02 20:11:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8257  Non0_acc_2: 0.8380  Non0_F1_score: 0.8389  Mult_acc_5: 0.5153  Mult_acc_7: 0.4105  MAE: 0.7283  Corr: 0.7949  Loss: 1.0647 
2021-02-02 20:11:10:INFO:TRAIN-(misa) (7/34/4)>> loss: 0.1808  Has0_acc_2: 0.9540  Has0_F1_score: 0.9540  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8458  Mult_acc_7: 0.8076  MAE: 0.1935  Corr: 0.9868 
2021-02-02 20:11:10:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8118  Non0_acc_2: 0.8333  Non0_F1_score: 0.8339  Mult_acc_5: 0.5502  Mult_acc_7: 0.4454  MAE: 0.7161  Corr: 0.7972  Loss: 1.0501 
2021-02-02 20:11:20:INFO:TRAIN-(misa) (8/35/4)>> loss: 0.1702  Has0_acc_2: 0.9618  Has0_F1_score: 0.9617  Non0_acc_2: 0.9805  Non0_F1_score: 0.9805  Mult_acc_5: 0.8629  Mult_acc_7: 0.8310  MAE: 0.1868  Corr: 0.9876 
2021-02-02 20:11:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8378  Non0_acc_2: 0.8565  Non0_F1_score: 0.8566  Mult_acc_5: 0.5415  Mult_acc_7: 0.4323  MAE: 0.7065  Corr: 0.7986  Loss: 1.0401 
2021-02-02 20:11:22:INFO:TEST-(misa) >>  Has0_acc_2: 0.8105  Has0_F1_score: 0.8109  Non0_acc_2: 0.8293  Non0_F1_score: 0.8290  Mult_acc_5: 0.5058  Mult_acc_7: 0.4402  MAE: 0.7470  Corr: 0.7822  Loss: 1.0374 
2021-02-02 20:11:27:INFO:Start running misa...
2021-02-02 20:11:27:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [2], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1115}>
2021-02-02 20:11:27:INFO:Let's use 1 GPUs!
2021-02-02 20:11:28:INFO:train samples: (1284,)
2021-02-02 20:11:28:INFO:valid samples: (229,)
2021-02-02 20:11:28:INFO:test samples: (686,)
2021-02-02 20:11:28:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-02 20:11:28:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-02 20:11:28:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-02 20:11:28:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-02 20:11:28:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-02 20:11:28:INFO:loading file None
2021-02-02 20:11:28:INFO:loading file None
2021-02-02 20:11:28:INFO:loading file None
2021-02-02 20:11:28:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-02 20:11:28:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-02 20:11:28:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-02 20:11:31:INFO:The model has 110620273 trainable parameters
2021-02-02 20:11:41:INFO:TRAIN-(misa) (1/1/5)>> loss: 4.2554  Has0_acc_2: 0.5942  Has0_F1_score: 0.6268  Non0_acc_2: 0.5865  Non0_F1_score: 0.6203  Mult_acc_5: 0.2017  Mult_acc_7: 0.2017  MAE: 1.2703  Corr: 0.2392 
2021-02-02 20:11:41:INFO:VAL-(misa) >>  Has0_acc_2: 0.7249  Has0_F1_score: 0.7447  Non0_acc_2: 0.7176  Non0_F1_score: 0.7380  Mult_acc_5: 0.2620  Mult_acc_7: 0.2620  MAE: 1.1505  Corr: 0.6618  Loss: 2.0227 
2021-02-02 20:11:52:INFO:TRAIN-(misa) (1/2/5)>> loss: 2.9438  Has0_acc_2: 0.8100  Has0_F1_score: 0.8096  Non0_acc_2: 0.8245  Non0_F1_score: 0.8247  Mult_acc_5: 0.3255  Mult_acc_7: 0.3201  MAE: 0.8829  Corr: 0.7109 
2021-02-02 20:11:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7798  Non0_acc_2: 0.8148  Non0_F1_score: 0.8139  Mult_acc_5: 0.3493  Mult_acc_7: 0.2926  MAE: 0.9420  Corr: 0.7221  Loss: 1.3837 
2021-02-02 20:12:03:INFO:TRAIN-(misa) (1/3/5)>> loss: 2.0892  Has0_acc_2: 0.8692  Has0_F1_score: 0.8686  Non0_acc_2: 0.8838  Non0_F1_score: 0.8836  Mult_acc_5: 0.4821  Mult_acc_7: 0.4455  MAE: 0.6331  Corr: 0.8430 
2021-02-02 20:12:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8016  Non0_acc_2: 0.8333  Non0_F1_score: 0.8325  Mult_acc_5: 0.4541  Mult_acc_7: 0.3755  MAE: 0.8325  Corr: 0.7566  Loss: 1.2489 
2021-02-02 20:12:15:INFO:TRAIN-(misa) (1/4/5)>> loss: 1.6215  Has0_acc_2: 0.8995  Has0_F1_score: 0.8991  Non0_acc_2: 0.9196  Non0_F1_score: 0.9194  Mult_acc_5: 0.5732  Mult_acc_7: 0.5265  MAE: 0.5160  Corr: 0.8999 
2021-02-02 20:12:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.8019  Non0_acc_2: 0.8056  Non0_F1_score: 0.8089  Mult_acc_5: 0.4760  Mult_acc_7: 0.3930  MAE: 0.8263  Corr: 0.7473  Loss: 1.3167 
2021-02-02 20:12:25:INFO:TRAIN-(misa) (2/5/5)>> loss: 1.2712  Has0_acc_2: 0.9315  Has0_F1_score: 0.9313  Non0_acc_2: 0.9456  Non0_F1_score: 0.9456  Mult_acc_5: 0.6449  Mult_acc_7: 0.5919  MAE: 0.4157  Corr: 0.9357 
2021-02-02 20:12:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7797  Non0_acc_2: 0.8148  Non0_F1_score: 0.8138  Mult_acc_5: 0.3799  Mult_acc_7: 0.3188  MAE: 0.8637  Corr: 0.7455  Loss: 1.2962 
2021-02-02 20:12:35:INFO:TRAIN-(misa) (3/6/5)>> loss: 1.0419  Has0_acc_2: 0.9182  Has0_F1_score: 0.9180  Non0_acc_2: 0.9374  Non0_F1_score: 0.9374  Mult_acc_5: 0.6931  Mult_acc_7: 0.6324  MAE: 0.3812  Corr: 0.9466 
2021-02-02 20:12:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8086  Non0_acc_2: 0.8194  Non0_F1_score: 0.8209  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.7921  Corr: 0.7651  Loss: 1.1176 
2021-02-02 20:12:46:INFO:TRAIN-(misa) (1/7/5)>> loss: 0.8459  Has0_acc_2: 0.9361  Has0_F1_score: 0.9360  Non0_acc_2: 0.9578  Non0_F1_score: 0.9578  Mult_acc_5: 0.7251  Mult_acc_7: 0.6721  MAE: 0.3248  Corr: 0.9619 
2021-02-02 20:12:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.8194  Non0_F1_score: 0.8202  Mult_acc_5: 0.4672  Mult_acc_7: 0.3755  MAE: 0.7951  Corr: 0.7593  Loss: 1.1650 
2021-02-02 20:12:57:INFO:TRAIN-(misa) (2/8/5)>> loss: 0.7196  Has0_acc_2: 0.9463  Has0_F1_score: 0.9462  Non0_acc_2: 0.9626  Non0_F1_score: 0.9626  Mult_acc_5: 0.7625  Mult_acc_7: 0.7056  MAE: 0.3037  Corr: 0.9675 
2021-02-02 20:12:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7973  Non0_acc_2: 0.8241  Non0_F1_score: 0.8233  Mult_acc_5: 0.4585  Mult_acc_7: 0.3755  MAE: 0.8026  Corr: 0.7643  Loss: 1.1466 
2021-02-02 20:13:07:INFO:TRAIN-(misa) (3/9/5)>> loss: 0.6088  Has0_acc_2: 0.9509  Has0_F1_score: 0.9509  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7819  Mult_acc_7: 0.7329  MAE: 0.2654  Corr: 0.9759 
2021-02-02 20:13:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.7991  Non0_acc_2: 0.8102  Non0_F1_score: 0.8110  Mult_acc_5: 0.4847  Mult_acc_7: 0.3886  MAE: 0.7909  Corr: 0.7657  Loss: 1.1753 
2021-02-02 20:13:17:INFO:TRAIN-(misa) (4/10/5)>> loss: 0.5408  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.7975  Mult_acc_7: 0.7547  MAE: 0.2331  Corr: 0.9803 
2021-02-02 20:13:18:INFO:VAL-(misa) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8110  Non0_acc_2: 0.8333  Non0_F1_score: 0.8331  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7839  Corr: 0.7648  Loss: 1.1898 
2021-02-02 20:13:27:INFO:TRAIN-(misa) (5/11/5)>> loss: 0.4810  Has0_acc_2: 0.9548  Has0_F1_score: 0.9547  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8357  Mult_acc_7: 0.7952  MAE: 0.2244  Corr: 0.9822 
2021-02-02 20:13:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8163  Non0_acc_2: 0.8241  Non0_F1_score: 0.8243  Mult_acc_5: 0.5109  Mult_acc_7: 0.4105  MAE: 0.7672  Corr: 0.7736  Loss: 1.0897 
2021-02-02 20:13:39:INFO:TRAIN-(misa) (1/12/5)>> loss: 0.4227  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9781  Non0_F1_score: 0.9781  Mult_acc_5: 0.8115  Mult_acc_7: 0.7741  MAE: 0.2217  Corr: 0.9834 
2021-02-02 20:13:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8166  Non0_acc_2: 0.8241  Non0_F1_score: 0.8246  Mult_acc_5: 0.5153  Mult_acc_7: 0.4061  MAE: 0.7658  Corr: 0.7772  Loss: 1.0467 
2021-02-02 20:13:50:INFO:TRAIN-(misa) (1/13/5)>> loss: 0.4094  Has0_acc_2: 0.9502  Has0_F1_score: 0.9501  Non0_acc_2: 0.9667  Non0_F1_score: 0.9667  Mult_acc_5: 0.7975  Mult_acc_7: 0.7555  MAE: 0.2362  Corr: 0.9801 
2021-02-02 20:13:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8239  Non0_acc_2: 0.8472  Non0_F1_score: 0.8466  Mult_acc_5: 0.4978  Mult_acc_7: 0.4061  MAE: 0.7725  Corr: 0.7740  Loss: 1.1263 
2021-02-02 20:14:00:INFO:TRAIN-(misa) (2/14/5)>> loss: 0.3941  Has0_acc_2: 0.9509  Has0_F1_score: 0.9508  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.7780  Mult_acc_7: 0.7430  MAE: 0.2433  Corr: 0.9791 
2021-02-02 20:14:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8041  Non0_acc_2: 0.8148  Non0_F1_score: 0.8161  Mult_acc_5: 0.4934  Mult_acc_7: 0.4017  MAE: 0.7758  Corr: 0.7743  Loss: 1.1134 
2021-02-02 20:14:11:INFO:TRAIN-(misa) (3/15/5)>> loss: 0.3673  Has0_acc_2: 0.9572  Has0_F1_score: 0.9571  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8030  Mult_acc_7: 0.7570  MAE: 0.2434  Corr: 0.9790 
2021-02-02 20:14:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8022  Non0_acc_2: 0.8241  Non0_F1_score: 0.8238  Mult_acc_5: 0.5197  Mult_acc_7: 0.4192  MAE: 0.7625  Corr: 0.7809  Loss: 1.1332 
2021-02-02 20:14:21:INFO:TRAIN-(misa) (4/16/5)>> loss: 0.3405  Has0_acc_2: 0.9564  Has0_F1_score: 0.9563  Non0_acc_2: 0.9732  Non0_F1_score: 0.9732  Mult_acc_5: 0.8442  Mult_acc_7: 0.8037  MAE: 0.2187  Corr: 0.9832 
2021-02-02 20:14:21:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8072  Non0_acc_2: 0.8241  Non0_F1_score: 0.8243  Mult_acc_5: 0.5328  Mult_acc_7: 0.4498  MAE: 0.7464  Corr: 0.7835  Loss: 1.0771 
2021-02-02 20:14:31:INFO:TRAIN-(misa) (5/17/5)>> loss: 0.3293  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.7967  Mult_acc_7: 0.7570  MAE: 0.2455  Corr: 0.9790 
2021-02-02 20:14:31:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8070  Non0_acc_2: 0.8287  Non0_F1_score: 0.8288  Mult_acc_5: 0.5240  Mult_acc_7: 0.4410  MAE: 0.7455  Corr: 0.7837  Loss: 1.1071 
2021-02-02 20:14:41:INFO:TRAIN-(misa) (6/18/5)>> loss: 0.2966  Has0_acc_2: 0.9486  Has0_F1_score: 0.9484  Non0_acc_2: 0.9724  Non0_F1_score: 0.9724  Mult_acc_5: 0.8232  Mult_acc_7: 0.7835  MAE: 0.2171  Corr: 0.9836 
2021-02-02 20:14:42:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8314  Non0_acc_2: 0.8333  Non0_F1_score: 0.8353  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7663  Corr: 0.7899  Loss: 1.1656 
2021-02-02 20:14:51:INFO:TRAIN-(misa) (7/19/5)>> loss: 0.3068  Has0_acc_2: 0.9533  Has0_F1_score: 0.9532  Non0_acc_2: 0.9716  Non0_F1_score: 0.9716  Mult_acc_5: 0.7702  Mult_acc_7: 0.7290  MAE: 0.2536  Corr: 0.9778 
2021-02-02 20:14:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8215  Non0_acc_2: 0.8333  Non0_F1_score: 0.8345  Mult_acc_5: 0.4978  Mult_acc_7: 0.4192  MAE: 0.7403  Corr: 0.7887  Loss: 1.0063 
2021-02-02 20:15:03:INFO:TRAIN-(misa) (1/20/5)>> loss: 0.3050  Has0_acc_2: 0.9447  Has0_F1_score: 0.9446  Non0_acc_2: 0.9634  Non0_F1_score: 0.9635  Mult_acc_5: 0.8022  Mult_acc_7: 0.7648  MAE: 0.2488  Corr: 0.9781 
2021-02-02 20:15:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8215  Non0_acc_2: 0.8380  Non0_F1_score: 0.8393  Mult_acc_5: 0.4978  Mult_acc_7: 0.4017  MAE: 0.7430  Corr: 0.7879  Loss: 1.0716 
2021-02-02 20:15:13:INFO:TRAIN-(misa) (2/21/5)>> loss: 0.2661  Has0_acc_2: 0.9494  Has0_F1_score: 0.9493  Non0_acc_2: 0.9675  Non0_F1_score: 0.9675  Mult_acc_5: 0.8014  Mult_acc_7: 0.7679  MAE: 0.2225  Corr: 0.9828 
2021-02-02 20:15:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8155  Non0_acc_2: 0.8426  Non0_F1_score: 0.8426  Mult_acc_5: 0.5502  Mult_acc_7: 0.4629  MAE: 0.7252  Corr: 0.7886  Loss: 1.1090 
2021-02-02 20:15:23:INFO:TRAIN-(misa) (3/22/5)>> loss: 0.2405  Has0_acc_2: 0.9579  Has0_F1_score: 0.9578  Non0_acc_2: 0.9748  Non0_F1_score: 0.9748  Mult_acc_5: 0.8310  Mult_acc_7: 0.7967  MAE: 0.2000  Corr: 0.9862 
2021-02-02 20:15:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8331  Non0_acc_2: 0.8565  Non0_F1_score: 0.8564  Mult_acc_5: 0.5415  Mult_acc_7: 0.4541  MAE: 0.7292  Corr: 0.7872  Loss: 1.0348 
2021-02-02 20:15:33:INFO:TRAIN-(misa) (4/23/5)>> loss: 0.2284  Has0_acc_2: 0.9556  Has0_F1_score: 0.9555  Non0_acc_2: 0.9764  Non0_F1_score: 0.9765  Mult_acc_5: 0.8388  Mult_acc_7: 0.8100  MAE: 0.1928  Corr: 0.9871 
2021-02-02 20:15:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8283  Non0_acc_2: 0.8519  Non0_F1_score: 0.8513  Mult_acc_5: 0.5197  Mult_acc_7: 0.4323  MAE: 0.7403  Corr: 0.7859  Loss: 1.0774 
2021-02-02 20:15:43:INFO:TRAIN-(misa) (5/24/5)>> loss: 0.2269  Has0_acc_2: 0.9634  Has0_F1_score: 0.9633  Non0_acc_2: 0.9854  Non0_F1_score: 0.9854  Mult_acc_5: 0.8271  Mult_acc_7: 0.7960  MAE: 0.1986  Corr: 0.9861 
2021-02-02 20:15:44:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8285  Non0_acc_2: 0.8519  Non0_F1_score: 0.8515  Mult_acc_5: 0.5371  Mult_acc_7: 0.4454  MAE: 0.7330  Corr: 0.7896  Loss: 1.0212 
2021-02-02 20:15:53:INFO:TRAIN-(misa) (6/25/5)>> loss: 0.2191  Has0_acc_2: 0.9603  Has0_F1_score: 0.9602  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8419  Mult_acc_7: 0.8123  MAE: 0.1979  Corr: 0.9865 
2021-02-02 20:15:54:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.8380  Non0_F1_score: 0.8383  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7336  Corr: 0.7905  Loss: 1.0483 
2021-02-02 20:16:03:INFO:TRAIN-(misa) (7/26/5)>> loss: 0.2056  Has0_acc_2: 0.9611  Has0_F1_score: 0.9610  Non0_acc_2: 0.9813  Non0_F1_score: 0.9813  Mult_acc_5: 0.8403  Mult_acc_7: 0.8115  MAE: 0.1789  Corr: 0.9888 
2021-02-02 20:16:04:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8152  Non0_acc_2: 0.8426  Non0_F1_score: 0.8422  Mult_acc_5: 0.5371  Mult_acc_7: 0.4585  MAE: 0.7326  Corr: 0.7893  Loss: 1.0128 
2021-02-02 20:16:13:INFO:TRAIN-(misa) (8/27/5)>> loss: 0.2153  Has0_acc_2: 0.9564  Has0_F1_score: 0.9562  Non0_acc_2: 0.9740  Non0_F1_score: 0.9740  Mult_acc_5: 0.8380  Mult_acc_7: 0.8061  MAE: 0.1998  Corr: 0.9859 
2021-02-02 20:16:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8278  Non0_acc_2: 0.8287  Non0_F1_score: 0.8314  Mult_acc_5: 0.5066  Mult_acc_7: 0.4061  MAE: 0.7850  Corr: 0.7891  Loss: 1.1694 
2021-02-02 20:16:16:INFO:TEST-(misa) >>  Has0_acc_2: 0.8178  Has0_F1_score: 0.8173  Non0_acc_2: 0.8232  Non0_F1_score: 0.8221  Mult_acc_5: 0.4388  Mult_acc_7: 0.3848  MAE: 0.8253  Corr: 0.7733  Loss: 1.1875 
2021-02-02 20:16:21:INFO:Results are added to results/results/normals/mosi-regression.csv...
2021-02-05 12:36:58:INFO:Start running misa...
2021-02-05 12:36:58:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1111}>
2021-02-05 12:36:58:INFO:Find gpu: 0, with memory: 2613903360 left!
2021-02-05 12:36:58:INFO:Let's use 1 GPUs!
2021-02-05 12:36:59:INFO:train samples: (1284,)
2021-02-05 12:36:59:INFO:valid samples: (229,)
2021-02-05 12:37:00:INFO:test samples: (686,)
2021-02-05 12:37:00:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-05 12:37:00:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-05 12:37:00:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-05 12:37:00:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-05 12:37:00:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-05 12:37:00:INFO:loading file None
2021-02-05 12:37:00:INFO:loading file None
2021-02-05 12:37:00:INFO:loading file None
2021-02-05 12:37:00:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-05 12:37:00:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-05 12:37:00:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-05 12:37:03:INFO:The model has 110621043 trainable parameters
2021-02-05 12:37:13:INFO:TRAIN-(misa) (1/1/1)>> loss: 2.8953  Has0_acc_2: 0.5296  Has0_F1_score: 0.5573  Non0_acc_2: 0.1284  Non0_F1_score: 0.0955  Acc_3: 0.5202  F1_score_3: 0.5557 
2021-02-05 12:37:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.5895  Has0_F1_score: 0.6540  Non0_acc_2: 0.0926  Non0_F1_score: 0.0455  Acc_3: 0.5852  F1_score_3: 0.6562  Loss: 0.8558 
2021-02-05 12:37:26:INFO:TRAIN-(misa) (1/2/1)>> loss: 2.3300  Has0_acc_2: 0.6760  Has0_F1_score: 0.6863  Non0_acc_2: 0.2315  Non0_F1_score: 0.1940  Acc_3: 0.6628  F1_score_3: 0.6854 
2021-02-05 12:37:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.7817  Has0_F1_score: 0.7855  Non0_acc_2: 0.2917  Non0_F1_score: 0.2658  Acc_3: 0.7555  F1_score_3: 0.7804  Loss: 0.7312 
2021-02-05 12:37:38:INFO:TRAIN-(misa) (1/3/1)>> loss: 1.8518  Has0_acc_2: 0.8559  Has0_F1_score: 0.8564  Non0_acc_2: 0.3721  Non0_F1_score: 0.3634  Acc_3: 0.8318  F1_score_3: 0.8496 
2021-02-05 12:37:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8303  Non0_acc_2: 0.3333  Non0_F1_score: 0.3259  Acc_3: 0.7860  F1_score_3: 0.8089  Loss: 0.6006 
2021-02-05 12:37:51:INFO:TRAIN-(misa) (1/4/1)>> loss: 1.3550  Has0_acc_2: 0.9540  Has0_F1_score: 0.9541  Non0_acc_2: 0.4370  Non0_F1_score: 0.4421  Acc_3: 0.9268  F1_score_3: 0.9461 
2021-02-05 12:37:52:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8190  Non0_acc_2: 0.3194  Non0_F1_score: 0.2991  Acc_3: 0.7904  F1_score_3: 0.8151  Loss: 0.6391 
2021-02-05 12:38:02:INFO:TRAIN-(misa) (2/5/1)>> loss: 0.9947  Has0_acc_2: 0.9766  Has0_F1_score: 0.9767  Non0_acc_2: 0.4460  Non0_F1_score: 0.4464  Acc_3: 0.9533  F1_score_3: 0.9733 
2021-02-05 12:38:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7958  Non0_acc_2: 0.3194  Non0_F1_score: 0.3123  Acc_3: 0.7598  F1_score_3: 0.7823  Loss: 0.7745 
2021-02-05 12:38:14:INFO:TRAIN-(misa) (3/6/1)>> loss: 0.7493  Has0_acc_2: 0.9829  Has0_F1_score: 0.9829  Non0_acc_2: 0.4476  Non0_F1_score: 0.4480  Acc_3: 0.9564  F1_score_3: 0.9765 
2021-02-05 12:38:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8269  Non0_acc_2: 0.3287  Non0_F1_score: 0.3138  Acc_3: 0.7948  F1_score_3: 0.8190  Loss: 0.8007 
2021-02-05 12:38:25:INFO:TRAIN-(misa) (4/7/1)>> loss: 0.6001  Has0_acc_2: 0.9805  Has0_F1_score: 0.9806  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9564  F1_score_3: 0.9754 
2021-02-05 12:38:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8163  Non0_acc_2: 0.3657  Non0_F1_score: 0.3881  Acc_3: 0.7773  F1_score_3: 0.7891  Loss: 0.8830 
2021-02-05 12:38:36:INFO:TRAIN-(misa) (5/8/1)>> loss: 0.4753  Has0_acc_2: 0.9891  Has0_F1_score: 0.9891  Non0_acc_2: 0.4484  Non0_F1_score: 0.4484  Acc_3: 0.9673  F1_score_3: 0.9777 
2021-02-05 12:38:37:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8171  Non0_acc_2: 0.3333  Non0_F1_score: 0.3297  Acc_3: 0.7773  F1_score_3: 0.7917  Loss: 1.0638 
2021-02-05 12:38:48:INFO:TRAIN-(misa) (6/9/1)>> loss: 0.4011  Has0_acc_2: 0.9766  Has0_F1_score: 0.9767  Non0_acc_2: 0.4476  Non0_F1_score: 0.4472  Acc_3: 0.9798  F1_score_3: 0.9826 
2021-02-05 12:38:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8344  Non0_acc_2: 0.3426  Non0_F1_score: 0.3407  Acc_3: 0.7773  F1_score_3: 0.7863  Loss: 1.1154 
2021-02-05 12:39:00:INFO:TRAIN-(misa) (7/10/1)>> loss: 0.3299  Has0_acc_2: 0.9868  Has0_F1_score: 0.9868  Non0_acc_2: 0.4452  Non0_F1_score: 0.4440  Acc_3: 0.9899  F1_score_3: 0.9900 
2021-02-05 12:39:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8301  Non0_acc_2: 0.3426  Non0_F1_score: 0.3407  Acc_3: 0.7860  F1_score_3: 0.7979  Loss: 1.0773 
2021-02-05 12:39:11:INFO:TRAIN-(misa) (8/11/1)>> loss: 0.3045  Has0_acc_2: 0.9673  Has0_F1_score: 0.9674  Non0_acc_2: 0.4460  Non0_F1_score: 0.4468  Acc_3: 0.9907  F1_score_3: 0.9907 
2021-02-05 12:39:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.6463  Has0_F1_score: 0.6657  Non0_acc_2: 0.3981  Non0_F1_score: 0.5033  Acc_3: 0.5939  F1_score_3: 0.6197  Loss: 1.9612 
2021-02-05 12:39:14:INFO:TEST-(misa) >>  Has0_acc_2: 0.8120  Has0_F1_score: 0.8106  Non0_acc_2: 0.4756  Non0_F1_score: 0.4634  Acc_3: 0.7886  F1_score_3: 0.8056  Loss: 0.5794 
2021-02-05 12:39:19:INFO:Start running misa...
2021-02-05 12:39:19:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [0], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1112}>
2021-02-05 12:39:19:INFO:Let's use 1 GPUs!
2021-02-05 12:39:20:INFO:train samples: (1284,)
2021-02-05 12:39:20:INFO:valid samples: (229,)
2021-02-05 12:39:21:INFO:test samples: (686,)
2021-02-05 12:39:21:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-05 12:39:21:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-05 12:39:21:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-05 12:39:21:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-05 12:39:21:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-05 12:39:21:INFO:loading file None
2021-02-05 12:39:21:INFO:loading file None
2021-02-05 12:39:21:INFO:loading file None
2021-02-05 12:39:21:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-05 12:39:21:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-05 12:39:21:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-05 12:39:24:INFO:The model has 110621043 trainable parameters
2021-02-05 12:39:35:INFO:TRAIN-(misa) (1/1/2)>> loss: 2.8770  Has0_acc_2: 0.5382  Has0_F1_score: 0.5814  Non0_acc_2: 0.1056  Non0_F1_score: 0.0673  Acc_3: 0.5156  F1_score_3: 0.5579 
2021-02-05 12:39:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.5895  Has0_F1_score: 0.6700  Non0_acc_2: 0.0787  Non0_F1_score: 0.0315  Acc_3: 0.5895  F1_score_3: 0.6730  Loss: 0.8672 
2021-02-05 12:39:48:INFO:TRAIN-(misa) (1/2/2)>> loss: 2.3960  Has0_acc_2: 0.5421  Has0_F1_score: 0.5945  Non0_acc_2: 0.0959  Non0_F1_score: 0.0557  Acc_3: 0.5366  F1_score_3: 0.5949 
2021-02-05 12:39:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.6245  Has0_F1_score: 0.6286  Non0_acc_2: 0.2361  Non0_F1_score: 0.2282  Acc_3: 0.6114  F1_score_3: 0.6312  Loss: 0.8645 
2021-02-05 12:40:01:INFO:TRAIN-(misa) (1/3/2)>> loss: 2.0571  Has0_acc_2: 0.5810  Has0_F1_score: 0.5953  Non0_acc_2: 0.1755  Non0_F1_score: 0.1444  Acc_3: 0.5646  F1_score_3: 0.5897 
2021-02-05 12:40:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.5546  Has0_F1_score: 0.6800  Non0_acc_2: 0.0278  Non0_F1_score: 0.0050  Acc_3: 0.5546  F1_score_3: 0.6805  Loss: 0.8591 
2021-02-05 12:40:14:INFO:TRAIN-(misa) (1/4/2)>> loss: 1.8015  Has0_acc_2: 0.5755  Has0_F1_score: 0.6061  Non0_acc_2: 0.1389  Non0_F1_score: 0.0970  Acc_3: 0.5646  F1_score_3: 0.6043 
2021-02-05 12:40:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5459  Has0_F1_score: 0.6941  Non0_acc_2: 0.0093  Non0_F1_score: 0.0006  Acc_3: 0.5459  F1_score_3: 0.6942  Loss: 0.8423 
2021-02-05 12:40:27:INFO:TRAIN-(misa) (1/5/2)>> loss: 1.5803  Has0_acc_2: 0.5693  Has0_F1_score: 0.6046  Non0_acc_2: 0.1308  Non0_F1_score: 0.0880  Acc_3: 0.5615  F1_score_3: 0.6046 
2021-02-05 12:40:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.5677  Has0_F1_score: 0.5738  Non0_acc_2: 0.1991  Non0_F1_score: 0.1888  Acc_3: 0.5546  F1_score_3: 0.5744  Loss: 0.8666 
2021-02-05 12:40:39:INFO:TRAIN-(misa) (2/6/2)>> loss: 1.3797  Has0_acc_2: 0.5662  Has0_F1_score: 0.5888  Non0_acc_2: 0.1568  Non0_F1_score: 0.1210  Acc_3: 0.5592  F1_score_3: 0.5901 
2021-02-05 12:40:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5721  Has0_F1_score: 0.6606  Non0_acc_2: 0.0648  Non0_F1_score: 0.0241  Acc_3: 0.5721  F1_score_3: 0.6629  Loss: 0.8442 
2021-02-05 12:40:50:INFO:TRAIN-(misa) (3/7/2)>> loss: 1.2442  Has0_acc_2: 0.5693  Has0_F1_score: 0.5924  Non0_acc_2: 0.1560  Non0_F1_score: 0.1193  Acc_3: 0.5615  F1_score_3: 0.5931 
2021-02-05 12:40:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5764  Has0_F1_score: 0.5910  Non0_acc_2: 0.1759  Non0_F1_score: 0.1520  Acc_3: 0.5677  F1_score_3: 0.5946  Loss: 0.8442 
2021-02-05 12:41:02:INFO:TRAIN-(misa) (4/8/2)>> loss: 1.1762  Has0_acc_2: 0.5755  Has0_F1_score: 0.5948  Non0_acc_2: 0.1690  Non0_F1_score: 0.1345  Acc_3: 0.5685  F1_score_3: 0.5965 
2021-02-05 12:41:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5066  Has0_F1_score: 0.5458  Non0_acc_2: 0.3472  Non0_F1_score: 0.4487  Acc_3: 0.4629  F1_score_3: 0.5107  Loss: 0.8764 
2021-02-05 12:41:14:INFO:TRAIN-(misa) (5/9/2)>> loss: 1.0987  Has0_acc_2: 0.5911  Has0_F1_score: 0.6019  Non0_acc_2: 0.1925  Non0_F1_score: 0.1650  Acc_3: 0.5755  F1_score_3: 0.5972 
2021-02-05 12:41:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5502  Has0_F1_score: 0.6676  Non0_acc_2: 0.0324  Non0_F1_score: 0.0075  Acc_3: 0.5502  F1_score_3: 0.6684  Loss: 0.8492 
2021-02-05 12:41:26:INFO:TRAIN-(misa) (6/10/2)>> loss: 1.0662  Has0_acc_2: 0.5989  Has0_F1_score: 0.6084  Non0_acc_2: 0.2047  Non0_F1_score: 0.1790  Acc_3: 0.5872  F1_score_3: 0.6074 
2021-02-05 12:41:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.5590  Has0_F1_score: 0.6927  Non0_acc_2: 0.0231  Non0_F1_score: 0.0028  Acc_3: 0.5590  F1_score_3: 0.6930  Loss: 0.8683 
2021-02-05 12:41:37:INFO:TRAIN-(misa) (7/11/2)>> loss: 1.0258  Has0_acc_2: 0.5950  Has0_F1_score: 0.6182  Non0_acc_2: 0.1641  Non0_F1_score: 0.1230  Acc_3: 0.5857  F1_score_3: 0.6182 
2021-02-05 12:41:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.5939  Has0_F1_score: 0.6458  Non0_acc_2: 0.1157  Non0_F1_score: 0.0677  Acc_3: 0.5939  F1_score_3: 0.6516  Loss: 0.8418 
2021-02-05 12:41:50:INFO:TRAIN-(misa) (1/12/2)>> loss: 1.0179  Has0_acc_2: 0.6028  Has0_F1_score: 0.6182  Non0_acc_2: 0.1909  Non0_F1_score: 0.1566  Acc_3: 0.5958  F1_score_3: 0.6207 
2021-02-05 12:41:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.5983  Has0_F1_score: 0.6545  Non0_acc_2: 0.1111  Non0_F1_score: 0.0612  Acc_3: 0.5983  F1_score_3: 0.6598  Loss: 0.8542 
2021-02-05 12:42:02:INFO:TRAIN-(misa) (2/13/2)>> loss: 1.0150  Has0_acc_2: 0.6067  Has0_F1_score: 0.6239  Non0_acc_2: 0.1828  Non0_F1_score: 0.1453  Acc_3: 0.5958  F1_score_3: 0.6232 
2021-02-05 12:42:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6243  Non0_acc_2: 0.1806  Non0_F1_score: 0.1495  Acc_3: 0.5983  F1_score_3: 0.6283  Loss: 0.8362 
2021-02-05 12:42:15:INFO:TRAIN-(misa) (1/14/2)>> loss: 0.9856  Has0_acc_2: 0.6207  Has0_F1_score: 0.6358  Non0_acc_2: 0.1966  Non0_F1_score: 0.1598  Acc_3: 0.6114  F1_score_3: 0.6368 
2021-02-05 12:42:16:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.6234  Non0_acc_2: 0.1991  Non0_F1_score: 0.1748  Acc_3: 0.6026  F1_score_3: 0.6284  Loss: 0.8404 
2021-02-05 12:42:27:INFO:TRAIN-(misa) (2/15/2)>> loss: 0.9668  Has0_acc_2: 0.6044  Has0_F1_score: 0.6261  Non0_acc_2: 0.1714  Non0_F1_score: 0.1300  Acc_3: 0.5950  F1_score_3: 0.6263 
2021-02-05 12:42:27:INFO:VAL-(misa) >>  Has0_acc_2: 0.5066  Has0_F1_score: 0.5275  Non0_acc_2: 0.3102  Non0_F1_score: 0.3865  Acc_3: 0.4629  F1_score_3: 0.4927  Loss: 0.8547 
2021-02-05 12:42:38:INFO:TRAIN-(misa) (3/16/2)>> loss: 0.9940  Has0_acc_2: 0.5763  Has0_F1_score: 0.5859  Non0_acc_2: 0.1982  Non0_F1_score: 0.1754  Acc_3: 0.5678  F1_score_3: 0.5871 
2021-02-05 12:42:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.5852  Has0_F1_score: 0.6415  Non0_acc_2: 0.1065  Non0_F1_score: 0.0599  Acc_3: 0.5852  F1_score_3: 0.6467  Loss: 0.8271 
2021-02-05 12:42:51:INFO:TRAIN-(misa) (1/17/2)>> loss: 0.9360  Has0_acc_2: 0.6192  Has0_F1_score: 0.6348  Non0_acc_2: 0.1933  Non0_F1_score: 0.1559  Acc_3: 0.6090  F1_score_3: 0.6351 
2021-02-05 12:42:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.6070  Has0_F1_score: 0.6314  Non0_acc_2: 0.1667  Non0_F1_score: 0.1289  Acc_3: 0.6026  F1_score_3: 0.6380  Loss: 0.8425 
2021-02-05 12:43:02:INFO:TRAIN-(misa) (2/18/2)>> loss: 0.9572  Has0_acc_2: 0.6215  Has0_F1_score: 0.6324  Non0_acc_2: 0.2080  Non0_F1_score: 0.1770  Acc_3: 0.6090  F1_score_3: 0.6311 
2021-02-05 12:43:03:INFO:VAL-(misa) >>  Has0_acc_2: 0.5633  Has0_F1_score: 0.6745  Non0_acc_2: 0.0417  Non0_F1_score: 0.0103  Acc_3: 0.5633  F1_score_3: 0.6755  Loss: 0.8403 
2021-02-05 12:43:14:INFO:TRAIN-(misa) (3/19/2)>> loss: 0.9291  Has0_acc_2: 0.6192  Has0_F1_score: 0.6343  Non0_acc_2: 0.1966  Non0_F1_score: 0.1601  Acc_3: 0.6106  F1_score_3: 0.6359 
2021-02-05 12:43:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.5939  Has0_F1_score: 0.6458  Non0_acc_2: 0.1157  Non0_F1_score: 0.0677  Acc_3: 0.5939  F1_score_3: 0.6516  Loss: 0.8382 
2021-02-05 12:43:25:INFO:TRAIN-(misa) (4/20/2)>> loss: 0.9100  Has0_acc_2: 0.6340  Has0_F1_score: 0.6452  Non0_acc_2: 0.2185  Non0_F1_score: 0.1865  Acc_3: 0.6277  F1_score_3: 0.6494 
2021-02-05 12:43:26:INFO:VAL-(misa) >>  Has0_acc_2: 0.6550  Has0_F1_score: 0.6682  Non0_acc_2: 0.2083  Non0_F1_score: 0.1756  Acc_3: 0.6419  F1_score_3: 0.6703  Loss: 0.8185 
2021-02-05 12:43:37:INFO:TRAIN-(misa) (1/21/2)>> loss: 0.8998  Has0_acc_2: 0.6324  Has0_F1_score: 0.6434  Non0_acc_2: 0.2120  Non0_F1_score: 0.1795  Acc_3: 0.6199  F1_score_3: 0.6423 
2021-02-05 12:43:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.6332  Has0_F1_score: 0.6639  Non0_acc_2: 0.1667  Non0_F1_score: 0.1189  Acc_3: 0.6332  F1_score_3: 0.6732  Loss: 0.8020 
2021-02-05 12:43:50:INFO:TRAIN-(misa) (1/22/2)>> loss: 0.8895  Has0_acc_2: 0.6737  Has0_F1_score: 0.6790  Non0_acc_2: 0.2608  Non0_F1_score: 0.2387  Acc_3: 0.6659  F1_score_3: 0.6835 
2021-02-05 12:43:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.6638  Has0_F1_score: 0.6822  Non0_acc_2: 0.1944  Non0_F1_score: 0.1519  Acc_3: 0.6507  F1_score_3: 0.6840  Loss: 0.8048 
2021-02-05 12:44:01:INFO:TRAIN-(misa) (2/23/2)>> loss: 0.8428  Has0_acc_2: 0.6900  Has0_F1_score: 0.6973  Non0_acc_2: 0.2559  Non0_F1_score: 0.2253  Acc_3: 0.6815  F1_score_3: 0.7011 
2021-02-05 12:44:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.6900  Has0_F1_score: 0.7116  Non0_acc_2: 0.1991  Non0_F1_score: 0.1473  Acc_3: 0.6812  F1_score_3: 0.7170  Loss: 0.7497 
2021-02-05 12:44:14:INFO:TRAIN-(misa) (1/24/2)>> loss: 0.7051  Has0_acc_2: 0.8154  Has0_F1_score: 0.8159  Non0_acc_2: 0.3574  Non0_F1_score: 0.3532  Acc_3: 0.7944  F1_score_3: 0.8113 
2021-02-05 12:44:15:INFO:VAL-(misa) >>  Has0_acc_2: 0.7555  Has0_F1_score: 0.7683  Non0_acc_2: 0.2407  Non0_F1_score: 0.1881  Acc_3: 0.7380  F1_score_3: 0.7695  Loss: 0.6940 
2021-02-05 12:44:27:INFO:TRAIN-(misa) (1/25/2)>> loss: 0.4616  Has0_acc_2: 0.9268  Has0_F1_score: 0.9270  Non0_acc_2: 0.4184  Non0_F1_score: 0.4134  Acc_3: 0.9112  F1_score_3: 0.9305 
2021-02-05 12:44:28:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8087  Non0_acc_2: 0.3241  Non0_F1_score: 0.3169  Acc_3: 0.7686  F1_score_3: 0.7911  Loss: 0.6955 
2021-02-05 12:44:38:INFO:TRAIN-(misa) (2/26/2)>> loss: 0.3906  Has0_acc_2: 0.9431  Has0_F1_score: 0.9432  Non0_acc_2: 0.4305  Non0_F1_score: 0.4313  Acc_3: 0.9229  F1_score_3: 0.9423 
2021-02-05 12:44:39:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7977  Non0_acc_2: 0.3056  Non0_F1_score: 0.2842  Acc_3: 0.7686  F1_score_3: 0.7930  Loss: 0.9812 
2021-02-05 12:44:50:INFO:TRAIN-(misa) (3/27/2)>> loss: 0.3516  Has0_acc_2: 0.9611  Has0_F1_score: 0.9611  Non0_acc_2: 0.4387  Non0_F1_score: 0.4395  Acc_3: 0.9385  F1_score_3: 0.9582 
2021-02-05 12:44:51:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8182  Non0_acc_2: 0.3241  Non0_F1_score: 0.3093  Acc_3: 0.7860  F1_score_3: 0.8100  Loss: 0.9310 
2021-02-05 12:45:02:INFO:TRAIN-(misa) (4/28/2)>> loss: 0.2927  Has0_acc_2: 0.9696  Has0_F1_score: 0.9697  Non0_acc_2: 0.4403  Non0_F1_score: 0.4379  Acc_3: 0.9486  F1_score_3: 0.9675 
2021-02-05 12:45:02:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7871  Non0_acc_2: 0.3194  Non0_F1_score: 0.3141  Acc_3: 0.7555  F1_score_3: 0.7778  Loss: 1.1296 
2021-02-05 12:45:13:INFO:TRAIN-(misa) (5/29/2)>> loss: 0.2527  Has0_acc_2: 0.9790  Has0_F1_score: 0.9790  Non0_acc_2: 0.4468  Non0_F1_score: 0.4472  Acc_3: 0.9548  F1_score_3: 0.9749 
2021-02-05 12:45:14:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7726  Non0_acc_2: 0.3472  Non0_F1_score: 0.3734  Acc_3: 0.7293  F1_score_3: 0.7480  Loss: 1.1215 
2021-02-05 12:45:24:INFO:TRAIN-(misa) (6/30/2)>> loss: 0.2502  Has0_acc_2: 0.9844  Has0_F1_score: 0.9844  Non0_acc_2: 0.4460  Non0_F1_score: 0.4456  Acc_3: 0.9556  F1_score_3: 0.9731 
2021-02-05 12:45:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7955  Non0_acc_2: 0.3241  Non0_F1_score: 0.3205  Acc_3: 0.7642  F1_score_3: 0.7808  Loss: 1.2070 
2021-02-05 12:45:36:INFO:TRAIN-(misa) (7/31/2)>> loss: 0.2148  Has0_acc_2: 0.9782  Has0_F1_score: 0.9782  Non0_acc_2: 0.4484  Non0_F1_score: 0.4492  Acc_3: 0.9696  F1_score_3: 0.9770 
2021-02-05 12:45:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7764  Non0_acc_2: 0.2870  Non0_F1_score: 0.2634  Acc_3: 0.7336  F1_score_3: 0.7532  Loss: 1.2412 
2021-02-05 12:45:47:INFO:TRAIN-(misa) (8/32/2)>> loss: 0.1887  Has0_acc_2: 0.9805  Has0_F1_score: 0.9806  Non0_acc_2: 0.4484  Non0_F1_score: 0.4484  Acc_3: 0.9696  F1_score_3: 0.9782 
2021-02-05 12:45:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8039  Non0_acc_2: 0.3380  Non0_F1_score: 0.3398  Acc_3: 0.7686  F1_score_3: 0.7684  Loss: 1.1751 
2021-02-05 12:45:50:INFO:TEST-(misa) >>  Has0_acc_2: 0.7070  Has0_F1_score: 0.7106  Non0_acc_2: 0.3323  Non0_F1_score: 0.2544  Acc_3: 0.6968  F1_score_3: 0.7145  Loss: 0.7336 
2021-02-05 12:45:55:INFO:Start running misa...
2021-02-05 12:45:55:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [0], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1113}>
2021-02-05 12:45:55:INFO:Let's use 1 GPUs!
2021-02-05 12:45:56:INFO:train samples: (1284,)
2021-02-05 12:45:56:INFO:valid samples: (229,)
2021-02-05 12:45:56:INFO:test samples: (686,)
2021-02-05 12:45:56:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-05 12:45:56:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-05 12:45:56:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-05 12:45:56:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-05 12:45:56:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-05 12:45:56:INFO:loading file None
2021-02-05 12:45:56:INFO:loading file None
2021-02-05 12:45:56:INFO:loading file None
2021-02-05 12:45:56:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-05 12:45:56:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-05 12:45:56:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-05 12:45:59:INFO:The model has 110621043 trainable parameters
2021-02-05 12:46:10:INFO:TRAIN-(misa) (1/1/3)>> loss: 2.9699  Has0_acc_2: 0.5748  Has0_F1_score: 0.6208  Non0_acc_2: 0.1089  Non0_F1_score: 0.0632  Acc_3: 0.5607  F1_score_3: 0.6142 
2021-02-05 12:46:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.5328  Has0_F1_score: 0.6816  Non0_acc_2: 0.0046  Non0_F1_score: 0.0004  Acc_3: 0.5328  F1_score_3: 0.6817  Loss: 0.8696 
2021-02-05 12:46:23:INFO:TRAIN-(misa) (1/2/3)>> loss: 2.4050  Has0_acc_2: 0.6822  Has0_F1_score: 0.7065  Non0_acc_2: 0.1917  Non0_F1_score: 0.1315  Acc_3: 0.6721  F1_score_3: 0.7074 
2021-02-05 12:46:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8209  Non0_acc_2: 0.3565  Non0_F1_score: 0.3677  Acc_3: 0.7860  F1_score_3: 0.8080  Loss: 0.7180 
2021-02-05 12:46:36:INFO:TRAIN-(misa) (1/3/3)>> loss: 1.8935  Has0_acc_2: 0.8762  Has0_F1_score: 0.8764  Non0_acc_2: 0.3883  Non0_F1_score: 0.3844  Acc_3: 0.8520  F1_score_3: 0.8700 
2021-02-05 12:46:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7913  Non0_acc_2: 0.2963  Non0_F1_score: 0.2661  Acc_3: 0.7729  F1_score_3: 0.7984  Loss: 0.6164 
2021-02-05 12:46:48:INFO:TRAIN-(misa) (1/4/3)>> loss: 1.4027  Has0_acc_2: 0.9486  Has0_F1_score: 0.9487  Non0_acc_2: 0.4330  Non0_F1_score: 0.4334  Acc_3: 0.9283  F1_score_3: 0.9479 
2021-02-05 12:46:49:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7800  Non0_acc_2: 0.3102  Non0_F1_score: 0.2961  Acc_3: 0.7598  F1_score_3: 0.7833  Loss: 0.6934 
2021-02-05 12:47:00:INFO:TRAIN-(misa) (2/5/3)>> loss: 1.0520  Has0_acc_2: 0.9720  Has0_F1_score: 0.9720  Non0_acc_2: 0.4411  Non0_F1_score: 0.4383  Acc_3: 0.9502  F1_score_3: 0.9702 
2021-02-05 12:47:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8075  Non0_acc_2: 0.3611  Non0_F1_score: 0.3849  Acc_3: 0.7642  F1_score_3: 0.7842  Loss: 0.7528 
2021-02-05 12:47:11:INFO:TRAIN-(misa) (3/6/3)>> loss: 0.8317  Has0_acc_2: 0.9720  Has0_F1_score: 0.9720  Non0_acc_2: 0.4435  Non0_F1_score: 0.4435  Acc_3: 0.9494  F1_score_3: 0.9694 
2021-02-05 12:47:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8164  Non0_acc_2: 0.3611  Non0_F1_score: 0.3780  Acc_3: 0.7817  F1_score_3: 0.8032  Loss: 0.7344 
2021-02-05 12:47:23:INFO:TRAIN-(misa) (4/7/3)>> loss: 0.6571  Has0_acc_2: 0.9782  Has0_F1_score: 0.9782  Non0_acc_2: 0.4484  Non0_F1_score: 0.4496  Acc_3: 0.9572  F1_score_3: 0.9762 
2021-02-05 12:47:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.7955  Non0_acc_2: 0.3380  Non0_F1_score: 0.3398  Acc_3: 0.7729  F1_score_3: 0.7955  Loss: 0.8820 
2021-02-05 12:47:35:INFO:TRAIN-(misa) (5/8/3)>> loss: 0.5442  Has0_acc_2: 0.9766  Has0_F1_score: 0.9767  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9681  F1_score_3: 0.9755 
2021-02-05 12:47:35:INFO:VAL-(misa) >>  Has0_acc_2: 0.7991  Has0_F1_score: 0.8032  Non0_acc_2: 0.3009  Non0_F1_score: 0.2723  Acc_3: 0.7773  F1_score_3: 0.7958  Loss: 1.1395 
2021-02-05 12:47:46:INFO:TRAIN-(misa) (6/9/3)>> loss: 0.4936  Has0_acc_2: 0.9743  Has0_F1_score: 0.9743  Non0_acc_2: 0.4435  Non0_F1_score: 0.4427  Acc_3: 0.9774  F1_score_3: 0.9789 
2021-02-05 12:47:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8032  Non0_acc_2: 0.3611  Non0_F1_score: 0.3832  Acc_3: 0.7598  F1_score_3: 0.7681  Loss: 1.1410 
2021-02-05 12:47:58:INFO:TRAIN-(misa) (7/10/3)>> loss: 0.3893  Has0_acc_2: 0.9727  Has0_F1_score: 0.9728  Non0_acc_2: 0.4476  Non0_F1_score: 0.4488  Acc_3: 0.9922  F1_score_3: 0.9923 
2021-02-05 12:47:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8079  Non0_acc_2: 0.3796  Non0_F1_score: 0.4202  Acc_3: 0.7642  F1_score_3: 0.7764  Loss: 1.2624 
2021-02-05 12:48:10:INFO:TRAIN-(misa) (8/11/3)>> loss: 0.3309  Has0_acc_2: 0.9836  Has0_F1_score: 0.9837  Non0_acc_2: 0.4484  Non0_F1_score: 0.4496  Acc_3: 0.9977  F1_score_3: 0.9977 
2021-02-05 12:48:11:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8096  Non0_acc_2: 0.3287  Non0_F1_score: 0.3176  Acc_3: 0.7860  F1_score_3: 0.8029  Loss: 1.0875 
2021-02-05 12:48:13:INFO:TEST-(misa) >>  Has0_acc_2: 0.7711  Has0_F1_score: 0.7698  Non0_acc_2: 0.4040  Non0_F1_score: 0.3502  Acc_3: 0.7536  F1_score_3: 0.7694  Loss: 0.6133 
2021-02-05 12:48:18:INFO:Start running misa...
2021-02-05 12:48:18:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [0], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1114}>
2021-02-05 12:48:18:INFO:Let's use 1 GPUs!
2021-02-05 12:48:18:INFO:train samples: (1284,)
2021-02-05 12:48:19:INFO:valid samples: (229,)
2021-02-05 12:48:19:INFO:test samples: (686,)
2021-02-05 12:48:19:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-05 12:48:19:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-05 12:48:19:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-05 12:48:19:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-05 12:48:19:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-05 12:48:19:INFO:loading file None
2021-02-05 12:48:19:INFO:loading file None
2021-02-05 12:48:19:INFO:loading file None
2021-02-05 12:48:19:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-05 12:48:19:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-05 12:48:19:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-05 12:48:22:INFO:The model has 110621043 trainable parameters
2021-02-05 12:48:32:INFO:TRAIN-(misa) (1/1/4)>> loss: 3.1450  Has0_acc_2: 0.5350  Has0_F1_score: 0.5571  Non0_acc_2: 0.1373  Non0_F1_score: 0.1064  Acc_3: 0.5195  F1_score_3: 0.5506 
2021-02-05 12:48:33:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.6778  Non0_acc_2: 0.0972  Non0_F1_score: 0.0441  Acc_3: 0.6070  F1_score_3: 0.6802  Loss: 0.8618 
2021-02-05 12:48:45:INFO:TRAIN-(misa) (1/2/4)>> loss: 2.5879  Has0_acc_2: 0.6036  Has0_F1_score: 0.6453  Non0_acc_2: 0.1324  Non0_F1_score: 0.0800  Acc_3: 0.5966  F1_score_3: 0.6461 
2021-02-05 12:48:46:INFO:VAL-(misa) >>  Has0_acc_2: 0.7205  Has0_F1_score: 0.7297  Non0_acc_2: 0.2500  Non0_F1_score: 0.2160  Acc_3: 0.7074  F1_score_3: 0.7342  Loss: 0.7760 
2021-02-05 12:48:58:INFO:TRAIN-(misa) (1/3/4)>> loss: 2.1561  Has0_acc_2: 0.7936  Has0_F1_score: 0.7957  Non0_acc_2: 0.3266  Non0_F1_score: 0.3058  Acc_3: 0.7765  F1_score_3: 0.7944 
2021-02-05 12:48:59:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7804  Non0_acc_2: 0.3009  Non0_F1_score: 0.2818  Acc_3: 0.7555  F1_score_3: 0.7795  Loss: 0.6937 
2021-02-05 12:49:11:INFO:TRAIN-(misa) (1/4/4)>> loss: 1.6763  Has0_acc_2: 0.8956  Has0_F1_score: 0.8962  Non0_acc_2: 0.3916  Non0_F1_score: 0.3795  Acc_3: 0.8754  F1_score_3: 0.8942 
2021-02-05 12:49:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.7555  Has0_F1_score: 0.7578  Non0_acc_2: 0.3935  Non0_F1_score: 0.4609  Acc_3: 0.7162  F1_score_3: 0.7369  Loss: 0.6838 
2021-02-05 12:49:24:INFO:TRAIN-(misa) (1/5/4)>> loss: 1.2773  Has0_acc_2: 0.9369  Has0_F1_score: 0.9370  Non0_acc_2: 0.4273  Non0_F1_score: 0.4292  Acc_3: 0.9143  F1_score_3: 0.9335 
2021-02-05 12:49:25:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8171  Non0_acc_2: 0.3426  Non0_F1_score: 0.3426  Acc_3: 0.7860  F1_score_3: 0.8088  Loss: 0.6250 
2021-02-05 12:49:37:INFO:TRAIN-(misa) (1/6/4)>> loss: 0.9825  Has0_acc_2: 0.9712  Has0_F1_score: 0.9712  Non0_acc_2: 0.4427  Non0_F1_score: 0.4419  Acc_3: 0.9494  F1_score_3: 0.9694 
2021-02-05 12:49:38:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7916  Non0_acc_2: 0.3241  Non0_F1_score: 0.3187  Acc_3: 0.7642  F1_score_3: 0.7869  Loss: 0.7194 
2021-02-05 12:49:49:INFO:TRAIN-(misa) (2/7/4)>> loss: 0.7427  Has0_acc_2: 0.9821  Has0_F1_score: 0.9821  Non0_acc_2: 0.4476  Non0_F1_score: 0.4484  Acc_3: 0.9556  F1_score_3: 0.9757 
2021-02-05 12:49:50:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7789  Non0_acc_2: 0.2870  Non0_F1_score: 0.2559  Acc_3: 0.7598  F1_score_3: 0.7854  Loss: 0.8334 
2021-02-05 12:50:00:INFO:TRAIN-(misa) (3/8/4)>> loss: 0.6167  Has0_acc_2: 0.9759  Has0_F1_score: 0.9759  Non0_acc_2: 0.4476  Non0_F1_score: 0.4476  Acc_3: 0.9579  F1_score_3: 0.9770 
2021-02-05 12:50:01:INFO:VAL-(misa) >>  Has0_acc_2: 0.7860  Has0_F1_score: 0.7858  Non0_acc_2: 0.3704  Non0_F1_score: 0.4067  Acc_3: 0.7511  F1_score_3: 0.7685  Loss: 0.9283 
2021-02-05 12:50:12:INFO:TRAIN-(misa) (4/9/4)>> loss: 0.5094  Has0_acc_2: 0.9829  Has0_F1_score: 0.9829  Non0_acc_2: 0.4476  Non0_F1_score: 0.4472  Acc_3: 0.9611  F1_score_3: 0.9770 
2021-02-05 12:50:13:INFO:VAL-(misa) >>  Has0_acc_2: 0.7642  Has0_F1_score: 0.7649  Non0_acc_2: 0.3241  Non0_F1_score: 0.3276  Acc_3: 0.7293  F1_score_3: 0.7363  Loss: 1.0986 
2021-02-05 12:50:24:INFO:TRAIN-(misa) (5/10/4)>> loss: 0.4055  Has0_acc_2: 0.9790  Has0_F1_score: 0.9790  Non0_acc_2: 0.4484  Non0_F1_score: 0.4496  Acc_3: 0.9790  F1_score_3: 0.9810 
2021-02-05 12:50:24:INFO:VAL-(misa) >>  Has0_acc_2: 0.7729  Has0_F1_score: 0.7729  Non0_acc_2: 0.3333  Non0_F1_score: 0.3439  Acc_3: 0.7380  F1_score_3: 0.7540  Loss: 1.0451 
2021-02-05 12:50:35:INFO:TRAIN-(misa) (6/11/4)>> loss: 0.3473  Has0_acc_2: 0.9766  Has0_F1_score: 0.9767  Non0_acc_2: 0.4460  Non0_F1_score: 0.4456  Acc_3: 0.9899  F1_score_3: 0.9901 
2021-02-05 12:50:36:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7900  Non0_acc_2: 0.3565  Non0_F1_score: 0.3817  Acc_3: 0.7555  F1_score_3: 0.7693  Loss: 1.1307 
2021-02-05 12:50:47:INFO:TRAIN-(misa) (7/12/4)>> loss: 0.3407  Has0_acc_2: 0.9688  Has0_F1_score: 0.9689  Non0_acc_2: 0.4444  Non0_F1_score: 0.4452  Acc_3: 0.9891  F1_score_3: 0.9891 
2021-02-05 12:50:48:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8075  Non0_acc_2: 0.3750  Non0_F1_score: 0.4050  Acc_3: 0.7729  F1_score_3: 0.7928  Loss: 1.4439 
2021-02-05 12:50:59:INFO:TRAIN-(misa) (8/13/4)>> loss: 0.3251  Has0_acc_2: 0.9836  Has0_F1_score: 0.9837  Non0_acc_2: 0.4419  Non0_F1_score: 0.4415  Acc_3: 0.9844  F1_score_3: 0.9845 
2021-02-05 12:51:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.7773  Has0_F1_score: 0.7821  Non0_acc_2: 0.2917  Non0_F1_score: 0.2639  Acc_3: 0.7598  F1_score_3: 0.7755  Loss: 1.4382 
2021-02-05 12:51:02:INFO:TEST-(misa) >>  Has0_acc_2: 0.8134  Has0_F1_score: 0.8127  Non0_acc_2: 0.4939  Non0_F1_score: 0.4952  Acc_3: 0.7930  F1_score_3: 0.8107  Loss: 0.5857 
2021-02-05 12:51:07:INFO:Start running misa...
2021-02-05 12:51:07:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results/models', 'res_save_dir': 'results/results/normals', 'gpu_ids': [0], 'seeds': [1111, 1112, 1113, 1114, 1115], 'dataPath': '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/StandardDatasets/MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 50, 50), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'use_finetune': True, 'use_bert': True, 'early_stop': 8, 'update_epochs': 2, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 0.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 0.002, 'seed': 1115}>
2021-02-05 12:51:07:INFO:Let's use 1 GPUs!
2021-02-05 12:51:07:INFO:train samples: (1284,)
2021-02-05 12:51:07:INFO:valid samples: (229,)
2021-02-05 12:51:08:INFO:test samples: (686,)
2021-02-05 12:51:08:INFO:Model name 'pretrained_model/bert_en' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'pretrained_model/bert_en' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-02-05 12:51:08:INFO:Didn't find file pretrained_model/bert_en/added_tokens.json. We won't load it.
2021-02-05 12:51:08:INFO:Didn't find file pretrained_model/bert_en/special_tokens_map.json. We won't load it.
2021-02-05 12:51:08:INFO:Didn't find file pretrained_model/bert_en/tokenizer_config.json. We won't load it.
2021-02-05 12:51:08:INFO:loading file pretrained_model/bert_en/vocab.txt
2021-02-05 12:51:08:INFO:loading file None
2021-02-05 12:51:08:INFO:loading file None
2021-02-05 12:51:08:INFO:loading file None
2021-02-05 12:51:08:INFO:loading configuration file pretrained_model/bert_en/config.json
2021-02-05 12:51:08:INFO:Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-02-05 12:51:08:INFO:loading weights file pretrained_model/bert_en/pytorch_model.bin
2021-02-05 12:51:11:INFO:The model has 110621043 trainable parameters
2021-02-05 12:51:21:INFO:TRAIN-(misa) (1/1/5)>> loss: 2.9588  Has0_acc_2: 0.5319  Has0_F1_score: 0.5979  Non0_acc_2: 0.0747  Non0_F1_score: 0.0378  Acc_3: 0.5070  F1_score_3: 0.5710 
2021-02-05 12:51:22:INFO:VAL-(misa) >>  Has0_acc_2: 0.6114  Has0_F1_score: 0.6742  Non0_acc_2: 0.0972  Non0_F1_score: 0.0454  Acc_3: 0.6026  F1_score_3: 0.6747  Loss: 0.8728 
2021-02-05 12:51:34:INFO:TRAIN-(misa) (1/2/5)>> loss: 2.3726  Has0_acc_2: 0.6815  Has0_F1_score: 0.6945  Non0_acc_2: 0.2250  Non0_F1_score: 0.1812  Acc_3: 0.6706  F1_score_3: 0.6955 
2021-02-05 12:51:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.7904  Has0_F1_score: 0.7910  Non0_acc_2: 0.3287  Non0_F1_score: 0.3287  Acc_3: 0.7598  F1_score_3: 0.7818  Loss: 0.7264 
2021-02-05 12:51:46:INFO:TRAIN-(misa) (1/3/5)>> loss: 1.9231  Has0_acc_2: 0.8762  Has0_F1_score: 0.8763  Non0_acc_2: 0.3972  Non0_F1_score: 0.3997  Acc_3: 0.8551  F1_score_3: 0.8731 
2021-02-05 12:51:47:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8383  Non0_acc_2: 0.3611  Non0_F1_score: 0.3725  Acc_3: 0.7948  F1_score_3: 0.8164  Loss: 0.5808 
2021-02-05 12:52:00:INFO:TRAIN-(misa) (1/4/5)>> loss: 1.4030  Has0_acc_2: 0.9509  Has0_F1_score: 0.9510  Non0_acc_2: 0.4362  Non0_F1_score: 0.4398  Acc_3: 0.9283  F1_score_3: 0.9478 
2021-02-05 12:52:00:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8250  Non0_acc_2: 0.3750  Non0_F1_score: 0.4033  Acc_3: 0.7817  F1_score_3: 0.8022  Loss: 0.6146 
2021-02-05 12:52:11:INFO:TRAIN-(misa) (2/5/5)>> loss: 1.0900  Has0_acc_2: 0.9681  Has0_F1_score: 0.9681  Non0_acc_2: 0.4427  Non0_F1_score: 0.4427  Acc_3: 0.9478  F1_score_3: 0.9678 
2021-02-05 12:52:12:INFO:VAL-(misa) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8214  Non0_acc_2: 0.3380  Non0_F1_score: 0.3361  Acc_3: 0.7817  F1_score_3: 0.8041  Loss: 0.6682 
2021-02-05 12:52:23:INFO:TRAIN-(misa) (3/6/5)>> loss: 0.8482  Has0_acc_2: 0.9790  Has0_F1_score: 0.9790  Non0_acc_2: 0.4468  Non0_F1_score: 0.4464  Acc_3: 0.9564  F1_score_3: 0.9765 
2021-02-05 12:52:23:INFO:VAL-(misa) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8390  Non0_acc_2: 0.3426  Non0_F1_score: 0.3369  Acc_3: 0.7991  F1_score_3: 0.8224  Loss: 0.6701 
2021-02-05 12:52:33:INFO:TRAIN-(misa) (4/7/5)>> loss: 0.6728  Has0_acc_2: 0.9798  Has0_F1_score: 0.9798  Non0_acc_2: 0.4468  Non0_F1_score: 0.4468  Acc_3: 0.9572  F1_score_3: 0.9751 
2021-02-05 12:52:34:INFO:VAL-(misa) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8266  Non0_acc_2: 0.3333  Non0_F1_score: 0.3221  Acc_3: 0.7991  F1_score_3: 0.8175  Loss: 0.8013 
2021-02-05 12:52:45:INFO:TRAIN-(misa) (5/8/5)>> loss: 0.5845  Has0_acc_2: 0.9805  Has0_F1_score: 0.9806  Non0_acc_2: 0.4476  Non0_F1_score: 0.4476  Acc_3: 0.9642  F1_score_3: 0.9760 
2021-02-05 12:52:45:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8165  Non0_acc_2: 0.3796  Non0_F1_score: 0.4168  Acc_3: 0.7467  F1_score_3: 0.7556  Loss: 1.0982 
2021-02-05 12:52:56:INFO:TRAIN-(misa) (6/9/5)>> loss: 0.4974  Has0_acc_2: 0.9798  Has0_F1_score: 0.9798  Non0_acc_2: 0.4476  Non0_F1_score: 0.4480  Acc_3: 0.9735  F1_score_3: 0.9774 
2021-02-05 12:52:57:INFO:VAL-(misa) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8096  Non0_acc_2: 0.3148  Non0_F1_score: 0.2986  Acc_3: 0.7773  F1_score_3: 0.7921  Loss: 1.0962 
2021-02-05 12:53:08:INFO:TRAIN-(misa) (7/10/5)>> loss: 0.4840  Has0_acc_2: 0.9712  Has0_F1_score: 0.9712  Non0_acc_2: 0.4395  Non0_F1_score: 0.4391  Acc_3: 0.9634  F1_score_3: 0.9661 
2021-02-05 12:53:08:INFO:VAL-(misa) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8164  Non0_acc_2: 0.3796  Non0_F1_score: 0.4152  Acc_3: 0.7642  F1_score_3: 0.7744  Loss: 1.2746 
2021-02-05 12:53:19:INFO:TRAIN-(misa) (8/11/5)>> loss: 0.5292  Has0_acc_2: 0.9361  Has0_F1_score: 0.9363  Non0_acc_2: 0.4257  Non0_F1_score: 0.4241  Acc_3: 0.9540  F1_score_3: 0.9541 
2021-02-05 12:53:20:INFO:VAL-(misa) >>  Has0_acc_2: 0.8035  Has0_F1_score: 0.8032  Non0_acc_2: 0.3704  Non0_F1_score: 0.3983  Acc_3: 0.7729  F1_score_3: 0.7924  Loss: 1.3352 
2021-02-05 12:53:22:INFO:TEST-(misa) >>  Has0_acc_2: 0.8134  Has0_F1_score: 0.8140  Non0_acc_2: 0.5015  Non0_F1_score: 0.5138  Acc_3: 0.7828  F1_score_3: 0.8013  Loss: 0.5593 
2021-02-05 12:53:27:INFO:Results are added to results/results/normals/mosi-classification.csv...
